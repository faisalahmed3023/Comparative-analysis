{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d78nCXIKRBmz"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "class CustomLLM(LLM):\n",
        "    max_token: int\n",
        "    URL: str = \"http://xxxxx\"\n",
        "    headers: dict = {\"Content-Type\": \"application/json\"}\n",
        "    payload: dict = {\"prompt\": \"\", \"history\": []}\n",
        "    logger: Any\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"CustomLLM\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        history: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "    ) -> str:\n",
        "        self.payload[\"prompt\"] = prompt\n",
        "        response = requests.post(\n",
        "            self.URL, headers=self.headers, data=json.dumps(self.payload)\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result[\"response\"]\n",
        "        else:\n",
        "            self.logger.error(\"CustomLLM error occurred with status code:\", response.text)\n",
        "        return response.text\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"Get the identifying parameters.\"\"\"\n",
        "        return {\n",
        "            \"max_token\": self.max_token,\n",
        "            \"URL\": self.URL,\n",
        "            \"headers\": self.headers,\n",
        "            \"payload\": self.payload,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7By_2Z6oR1sd"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import base64\n",
        "# import json\n",
        "import logging\n",
        "from typing import Any, Dict, Optional, List, Tuple\n",
        "# import re\n",
        "# import itertools\n",
        "# import random\n",
        "from yacs.config import CfgNode\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import math\n",
        "# from langchain.llms import OpenAI\n",
        "\n",
        "# logger\n",
        "def set_logger(log_file, name=\"default\"):\n",
        "    \"\"\"\n",
        "    Set logger.\n",
        "    Args:\n",
        "        log_file (str): log file path\n",
        "        name (str): logger name\n",
        "    \"\"\"\n",
        "\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "        \"%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "    print(formatter.format(logging.LogRecord(\n",
        "    name='root',\n",
        "    level=logging.INFO,\n",
        "    pathname=None,\n",
        "    lineno=None,\n",
        "    msg='Test message',\n",
        "    args=None,\n",
        "    exc_info=None,\n",
        "    )))\n",
        "    output_folder = \"output\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Create the 'log' folder if it doesn't exist\n",
        "    log_folder = os.path.join(output_folder, \"log\")\n",
        "    if not os.path.exists(log_folder):\n",
        "        os.makedirs(log_folder)\n",
        "\n",
        "    # Create the 'message' folder if it doesn't exist\n",
        "    message_folder = os.path.join(output_folder, \"message\")\n",
        "    if not os.path.exists(message_folder):\n",
        "        os.makedirs(message_folder)\n",
        "    log_file = os.path.join(log_folder, log_file)\n",
        "    handler = logging.FileHandler(log_file, mode=\"w\")\n",
        "    handler.setLevel(logging.INFO)\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.handlers = []\n",
        "    logger.addHandler(handler)\n",
        "    print(logger)\n",
        "    return logger\n",
        "\n",
        "def load_cfg(cfg_file: str, new_allowed: bool = True) -> CfgNode:\n",
        "    \"\"\"\n",
        "    Load config from file.\n",
        "    Args:\n",
        "        cfg_file (str): config file path\n",
        "        new_allowed (bool): whether to allow new keys in config\n",
        "    \"\"\"\n",
        "    with open(cfg_file, \"r\") as fi:\n",
        "        cfg = CfgNode.load_cfg(fi)\n",
        "    cfg.set_new_allowed(new_allowed)\n",
        "    return cfg\n",
        "\n",
        "def add_variable_to_config(cfg: CfgNode, name: str, value: Any) -> CfgNode:\n",
        "    \"\"\"\n",
        "    Add variable to config.\n",
        "    Args:\n",
        "        cfg (CfgNode): config\n",
        "        name (str): variable name\n",
        "        value (Any): variable value\n",
        "    \"\"\"\n",
        "    cfg.defrost()\n",
        "    cfg[name] = value\n",
        "    cfg.freeze()\n",
        "    return cfg\n",
        "\n",
        "def get_llm(config, logger, api_key):\n",
        "    \"\"\"\n",
        "    Get the large language model.\n",
        "    Args:\n",
        "        config (CfgNode): The config.\n",
        "        logger (Logger): The logger.\n",
        "        api_key (str): The API key.\n",
        "    \"\"\"\n",
        "    if config[\"llm\"] == \"gpt-4\":\n",
        "        LLM = ChatOpenAI(\n",
        "            max_tokens=config[\"max_token\"],\n",
        "            temperature=config[\"temperature\"],\n",
        "            openai_api_key=api_key,\n",
        "            model=\"gpt-4\",\n",
        "            max_retries=config[\"max_retries\"]\n",
        "        )\n",
        "    elif config[\"llm\"] == \"gpt-3.5-16k\":\n",
        "        LLM = ChatOpenAI(\n",
        "            max_tokens=config[\"max_token\"],\n",
        "            temperature=config[\"temperature\"],\n",
        "            openai_api_key=api_key,\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            max_retries=config[\"max_retries\"]\n",
        "        )\n",
        "    elif config[\"llm\"] == \"gpt-3.5\":\n",
        "        LLM = ChatOpenAI(\n",
        "            max_tokens=config[\"max_token\"],\n",
        "            temperature=config[\"temperature\"],\n",
        "            openai_api_key=api_key,\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            max_retries=config[\"max_retries\"]\n",
        "        )\n",
        "    elif config[\"llm\"] == \"gpt-4o-mini\":\n",
        "        LLM = ChatOpenAI(\n",
        "            max_tokens=config[\"max_token\"],\n",
        "            temperature=config[\"temperature\"],\n",
        "            openai_api_key=api_key,\n",
        "            model=\"gpt-4o-mini\",\n",
        "            max_retries=config[\"max_retries\"]\n",
        "            )\n",
        "    elif config[\"llm\"] == \"gpt-4.1-mini\":\n",
        "        LLM = ChatOpenAI(\n",
        "            max_tokens=config[\"max_token\"],\n",
        "            temperature=config[\"temperature\"],\n",
        "            openai_api_key=api_key,\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            max_retries=config[\"max_retries\"]\n",
        "            )\n",
        "    elif config[\"llm\"] == \"custom\":\n",
        "        LLM = CustomLLM(max_token=2048, logger=logger,max_retries=config[\"max_retries\"])\n",
        "    elif config[\"llm\"] == \"new\":\n",
        "        LLM = OpenAI(model=\"davinci-002\")\n",
        "    return LLM\n",
        "\n",
        "def ensure_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Make sure the directory exists, if it does not exist, create it\n",
        "    Args:\n",
        "        dir_path (str): The directory path.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "\n",
        "def generate_id(dir_name):\n",
        "    ensure_dir(dir_name)\n",
        "    existed_id = set()\n",
        "    for f in os.listdir(dir_name):\n",
        "        existed_id.add(f.split(\"-\")[0])\n",
        "    id = random.randint(1, 999999999)\n",
        "    while id in existed_id:\n",
        "        id = random.randint(1, 999999999)\n",
        "    return id\n",
        "\n",
        "def get_feature_description(feature):\n",
        "    \"\"\"Get description of given features.\"\"\"\n",
        "    descriptions = {\n",
        "        \"Watcher\": \"Choose movies, enjoy watching, and provide feedback and ratings to the recommendation system.\",\n",
        "        \"Explorer\": \"Search for movies heard of before and expand movie experiences.\",\n",
        "        \"Critic\": \"Demanding high standards for movies and the recommendation system, may criticize both the recommendation system and the movies.\",\n",
        "        \"Chatter\": \"Engage in private conversations, trust friends' recommendations.\",\n",
        "        \"Poster\": \"Enjoy publicly posting on social media and sharing content and insights with more people.\"\n",
        "    }\n",
        "    features = feature.split(\";\")\n",
        "    descriptions_list = [descriptions[feature] for feature in features if feature in descriptions]\n",
        "    return \".\".join(descriptions_list)\n",
        "\n",
        "def extract_item_names(observation: str, action: str = \"RECOMMENDER\") -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract item names from observation\n",
        "    Args:\n",
        "        observation: observation from the environment\n",
        "        action: action type, RECOMMENDER or SOCIAL\n",
        "    \"\"\"\n",
        "    item_names = []\n",
        "    if observation.find(\"<\") != -1:\n",
        "        matches = re.findall(r\"<(.*?)>\", observation)\n",
        "        item_names = []\n",
        "        for match in matches:\n",
        "            item_names.append(match)\n",
        "    elif observation.find(\";\") != -1:\n",
        "        item_names = observation.split(\";\")\n",
        "        item_names = [item.strip(\" '\\\"\") for item in item_names]\n",
        "    elif action == \"RECOMMENDER\":\n",
        "        matches = re.findall(r'\"([^\"]+)\"', observation)\n",
        "        for match in matches:\n",
        "            item_names.append(match)\n",
        "    elif action == \"SOCIAL\":\n",
        "        matches = re.findall(r'[<\"]([^<>\"]+)[\">]', observation)\n",
        "        for match in matches:\n",
        "            item_names.append(match)\n",
        "    return item_names\n",
        "\n",
        "\n",
        "def count_files_in_directory(target_directory:str):\n",
        "    \"\"\"Count the number of files in the target directory\"\"\"\n",
        "    return len(os.listdir(target_directory))\n",
        "\n",
        "def get_avatar_url(id:int,gender:str,type:str=\"origin\",role=False):\n",
        "    if role:\n",
        "        target='/asset/img/avatar/role/'+gender+'/'\n",
        "        return target+str(id%10)+'.png'\n",
        "    target='/asset/img/avatar/'+type+\"/\"+gender+'/'\n",
        "    return target+str(id%10)+'.png'\n",
        "\n",
        "def is_chatting(agent, agent2):\n",
        "    \"\"\"Determine if agent1 and agent2 is chatting\"\"\"\n",
        "    name = agent.name\n",
        "    agent_name2 = agent2.name\n",
        "    return (\n",
        "        (agent2.event.target_agent)\n",
        "        and (agent.event.target_agent)\n",
        "        and (name in agent2.event.target_agent)\n",
        "        and (agent_name2 in agent.event.target_agent)\n",
        "    )\n",
        "\n",
        "def calculate_entropy(movie_types):\n",
        "    type_freq = {}\n",
        "    for movie_type in movie_types:\n",
        "        if movie_type in type_freq:\n",
        "            type_freq[movie_type] += 1\n",
        "        else:\n",
        "            type_freq[movie_type] = 1\n",
        "\n",
        "    total_movies = len(movie_types)\n",
        "\n",
        "    entropy = 0\n",
        "    for key in type_freq:\n",
        "        prob = type_freq[key] / total_movies\n",
        "        entropy -= prob * math.log2(prob)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def get_entropy(inters, data):\n",
        "    genres = data.get_genres_by_id(inters)\n",
        "    entropy = calculate_entropy(genres)\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsqesNSdMjQ0"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, List\n",
        "from pydantic import BaseModel\n",
        "class Event(BaseModel):\n",
        "    \"\"\"\n",
        "    Event class for each agent.\n",
        "    \"\"\"\n",
        "    start_time: datetime\n",
        "    # action start time\n",
        "    duration: int\n",
        "    # action duration. The default unit is hour.\n",
        "    target_agent: Optional[List[str]]\n",
        "    # target agent for chatting.\n",
        "    action_type: str\n",
        "    # ('watching','chatting','posting' or 'idle').\n",
        "    end_time: Optional[datetime]=None\n",
        "    # action end time\n",
        "\n",
        "    \"\"\"Event for each agent\"\"\"\n",
        "    def __init__(self, **data):\n",
        "        super().__init__(**data)\n",
        "        self.end_time = self.start_time + timedelta(hours=self.duration)\n",
        "\n",
        "\n",
        "def update_event(original_event, start_time, duration, target_agent, action_type):\n",
        "    if action_type == \"reading\" or action_type==\"posting\":\n",
        "        result = Event(start_time=start_time, duration=duration, target_agent=None, action_type=action_type)\n",
        "\n",
        "    if action_type == \"chatting\":\n",
        "        # If the agent is not chatting\n",
        "        if original_event.action_type == \"idle\" or original_event.action_type == \"posting\":\n",
        "            result = Event(start_time=start_time, duration=duration, target_agent=[target_agent], action_type=action_type)\n",
        "        # If the agent is chatting\n",
        "        else:\n",
        "            # maintain maximum chat time\n",
        "            end_time = start_time + timedelta(hours=duration)  # current chat end time\n",
        "            original_end_time = original_event.end_time\n",
        "            if end_time > original_end_time:\n",
        "                if target_agent in original_event.target_agent:\n",
        "                    new_target_agent = original_event.target_agent\n",
        "                else:\n",
        "                    new_target_agent = original_event.target_agent + [target_agent]\n",
        "                result = Event(start_time=start_time, duration=duration, target_agent=new_target_agent, action_type=action_type)\n",
        "            else:\n",
        "                result = original_event\n",
        "                if target_agent not in result.target_agent:\n",
        "                    result.target_agent.append(target_agent)\n",
        "    return result\n",
        "\n",
        "\n",
        "def reset_event(start_time):\n",
        "    return Event(start_time=start_time, duration=0, target_agent=None, action_type='idle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JArbnuS2-FL"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "class Message(BaseModel):\n",
        "    \"\"\"\n",
        "    Message class for communication between backend and frontend.\n",
        "    \"\"\"\n",
        "    content: str\n",
        "    agent_id: int\n",
        "    action: str\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, message_dict):\n",
        "        return cls(\n",
        "            message_dict[\"agent_id\"], message_dict[\"action\"], message_dict[\"content\"]\n",
        "        )\n",
        "\n",
        "class RecommenderStat(BaseModel):\n",
        "    tot_user_num: int\n",
        "    cur_user_num: int\n",
        "    tot_item_num: int\n",
        "    inter_num: int\n",
        "    rec_model: str\n",
        "    pop_items: list[str]\n",
        "\n",
        "class SocialStat(BaseModel):\n",
        "    tot_user_num: int\n",
        "    cur_user_num: int\n",
        "    tot_link_num: int\n",
        "    chat_num: int\n",
        "    cur_chat_num: int\n",
        "    post_num: int\n",
        "    pop_items: list[str]\n",
        "    network_density: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbwkmi_fBcwK"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "\n",
        "\n",
        "class Interval:\n",
        "    \"\"\"\n",
        "    Interval class for each round.\n",
        "    \"\"\"\n",
        "    def __init__(self, value, unit):\n",
        "        self.value = value\n",
        "        self.unit = unit\n",
        "\n",
        "\n",
        "def parse_interval(string):\n",
        "    value = int(string[:-1])\n",
        "    unit = string[-1]\n",
        "\n",
        "    if unit == \"s\":\n",
        "        return Interval(value, \"seconds\")\n",
        "    elif unit == \"m\":\n",
        "        return Interval(value, \"minutes\")\n",
        "    elif unit == \"h\":\n",
        "        return Interval(value, \"hours\")\n",
        "    elif unit == \"d\":\n",
        "        return Interval(value, \"days\")\n",
        "    elif unit == \"M\":\n",
        "        return Interval(value, \"months\")\n",
        "    elif unit == \"y\":\n",
        "        return Interval(value, \"years\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid unit: {}\".format(unit))\n",
        "\n",
        "\n",
        "def add_interval(date, interval):\n",
        "    if interval.unit == \"seconds\":\n",
        "        return date + timedelta(seconds=interval.value)\n",
        "    elif interval.unit == \"minutes\":\n",
        "        return date + timedelta(minutes=interval.value)\n",
        "    elif interval.unit == \"hours\":\n",
        "        return date + timedelta(hours=interval.value)\n",
        "    elif interval.unit == \"days\":\n",
        "        return date + timedelta(days=interval.value)\n",
        "    elif interval.unit == \"months\":\n",
        "        # Adding months to a date is a bit more complex\n",
        "        new_year = date.year + (date.month + interval.value - 1) // 12\n",
        "        new_month = (date.month + interval.value - 1) % 12 + 1\n",
        "        new_day = min(date.day, calendar.monthrange(new_year, new_month)[1])\n",
        "        return date.replace(year=new_year, month=new_month, day=new_day)\n",
        "    elif interval.unit == \"years\":\n",
        "        # Adding years to a date is similar to adding months\n",
        "        new_year = date.year + interval.value\n",
        "        new_month = date.month\n",
        "        new_day = min(date.day, calendar.monthrange(new_year, new_month)[1])\n",
        "        return date.replace(year=new_year, month=new_month, day=new_day)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid interval unit: {}\".format(interval.unit))\n",
        "\n",
        "\n",
        "def format_time(date):\n",
        "    return date.strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "\n",
        "\n",
        "def get_weekday(date):\n",
        "    return date.strftime(\"%A\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoAftfp9ViEA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Data:\n",
        "    \"\"\"\n",
        "    Data class for loading data from local files.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.items = {}\n",
        "        self.users = {}\n",
        "        self.db = None\n",
        "        self.tot_relationship_num = 0\n",
        "        self.netwerk_density = 0.0\n",
        "        self.role_id = -1\n",
        "        self.interrating = {}\n",
        "        self.user_ratings = {}\n",
        "        self.item_ratings = {}\n",
        "        self.load_items(config[\"item_path\"])\n",
        "        self.load_users(config[\"user_path\"])\n",
        "        self.load_relationship(config[\"relationship_path\"])\n",
        "        self.load_faiss_db(config[\"index_name\"])\n",
        "        self.load_interactions_rating(config[\"rating_path\"])\n",
        "\n",
        "    def load_faiss_db(self, index_name):\n",
        "        \"\"\"\n",
        "        Load faiss db from local if exists, otherwise create a new one.\n",
        "\n",
        "        \"\"\"\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        try:\n",
        "            self.db = FAISS.load_local(index_name, embeddings)\n",
        "            print(\"Load faiss db from local\")\n",
        "        except:\n",
        "            titles = [item[\"name\"] for item in self.items.values()]\n",
        "            self.db = FAISS.from_texts(titles, embeddings)\n",
        "            self.db.save_local(index_name)\n",
        "\n",
        "    def load_relationship(self, file_path):\n",
        "        \"\"\"\n",
        "        Load relationship of agents from local file.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)\n",
        "            for row in reader:\n",
        "                user_1, user_2, relationship, _ = row\n",
        "                user_1 = int(user_1)\n",
        "                user_2 = int(user_2)\n",
        "\n",
        "                if user_1 not in self.users or user_2 not in self.users:\n",
        "                    continue\n",
        "                if \"contact\" not in self.users[user_1]:\n",
        "                    self.users[user_1][\"contact\"] = dict()\n",
        "\n",
        "                self.users[user_1][\"contact\"][user_2] = relationship\n",
        "                self.tot_relationship_num += 1\n",
        "\n",
        "    def load_items(self, file_path):\n",
        "        \"\"\"\n",
        "        Load items from local file.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                item_id, title, genre, description = row\n",
        "                self.items[int(item_id)] = {\n",
        "                    \"name\": title.strip(),\n",
        "                    \"genre\": genre,\n",
        "                    \"description\": description.strip(),\n",
        "                    \"inter_cnt\": 0,\n",
        "                    \"mention_cnt\": 0,\n",
        "                }\n",
        "\n",
        "    def load_users(self, file_path):\n",
        "        \"\"\"\n",
        "        Load users from local file.\n",
        "        \"\"\"\n",
        "        cnt = 1\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                # print(len(row), row)\n",
        "                user_id, name, gender, age, traits, status, interest, feature = row\n",
        "\n",
        "                self.users[cnt] = {\n",
        "                    \"name\": name,\n",
        "                    \"gender\": gender,\n",
        "                    \"age\": int(age),\n",
        "                    \"traits\": traits,\n",
        "                    \"status\": status,\n",
        "                    \"interest\": interest,\n",
        "                    \"feature\": feature,\n",
        "                }\n",
        "                cnt += 1\n",
        "\n",
        "    def load_role(\n",
        "        self, id, name, gender, age, traits, status, interest, feature, relationships\n",
        "    ):\n",
        "        \"\"\"\n",
        "        @ Zeyu Zhang\n",
        "        Load the role user into this `Data` object. Then other agents can interact with the role.\n",
        "        \"\"\"\n",
        "        self.role_id = id\n",
        "        self.users[id] = {\n",
        "            \"name\": name,\n",
        "            \"gender\": gender,\n",
        "            \"age\": int(age),\n",
        "            \"traits\": traits,\n",
        "            \"status\": status,\n",
        "            \"interest\": interest,\n",
        "            \"feature\": feature,\n",
        "        }\n",
        "        for id2, rel_value in relationships.items():\n",
        "            if \"contact\" not in self.users[id]:\n",
        "                self.users[id][\"contact\"] = dict()\n",
        "            self.users[id][\"contact\"][id2] = rel_value\n",
        "\n",
        "    def load_interactions_rating(self, file_path):\n",
        "      \"\"\"\n",
        "      Load user-item interactions (with rating) from local file.\n",
        "      Stores in self.interrating as a dict:\n",
        "      {user_id: [(item_id, rating), ...], ...}\n",
        "      \"\"\"\n",
        "      with open(file_path, \"r\", newline=\"\") as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader)  # Skip the header line\n",
        "        for row in reader:\n",
        "            user_id, item_id, rating = row\n",
        "            user_id = int(user_id)\n",
        "            item_id = int(item_id)\n",
        "            rating = int(rating)\n",
        "            if user_id not in self.interrating:\n",
        "                self.interrating[user_id] = []\n",
        "            self.interrating[user_id].append((item_id, rating))\n",
        "\n",
        "            if user_id not in self.user_ratings:\n",
        "                self.user_ratings[user_id] = []\n",
        "            self.user_ratings[user_id].append(rating)\n",
        "\n",
        "            # Store item rating\n",
        "            if item_id not in self.item_ratings:\n",
        "                self.item_ratings[item_id] = []\n",
        "            self.item_ratings[item_id].append(rating)\n",
        "\n",
        "      # Compute and store average historical rating for each user\n",
        "      self.user_avg_rating = {uid: sum(ratings)/len(ratings) for uid, ratings in self.user_ratings.items() if ratings}\n",
        "\n",
        "      # Compute and store average historical rating for each item\n",
        "      self.item_avg_rating = {iid: sum(ratings)/len(ratings) for iid, ratings in self.item_ratings.items() if ratings}\n",
        "\n",
        "\n",
        "    def get_full_items(self):\n",
        "        return list(self.items.keys())\n",
        "\n",
        "    def get_inter_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of interactions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"inter_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def add_inter_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        print(\"item ids:\", item_ids)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"inter_cnt\"] += 1\n",
        "\n",
        "    def add_mention_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"mention_cnt\"] += 1\n",
        "\n",
        "    def get_mention_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of mentions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"mention_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def get_item_names(self, item_ids):\n",
        "        return [\"<\" + self.items[item_id][\"name\"] + \">\" for item_id in item_ids]\n",
        "\n",
        "    def get_item_ids(self, item_names):\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] in item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_item_ids_exact(self, item_names):\n",
        "        \"\"\"\n",
        "        Get item ids from item names.\n",
        "        I coundn't find any difference with the get_item_ids(item_names) function\n",
        "        \"\"\"\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] == item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_full_users(self):\n",
        "        return list(self.users.keys())\n",
        "\n",
        "    def get_user_profile(self, user_id):\n",
        "        \"\"\"\n",
        "        Return the user profile as a formatted string for the given user_id.\n",
        "        \"\"\"\n",
        "        user = self.users.get(user_id)\n",
        "        if not user:\n",
        "           return f\"User ID {user_id} not found.\"\n",
        "\n",
        "        profile = (\n",
        "        f\"User ID: {user_id};; Name: {user['name']}\\n\"\n",
        "        f\"Gender: {user['gender']};; Age: {user['age']};; Status: {user['status']}\\n\"\n",
        "        f\"Traits: {user['traits']};; Interest: {user['interest']};; Feature: {user['feature']}\\n\")\n",
        "        return profile\n",
        "\n",
        "    def get_user_names(self, user_ids):\n",
        "        return [self.users[user_id][\"name\"] for user_id in user_ids]\n",
        "\n",
        "    def get_user_ids(self, user_names):\n",
        "        user_ids = []\n",
        "        for user in user_names:\n",
        "            for user_id, user_info in self.users.items():\n",
        "                if user_info[\"name\"] == user:\n",
        "                    user_ids.append(user_id)\n",
        "                    break\n",
        "        return user_ids\n",
        "\n",
        "    def get_user_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of users.\n",
        "        \"\"\"\n",
        "        return len(self.users.keys())\n",
        "\n",
        "    def get_item_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of items.\n",
        "        \"\"\"\n",
        "        return len(self.items.keys())\n",
        "\n",
        "    def get_relationship_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of relationships.\n",
        "        \"\"\"\n",
        "        return self.tot_relationship_num\n",
        "\n",
        "    def get_role_id(self):\n",
        "        \"\"\"\n",
        "        Return the number of relationships.\n",
        "        \"\"\"\n",
        "        return self.role_id\n",
        "\n",
        "    def search_items(self, item, k=50):\n",
        "        \"\"\"\n",
        "        Search similar items from faiss db.\n",
        "        Args:\n",
        "            item: str, item name\n",
        "            k: int, number of similar items to return\n",
        "        \"\"\"\n",
        "        docs = self.db.similarity_search(item, k)\n",
        "        item_names = [doc.page_content for doc in docs]\n",
        "        return item_names\n",
        "\n",
        "    def get_all_contacts(self, user_id):\n",
        "        \"\"\"\n",
        "        Get all contacts of a user.\n",
        "        \"\"\"\n",
        "        if \"contact\" not in self.users[user_id]:\n",
        "            print(f\"{user_id} has no contact.\")\n",
        "            return []\n",
        "        ids = []\n",
        "        for id in self.users[user_id][\"contact\"]:\n",
        "            if id < self.get_user_num():\n",
        "                ids.append(id)\n",
        "        return self.get_user_names(ids)\n",
        "\n",
        "    def get_all_contacts_id(self, user_id):\n",
        "        \"\"\"\n",
        "        Get all contacts of a user.\n",
        "        \"\"\"\n",
        "        if \"contact\" not in self.users[user_id]:\n",
        "            print(f\"{user_id} has no contact.\")\n",
        "            return []\n",
        "        ids = []\n",
        "        for id in self.users[user_id][\"contact\"]:\n",
        "            if id < self.get_user_num():\n",
        "                ids.append(id)\n",
        "        return ids\n",
        "\n",
        "    def get_relationships(self, user_id):\n",
        "        \"\"\"\n",
        "        Get all relationships of a user.\n",
        "        \"\"\"\n",
        "        if \"contact\" not in self.users[user_id]:\n",
        "            print(f\"{user_id} has no contact.\")\n",
        "            return dict()\n",
        "        return self.users[user_id][\"contact\"]\n",
        "\n",
        "    def get_relationship_names(self, user_id):\n",
        "        \"\"\"\n",
        "        Get all relationship IDs of a user.\n",
        "        \"\"\"\n",
        "        if \"contact\" not in self.users[user_id]:\n",
        "            print(f\"{user_id} has no contact.\")\n",
        "            return dict()\n",
        "        relatiobnships = dict()\n",
        "        for id in self.users[user_id][\"contact\"]:\n",
        "            relatiobnships[self.users[id][\"name\"]] = self.users[user_id][\"contact\"][id]\n",
        "        return relatiobnships\n",
        "\n",
        "    def get_network_density(self):\n",
        "        \"\"\"\n",
        "        Get the network density of the social network.\n",
        "        \"\"\"\n",
        "        self.network_density = round(\n",
        "            self.tot_relationship_num\n",
        "            * 2\n",
        "            / (self.get_user_num() * (self.get_user_num() - 1)),\n",
        "            2,\n",
        "        )\n",
        "        return self.network_density\n",
        "\n",
        "    def get_item_description_by_id(self, item_ids):\n",
        "        \"\"\"\n",
        "        Get description of items by item id.\n",
        "        \"\"\"\n",
        "        return [self.items[item_id][\"description\"] for item_id in item_ids]\n",
        "\n",
        "    def get_item_description_by_name(self, item_names):\n",
        "        \"\"\"\n",
        "        Get description of items by item name.\n",
        "        \"\"\"\n",
        "        item_descriptions = []\n",
        "        for item in item_names:\n",
        "            found = False\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] == item.strip(\" <>\"):\n",
        "                    item_descriptions.append(item_info[\"description\"])\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                item_descriptions.append(\"\")\n",
        "        return item_descriptions\n",
        "\n",
        "    def get_genres_by_id(self, item_ids):\n",
        "        \"\"\"\n",
        "        Get genre of items by item id.\n",
        "        \"\"\"\n",
        "        # return [self.items[item_id][\"genre\"] for item_id in item_ids]\n",
        "        return [\n",
        "            genre\n",
        "            for item_id in item_ids\n",
        "            for genre in self.items[item_id][\"genre\"].split('|')\n",
        "        ]\n",
        "\n",
        "    def hit_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Return 1 if any of the top-k predicted are relevant, else 0.\"\"\"\n",
        "        return int(bool(set(ground_truth) & set(predicted[:k])))\n",
        "\n",
        "    def ndcg_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Compute NDCG@k for a single user.\"\"\"\n",
        "        def dcg(rel):\n",
        "          return np.sum([(2**r - 1) / np.log2(i + 2) for i, r in enumerate(rel)])\n",
        "\n",
        "        rel = [1 if item in ground_truth else 0 for item in predicted[:k]]\n",
        "        ideal_rel = sorted([1]*min(len(ground_truth), k) + [0]*(k - min(len(ground_truth), k)), reverse=True)\n",
        "        dcg_score = dcg(rel)\n",
        "        idcg_score = dcg(ideal_rel)\n",
        "        return dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
        "\n",
        "    def mse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute MSE for ratings (on items in both sets).\"\"\"\n",
        "        if items is None:\n",
        "           items = set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        else:\n",
        "           items = set(items) & set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        if not items:\n",
        "           return np.nan\n",
        "        errors = [(ground_truth_ratings[i] - predicted_ratings[i]) ** 2 for i in items]\n",
        "        return np.mean(errors)\n",
        "\n",
        "    def rmse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute RMSE for ratings.\"\"\"\n",
        "        return np.sqrt(self.mse(ground_truth_ratings, predicted_ratings, items))\n",
        "\n",
        "    def safe_log(self, x):\n",
        "        \"\"\"Numerically safe log.\"\"\"\n",
        "        return math.log(max(x, 1e-15))\n",
        "\n",
        "    def ordered_probit_probs(self, pred_int, K, taus=None):\n",
        "        \"\"\"\n",
        "        Compute ordered probit class probabilities for a predicted integer rating.\n",
        "\n",
        "        pred_int : int\n",
        "            The predicted integer rating (e.g., 1..K).\n",
        "        K : int\n",
        "            Number of rating classes (e.g., 5 for 1–5 stars).\n",
        "        taus : list or array, optional\n",
        "            Thresholds separating the ordered categories.\n",
        "            If None, uses equally spaced thresholds [1.5, 2.5, ..., K-0.5].\n",
        "        \"\"\"\n",
        "\n",
        "        if taus is None:\n",
        "           taus = np.array([1.5 + i for i in range(K-1)])  # default thresholds\n",
        "\n",
        "        assert len(taus) == K-1\n",
        "\n",
        "        def Phi(z):\n",
        "            return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))  # Normal CDF\n",
        "\n",
        "        probs = []\n",
        "        for k in range(1, K+1):\n",
        "           if k == 1:\n",
        "              lower = -np.inf\n",
        "              upper = taus[0]\n",
        "           elif k == K:\n",
        "              lower = taus[-1]\n",
        "              upper = np.inf\n",
        "           else:\n",
        "              lower = taus[k-2]\n",
        "              upper = taus[k-1]\n",
        "           p_lower = 0.0 if lower == -np.inf else Phi((lower - pred_int))\n",
        "           p_upper = 1.0 if upper == np.inf else Phi((upper - pred_int))\n",
        "           probs.append(max(p_upper - p_lower, 1e-15))\n",
        "\n",
        "        probs = np.array(probs)\n",
        "        probs /= probs.sum()  # normalize\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_S3BcwiBkZb"
      },
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "    \"\"\"Base class for all models.\"\"\"\n",
        "\n",
        "    def __init__(self, config, n_users, n_items):\n",
        "        self.config = config\n",
        "        self.items = None\n",
        "\n",
        "    def get_full_sort_items(self, user_id, *args, **kwargs):\n",
        "        \"\"\"Get a list of sorted items for a given user.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _sort_full_items(self, user_id, *args, **kwargs):\n",
        "        \"\"\"Sort a list of items for a given user.\"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj1Lo81_BqVa"
      },
      "outputs": [],
      "source": [
        "from typing import Union, List, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MF(BaseModel, nn.Module):\n",
        "    def __init__(self, config, n_users, n_items):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "        self.config = config\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        torch.manual_seed(config['seed'])\n",
        "        # define layers and loss\n",
        "        self.user_embedding = nn.Embedding(self.n_users+1, self.embedding_size)\n",
        "        self.item_embedding = nn.Embedding(self.n_items+1, self.embedding_size)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        \"\"\"Predicts the rating of a user for an item.\"\"\"\n",
        "        user_embed = self.user_embedding(user)\n",
        "        item_embed = self.item_embedding(item)\n",
        "\n",
        "        # Dot product between user and item embeddings to predict rating\n",
        "        predicted_rating = (user_embed * item_embed).sum(1)\n",
        "\n",
        "        return predicted_rating\n",
        "\n",
        "    def get_full_sort_items(self, user, items):\n",
        "        \"\"\"Get a list of sorted items for a given user.\"\"\"\n",
        "        predicted_ratings = self.forward(user, items)\n",
        "        sorted_items = self._sort_full_items(user, predicted_ratings, items)\n",
        "        return sorted_items.tolist()\n",
        "\n",
        "    def _sort_full_items(self, user, predicted_ratings, items):\n",
        "        \"\"\"Sort items based on their predicted ratings.\"\"\"\n",
        "        # Sort items based on ratings in descending order and return item indices\n",
        "        _, sorted_indices = torch.sort(predicted_ratings, descending=True)\n",
        "        return items[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tr3FZxAxkFR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Tuple, Iterable, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LightGCN(BaseModel, nn.Module):\n",
        "    \"\"\"\n",
        "    LightGCN for recommendation.\n",
        "    Reference: He et al., \"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        n_users: int,\n",
        "        n_items: int,\n",
        "        interactions: Iterable[Tuple[int, int]],\n",
        "        n_layers: int = 3,\n",
        "        embedding_dim: int = 64,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        interactions: iterable of (user_id, item_id) pairs (duplicates okay, handled as multi-edges of weight 1)\n",
        "        \"\"\"\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        torch.manual_seed(config.get(\"seed\", 2023))\n",
        "\n",
        "        # Embeddings\n",
        "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "\n",
        "        # Build normalized adjacency once\n",
        "        self.Graph = self._build_normalized_adj(interactions).to(self.device)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    # ---------- Graph utilities ----------\n",
        "    def _build_normalized_adj(self, interactions: Iterable[Tuple[int, int]]) -> torch.sparse.FloatTensor:\n",
        "        \"\"\"\n",
        "        Build the symmetrically normalized adjacency matrix:\n",
        "            A_hat = D^{-1/2} * A * D^{-1/2}\n",
        "        for the bipartite user-item graph where nodes = users + items\n",
        "        Size: (n_nodes, n_nodes) with n_nodes = n_users + n_items\n",
        "        \"\"\"\n",
        "        n_nodes = self.n_users + self.n_items\n",
        "\n",
        "        # Collect COO edges (user <-> item, undirected)\n",
        "        rows = []\n",
        "        cols = []\n",
        "        vals = []\n",
        "\n",
        "        for u, i, *rest in interactions:\n",
        "            # Allow (u,i) or (u,i,rating) — rating ignored here (implicit 1)\n",
        "            if u < 0 or u >= self.n_users or i < 0 or i >= self.n_items:\n",
        "                continue\n",
        "            i_offset = self.n_users + i  # item node index in unified graph\n",
        "            # u -> i\n",
        "            rows.append(u); cols.append(i_offset); vals.append(1.0)\n",
        "            # i -> u\n",
        "            rows.append(i_offset); cols.append(u); vals.append(1.0)\n",
        "\n",
        "        if len(rows) == 0:\n",
        "            # Empty graph fallback (identity to avoid NaNs)\n",
        "            indices = torch.arange(n_nodes, dtype=torch.long)\n",
        "            indices = torch.stack([indices, indices], dim=0)\n",
        "            values = torch.ones(n_nodes, dtype=torch.float32)\n",
        "            return torch.sparse_coo_tensor(indices, values, (n_nodes, n_nodes)).coalesce()\n",
        "\n",
        "        indices = torch.tensor([rows, cols], dtype=torch.long)\n",
        "        values = torch.tensor(vals, dtype=torch.float32)\n",
        "        A = torch.sparse_coo_tensor(indices, values, (n_nodes, n_nodes)).coalesce()\n",
        "\n",
        "        # Degree vector d = sum of rows\n",
        "        deg = torch.sparse.sum(A, dim=1).to_dense()  # (n_nodes,)\n",
        "        # Avoid divide-by-zero\n",
        "        deg = torch.clamp(deg, min=1e-12)\n",
        "        d_inv_sqrt = torch.pow(deg, -0.5)\n",
        "\n",
        "        # Normalize values: for each edge (i,j), val *= d^-1/2[i] * d^-1/2[j]\n",
        "        row, col = A.indices()\n",
        "        norm_vals = A.values() * d_inv_sqrt[row] * d_inv_sqrt[col]\n",
        "\n",
        "        A_hat = torch.sparse_coo_tensor(A.indices(), norm_vals, A.size()).coalesce()\n",
        "        return A_hat\n",
        "\n",
        "    # ---------- Embedding propagation ----------\n",
        "    def propagate(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Perform K-layer LightGCN propagation and return final user & item embeddings.\n",
        "        E^(0) = concat([U, I])  -> shape (n_users + n_items, d)\n",
        "        E_final = 1/(K+1) * sum_{k=0..K} E^(k)\n",
        "        \"\"\"\n",
        "        E_u0 = self.user_embedding.weight\n",
        "        E_i0 = self.item_embedding.weight\n",
        "        E0 = torch.cat([E_u0, E_i0], dim=0)  # (n_users + n_items, d)\n",
        "\n",
        "        all_layers = [E0]\n",
        "        x = E0\n",
        "        for _ in range(self.n_layers):\n",
        "            x = torch.sparse.mm(self.Graph, x)  # LightGCN propagation (no weights, no nonlinearity)\n",
        "            all_layers.append(x)\n",
        "\n",
        "        E = torch.stack(all_layers, dim=0).mean(dim=0)  # layer-wise average\n",
        "        Eu, Ei = torch.split(E, [self.n_users, self.n_items], dim=0)\n",
        "        return Eu, Ei\n",
        "\n",
        "    # ---------- Scoring ----------\n",
        "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predict scores for (users, items). Supports:\n",
        "          - users: (B,), items: (B,)  -> elementwise scores\n",
        "          - users: (B,), items: (N,)  -> broadcast users for all N items (returns (B,N))\n",
        "        \"\"\"\n",
        "        users = users.to(self.device)\n",
        "        items = items.to(self.device)\n",
        "\n",
        "        Eu, Ei = self.propagate()\n",
        "\n",
        "        if users.dim() == 1 and items.dim() == 1 and users.shape[0] == items.shape[0]:\n",
        "            u_emb = Eu[users]                   # (B, d)\n",
        "            i_emb = Ei[items]                   # (B, d)\n",
        "            return (u_emb * i_emb).sum(dim=1)   # (B,)\n",
        "\n",
        "        # Broadcast to (B, N)\n",
        "        u_emb = Eu[users]                       # (B, d)\n",
        "        i_emb = Ei[items]                       # (N, d)\n",
        "        scores = u_emb @ i_emb.t()              # (B, N)\n",
        "        return scores\n",
        "\n",
        "    def predict(self, user_ids: List[int], item_ids: Optional[List[int]] = None) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Convenience method to get scores as numpy.\n",
        "        - If item_ids is None: scores for all items for each user -> shape (B, n_items)\n",
        "        - Else: scores for user_ids x item_ids -> (B, len(item_ids))\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            u = torch.tensor(user_ids, dtype=torch.long, device=self.device)\n",
        "            if item_ids is None:\n",
        "                items = torch.arange(self.n_items, dtype=torch.long, device=self.device)\n",
        "                scores = self.forward(u, items)        # (B, n_items)\n",
        "            else:\n",
        "                items = torch.tensor(item_ids, dtype=torch.long, device=self.device)\n",
        "                scores = self.forward(u, items)        # (B, len(item_ids))\n",
        "        return scores.detach().cpu().numpy()\n",
        "\n",
        "    # ---------- Ranking API (BaseModel) ----------\n",
        "    def get_full_sort_items(self, user_id: int, seen_items: Optional[Iterable[int]] = None, top_k: Optional[int] = None) -> List[int]:\n",
        "        \"\"\"\n",
        "        Rank all items for a given user (descending by predicted score).\n",
        "        Optionally drop previously seen items.\n",
        "        \"\"\"\n",
        "        scores = self.predict([user_id], None).ravel()  # (n_items,)\n",
        "        if seen_items is not None:\n",
        "            # push seen items to bottom\n",
        "            seen_items = [i for i in seen_items if 0 <= i < self.n_items]\n",
        "            scores[np.array(seen_items, dtype=np.int64)] = -np.inf\n",
        "\n",
        "        order = np.argsort(-scores)  # descending\n",
        "        if top_k is not None:\n",
        "            order = order[:top_k]\n",
        "        return order.tolist()\n",
        "\n",
        "    def _sort_full_items(self, user_id: int, predicted_ratings: torch.Tensor, items: torch.Tensor):\n",
        "        # Not used here; keeping for BaseModel compatibility\n",
        "        _, idx = torch.sort(predicted_ratings, descending=True)\n",
        "        return items[idx]\n",
        "\n",
        "\n",
        "class BPRLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Pairwise Bayesian Personalized Ranking loss with L2 regularization on embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, reg: float = 1e-4):\n",
        "        super().__init__()\n",
        "        self.reg = reg\n",
        "\n",
        "    def forward(self, u_emb, pos_emb, neg_emb):\n",
        "        pos_scores = (u_emb * pos_emb).sum(dim=1)\n",
        "        neg_scores = (u_emb * neg_emb).sum(dim=1)\n",
        "        loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
        "        reg = (u_emb.norm(2).pow(2) + pos_emb.norm(2).pow(2) + neg_emb.norm(2).pow(2)) / u_emb.shape[0]\n",
        "        return loss + self.reg * reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0YtIs7-oQL0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Optional, Tuple, Iterable, List, Dict\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class InteractionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that yields dense user vectors (torch.float32).\n",
        "    Accepts a scipy.sparse CSR matrix or a numpy array of shape (n_users, n_items).\n",
        "    \"\"\"\n",
        "    def __init__(self, user_item_matrix):\n",
        "        # Accept CSR matrix or numpy array\n",
        "        if hasattr(user_item_matrix, \"toarray\") and hasattr(user_item_matrix, \"tocsr\"):\n",
        "            self.mat = user_item_matrix.tocsr()\n",
        "            self.is_sparse = True\n",
        "            self.n_users, self.n_items = self.mat.shape\n",
        "        else:\n",
        "            self.mat = np.asarray(user_item_matrix, dtype=np.float32)\n",
        "            self.is_sparse = False\n",
        "            self.n_users, self.n_items = self.mat.shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_sparse:\n",
        "            row = self.mat.getrow(idx).toarray().astype(np.float32).squeeze(0)\n",
        "            return torch.from_numpy(row)\n",
        "        else:\n",
        "            return torch.from_numpy(self.mat[idx].astype(np.float32))\n",
        "\n",
        "\n",
        "class MultiVAE(BaseModel, nn.Module):\n",
        "    \"\"\"\n",
        "    MultiVAE model (variational autoencoder for collaborative filtering).\n",
        "    - encoder: two-layer MLP -> mu, logvar\n",
        "    - decoder: linear mapping from latent z to item logits\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: dict,\n",
        "        n_users: int,\n",
        "        n_items: int,\n",
        "        hidden_dim: int = 600,\n",
        "        latent_dim: int = 200,\n",
        "        dropout=0.5,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "\n",
        "        # model dims\n",
        "        self.hidden_dim = config.get(\"vae_hidden_dim\", hidden_dim)\n",
        "        self.latent_dim = config.get(\"vae_latent_dim\", latent_dim)\n",
        "        self.dropout = config.get(\"vae_dropout\", dropout)\n",
        "\n",
        "        # encoder\n",
        "        self.encoder_fc1 = nn.Linear(n_items, self.hidden_dim)\n",
        "        self.encoder_fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.mu_layer = nn.Linear(self.hidden_dim, self.latent_dim)\n",
        "        self.logvar_layer = nn.Linear(self.hidden_dim, self.latent_dim)\n",
        "\n",
        "        # decoder (linear + bias to produce logits over items)\n",
        "        self.decoder = nn.Linear(self.latent_dim, n_items, bias=True)\n",
        "\n",
        "        self.act = nn.Tanh()\n",
        "        self.drop = nn.Dropout(self.dropout)\n",
        "\n",
        "        # initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    # ---------- VAE ops ----------\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        x: (B, n_items) input user vectors\n",
        "        returns mu, logvar (each (B, latent_dim))\n",
        "        \"\"\"\n",
        "        h = self.drop(self.act(self.encoder_fc1(x)))\n",
        "        h = self.drop(self.act(self.encoder_fc2(h)))\n",
        "        mu = self.mu_layer(h)\n",
        "        logvar = self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns logits for items: (B, n_items)\n",
        "        \"\"\"\n",
        "        logits = self.decoder(z)\n",
        "        return logits\n",
        "\n",
        "    def forward(self, x: torch.Tensor, sample: bool = True) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        One forward pass:\n",
        "        - encodes x -> mu, logvar\n",
        "        - draws z (reparameterization)\n",
        "        - decodes logits\n",
        "        Returns: logits, mu, logvar\n",
        "        \"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        if self.training and sample:\n",
        "            z = self.reparameterize(mu, logvar)\n",
        "        else:\n",
        "            z = mu  # use mean for deterministic inference\n",
        "        logits = self.decode(z)\n",
        "        return logits, mu, logvar\n",
        "\n",
        "    # ---------- Loss / ELBO ----------\n",
        "    def loss_function(\n",
        "        self,\n",
        "        logits: torch.Tensor,\n",
        "        input_batch: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "        anneal: float = 1.0,\n",
        "    ) -> Tuple[torch.Tensor, float, float]:\n",
        "        \"\"\"\n",
        "        Multinomial likelihood version used in MultiVAE:\n",
        "        recon_loss = - sum_j x_j * log_softmax(logits)_j\n",
        "\n",
        "        KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
        "        total_loss = recon_loss + anneal * KL\n",
        "        Returns (loss, recon_loss_scalar, kl_scalar)\n",
        "        \"\"\"\n",
        "        # reconstruction: log softmax and weighted by counts\n",
        "        log_softmax = F.log_softmax(logits, dim=1)  # (B, n_items)\n",
        "        # input_batch may be counts (0/1 or counts). multiply and sum per sample\n",
        "        recon = -torch.sum(log_softmax * input_batch, dim=1)  # (B,)\n",
        "        recon_loss = torch.mean(recon)\n",
        "\n",
        "        # KL\n",
        "        kl = -0.5 * torch.sum(1.0 + logvar - mu.pow(2) - logvar.exp(), dim=1)  # (B,)\n",
        "        kl_loss = torch.mean(kl)\n",
        "\n",
        "        loss = recon_loss + anneal * kl_loss\n",
        "        return loss, recon_loss.item(), kl_loss.item()\n",
        "\n",
        "\n",
        "    # ---------- Embeddings helper (for ranking similar to LightGCN propagate) ----------\n",
        "    def get_user_latent(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Return deterministic latent mu for x (no sampling).\n",
        "        x: (B, n_items)\n",
        "        returns mu: (B, latent_dim)\n",
        "        \"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        return mu\n",
        "\n",
        "    # ---------- Prediction / Ranking (BaseModel methods) ----------\n",
        "    def predict(self, user_vectors: torch.Tensor) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Predict item scores for a batch of user vectors.\n",
        "        user_vectors: torch.Tensor (B, n_items) on cpu or device\n",
        "        returns: numpy array (B, n_items) of logits (higher = more recommended)\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            user_vectors = user_vectors.to(self.device)\n",
        "            logits, mu, logvar = self.forward(user_vectors, sample=False)\n",
        "            # Return logits (no softmax) so they can be sorted. move to cpu\n",
        "            return logits.detach().cpu().numpy()\n",
        "\n",
        "    def get_full_sort_items(self, user_id: int, user_item_matrix, seen_items: Optional[Iterable[int]] = None, top_k: Optional[int] = None) -> List[int]:\n",
        "        \"\"\"\n",
        "        Rank all items for a given user.\n",
        "        - user_item_matrix: the full user-item matrix (csr or numpy) to extract the user's vector\n",
        "        - seen_items: optional iterable to mask (push to bottom)\n",
        "        \"\"\"\n",
        "        # build user vector\n",
        "        if hasattr(user_item_matrix, \"getrow\"):\n",
        "            vec = user_item_matrix.getrow(user_id).toarray().astype(np.float32)\n",
        "            user_vec = torch.from_numpy(vec).to(self.device)\n",
        "        else:\n",
        "            user_vec = torch.from_numpy(np.asarray(user_item_matrix[user_id], dtype=np.float32)).to(self.device)\n",
        "\n",
        "        scores = self.predict(user_vec.unsqueeze(0)).ravel()  # (n_items,)\n",
        "\n",
        "        if seen_items is not None:\n",
        "            seen = [i for i in seen_items if 0 <= i < self.n_items]\n",
        "            scores[np.array(seen, dtype=np.int64)] = -np.inf\n",
        "\n",
        "        order = np.argsort(-scores)\n",
        "        if top_k is not None:\n",
        "            order = order[:top_k]\n",
        "        return order.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wROC4JFetYl7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "class FMModel(BaseModel, nn.Module):\n",
        "    def __init__(self, config, n_users, n_items, n_factors=16):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "\n",
        "        # Linear terms\n",
        "        self.user_bias = nn.Embedding(n_users, 1)\n",
        "        self.item_bias = nn.Embedding(n_items, 1)\n",
        "\n",
        "        # Factorization embeddings\n",
        "        self.user_embedding = nn.Embedding(n_users, n_factors)\n",
        "        self.item_embedding = nn.Embedding(n_items, n_factors)\n",
        "\n",
        "        # Global bias\n",
        "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        # Init\n",
        "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
        "        nn.init.zeros_(self.user_bias.weight)\n",
        "        nn.init.zeros_(self.item_bias.weight)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_vec = self.user_embedding(user_ids)\n",
        "        item_vec = self.item_embedding(item_ids)\n",
        "\n",
        "        linear_terms = self.user_bias(user_ids) + self.item_bias(item_ids)\n",
        "        interaction = torch.sum(user_vec * item_vec, dim=1, keepdim=True)\n",
        "\n",
        "        score = self.global_bias + linear_terms + interaction\n",
        "        return score.view(-1)\n",
        "\n",
        "    def get_full_sort_items(self, user_id):\n",
        "        device = next(self.parameters()).device\n",
        "        user_id_tensor = torch.tensor([user_id], device=device)\n",
        "        item_ids = torch.arange(self.n_items, device=device)\n",
        "        user_id_expand = user_id_tensor.expand(self.n_items)\n",
        "        scores = self.forward(user_id_expand, item_ids)\n",
        "        return torch.argsort(scores, descending=True).tolist()\n",
        "\n",
        "    def _sort_full_items(self, user_id):\n",
        "        return self.get_full_sort_items(user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exeql03FHnK_"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Iterable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Utility: set all seeds\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def sasrec_pointwise_step(model, batch, device, logit_clip=20.0):\n",
        "    users, seqs, pos_items, neg_items, mask = batch\n",
        "    seqs, pos_items, neg_items = seqs.to(device), pos_items.to(device), neg_items.to(device)\n",
        "    mask = mask.to(device).bool()\n",
        "\n",
        "    seq_out = model(seqs)\n",
        "    item_emb = model.item_embedding.weight\n",
        "\n",
        "    pos_logits = torch.sum(seq_out * item_emb[pos_items], dim=-1).clamp(-logit_clip, logit_clip)\n",
        "    neg_logits = torch.sum(seq_out * item_emb[neg_items], dim=-1).clamp(-logit_clip, logit_clip)\n",
        "\n",
        "    valid_mask = (pos_items > 0) & mask\n",
        "    if valid_mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
        "\n",
        "    loss_pos = F.binary_cross_entropy_with_logits(pos_logits[valid_mask], torch.ones_like(pos_logits[valid_mask]))\n",
        "    loss_neg = F.binary_cross_entropy_with_logits(neg_logits[valid_mask], torch.zeros_like(neg_logits[valid_mask]))\n",
        "\n",
        "    loss = loss_pos + loss_neg\n",
        "\n",
        "    # L2 reg, skip padding embedding\n",
        "    if model.l2_emb > 0:\n",
        "        loss += model.l2_emb * (item_emb[1:].norm(p=2) ** 2) / 2\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Dataset & Collate\n",
        "class SASRecDataset(Dataset):\n",
        "    \"\"\"Builds sequences for SASRec training.\n",
        "\n",
        "    Args:\n",
        "        user2items: dict mapping user_id -> list of interacted item ids (in time order)\n",
        "        n_items: total number of items (max ID)\n",
        "        max_seq_len: truncate/pad sequences to this length\n",
        "        min_seq_len: smallest effective length (>=2 to have a next item)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 user2items: Dict[int, List[int]],\n",
        "                 n_items: int,\n",
        "                 max_seq_len: int = 50,\n",
        "                 min_seq_len: int = 2):\n",
        "        self.user2items = user2items\n",
        "        self.users = [u for u, seq in user2items.items() if len(seq) >= min_seq_len]\n",
        "        self.n_items = n_items\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        user = self.users[idx]\n",
        "        full = self.user2items[user]\n",
        "        # Truncate to latest max_seq_len\n",
        "        seq = full[-self.max_seq_len:]\n",
        "        return user, seq\n",
        "\n",
        "\n",
        "def _pad_sequence(seq: list, max_len: int) -> list:\n",
        "    \"\"\"Left-pad sequence with 0 to max_len.\"\"\"\n",
        "    seq = seq[-max_len:]\n",
        "    return [0] * (max_len - len(seq)) + seq\n",
        "\n",
        "def _build_pos_items(seq: list) -> list:\n",
        "    \"\"\"Next-item targets, last position padded with 0.\"\"\"\n",
        "    return seq[1:] + [0]\n",
        "\n",
        "\n",
        "def _sample_negatives(seq: list, n_items: int) -> list:\n",
        "    \"\"\"Sample negatives for each position, avoiding seq items.\"\"\"\n",
        "    user_set = set(seq)\n",
        "    negatives = []\n",
        "    for _ in range(len(seq)):\n",
        "        neg = random.randint(1, n_items - 1)  # avoid 0\n",
        "        while neg in user_set:\n",
        "            neg = random.randint(1, n_items - 1)\n",
        "        negatives.append(neg)\n",
        "    return negatives\n",
        "\n",
        "\n",
        "def sasrec_collate(batch, n_items: int, max_seq_len: int):\n",
        "    users, seqs = zip(*batch)\n",
        "    seqs = [_pad_sequence(s, max_seq_len) for s in seqs]\n",
        "\n",
        "    pos_items = [_build_pos_items(s) for s in seqs]\n",
        "    neg_items = [_sample_negatives(s, n_items) for s in seqs]\n",
        "    mask = [[1 if x != 0 else 0 for x in s] for s in seqs]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(users, dtype=torch.long),\n",
        "        torch.tensor(seqs, dtype=torch.long),\n",
        "        torch.tensor(pos_items, dtype=torch.long),\n",
        "        torch.tensor(neg_items, dtype=torch.long),\n",
        "        torch.tensor(mask, dtype=torch.float),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_user2items(train_data):\n",
        "    user2items = defaultdict(list)\n",
        "    for u, i, r in sorted(train_data, key=lambda x: (x[0], x[2])):\n",
        "        user2items[u].append(i)\n",
        "    return user2items\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Model\n",
        "# ------------------------------\n",
        "class SASRec(nn.Module, BaseModel):\n",
        "    def __init__(self, config, n_users: int, n_items: int):\n",
        "        nn.Module.__init__(self)  # initialize nn.Module\n",
        "        BaseModel.__init__(self, config, n_users, n_items)  # keep BaseModel logic\n",
        "\n",
        "        self.n_items = n_items\n",
        "        self.hidden_units = int(config.get(\"hidden_units\", 128))\n",
        "        self.max_seq_len = int(config.get(\"max_seq_len\", 50))\n",
        "        self.num_heads = int(config.get(\"num_heads\", 2))\n",
        "        self.num_blocks = int(config.get(\"num_blocks\", 2))\n",
        "        self.dropout_rate = float(config.get(\"dropout_rate\", 0.2))\n",
        "        self.l2_emb = float(config.get(\"l2_emb\", 0.0))\n",
        "\n",
        "        # Embeddings\n",
        "        self.item_embedding = nn.Embedding(n_items + 1, self.hidden_units, padding_idx=0)\n",
        "        self.position_embedding = nn.Embedding(self.max_seq_len, self.hidden_units)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=self.hidden_units,\n",
        "                nhead=self.num_heads,\n",
        "                dim_feedforward=self.hidden_units * 4,\n",
        "                dropout=self.dropout_rate,\n",
        "                activation=\"gelu\",\n",
        "                batch_first=True,\n",
        "            ) for _ in range(self.num_blocks)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(self.dropout_rate)\n",
        "        self.layer_norm = nn.LayerNorm(self.hidden_units)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.02)\n",
        "        nn.init.normal_(self.position_embedding.weight, std=0.02)\n",
        "\n",
        "    def _causal_mask(self, L: int, device=None):\n",
        "        # True means masked in PyTorch\n",
        "        mask = torch.triu(torch.ones(L, L, device=device), diagonal=1).bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, item_seq: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encode sequence safely, with padding & causal masks.\n",
        "        Args:\n",
        "            item_seq: (B, L) padded with 0 on left\n",
        "        Returns:\n",
        "            seq_out: (B, L, H)\n",
        "        \"\"\"\n",
        "        B, L = item_seq.shape\n",
        "        device = item_seq.device\n",
        "        pos_ids = torch.arange(L, device=device).unsqueeze(0).expand(B, L)\n",
        "\n",
        "        # Embeddings\n",
        "        x = self.item_embedding(item_seq) + self.position_embedding(pos_ids)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        key_padding_mask = (item_seq == 0)  # True = pad\n",
        "        attn_mask = self._causal_mask(L, device=device)  # True = masked\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(\n",
        "            x,\n",
        "            src_mask=attn_mask,\n",
        "            src_key_padding_mask=key_padding_mask\n",
        "            )\n",
        "            # Safety: replace NaN/inf\n",
        "            if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "               x = torch.nan_to_num(x, nan=0.0, posinf=1e4, neginf=-1e4)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_full_sort_items(self, user_id, user_seq: torch.Tensor):\n",
        "        \"\"\"Return sorted item IDs by score for a single user.\n",
        "        Args:\n",
        "            user_seq: (1, L)\n",
        "        Returns:\n",
        "            torch.Tensor of sorted item ids (desc)\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        seq_out = self.forward(user_seq)[:, -1, :]  # (1, H)\n",
        "        all_item_emb = self.item_embedding.weight  # (n_items+1, H)\n",
        "        scores = torch.matmul(seq_out, all_item_emb.t()).squeeze(0)  # (n_items+1,)\n",
        "        # Avoid recommending padding id 0\n",
        "        scores[0] = -1e9\n",
        "        return torch.argsort(scores, descending=True)\n",
        "\n",
        "    def _sort_full_items(self, user_id, *args, **kwargs):\n",
        "        raise NotImplementedError(\"Use get_full_sort_items(user_id, user_seq)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7j8PUx0BS5r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import spearmanr\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class Recommender:\n",
        "    \"\"\"\n",
        "    Recommender System class\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, logger, data):\n",
        "        self.data = data\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.page_size = config[\"page_size\"]\n",
        "        self.items_per_page = config[\"items_per_page\"]\n",
        "        self.random_k = config[\"rec_random_k\"]\n",
        "        self.train_data = []\n",
        "        self.n_layers = 3\n",
        "        self.embedding_dim = 4\n",
        "        if config[\"rec_model\"] == \"MF\":\n",
        "           self.model = MF(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"LightGCN\":\n",
        "           self.model = LightGCN(config, self.data.get_user_num(), self.data.get_item_num(), self.train_data, n_layers=self.n_layers, embedding_dim=self.embedding_dim)\n",
        "        elif config[\"rec_model\"] == \"SASRec\":\n",
        "           self.model = SASRec(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"MultiVAE\":\n",
        "           self.model = MultiVAE(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"FM\":\n",
        "           self.model = FMModel(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        else:\n",
        "           raise ValueError(f\"Unknown model: {config['rec_model']}\")\n",
        "\n",
        "        self.criterion = nn.MSELoss()\n",
        "        if config[\"rec_model\"] != \"FM\":\n",
        "           self.optimizer = optim.Adam(self.model.parameters(), lr=config[\"lr\"], weight_decay=1e-5)\n",
        "\n",
        "        self.epoch_num = config[\"epoch_num\"]\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.record = {}\n",
        "        self.round_record = {}\n",
        "        self.positive = {}\n",
        "        self.interaction_dict = {}\n",
        "        self.inter_df = None\n",
        "        self.inter_num = 0\n",
        "        for user in self.data.get_full_users():\n",
        "            self.record[user] = []\n",
        "            self.positive[user] = []\n",
        "            self.round_record[user] = []\n",
        "        self.user_data = {\n",
        "            \"user\": [],\n",
        "            \"N_expose\": [],\n",
        "            \"N_view\": [],\n",
        "            \"N_like\": [],\n",
        "            \"N_exit\": [],\n",
        "            \"S_sat\": []\n",
        "            }\n",
        "        self.rating_feeling = {\n",
        "            \"User\": [],\n",
        "            \"Rating\": [],\n",
        "            \"Feelings\": []\n",
        "        }\n",
        "\n",
        "    def sample_bpr_triples(self,\n",
        "                           user_pos_items: List[List[int]],\n",
        "                           n_items: int,\n",
        "                           batch_size: int,\n",
        "                           device: torch.device,\n",
        "                           ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        user_pos_items: list of lists; for each user u, a list of items they've interacted with (positive)\n",
        "        returns (users, pos_items, neg_items) tensors of length batch_size\n",
        "        \"\"\"\n",
        "        users = []\n",
        "        pos = []\n",
        "        neg = []\n",
        "        for _ in range(batch_size):\n",
        "           # sample a user with at least one positive\n",
        "           while True:\n",
        "               u = np.random.randint(0, len(user_pos_items))\n",
        "               if len(user_pos_items[u]) > 0:\n",
        "                  break\n",
        "\n",
        "           i = np.random.choice(user_pos_items[u])\n",
        "           # sample a negative item\n",
        "\n",
        "           while True:\n",
        "               j = np.random.randint(0, n_items)\n",
        "               if j not in user_pos_items[u]:\n",
        "                  break\n",
        "\n",
        "           users.append(u)\n",
        "           pos.append(i)\n",
        "           neg.append(j)\n",
        "\n",
        "        return (\n",
        "        torch.tensor(users, dtype=torch.long, device=self.device),\n",
        "        torch.tensor(pos, dtype=torch.long, device=self.device),\n",
        "        torch.tensor(neg, dtype=torch.long, device=self.device),\n",
        "        )\n",
        "\n",
        "    def train_lightgcn_bpr(self,\n",
        "        reg: float = 1e-4,\n",
        "        log: bool = True):\n",
        "        \"\"\"\n",
        "        Train LightGCN with BPR loss.\n",
        "        - train_interactions/val_interactions can be (u,i) or (u,i,rating>0) tuples.\n",
        "        - If ckpt_path is provided, saves the best (by simple val recall proxy) state dict.\n",
        "        \"\"\"\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config[\"lr\"])\n",
        "        self.criterion = BPRLoss(reg=reg)\n",
        "\n",
        "        # Build user -> positives list\n",
        "        user_pos = [[] for _ in range(self.model.n_users)]\n",
        "        for u, i, *rest in self.train_data:\n",
        "            if 0 <= u < self.model.n_users and 0 <= i < self.model.n_items:\n",
        "               user_pos[u].append(i)\n",
        "\n",
        "        # Basic validation proxy: count of positives ranked in top-10 (cheap & optional)\n",
        "        def quick_val_topk_hits(k: int = 10) -> float:\n",
        "            if self.val_data is None:\n",
        "               return -1.0\n",
        "            # build val positives per user\n",
        "            val_pos = [[] for _ in range(self.model.n_users)]\n",
        "            for u, i, *rest in self.val_data:\n",
        "               if 0 <= u < self.model.n_users and 0 <= i < self.model.n_items:\n",
        "                   val_pos[u].append(i)\n",
        "\n",
        "            hits = 0\n",
        "            total = 0\n",
        "\n",
        "            for u in range(self.model.n_users):\n",
        "               if not val_pos[u]:\n",
        "                  continue\n",
        "               recs = self.model.get_full_sort_items(u, seen_items=set(user_pos[u]), top_k=k)\n",
        "               s = set(val_pos[u])\n",
        "               hits += len([r for r in recs if r in s])\n",
        "               total += min(k, len(s))\n",
        "            return hits / total if total > 0 else -1.0\n",
        "\n",
        "        best_metric = -math.inf\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_lightGCN_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "            self.model.train()\n",
        "\n",
        "            # One epoch of mini-batch BPR\n",
        "            n_steps = max(1, sum(len(v) for v in user_pos) // max(1, config['batch_size']))\n",
        "            losses = []\n",
        "            for _ in range(n_steps):\n",
        "                users, pos_items, neg_items = self.sample_bpr_triples(user_pos, self.model.n_items, config['batch_size'], self.device)\n",
        "                Eu, Ei = self.model.propagate()\n",
        "                u_emb = Eu[users]\n",
        "                p_emb = Ei[pos_items]\n",
        "                n_emb = Ei[neg_items]\n",
        "                loss = self.criterion(u_emb, p_emb, n_emb)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "            # quick validation metric\n",
        "            metric = quick_val_topk_hits(k=10)\n",
        "            if log:\n",
        "               print(f\"[Epoch {epoch:3d}] BPR Loss: {np.mean(losses):.4f} | Val@10: {metric:.4f}\")\n",
        "\n",
        "            # Save checkpoint if validation improves\n",
        "            if metric > best_metric:\n",
        "               best_metric = metric\n",
        "               torch.save({\n",
        "                   \"epoch\": self.epoch_num + 1,\n",
        "                   \"model_state_dict\": self.model.state_dict(),\n",
        "                   \"n_users\": self.data.get_user_num(),\n",
        "                   \"n_items\": self.data.get_item_num(),\n",
        "                   \"n_layers\": self.n_layers,\n",
        "                   \"embedding_dim\": self.embedding_dim,\n",
        "                   \"metric\": metric,\n",
        "                   }, ckpt_file)\n",
        "               self.logger.info(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        # Load best (optional)\n",
        "        if ckpt_file is not None and best_metric > -math.inf:\n",
        "           # At the end, reload the best weights for inference\n",
        "           checkpoint = torch.load(ckpt_file)\n",
        "           self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def bce_sampled_loss(self, seq_out: torch.Tensor,\n",
        "        pos_items: torch.Tensor,\n",
        "        neg_items: torch.Tensor,\n",
        "        item_embedding: nn.Embedding,\n",
        "        mask: torch.Tensor,\n",
        "        l2_emb: float = 0.0) -> torch.Tensor:\n",
        "        \"\"\"Binary cross-entropy on sampled positives/negatives per position.\n",
        "        Args:\n",
        "            seq_out: (B, L, H)\n",
        "            pos_items: (B, L) next-item ids (0 where no target)\n",
        "            neg_items: (B, L) sampled negatives (0 where no target)\n",
        "            item_embedding: embedding module (to fetch item vectors)\n",
        "            mask: (B, L) boolean, True where a target exists (i.e., pos_items > 0)\n",
        "            l2_emb: weight decay on item embeddings (regularizes pos/neg lookups)\n",
        "        \"\"\"\n",
        "        B, L, H = seq_out.shape\n",
        "\n",
        "        pos_vecs = item_embedding(pos_items)  # (B, L, H)\n",
        "        neg_vecs = item_embedding(neg_items)  # (B, L, H)\n",
        "\n",
        "        pos_logits = (seq_out * pos_vecs).sum(-1)  # (B, L)\n",
        "        neg_logits = (seq_out * neg_vecs).sum(-1)  # (B, L)\n",
        "\n",
        "        # Targets: pos -> 1, neg -> 0\n",
        "        pos_loss = F.binary_cross_entropy_with_logits(pos_logits[mask], torch.ones_like(pos_logits[mask]))\n",
        "        neg_loss = F.binary_cross_entropy_with_logits(neg_logits[mask], torch.zeros_like(neg_logits[mask]))\n",
        "        loss = pos_loss + neg_loss\n",
        "\n",
        "        if l2_emb > 0:\n",
        "           reg = (pos_vecs[mask].pow(2).sum() + neg_vecs[mask].pow(2).sum()) / mask.sum().clamp_min(1)\n",
        "           loss = loss + l2_emb * reg\n",
        "        return loss\n",
        "\n",
        "    def train_sasrec(self, grad_clip=1.0, logit_clip=20.0):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Build user->items dict and dataset\n",
        "        user2items = build_user2items(self.train_data)\n",
        "        n_items_global = int(self.data.get_item_num())\n",
        "        max_seq_len = self.model.max_seq_len\n",
        "\n",
        "        train_dataset = SASRecDataset(user2items, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=True,\n",
        "            collate_fn=lambda batch: sasrec_collate(batch, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "            )\n",
        "\n",
        "        # Validation loader\n",
        "        val_user2items = build_user2items(self.val_data)\n",
        "        val_dataset = SASRecDataset(val_user2items, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=False,\n",
        "            collate_fn=lambda batch: sasrec_collate(batch, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "            )\n",
        "\n",
        "        # Checkpoint setup\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_SASRec_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "        best_metric = -float(\"inf\")\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "           self.model.train()\n",
        "           running = 0.0\n",
        "           n_steps = 0\n",
        "\n",
        "           for users, seqs, pos, neg, umask in train_loader:\n",
        "              users, seqs, pos, neg, umask = (\n",
        "                users.to(self.device),\n",
        "                seqs.to(self.device),\n",
        "                pos.to(self.device),\n",
        "                neg.to(self.device),\n",
        "                umask.to(self.device).bool(),  # ensure bool type\n",
        "                )\n",
        "\n",
        "              # Compute mask dynamically\n",
        "              mask = pos > 0\n",
        "              mask = mask.bool()\n",
        "              if mask.sum() == 0:\n",
        "                 continue  # skip batch with no valid positions\n",
        "\n",
        "              # Compute stable loss\n",
        "              loss = sasrec_pointwise_step(self.model, (users, seqs, pos, neg, mask), device=self.device, logit_clip=logit_clip)\n",
        "\n",
        "              self.optimizer.zero_grad(set_to_none=True)\n",
        "              loss.backward()\n",
        "              if grad_clip is not None:\n",
        "                 nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "              self.optimizer.step()\n",
        "\n",
        "              running += loss.item()\n",
        "              n_steps += 1\n",
        "\n",
        "           avg_loss = running / max(1, n_steps)\n",
        "           print(f\"Epoch {epoch}/{self.epoch_num} - train loss: {avg_loss:.4f}\")\n",
        "\n",
        "           # Validation\n",
        "           if val_loader is not None:\n",
        "              self.model.eval()\n",
        "              val_loss = 0.0\n",
        "              n_val_steps = 0\n",
        "              with torch.no_grad():\n",
        "                  for users, seqs, pos, neg, umask in val_loader:\n",
        "                    #  print(\"Users:\", users)\n",
        "                    #  print(\"Pos min/max:\", pos.min().item(), pos.max().item())\n",
        "                    #  print(\"Neg min/max:\", neg.min().item(), neg.max().item())\n",
        "                     users, seqs, pos, neg, umask = (\n",
        "                         users.to(self.device),\n",
        "                         seqs.to(self.device),\n",
        "                         pos.to(self.device),\n",
        "                         neg.to(self.device),\n",
        "                         umask.to(self.device).bool(),)\n",
        "\n",
        "                     mask = pos > 0\n",
        "                     if mask.sum() == 0:\n",
        "                        # print(\"Skipped empty batch\")\n",
        "                        continue\n",
        "\n",
        "                     loss = sasrec_pointwise_step(self.model, (users, seqs, pos, neg, mask), device=self.device, logit_clip=logit_clip)\n",
        "                    #  print(\"Batch loss:\", loss.item())\n",
        "                     val_loss += loss.item()\n",
        "                     n_val_steps += 1\n",
        "              val_loss /= max(1, n_val_steps)\n",
        "              metric = -val_loss\n",
        "              print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}\")\n",
        "           else:\n",
        "              metric = -avg_loss\n",
        "\n",
        "           # Save best model\n",
        "           if metric > best_metric:\n",
        "              best_metric = metric\n",
        "              torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"metric\": metric,\n",
        "              }, ckpt_file)\n",
        "              print(f\"Best model updated at epoch {epoch}, saved to {ckpt_file}\")\n",
        "\n",
        "        # Load best model after training\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "\n",
        "    def train_fm(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.config['lr'])\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        best_metric = -math.inf\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_FM_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        # 🔹 Wrap datasets into DataLoaders\n",
        "        train_loader = DataLoader(self.train_data, batch_size=self.config['batch_size'], shuffle=True)\n",
        "        val_loader = None\n",
        "        if self.val_data is not None:\n",
        "           val_loader = DataLoader(self.val_data, batch_size=self.config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "        for epoch in range(self.epoch_num):\n",
        "           self.model.train()\n",
        "           total_loss = 0\n",
        "\n",
        "           for user, item, rating in train_loader:  # must be DataLoader\n",
        "              user, item, rating = user.to(self.device), item.to(self.device), rating.float().to(self.device)\n",
        "\n",
        "              self.optimizer.zero_grad()\n",
        "              preds = self.model(user, item)\n",
        "              loss = self.criterion(preds, rating)\n",
        "              loss.backward()\n",
        "              self.optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "           avg_loss = total_loss / len(train_loader)\n",
        "           print(f\"Epoch {epoch+1}/{self.epoch_num}, Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "           metric = None\n",
        "           if val_loader is not None:\n",
        "              self.model.eval()\n",
        "              with torch.no_grad():\n",
        "                  val_loss = 0\n",
        "                  for user, item, rating in val_loader:\n",
        "                      user, item, rating = user.to(self.device), item.to(self.device), rating.to(self.device)\n",
        "                      preds = self.model(user, item)\n",
        "                      val_loss += self.criterion(preds, rating).item()\n",
        "                  val_loss /= len(val_loader)\n",
        "\n",
        "              metric = -val_loss\n",
        "              print(f\"Epoch {epoch+1}, Val Loss: {val_loss:.4f}\")\n",
        "           else:\n",
        "              metric = -avg_loss  # fallback if no validation set\n",
        "\n",
        "           # save best model\n",
        "           if metric > best_metric:\n",
        "              best_metric = metric\n",
        "              torch.save({\n",
        "                \"epoch\": epoch+1,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"n_users\": self.model.n_users,\n",
        "                \"n_items\": self.model.n_items,\n",
        "                \"n_factors\": self.model.n_factors,\n",
        "                \"metric\": metric,\n",
        "                }, ckpt_file)\n",
        "              print(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "\n",
        "    def train_multivae(self,\n",
        "        weight_decay: float = 0.0,\n",
        "        anneal_cap: float = 0.2,\n",
        "        total_anneal_steps: int = 200000,\n",
        "        patience: int = 100,\n",
        "        verbose: bool = True,):\n",
        "        \"\"\"\n",
        "        Train MultiVAE on user-item matrix (CSR or dense numpy).\n",
        "        - anneal_cap: maximum beta for KL weighting\n",
        "        - total_anneal_steps: number of optimization steps over which to ramp beta from 0->anneal_cap\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        dataset = InteractionDataset(self.train_matrix)\n",
        "        loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True, drop_last=False)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['lr'], weight_decay=weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        update_count = 0\n",
        "        best_val_loss = float(\"inf\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MultiVAE_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        wait = 0\n",
        "\n",
        "        # AMP scaler (for mixed precision training)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "        # validation dataset (create once, not per epoch)\n",
        "        val_loader, val_dataset = None, None\n",
        "        if self.val_matrix is not None:\n",
        "           val_dataset = InteractionDataset(self.val_matrix)\n",
        "           val_loader = DataLoader(val_dataset, batch_size=self.config['batch_size'], shuffle=False)\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "            self.model.train()\n",
        "            epoch_loss, epoch_recon, epoch_kl, n_batches = 0.0, 0.0, 0.0, 0\n",
        "\n",
        "            for batch in loader:\n",
        "                batch = batch.to(self.device).float()\n",
        "                assert batch.shape[1] == self.model.n_items, \"Batch dimension mismatch!\"\n",
        "\n",
        "                # anneal factor\n",
        "                if total_anneal_steps > 0:\n",
        "                   anneal = min(anneal_cap, update_count / total_anneal_steps)\n",
        "                else:\n",
        "                   anneal = anneal_cap\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                    logits, mu, logvar = self.model(batch, sample=True)\n",
        "                    # clamp logvar inside model (optional, numerical stability)\n",
        "                    logvar = torch.clamp(logvar, min=-10, max=10)\n",
        "                    loss, recon_l, kl_l = self.model.loss_function(logits, batch, mu, logvar, anneal)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                epoch_recon += recon_l\n",
        "                epoch_kl += kl_l\n",
        "                update_count += 1\n",
        "                n_batches += 1\n",
        "\n",
        "            scheduler.step()\n",
        "            avg_train_elbo = epoch_loss / n_batches\n",
        "\n",
        "            if verbose:\n",
        "               print(f\"[Epoch {epoch}] Train ELBO: {avg_train_elbo:.4f} | \"\n",
        "                  f\"Recon: {epoch_recon / n_batches:.4f} | KL: {epoch_kl / n_batches:.4f} | \"\n",
        "                  f\"Anneal: {anneal:.4f}\")\n",
        "\n",
        "            # ---------- Validation ----------\n",
        "            if val_loader is not None:\n",
        "               self.model.eval()\n",
        "               val_losses = []\n",
        "               with torch.no_grad():\n",
        "                   for vb in val_loader:\n",
        "                      vb = vb.to(self.device).float()\n",
        "                      logits, mu, logvar = self.model(vb, sample=False)\n",
        "                      logvar = torch.clamp(logvar, min=-10, max=10)\n",
        "                      vloss, vrec, vkl = self.model.loss_function(logits, vb, mu, logvar, anneal)\n",
        "                      val_losses.append(vloss.item() * len(vb))\n",
        "\n",
        "               val_loss = float(np.sum(val_losses) / len(val_dataset))\n",
        "\n",
        "               if verbose:\n",
        "                 print(f\"  -> Val ELBO: {val_loss:.4f}\")\n",
        "\n",
        "               # save best with early stopping\n",
        "               if val_loss < best_val_loss:\n",
        "                  best_val_loss = val_loss\n",
        "                  wait = 0\n",
        "                  torch.save({\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state_dict\": self.model.state_dict(),\n",
        "                    \"optimizer\": self.optimizer.state_dict(),\n",
        "                    \"n_users\": self.data.get_user_num(),\n",
        "                    \"n_items\": self.data.get_item_num(),\n",
        "                    \"hidden_dim\": self.config[\"vae_hidden_dim\"],\n",
        "                    \"latent_dim\": self.config[\"vae_latent_dim\"],\n",
        "                    \"config\": self.config,\n",
        "                    }, ckpt_file)\n",
        "                  self.logger.info(f\"Best model updated at epoch {epoch}, saved to {ckpt_file}\")\n",
        "               else:\n",
        "                  wait += 1\n",
        "                  if wait >= patience:\n",
        "                     print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "                     break\n",
        "\n",
        "        # reload best model\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "\n",
        "    def swap_items(self, lst, page_size, random_k):\n",
        "        total_pages = len(lst) // page_size\n",
        "        lst = lst[: total_pages * page_size]\n",
        "        for page in range(1, total_pages // 2 + 1):\n",
        "            start_idx = (page - 1) * page_size\n",
        "            end_idx = start_idx + page_size - 1\n",
        "            symmetric_start_idx = (total_pages - page) * page_size\n",
        "            symmetric_end_idx = symmetric_start_idx + page_size\n",
        "\n",
        "            for k in range(1, random_k + 1):\n",
        "                lst[end_idx - k], lst[symmetric_end_idx - k] = (\n",
        "                    lst[symmetric_end_idx - k],\n",
        "                    lst[end_idx - k],\n",
        "                )\n",
        "\n",
        "        return lst\n",
        "\n",
        "    def add_random_items(self, user, item_ids):\n",
        "        item_ids = self.swap_items(item_ids, self.page_size, self.random_k)\n",
        "        return item_ids\n",
        "\n",
        "    def ordered_probit_loglik(self, y_true, y_pred_int, K=5, taus=None):\n",
        "        \"\"\"\n",
        "        Compute log-likelihood for ordered probit model given integer predictions.\n",
        "\n",
        "        y_true : list or array\n",
        "           True ratings (1..K).\n",
        "        y_pred_int : list or array\n",
        "           Predicted integer ratings (1..K).\n",
        "        K : int\n",
        "           Number of rating categories (default 5).\n",
        "        taus : list or array, optional\n",
        "           Thresholds (default: equally spaced).\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(y_true) == len(y_pred_int), \"Mismatch in true vs predicted length\"\n",
        "        ll = 0.0\n",
        "        for t, p in zip(y_true, y_pred_int):\n",
        "           probs = self.data.ordered_probit_probs(p, K, taus)\n",
        "           ll += self.data.safe_log(probs[t-1])  # subtract 1 for 0-based index\n",
        "        avg_ll = ll / len(y_true)\n",
        "        return ll, avg_ll\n",
        "\n",
        "    def update_user_interactions(self, user_id, new_items):\n",
        "        \"\"\"\n",
        "        Updates the directory of user_id and interacted_items.\n",
        "        - interaction_dict: dict mapping user_id -> set of interacted item ids\n",
        "        - user_id: int or str\n",
        "        - new_items: iterable of item ids (list, set, etc)\n",
        "\n",
        "        After calling, interaction_dict[user_id] contains all unique interacted items.\n",
        "        \"\"\"\n",
        "        # Ensure the user's interaction set exists\n",
        "        if user_id not in self.interaction_dict:\n",
        "          self.interaction_dict[user_id] = set()\n",
        "\n",
        "        new_items = set(new_items) - self.interaction_dict[user_id]\n",
        "        self.interaction_dict[user_id].update(new_items)\n",
        "\n",
        "    def get_full_manual_items(self, user_id, gt_ratio, rd_ratio, total_items, read = None, heard = None):\n",
        "        \"\"\"\n",
        "        Get a list of manual items for a given user.\n",
        "        \"\"\"\n",
        "        gtruth_items = self.data.interrating[user_id]\n",
        "        gt_items = [item for item, rating in gtruth_items]\n",
        "        rd_items = self.data.get_full_items()\n",
        "\n",
        "        # Remove any gt_items from rd_items to avoid duplicates\n",
        "        rd_items = list(set(rd_items) - set(gt_items))\n",
        "\n",
        "        # 1. Determine counts\n",
        "        total_ratio = gt_ratio + rd_ratio\n",
        "        gt_count = round(total_items * gt_ratio / total_ratio)\n",
        "        rd_count = total_items - gt_count\n",
        "\n",
        "        # Make sure we don't try to sample more than available\n",
        "        gt_count = min(gt_count, len(gt_items))\n",
        "        rd_count = min(rd_count, len(rd_items))\n",
        "\n",
        "        # 2. Randomly sample\n",
        "        chosen_gt = random.sample(gt_items, gt_count) if gt_count > 0 else []\n",
        "        chosen_rd = random.sample(rd_items, rd_count) if rd_count > 0 else []\n",
        "\n",
        "        # 3. Combine and shuffle if desired\n",
        "        final_items = chosen_gt + chosen_rd\n",
        "\n",
        "        # items discriptions\n",
        "        sorted_item_names = self.data.get_item_names(final_items)\n",
        "        description = self.data.get_item_description_by_id(final_items)\n",
        "        eb_item = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([final_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return final_items, eb_item, chosen_gt\n",
        "\n",
        "    def get_full_sort_items(self, user, random=False):\n",
        "        \"\"\"\n",
        "        Get a list of sorted items for a given user.\n",
        "        \"\"\"\n",
        "        items = self.data.get_full_items()\n",
        "        user_tensor = torch.tensor(user)\n",
        "        items_tensor = torch.tensor(items)\n",
        "        sorted_items = self.model.get_full_sort_items(user_tensor, items_tensor)\n",
        "        if self.random_k > 0 and random == True:\n",
        "            sorted_items = self.add_random_items(user, sorted_items)\n",
        "        sorted_items = [item for item in sorted_items if item not in self.record[user]]\n",
        "        sorted_item_names = self.data.get_item_names(sorted_items)\n",
        "        description = self.data.get_item_description_by_id(sorted_items)\n",
        "        items = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([sorted_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return sorted_items, items\n",
        "\n",
        "    def get_item(self, idx):\n",
        "        item_name = self.data.get_item_names([idx])[0]\n",
        "        description = self.data.get_item_description_by_id([idx])[0]\n",
        "        item = item_name + \";;\" + description\n",
        "        return item\n",
        "\n",
        "    def get_search_items(self, item_name):\n",
        "        return self.data.search_items(item_name)\n",
        "\n",
        "    def get_inter_num(self):\n",
        "        return self.inter_num\n",
        "\n",
        "    def update_history_by_name(self, user_id, item_names):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        item_names = [item_name.strip(\" <>'\\\"\") for item_name in item_names]\n",
        "        item_ids = self.data.get_item_ids(item_names)\n",
        "        self.record[user_id].extend(item_ids)\n",
        "\n",
        "    def update_history_by_id(self, user_id, item_ids):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        self.record[user_id].extend(item_ids)\n",
        "\n",
        "    def update_positive(self, user_id, item_names):\n",
        "        \"\"\"\n",
        "        Update the positive history of a given user.\n",
        "        \"\"\"\n",
        "        item_ids = self.data.get_item_ids(item_names)\n",
        "        if len(item_ids) == 0:\n",
        "            return\n",
        "        self.positive[user_id].extend(item_ids)\n",
        "        self.inter_num += len(item_ids)\n",
        "\n",
        "    def update_positive_by_id(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        self.positive[user_id].append(item_id)\n",
        "\n",
        "    def save_interaction(self):\n",
        "        \"\"\"\n",
        "        Save the interaction history to a csv file.\n",
        "        \"\"\"\n",
        "        inters = []\n",
        "        users = self.data.get_full_users()\n",
        "        for user in users:\n",
        "            for item in self.positive[user]:\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 1}\n",
        "                inters.append(new_row)\n",
        "\n",
        "            for item in self.record[user]:\n",
        "                if item in self.positive[user]:\n",
        "                    continue\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 0}\n",
        "                inters.append(new_row)\n",
        "\n",
        "        df = pd.DataFrame(inters)\n",
        "        df.to_csv(\n",
        "            self.config[\"interaction_path\"],\n",
        "            index=False,\n",
        "        )\n",
        "\n",
        "        self.inter_df = df\n",
        "\n",
        "    def add_train_data(self, user, item, label):\n",
        "        self.train_data.append((user, item, label))\n",
        "\n",
        "    def clear_train_data(self):\n",
        "        self.train_data = []\n",
        "\n",
        "    def add_user(self, user_id, N_expose, N_view, N_like, N_exit, S_sat):\n",
        "        self.user_data[\"user\"].append(user_id)\n",
        "        self.user_data[\"N_expose\"].append(N_expose)\n",
        "        self.user_data[\"N_view\"].append(N_view)\n",
        "        self.user_data[\"N_like\"].append(N_like)\n",
        "        self.user_data[\"N_exit\"].append(N_exit)\n",
        "        self.user_data[\"S_sat\"].append(S_sat)\n",
        "\n",
        "    def add_review(self, user_id, rating, feelings):\n",
        "        self.rating_feeling[\"User\"].append(user_id)\n",
        "        self.rating_feeling[\"Rating\"].append(rating)\n",
        "        self.rating_feeling[\"Feelings\"].append(feelings)\n",
        "\n",
        "    def satisfaction_metrics(self):\n",
        "        sm_df = pd.DataFrame(self.user_data)\n",
        "        if len(sm_df) == 0:\n",
        "           return None  # no data yet\n",
        "\n",
        "        metrics = {}\n",
        "        sm_df[\"view_ratio\"] = sm_df[\"N_view\"] / sm_df[\"N_expose\"]\n",
        "        sm_df[\"like_ratio\"] = sm_df[\"N_like\"] / sm_df[\"N_expose\"]\n",
        "\n",
        "        metrics[\"P_view\"] = sm_df[\"view_ratio\"].mean()\n",
        "        metrics[\"N_like\"] = sm_df[\"N_like\"].mean()\n",
        "        metrics[\"P_like\"] = sm_df[\"like_ratio\"].mean()\n",
        "        metrics[\"N_exit\"] = sm_df[\"N_exit\"].mean()\n",
        "        metrics[\"S_sat\"] = sm_df[\"S_sat\"].mean()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_entropy(\n",
        "        self,\n",
        "    ):\n",
        "        tot_entropy = 0\n",
        "        for user in self.record.keys():\n",
        "            inters = self.record[user]\n",
        "            genres = self.data.get_genres_by_id(inters)\n",
        "            entropy = calculate_entropy(genres)\n",
        "            tot_entropy += entropy\n",
        "\n",
        "        return tot_entropy / len(self.record.keys())\n",
        "\n",
        "    def check_train_data(self):\n",
        "        \"\"\"\n",
        "        Print or inspect the training data.\n",
        "        \"\"\"\n",
        "        print(\"Training Data:\")\n",
        "        for user, item, label in self.train_data:\n",
        "            print(f\"User: {user}, Item: {item}, Label: {label}\")\n",
        "\n",
        "    def create_train_data(self):\n",
        "        \"\"\"\n",
        "        Create a training dataset with random samples.\n",
        "\n",
        "        Args:\n",
        "            num_samples (int): Number of samples to generate.\n",
        "        \"\"\"\n",
        "        self.clear_train_data()  # Clear existing training data\n",
        "        all_data = self.data.interrating  # You need to implement this or use available interaction data\n",
        "\n",
        "        # Convert dict to list of (user, item, label)\n",
        "        # triplets = []\n",
        "        for user, interactions in all_data.items():\n",
        "            for item, rating in interactions:\n",
        "                self.add_train_data(user, item, float(rating))\n",
        "                # triplets.append((user, item, float(rating)))  # keep exact rating\n",
        "\n",
        "        # Split 80% train, 20% temp (to further split into val/test)\n",
        "        self.train_data, self.temp_data = train_test_split(self.train_data, test_size=0.2, random_state=2025)\n",
        "\n",
        "        # Split temp into 10% val and 10% test (from the total dataset)\n",
        "        self.val_data, self.test_data = train_test_split(self.temp_data, test_size=0.5, random_state=2025)\n",
        "\n",
        "        train_users = max([u for u, i, r in self.train_data]) + 1\n",
        "        train_items = max([i for u, i, r in self.train_data]) + 1\n",
        "\n",
        "        val_users = max([u for u, i, r in self.val_data]) + 1\n",
        "        val_items = max([i for u, i, r in self.val_data]) + 1\n",
        "\n",
        "        test_users = max([u for u, i, r in self.test_data]) + 1\n",
        "        test_items = max([i for u, i, r in self.test_data]) + 1\n",
        "\n",
        "        n_items_global = int(self.data.get_item_num())\n",
        "\n",
        "        # Initialize user-item matrix\n",
        "        self.train_matrix = np.zeros((train_users, n_items_global), dtype=np.float32)\n",
        "        self.val_matrix = np.zeros((val_users, n_items_global), dtype=np.float32)\n",
        "        self.test_matrix = np.zeros((test_users, n_items_global), dtype=np.float32)\n",
        "\n",
        "        # Fill interactions safely\n",
        "        for u, i, r in self.train_data:\n",
        "           if i >= n_items_global: continue  # skip bad indices\n",
        "           self.train_matrix[u, i] = r\n",
        "\n",
        "        for u, i, r in self.val_data:\n",
        "           if i >= n_items_global: continue\n",
        "           self.val_matrix[u, i] = r\n",
        "\n",
        "        for u, i, r in self.test_data:\n",
        "           if i >= n_items_global: continue\n",
        "           self.test_matrix[u, i] = r\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_user_metrics(\n",
        "        self, user_id, sim_recommended, all_items, threshold = 3):\n",
        "        \"\"\"\n",
        "        Evaluate precision, recall, (optionally real) accuracy, and F1 for a single user.\n",
        "\n",
        "        Returns:\n",
        "            dict: { 'precision': float, 'recall': float, 'accuracy': float, 'f1': float }\n",
        "        \"\"\"\n",
        "\n",
        "        if user_id not in self.data.interrating:\n",
        "           return {'precision': 0, 'recall': 0, 'accuracy': 0, 'f1': 0}\n",
        "\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= threshold and item in all_items)\n",
        "        sim_recommended = set(sim_recommended)\n",
        "        all_items = set(all_items)\n",
        "\n",
        "        TP = len(gt_relevant & sim_recommended)\n",
        "        FP = len(sim_recommended - gt_relevant)\n",
        "        FN = len(gt_relevant - sim_recommended)\n",
        "        TN = len(all_items - (gt_relevant | sim_recommended))\n",
        "\n",
        "        precision = TP / (TP + FP) if (TP + FP) else 0.0\n",
        "        recall = TP / (TP + FN) if (TP + FN) else 0.0\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0.0\n",
        "        accuracy = (TP + TN) / len(all_items) if all_items else 0\n",
        "\n",
        "        print(\"precision:\", precision, \"recall:\", recall, \"accuracy:\", accuracy, \"f1:\", f1)\n",
        "        return precision, recall, accuracy, f1\n",
        "\n",
        "    def precisionandrecallk(\n",
        "        self, user_id, recommended, k):\n",
        "        if user_id not in self.data.interrating:\n",
        "           return {'precision_at_k': 0, 'recall_at_k': 0}\n",
        "\n",
        "        sim_recommended = list(dict.fromkeys(recommended))\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= 3)\n",
        "        recommended_at_k = sim_recommended[:k]\n",
        "        hits = sum([1 for item in recommended_at_k if item in gt_relevant])\n",
        "        precision_at_k = hits / k\n",
        "        recall_at_k = hits / len(gt_relevant) if gt_relevant else 0\n",
        "        return precision_at_k, recall_at_k\n",
        "\n",
        "\n",
        "    def calculation_of_rating(self, user_id, item_names, book_rating):\n",
        "        item_ids = self.data.get_item_ids([item_names])\n",
        "        if user_id in self.data.interrating:\n",
        "           # Check for item in user's ratings\n",
        "           for (itm, rating) in self.data.interrating[user_id]:\n",
        "               if itm == item_ids[0]:\n",
        "                  return (rating, book_rating)\n",
        "\n",
        "        # If not found\n",
        "        return (0, book_rating)\n",
        "\n",
        "\n",
        "    def calc_mse_rmse_rating_percentages(self, rating_pairs):\n",
        "\n",
        "        print(\"Incoming rating_pairs:\", rating_pairs[:20])  # show first 20 pairs\n",
        "        print(\"Total pairs:\", len(rating_pairs))\n",
        "\n",
        "        # Remove pairs with zero in ground truth or predicted rating\n",
        "        filtered_pairs = [(gt, pred) for gt, pred in rating_pairs\n",
        "                          if int(gt) != 0]\n",
        "\n",
        "        print(\"After filtering:\", filtered_pairs[:20])\n",
        "        print(\"Remaining pairs:\", len(filtered_pairs))\n",
        "\n",
        "        if not filtered_pairs:\n",
        "           # No valid data after filtering\n",
        "           return None, None, {}, {}, None, None, None\n",
        "\n",
        "        # Convert ratings to int\n",
        "        gt = [int(gt) for gt, pred in filtered_pairs]\n",
        "        pred = [int(pred) for gt, pred in filtered_pairs]\n",
        "        mse = np.mean([(g - p) ** 2 for g, p in zip(gt, pred)])\n",
        "        rmse = np.sqrt(mse)\n",
        "        loglike, ob_loglike = self.ordered_probit_loglik(gt, pred)\n",
        "        rho, p_value = spearmanr(gt, pred)\n",
        "\n",
        "        gt_count = Counter(gt)\n",
        "        pred_count = Counter(pred)\n",
        "        total = len(filtered_pairs)\n",
        "\n",
        "        gt_pct = {r: gt_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        pred_pct = {r: pred_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        return mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, rho\n",
        "\n",
        "\n",
        "    def test_recommendations(self, user_id):\n",
        "        # Get the full list of items\n",
        "        all_items = self.data.get_full_items()\n",
        "\n",
        "        # Convert the user ID to tensor\n",
        "        user_tensor = torch.tensor(user_id)\n",
        "\n",
        "        # Convert all items to tensor\n",
        "        items_tensor = torch.tensor(all_items)\n",
        "\n",
        "        # Get sorted items based on the model's prediction\n",
        "        sorted_items = self.model.get_full_sort_items(user_tensor, items_tensor)\n",
        "\n",
        "        # Filter out items that are already in the user's history\n",
        "        recommended_items = [item for item in sorted_items if item not in self.record[user_id]]\n",
        "\n",
        "        # Return the recommended items\n",
        "        return recommended_items\n",
        "\n",
        "    def evaluate(self, dataset):\n",
        "        self.model.eval()\n",
        "        users = torch.tensor([x[0] for x in dataset])\n",
        "        items = torch.tensor([x[1] for x in dataset])\n",
        "        labels = torch.tensor([x[2] for x in dataset]).float()\n",
        "\n",
        "        with torch.no_grad():\n",
        "             outputs = self.model(users, items)\n",
        "             loss = self.criterion(outputs, labels)\n",
        "        return loss.item()\n",
        "\n",
        "    def load_checkpoint(self, path=\"best_model.pth\", resume_training=False):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        if resume_training:\n",
        "           # Load optimizer state to resume training exactly where it left off\n",
        "           self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "           start_epoch = checkpoint[\"epoch\"]\n",
        "           self.logger.info(f\"Resuming training from epoch {start_epoch}\")\n",
        "           return start_epoch\n",
        "        else:\n",
        "           self.model.eval()  # set to eval mode for inference\n",
        "\n",
        "    def train_mf(self):\n",
        "        if len(self.train_data) == 0:\n",
        "            print(\"No training data!\")\n",
        "            return\n",
        "\n",
        "        users = [x[0] for x in self.train_data]\n",
        "        items = [x[1] for x in self.train_data]\n",
        "        labels = [x[2] for x in self.train_data]\n",
        "\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(\n",
        "        torch.tensor(users), torch.tensor(items), torch.tensor(labels))\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=self.config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MF_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        for epoch in range(self.epoch_num):\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            for user, item, label in train_loader:\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(user, item)\n",
        "                loss = self.criterion(outputs, label.float())\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            val_loss = self.evaluate(self.val_data)  # Evaluate on validation set\n",
        "\n",
        "            self.logger.info(\n",
        "            f\"Epoch {epoch+1}/{self.epoch_num}, Train Loss: {epoch_loss/len(train_loader):.4f}, \"\n",
        "            f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "            # Save checkpoint if validation improves\n",
        "            if val_loss < best_val_loss:\n",
        "               best_val_loss = val_loss\n",
        "               torch.save({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
        "                \"val_loss\": val_loss,\n",
        "                }, ckpt_file)\n",
        "               self.logger.info(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        # At the end, reload the best weights for inference\n",
        "        checkpoint = torch.load(ckpt_file)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def load_best_model(self):\n",
        "        if self.config['rec_model'] == 'MF':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MF_model.pth\")\n",
        "        elif self.config['rec_model'] == 'MultiVAE':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MultiVAE_model.pth\")\n",
        "        elif self.config['rec_model'] == 'LightGCN':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_lightGCN_model.pth\")\n",
        "        elif self.config['rec_model'] == 'FM':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_FM_model.pth\")\n",
        "        elif self.config['rec_model'] == 'SASRec':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_SASRec_model.pth\")\n",
        "        else:\n",
        "           raise ValueError(f\"Unknown model type: {self.config['rec_model']}\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        checkpoint = torch.load(ckpt_file)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.eval()\n",
        "        self.logger.info(f\"Loaded best model from {ckpt_file}\")\n",
        "\n",
        "    def get_rec_discription(self, final_items):\n",
        "        # items discriptions\n",
        "        sorted_item_names = self.data.get_item_names(final_items)\n",
        "        description = self.data.get_item_description_by_id(final_items)\n",
        "        eb_item = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([final_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return eb_item\n",
        "\n",
        "    def get_full_rankings(self, use_test=False, batch_size=512):\n",
        "        \"\"\"\n",
        "        Compute full rankings for all users in self.data.\n",
        "        - training items are pushed to the end\n",
        "        - optionally, ground-truth test items can be put on top\n",
        "        \"\"\"\n",
        "        if self.config['rec_model'] == 'MF':\n",
        "           n_users = self.data.get_user_num()\n",
        "           n_items = self.data.get_item_num()\n",
        "\n",
        "           item_embed = self.model.item_embedding.weight[:n_items, :]\n",
        "\n",
        "           self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "           for user in range(n_users):\n",
        "              user_tensor = torch.tensor([user])\n",
        "              user_embed = self.model.user_embedding(user_tensor)\n",
        "\n",
        "              scores = torch.matmul(user_embed, item_embed.T).squeeze(0).detach().numpy()\n",
        "\n",
        "              # Only consider valid item indices\n",
        "              train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "              scores[train_items] = -np.inf\n",
        "\n",
        "              self.full_rankings[user] = np.argsort(-scores)\n",
        "\n",
        "              # # Optionally move ground-truth test items on top\n",
        "              if use_test:\n",
        "                 test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                 for idx, item in enumerate(test_items):\n",
        "                    if item in self.full_rankings[user]:\n",
        "                       current_pos = np.where(self.full_rankings[user] == item)[0][0]\n",
        "                       self.full_rankings[user][idx], self.full_rankings[user][current_pos] = (\n",
        "                         self.full_rankings[user][current_pos],\n",
        "                         self.full_rankings[user][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'LightGCN':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            # === 1. Get all user/item embeddings from LightGCN ===\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                all_user_emb, all_item_emb = self.model.propagate()\n",
        "                # shapes: (n_users, embed_dim), (n_items, embed_dim)\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            for user in range(n_users):\n",
        "               # Get user embedding\n",
        "               user_embed = all_user_emb[user].unsqueeze(0)   # (1, embed_dim)\n",
        "\n",
        "               # Compute scores for all items (dot product)\n",
        "               scores = torch.matmul(user_embed, all_item_emb.T).squeeze(0).cpu().numpy()\n",
        "\n",
        "               # Push training items to -inf\n",
        "               train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "               scores[train_items] = -np.inf\n",
        "\n",
        "               # Sort descending\n",
        "               self.full_rankings[user] = np.argsort(-scores)\n",
        "\n",
        "               # # Optionally move ground-truth test items on top\n",
        "               if use_test:\n",
        "                  test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                  for idx, item in enumerate(test_items):\n",
        "                     if item in self.full_rankings[user]:\n",
        "                        current_pos = np.where(self.full_rankings[user] == item)[0][0]\n",
        "                        self.full_rankings[user][idx], self.full_rankings[user][current_pos] = (\n",
        "                           self.full_rankings[user][current_pos],\n",
        "                           self.full_rankings[user][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'MultiVAE':\n",
        "            # n_users = self.data.get_user_num()\n",
        "            # n_items = self.data.get_item_num()\n",
        "            if use_test:\n",
        "               matrix = self.test_matrix\n",
        "            else:\n",
        "               matrix = self.train_matrix\n",
        "\n",
        "            n_users, n_items = matrix.shape\n",
        "\n",
        "            self.model.eval()\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for start in range(0, n_users, batch_size):\n",
        "                   end = min(start + batch_size, n_users)\n",
        "\n",
        "                   # === 1. Build user input batch (interaction vectors) ===\n",
        "                   batch_users = []\n",
        "                   for u in range(start, end):\n",
        "                      row = self.train_matrix[u]  # should return (n_items,) vector\n",
        "                      batch_users.append(row)\n",
        "                   batch_users = torch.tensor(batch_users, dtype=torch.float32).to(self.model.device)\n",
        "\n",
        "                   # === 2. Forward pass through MultiVAE ===\n",
        "                   logits, mu, logvar = self.model(batch_users)   # shape: (batch_size, n_items)\n",
        "                   scores = logits.cpu().numpy()\n",
        "\n",
        "                   # === 3. Postprocess each user in batch ===\n",
        "                   for i, u in enumerate(range(start, end)):\n",
        "                      user_scores = scores[i]\n",
        "\n",
        "                      train_items = [x[1] for x in self.train_data if x[0] == u and x[1] < n_items]\n",
        "                      user_scores[train_items] = -np.inf\n",
        "\n",
        "                      # Sort items by descending score\n",
        "                      self.full_rankings[u] = np.argsort(-user_scores)\n",
        "\n",
        "                      # Optionally move ground-truth test items on top\n",
        "                      if use_test:\n",
        "                         test_items = [x[1] for x in self.test_data if x[0] == u and x[1] < n_items]\n",
        "                         for idx, item in enumerate(test_items):\n",
        "                            if item in self.full_rankings[u]:\n",
        "                               current_pos = np.where(self.full_rankings[u] == item)[0][0]\n",
        "                               self.full_rankings[u][idx], self.full_rankings[u][current_pos] = (\n",
        "                                   self.full_rankings[u][current_pos],\n",
        "                                   self.full_rankings[u][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'FM':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            self.model.eval()\n",
        "            device = next(self.model.parameters()).device\n",
        "\n",
        "            for user in range(n_users):\n",
        "               # Generate all item IDs\n",
        "               item_ids = torch.arange(n_items, device=device)\n",
        "               user_ids = torch.full((n_items,), user, dtype=torch.long, device=device)\n",
        "\n",
        "               # Compute scores using FM forward\n",
        "               with torch.no_grad():\n",
        "                  scores = self.model(user_ids, item_ids).cpu().numpy()\n",
        "\n",
        "               # Push training items to the end\n",
        "               train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "               scores[train_items] = -np.inf\n",
        "\n",
        "               # Sort items by descending score\n",
        "               ranking = np.argsort(-scores)\n",
        "\n",
        "               # Optionally move ground-truth test items to the top\n",
        "               if use_test:\n",
        "                  test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                  for idx, item in enumerate(test_items):\n",
        "                     if item in ranking:\n",
        "                        current_pos = np.where(ranking == item)[0][0]\n",
        "                        ranking[idx], ranking[current_pos] = ranking[current_pos], ranking[idx]\n",
        "\n",
        "               self.full_rankings[user] = ranking\n",
        "\n",
        "        elif self.config['rec_model'] == 'SASRec':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "            self.model.eval()\n",
        "            device = next(self.model.parameters()).device\n",
        "\n",
        "            with torch.no_grad():\n",
        "               for start in range(0, n_users, batch_size):\n",
        "                  end = min(start + batch_size, n_users)\n",
        "                  batch_users = list(range(start, end))\n",
        "\n",
        "                  # Build input sequences for batch\n",
        "                  batch_seqs = []\n",
        "                  for u in batch_users:\n",
        "                     # Get user interaction sequence from train_data\n",
        "                     user_items = [x[1] for x in self.train_data if x[0] == u]\n",
        "                     padded_seq = _pad_sequence(user_items, self.model.max_seq_len)\n",
        "                     batch_seqs.append(padded_seq)\n",
        "\n",
        "                  batch_seqs = torch.tensor(batch_seqs, dtype=torch.long, device=device)\n",
        "\n",
        "                  # Forward pass: get sequence embeddings\n",
        "                  seq_out = self.model(batch_seqs)  # (B, L, H)\n",
        "                  seq_out_last = seq_out[:, -1, :]  # use last position (B, H)\n",
        "\n",
        "                  # All item embeddings\n",
        "                  all_item_emb = self.model.item_embedding.weight[:n_items, :]  # (n_items, H)\n",
        "\n",
        "                  # Compute scores\n",
        "                  scores = torch.matmul(seq_out_last, all_item_emb.T)  # (B, n_items)\n",
        "                  scores = scores.cpu().numpy()\n",
        "\n",
        "                  # Mask training items\n",
        "                  for i, u in enumerate(batch_users):\n",
        "                     train_items = [x[1] for x in self.train_data if x[0] == u and x[1] < n_items]\n",
        "                     scores[i, train_items] = -np.inf  # push train items to the end\n",
        "\n",
        "                     ranking = np.argsort(-scores[i])  # full ranking by score (highest first)\n",
        "                     if use_test:\n",
        "                        test_items = [x[1] for x in self.test_data if x[0] == u and x[1] < n_items]\n",
        "                        # Keep only test items that appear in ranking\n",
        "                        test_items_in_ranking = [item for item in ranking if item in test_items]\n",
        "                        # Take at most 5 test items\n",
        "                        top_test_items = test_items_in_ranking[:5]\n",
        "                        # Remaining items (exclude the ones we forced to the top)\n",
        "                        other_items = [item for item in ranking if item not in top_test_items]\n",
        "\n",
        "                        # New ranking: top test items first, then the rest in score order\n",
        "                        ranking = np.array(top_test_items + other_items)\n",
        "                     # Store final ranking\n",
        "                     self.full_rankings[u] = ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAhGbgdkrnD"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import random\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "# from random import random\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SensoryMemory():\n",
        "    \"\"\"\n",
        "    Sensory memory is intended to receive the observations (that are ready to be stored as memories) from the environment,\n",
        "    extract and summarize important elements by attention mechanism, and output them to short term memory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm, buffer_size=1):\n",
        "        \"\"\"\n",
        "        Initialize the sensory memory.\n",
        "        :param llm: The LLM object passed from RecAgentMemory.\n",
        "        :param buffer_size (default as 1): Maximum number of observations. When len(self.buffer) >= buffer_size,\n",
        "            then dump them as a piece of short term memory.\n",
        "        \"\"\"\n",
        "\n",
        "        self.llm = llm\n",
        "        self.buffer_size = buffer_size\n",
        "\n",
        "        # Important weight can be used to adjust the balance between 'importance' and 'recency'.\n",
        "        self.importance_weight = 0.9\n",
        "\n",
        "        # Store a batch of observations.\n",
        "        self.buffer = []\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"\n",
        "        Clear the short term memory.\n",
        "        \"\"\"\n",
        "        self.buffer = []\n",
        "\n",
        "    def _score_memory_importance(self, observation: str) -> float:\n",
        "        \"\"\"\n",
        "        Obtain the importance score of this memory.\n",
        "        :param observation: The text of the observation.\n",
        "        :return: (float) The importance of this observation.\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Please give an importance score between 1 to 10 for the following observation. Higher score indicates the observation is more important. More rules that should be followed are\n",
        "            \\n(1) The observation that includes entering social media is not important. e.g., David Smith takes action by entering the world of social media.\n",
        "            \\n(2) The observation that describes chatting with someone but no specific book name is not important. e.g., David Smith observed that David Miller expressed interest in chatting about books.\n",
        "            \\n(3) The observation that includes 'chatting' is not important. e.g., David Smith observed that David Miller expressed interest in chatting about movies, indicating a shared passion for films.\n",
        "            \\n(4) The observation that includes 'enter the recommender system' is not important. e.g. David Smith enters the Recommender System to explore book recommendations based on his interests and preferences.\n",
        "            \\n(5) The observation that recommends or mentions specific books is important.\n",
        "            \\n(6) More informative indicates more important, especially when two people are chatting.\n",
        "            Please respond with a single integer.\n",
        "            \\nObservation:{observation}\n",
        "            \\nRating:\n",
        "            \"\"\"\n",
        "        )\n",
        "        score = LLMChain(llm=self.llm, prompt=prompt).run(observation=observation).strip()\n",
        "        match = re.search(r\"^\\D*(\\d+)\", score)\n",
        "        if match:\n",
        "            return (float(match.group(1)) / 10) * self.importance_weight\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def dump_shortTerm_list(self):\n",
        "        \"\"\"\n",
        "        Convert all the observations in buffer to a piece of short term memory, and clear the buffer.\n",
        "        :return: List of tuple (score[float], stm[str])\n",
        "        \"\"\"\n",
        "\n",
        "        def parse_res(text: str):\n",
        "            \"\"\"\n",
        "            Parse the output of LLM.\n",
        "            \"\"\"\n",
        "            return [text]\n",
        "\n",
        "        # Construct a string which includes all the observations in the buffer.\n",
        "        obs_str = \"The observations are as following:\\n\"\n",
        "        for ind, obs in enumerate(self.buffer):\n",
        "            obs_str += \"[%d] %s\\n\" % (ind, obs)\n",
        "\n",
        "        # Construct the order for converting.\n",
        "        order_str = \"You should summarize the above observation(s) into one independent sentence.\" \\\n",
        "                    \"If there is a person's name in the observation, use third person, otherwise use first person. \" \\\n",
        "                    \"Note that the sentence should pay more attention to the book interest and the reasons in the \" \\\n",
        "                    \"observations.\" \\\n",
        "                    \"The summarization should not include the profile explicitly.\"\n",
        "\n",
        "        # Construct the prompt for LLM.\n",
        "        prompt = PromptTemplate.from_template(obs_str + order_str)\n",
        "        result = LLMChain(llm=self.llm, prompt=prompt).run({})\n",
        "        result = parse_res(result)\n",
        "        # Give the short term memory an importance score.\n",
        "        result = [(self._score_memory_importance(text), text) for text in result]\n",
        "        # Remove the short term memory whose importance score is lower than a threshold.\n",
        "        result = [text for text in result if text[0] > 0.62]\n",
        "\n",
        "        # Clear the buffer.\n",
        "        self.clear()\n",
        "\n",
        "        if len(result) != 0:\n",
        "            return result\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def add_ssm(self, obs):\n",
        "        \"\"\"\n",
        "        This function is only called in the function RecAgentMemory.save_context(). It is used to transport observations to a piece of short term memory.\n",
        "        For each time, it receives only one observation, and adds into buffer. If buffer is full, then converts them into a piece of term memory.\n",
        "        :param obs: The observation that is ready to transport to short term memory.\n",
        "        :return: (1)Buffer full: List of tuple (score[float], stm[str]). (2) Buffer not full: None.\n",
        "        \"\"\"\n",
        "        # Add the observation into the buffer.\n",
        "        self.buffer.append(obs)\n",
        "\n",
        "        # If the buffer is full, then dump and return the short term list to RecAgentMemory.\n",
        "        # If the buffer is not full, then directly return 'None'.\n",
        "        if len(self.buffer) >= self.buffer_size:\n",
        "            return self.dump_shortTerm_list()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "class ShortTermMemory():\n",
        "    \"\"\"\n",
        "    The short-term memory module is to temporally store the observations from sensory memory module,\n",
        "    which can be enhanced by other observations or retrieved memories to enter the long-term memory module.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        \"\"\"The core language model.\"\"\"\n",
        "        self.verbose: bool = False\n",
        "\n",
        "        self.capacity: int = 10\n",
        "        \"\"\"The capacity of Short-term memory\"\"\"\n",
        "\n",
        "        self.short_memories: List[str] = []\n",
        "        \"\"\"The list of short-term memories\"\"\"\n",
        "\n",
        "        self.short_embeddings: List[List[float]] = []\n",
        "        \"\"\"The OpenAI embeddings of short-term memories\"\"\"\n",
        "\n",
        "        self.memory_importance: List[float] = []\n",
        "        \"\"\"The importance score list of short-term memories\"\"\"\n",
        "\n",
        "        self.enhance_cnt: List[int] = [0 for _ in range(self.capacity)]\n",
        "        \"\"\"The number of enhancement of short-term memories\"\"\"\n",
        "\n",
        "        self.enhance_memories: List[List[str]] = [[] for _ in range(self.capacity)]\n",
        "        \"\"\"The enhance memory of each short-term memory\"\"\"\n",
        "\n",
        "        self.enhance_threshold: int = 3\n",
        "        \"\"\"Summary the short-term memory with enhanced count larger or equal than the threshold\"\"\"\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_list(text: str) -> List[str]:\n",
        "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
        "        lines = re.split(r\"\\n\", text.strip())\n",
        "        lines = [line for line in lines if line.strip()]  # remove empty lines\n",
        "        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n",
        "\n",
        "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
        "        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "\n",
        "    def get_short_term_insight(self, content: str):\n",
        "        \"\"\"\n",
        "        Get insight of the short-term memory and other memories or observations that enhance that short-term memory.\n",
        "        :param content: short-term memory and other memories or observations that enhance that short-term memory\n",
        "        :return: (List[str]) The insight of the short-term memory.\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"There are some memories separated by semicolons (;): {content}\\n\"\n",
        "            + \"Can you infer from the above memories the high-level insight for this person's character?\"\n",
        "            + \"The insight needs to be significantly different from the content and structure of the original memories.\"\n",
        "            + \"Respond in one sentence.\"\n",
        "            + \"\\n\\nResults:\"\n",
        "        )\n",
        "        result = self.chain(prompt).run(content=content).strip()\n",
        "        return self._parse_list(result)\n",
        "\n",
        "    def transfer_memories(self, observation):\n",
        "        \"\"\"\n",
        "        Transfer all possible short-term memories to long-term memory.\n",
        "        :param observation: the observation enters the short-term memory or the retrieved memory\n",
        "        :return\n",
        "            (List[str]) memory_content: the enhanced short-term memories\n",
        "            (List[float]) memory_importance: the importance scores of the enhanced short-term memories\n",
        "            (List[List[str]]) insight_content: the insight from the short-term memories\n",
        "        \"\"\"\n",
        "        # if the observation is summarized, otherwise add it into short-term memory\n",
        "        transfer_flag = False\n",
        "        existing_memory = [True for _ in range(len(self.short_memories))]\n",
        "        memory_content, memory_importance, insight_content = [], [], []\n",
        "        for idx, memory in enumerate(self.short_memories):\n",
        "            if self.enhance_cnt[idx] >= self.enhance_threshold or existing_memory[idx] is True:\n",
        "                existing_memory[idx] = False\n",
        "                transfer_flag = True\n",
        "                # combine all existing related memories to current memory in short-term memories\n",
        "                content = [memory]\n",
        "                # do not repeatedly add observation memory to summary, so use [:-1].\n",
        "                for enhance_memory in self.enhance_memories[idx][:-1]:\n",
        "                    content.append(enhance_memory)\n",
        "                content.append(observation)\n",
        "                content = ';'.join(content)\n",
        "                memory_content.append(memory)\n",
        "                # memory_importance.append(self.memory_importance[idx])\n",
        "                insight = self.get_short_term_insight(content)\n",
        "                insight_content.append(insight)\n",
        "\n",
        "        # remove the transferred memories from short-term memories\n",
        "        if transfer_flag:\n",
        "            # re-construct the indexes of short-term memories after removing summarized memories\n",
        "            new_memories = []\n",
        "            new_embeddings = []\n",
        "            new_importance = []\n",
        "            new_enhance_memories = [[] for _ in range(self.capacity)]\n",
        "            new_enhance_cnt = [0 for _ in range(self.capacity)]\n",
        "            for idx, memory in enumerate(self.short_memories):\n",
        "                if existing_memory[idx]:  # True\n",
        "                    new_enhance_memories[len(new_memories)] = self.enhance_memories[idx]\n",
        "                    new_enhance_cnt[len(new_memories)] = self.enhance_cnt[idx]\n",
        "                    new_memories.append(memory)\n",
        "                    new_embeddings.append(self.short_embeddings[idx])\n",
        "                    new_importance.append(self.memory_importance[idx])\n",
        "            self.short_memories = new_memories\n",
        "            self.short_embeddings = new_embeddings\n",
        "            self.memory_importance = new_importance\n",
        "            self.enhance_memories = new_enhance_memories\n",
        "            self.enhance_cnt = new_enhance_cnt\n",
        "\n",
        "        if len(memory_content) > 0:\n",
        "            # print(\"memory_content is not None\")\n",
        "            if len(memory_importance) == 0:\n",
        "                memory_importance = [0.5]\n",
        "\n",
        "        return memory_content, memory_importance, insight_content\n",
        "\n",
        "    def discard_memories(self) -> str:\n",
        "        \"\"\"\n",
        "        discard the least importance memory when short-term memory module exceeds its capacity\n",
        "        :return: (str) The content of the discard memory\n",
        "        \"\"\"\n",
        "        if len(self.short_memories) > self.capacity:\n",
        "            memory_dict = dict()\n",
        "            for idx in range(len(self.short_memories) - 1):\n",
        "                memory_dict[self.short_memories[idx]] = {'enhance_count': self.enhance_cnt[idx],\n",
        "                                                         'importance': self.memory_importance[idx]}\n",
        "\n",
        "            sort_list = sorted(memory_dict.keys(),\n",
        "                               key=lambda x: (memory_dict[x]['importance'], memory_dict[x]['enhance_count']))\n",
        "            find_idx = self.short_memories.index(sort_list[0])\n",
        "            self.enhance_cnt.pop(find_idx)\n",
        "            self.enhance_cnt.append(0)\n",
        "            self.enhance_memories.pop(find_idx)\n",
        "            self.enhance_memories.append([])\n",
        "            self.memory_importance.pop(find_idx)\n",
        "            discard_memory = self.short_memories.pop(find_idx)\n",
        "            self.short_embeddings.pop(find_idx)\n",
        "\n",
        "            # remove the discard_memory from other short-term memory's enhanced list\n",
        "            for idx in range(len(self.short_memories)):\n",
        "                if self.enhance_memories[idx].count(sort_list[0]) != 0:\n",
        "                    self.enhance_memories[idx].remove(sort_list[0])\n",
        "                    self.enhance_cnt[idx] -= 1\n",
        "\n",
        "            return discard_memory\n",
        "\n",
        "    @staticmethod\n",
        "    def cosine_similarity(embedding1: List[float], embedding2: List[float]):\n",
        "        \"\"\"\n",
        "        Calculate the cosine similarity between two vectors.\n",
        "        :param embedding1: the first embedding\n",
        "        :param embedding2: the second embedding\n",
        "        :return: (float) the cosine similarity\n",
        "        \"\"\"\n",
        "        dot_product = np.dot(embedding1, embedding2)\n",
        "        norm1 = np.linalg.norm(embedding1)\n",
        "        norm2 = np.linalg.norm(embedding2)\n",
        "        similarity = dot_product / (norm1 * norm2)\n",
        "        return similarity\n",
        "\n",
        "\n",
        "    def add_stm_memory(self, observation: str, importance: float, op: str):\n",
        "        \"\"\"\n",
        "        Add a new observation into short-term memory, and return the enhanced short-term memory and with the insight.\n",
        "        :param observation: the content of the sensory memory of retrieved memory\n",
        "        :param imporatance: the importance score of observation\n",
        "        :param op: specify the types of observation. \"add\" means that the observation is sensory memory,\n",
        "                 \"retrieval\" means that the observation is the retrieved memory.\n",
        "        \"\"\"\n",
        "        const = 0.1\n",
        "        # compute the vector similarities between observation and the existing short-term memories\n",
        "        embeddings_model = OpenAIEmbeddings()\n",
        "        observation_embedding = embeddings_model.embed_query(observation)\n",
        "        for idx, memory_embedding in enumerate(self.short_embeddings):\n",
        "            similarity = self.cosine_similarity(observation_embedding, memory_embedding)\n",
        "            # primacy effect\n",
        "            # The following one line was corrected by Zeyu on 23.8.27-7pm. Ori: if idx + 1 == len(short_term_embeddings):\n",
        "            if idx + 1 == len(self.short_embeddings):\n",
        "                similarity += const\n",
        "            # sample and select the enhanced short-term memory\n",
        "            # Sigmoid function\n",
        "            prob = 1 / (1 + np.exp(-similarity))\n",
        "            if prob >= 0.7 and random.random() <= prob:\n",
        "                self.enhance_cnt[idx] += 1\n",
        "                self.enhance_memories[idx].append(observation)\n",
        "        memory_content, memory_importance, insight_content = self.transfer_memories(observation)\n",
        "        if op == \"add\":\n",
        "            self.short_memories.append(observation)\n",
        "            self.memory_importance.append(importance)\n",
        "            self.short_embeddings.append(observation_embedding)\n",
        "            self.discard_memories()\n",
        "        return memory_content, memory_importance, insight_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18VZ_nOTrAy2"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain.schema import BaseMemory\n",
        "import random\n",
        "import re\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.base_language import BaseLanguageModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.utils import mock_now\n",
        "\n",
        "import os\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "class Document:\n",
        "    \"\"\"Example Document class.\"\"\"\n",
        "    def __init__(self, page_content: str, metadata: dict = None):\n",
        "        self.page_content = page_content\n",
        "        if metadata is None:\n",
        "            metadata = {}\n",
        "        if \"created_at\" not in metadata:\n",
        "            metadata[\"created_at\"] = datetime.now()  # Set default created_at value\n",
        "        if \"last_accessed_at\" not in metadata:\n",
        "            metadata[\"last_accessed_at\"] = datetime.now()  # Set default last_accessed_at value\n",
        "        self.metadata = metadata\n",
        "\n",
        "class TimeWeightedVectorStoreRetriever:\n",
        "    \"\"\"Example TimeWeightedVectorStoreRetriever class.\"\"\"\n",
        "    def __init__(self, now: datetime, memory_stream: List[Document], vectorstore: Any):\n",
        "        self.now = now\n",
        "        self.memory_stream = memory_stream\n",
        "        self.vectorstore = vectorstore\n",
        "\n",
        "class RecAgentRetriever(TimeWeightedVectorStoreRetriever):\n",
        "    \"\"\"\n",
        "    RecAgentRetriever is to retrieve memories from long-term memory module based on memory salience, importance and recency.\n",
        "    \"\"\"\n",
        "    def __init__(self, now: datetime, memory_stream: List[Document], k: int, vectorstore: Any):\n",
        "        super().__init__(now, memory_stream, vectorstore)\n",
        "        self.k = k\n",
        "        self.default_salience = 0.5  # Add default_salience attribute\n",
        "\n",
        "    def get_salient_docs(self, query: str) -> Dict[int, float]:\n",
        "        \"\"\"\n",
        "        Return salient documents based on the query.\n",
        "\n",
        "        This method calculates the salience score for each document in the memory stream\n",
        "        based on the given query using TF-IDF cosine similarity.\n",
        "        \"\"\"\n",
        "        salient_docs = {}\n",
        "\n",
        "        # Filter out non-Document objects from memory_stream\n",
        "        document_memory_stream = [doc for doc in self.memory_stream if isinstance(doc, Document)]\n",
        "\n",
        "        # Extract text content from documents\n",
        "        document_texts = [doc.page_content for doc in document_memory_stream]\n",
        "\n",
        "        # Vectorize documents and query using TF-IDF\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        document_vectors = vectorizer.fit_transform(document_texts)\n",
        "        query_vector = vectorizer.transform([query])\n",
        "\n",
        "        # Calculate cosine similarity between query and documents\n",
        "        similarities = cosine_similarity(query_vector, document_vectors)[0]\n",
        "\n",
        "        # Assign similarity scores to documents\n",
        "        for i, doc in enumerate(document_memory_stream):\n",
        "            # print(\"\\nSimilarities check: \", doc.metadata, \"similar:\", similarities[i])\n",
        "            # salient_docs[doc.metadata[\"buffer_idx\"]] = similarities[i]\n",
        "            salient_docs[doc.metadata[\"importance\"]] = similarities[i]\n",
        "\n",
        "        return salient_docs\n",
        "\n",
        "    def add_documents(self, documents: List[Document], current_time: datetime):\n",
        "        \"\"\"\n",
        "        Add new documents to the memory stream.\n",
        "        \"\"\"\n",
        "        for document in documents:\n",
        "            document.metadata[\"last_accessed_at\"] = current_time\n",
        "            self.memory_stream.append(document)\n",
        "            # print(\"\\nDocuments in add Document:\", self.memory_stream, \"Page content in add document:\", document.page_content, \"Metadata in add document:\", document.metadata)\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"Return documents that are relevant to the query.\"\"\"\n",
        "        current_time = self.now\n",
        "        relevant_docs = [doc for doc in self.memory_stream if isinstance(doc, Document)]  # Filter out non-Document objects\n",
        "        docs_and_scores = {\n",
        "            doc: self.default_salience\n",
        "            # Calculate for all memories.\n",
        "            for doc in relevant_docs\n",
        "        }\n",
        "        # If a doc is considered salient, update the salience score\n",
        "        salient_docs = self.get_salient_docs(query)\n",
        "        for doc in salient_docs:\n",
        "            docs_and_scores[doc] = salient_docs[doc]\n",
        "        rescored_docs = [\n",
        "            (doc, relevance, 0.4)\n",
        "            for doc, relevance in docs_and_scores.items() if isinstance(doc, Document)  # Filter out non-Document objects\n",
        "        ]\n",
        "        rescored_docs.sort(key=lambda x: x[2], reverse=True)\n",
        "        result = []\n",
        "        # Ensure frequently accessed memories aren't forgotten\n",
        "        retrieved_num = 0\n",
        "        for doc, _, _ in rescored_docs:\n",
        "            if retrieved_num < self.k and doc.page_content.find('[FORGET]') == -1 \\\n",
        "                    and doc.page_content.find('[MERGE]') == -1:\n",
        "                retrieved_num += 1\n",
        "                # buffered_doc = self.memory_stream[doc.metadata['buffer_idx']]\n",
        "                doc.metadata[\"last_accessed_at\"] = current_time\n",
        "                # buffered_doc.metadata[\"last_accessed_at\"] = current_time\n",
        "                # result.append(buffered_doc)\n",
        "                result.append(doc)\n",
        "                # print(\"Memory result:\", result, \"Metadata:\", doc.page_content)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "class LongTermMemory(BaseMemory):\n",
        "    \"\"\"\n",
        "    Long-term memory is the memory base for the RecAgent.\n",
        "    \"\"\"\n",
        "    llm: BaseLanguageModel\n",
        "    now: datetime\n",
        "    memory_retriever: RecAgentRetriever\n",
        "\n",
        "    verbose: bool = False\n",
        "\n",
        "    reflection_threshold: Optional[float] = None\n",
        "    max_tokens_limit: int = 1000000000\n",
        "    aggregate_importance: float = 0.0\n",
        "    decay_rate: float = 0.01\n",
        "    \"\"\"The exponential decay factor used as (1.0-decay_rate)**(hrs_passed).\"\"\"\n",
        "\n",
        "    # input keys\n",
        "    queries_key: str = \"queries\"\n",
        "    most_recent_memories_token_key: str = \"recent_memories_token\"\n",
        "    add_memory_key: str = \"add_memory\"\n",
        "    # output keys\n",
        "    relevant_memories_key: str = \"relevant_memories\"\n",
        "    relevant_memories_simple_key: str = \"relevant_memories_simple\"\n",
        "    most_recent_memories_key: str = \"most_recent_memories\"\n",
        "    now_key: str = \"now\"\n",
        "\n",
        "    reflecting: bool = False\n",
        "    forgetting: bool = False\n",
        "\n",
        "    forget_num: int = 3\n",
        "\n",
        "    importance_weight: float = 0.15\n",
        "    \"\"\"How much weight to assign the memory importance.\"\"\"\n",
        "\n",
        "\n",
        "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
        "        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_list(text: str) -> List[str]:\n",
        "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
        "        lines = re.split(r\"\\n\", text.strip())\n",
        "        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_insight_with_connections(text: str):\n",
        "        \"\"\"\n",
        "    #     Parse the output of LLM to the insight and the corresponding connections.\n",
        "    #     :param text: The output of LLM.\n",
        "    #     :return: The insight, and the list of connections.\n",
        "    #     \"\"\"\n",
        "        pattern = r'\\[.*?\\]'\n",
        "        insight = re.sub(pattern, '', text)\n",
        "        nums = re.findall(r'\\d+', text)\n",
        "        if len(nums) != 0:\n",
        "            connection_list = list(map(int, nums))\n",
        "        else:\n",
        "            connection_list = [0]\n",
        "\n",
        "        return insight, connection_list\n",
        "\n",
        "\n",
        "    def _score_memory_importance(self, memory_content: str) -> float:\n",
        "        \"\"\"\n",
        "        Obtain the importance score of this memory.\n",
        "        :param memory_content: The text of the observation.\n",
        "        :return: (float) The importance of this observation.\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Please give an importance score between 1 to 10 for the following observation. Higher score indicates the observation is more important. More rules that should be followed are\n",
        "            \\n(1) The observation that includes entering social media is not important. e.g., David Smith takes action by entering the world of social media.\n",
        "            \\n(2) The observation that describes chatting with someone but no specific book name is not important. e.g., David Smith observed that David Miller expressed interest in chatting about books.\n",
        "            \\n(3) The observation that includes 'chatting' is not important. e.g., David Smith observed that David Miller expressed interest in chatting about books, indicating a shared passion for books.\n",
        "            \\n(4) The observation that includes 'enter the recommender system' is not important. e.g. David Smith enters the Recommender System to explore book recommendations based on his interests and preferences.\n",
        "            \\n(5) The observation that recommends or mentions specific books is important.\n",
        "            \\n(6) More informative indicates more important, especially when two people are chatting.\n",
        "            Please respond with a single integer.\n",
        "            \\nObservation:{memory_content}\n",
        "            \\nRating:\n",
        "            \"\"\"\n",
        "        )\n",
        "        score = LLMChain(llm=self.llm, prompt=prompt).run(memory_content=memory_content).strip()\n",
        "        match = re.search(r\"^\\D*(\\d+)\", score)\n",
        "        if match:\n",
        "            return (float(match.group(1)) / 10) * self.importance_weight\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def fetch_memories_with_list(self, observation, stm):\n",
        "        \"\"\"\n",
        "        Transfer the retrieved memories and the enhanced short-term memory with the insight into List.\n",
        "        :param observation: the observation to retrieve related memories\n",
        "        :param stm: the short term memory instance\n",
        "        :return\n",
        "            (List[(float, str)]) res: the list tuples contains the memory content with corresponding importance score\n",
        "            (Tuple(List[str], List[float], List[str])) memories_tuple: contains the short-term memories, importances and the insights.\n",
        "        \"\"\"\n",
        "        res_list, memories_tuple = self.fetch_memories(observation, stm=stm)\n",
        "        res = [(res.metadata['importance'], res.page_content) for res in res_list]\n",
        "        return res, memories_tuple\n",
        "\n",
        "    def fetch_memories(self, observation: str, stm=None, now: Optional[datetime] = None):\n",
        "        \"\"\"\n",
        "        Fetch related memories.\n",
        "        :param observation: the observation to retrieve related memories\n",
        "        :param stm: the short term memory instance\n",
        "        :param now: (optional) the current time.\n",
        "        :return\n",
        "                (List[Document]) the retrieved memory documents\n",
        "                (Tuple(List[str], List[float], List[str])) memories_tuple: contains the short-term memories, importances and the insights.\n",
        "        \"\"\"\n",
        "        with mock_now(now):\n",
        "            # reflection do not enhance the short-term memories\n",
        "            retrieved_list = self.memory_retriever.get_relevant_documents(observation)\n",
        "            if stm is None:\n",
        "                return retrieved_list\n",
        "            # retrieval enhance the short-term memories\n",
        "            else:\n",
        "                ltm_memory_list, ltm_importance_scores = [], []\n",
        "                insight_memory_list = []\n",
        "                for document in retrieved_list:\n",
        "                    memory_content, memory_importance, insight_content = \\\n",
        "                        stm.add_stm_memory(document.page_content, document.metadata['importance'], op='Retrieval')\n",
        "                    ltm_memory_list.extend(memory_content)\n",
        "                    ltm_importance_scores.extend(memory_importance)\n",
        "                    insight_memory_list.extend(insight_content)\n",
        "\n",
        "                for idx in range(len(stm.short_memories)):\n",
        "                    short_term_document = Document(\n",
        "                        page_content=stm.short_memories[idx],\n",
        "                        metadata={\"importance\": stm.memory_importance[idx]}\n",
        "                    )\n",
        "                    retrieved_list.append(short_term_document)\n",
        "\n",
        "                return retrieved_list, (ltm_memory_list, ltm_importance_scores, insight_memory_list)\n",
        "\n",
        "    def format_memories_detail(self, relevant_memories: List[Document]) -> str:\n",
        "        content_strs = set()\n",
        "        content = []\n",
        "        for mem in relevant_memories:\n",
        "            if mem.page_content in content_strs:\n",
        "                continue\n",
        "            content_strs.add(mem.page_content)\n",
        "            created_time = mem.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "            content.append(f\"- {created_time}: {mem.page_content.strip()}\")\n",
        "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
        "\n",
        "\n",
        "    def format_memories_simple(self, relevant_memories: List[Document]) -> str:\n",
        "        return \"; \".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
        "\n",
        "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
        "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
        "        result = []\n",
        "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
        "            if consumed_tokens >= self.max_tokens_limit:\n",
        "                break\n",
        "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
        "            if consumed_tokens < self.max_tokens_limit:\n",
        "                result.append(doc)\n",
        "        result = self.format_memories_simple(result)\n",
        "        return result\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        return []\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def cosine_similarity(embedding1: List[float], embedding2: List[float]):\n",
        "        dot_product = np.dot(embedding1, embedding2)\n",
        "        norm1 = np.linalg.norm(embedding1)\n",
        "        norm2 = np.linalg.norm(embedding2)\n",
        "        similarity = dot_product / (norm1 * norm2)\n",
        "        return similarity\n",
        "\n",
        "    def _get_topics_of_reflection(self, last_k: int = 50) -> List[str]:\n",
        "        \"\"\"Return the 1 most salient high-level questions about recent observations.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"{observations}\\n\\n\"\n",
        "            + \"Given only the information above, what is the 1 most salient\"\n",
        "            + \" high-level questions we can answer about the subjects in\"\n",
        "            + \" the statements? Provide the question on a new line.\\n\\n\"\n",
        "        )\n",
        "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
        "        observation_str = \"\\n\".join([o.page_content for o in observations if hasattr(o, 'page_content')])\n",
        "        result = self.chain(prompt).run(observations=observation_str)\n",
        "        # print(\"\\n_get_topics_of_reflection result:\", result)\n",
        "        return self._parse_list(result)\n",
        "\n",
        "    def _get_insights_on_topic(\n",
        "            self, topic: str, now: Optional[datetime] = None\n",
        "    ):\n",
        "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
        "        prompt_insight = PromptTemplate.from_template(\n",
        "            \"The topic or question is:\\n\"\n",
        "            + \"{topic}\\n\"\n",
        "            + \"Some statements are provided in the format [id] in the following:\\n\"\n",
        "            + \"{related_statements}\\n\"\n",
        "            + \"please identify one main insight to answer the above question, \"\n",
        "            + \"and simultaneously specify which statements the insight is derived from:\\n\"\n",
        "            + \"Respond ONLY with the insight and the Ids of their related statements, adhering strictly to the following format:\\n\"\n",
        "            + \"Content of insight [Related statement IDs]\\n\"\n",
        "            + \"An insight can be derived from multiple statements.\"\n",
        "            + \"The insight needs to be significantly different from the statement(s) in sentence structure and content it is derived from.\"\n",
        "        )\n",
        "\n",
        "        related_memories = self.fetch_memories(topic, now=now)\n",
        "        related_statements = \"\\n\".join(\n",
        "            [\n",
        "                # f\"{i + 1}. {memory.page_content}\"\n",
        "                f\"{memory.page_content}\"\n",
        "                for i, memory in enumerate(related_memories)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        result_insight = self.chain(prompt_insight).run(\n",
        "            topic=topic, related_statements=related_statements\n",
        "        )\n",
        "\n",
        "        result_insight = self._parse_list(result_insight)\n",
        "        result_insight = [self._parse_insight_with_connections(res) for res in result_insight]\n",
        "        statements_id = result_insight[0][1]\n",
        "\n",
        "        pattern = r\"(?<=\\[)\\d+(?=\\])\"\n",
        "        indexes = []\n",
        "        embeddings_model = OpenAIEmbeddings()\n",
        "        embedding_1 = embeddings_model.embed_query(result_insight[0][0])\n",
        "        for memory_id in statements_id:\n",
        "            if memory_id < 0 or memory_id >= len(self.memory_retriever.memory_stream):\n",
        "                continue\n",
        "            # print(\"\\n_get_insights_on_topic: \", self.memory_retriever.memory_stream[memory_id])\n",
        "            # print(\"\\n_get_insights_on_topic page content: \", self.memory_retriever.memory_stream[memory_id].page_content)\n",
        "            if hasattr(self.memory_retriever.memory_stream[memory_id], 'page_content'):\n",
        "                memory = self.memory_retriever.memory_stream[memory_id].page_content\n",
        "                if memory == '[MERGE]' or memory == '[FORGET]':\n",
        "                    continue\n",
        "                memory_embedding = embeddings_model.embed_query(memory)\n",
        "                similarity = self.cosine_similarity(embedding_1, memory_embedding)\n",
        "                # Sigmoid function\n",
        "                value = 1 / (1 + np.exp(-similarity))\n",
        "                if value >= 0.72:\n",
        "                    match = re.search(pattern, memory)\n",
        "                    idx = match.group()\n",
        "                    indexes.append(int(idx))\n",
        "\n",
        "\n",
        "        for idx in indexes:\n",
        "            self.memory_retriever.memory_stream[idx].page_content = '[MERGE]'\n",
        "            self.memory_retriever.memory_stream[idx].metadata['importance'] = 1.0\n",
        "            self.memory_retriever.memory_stream[idx].metadata['last_accessed_at'] = self.now\n",
        "\n",
        "        return result_insight\n",
        "\n",
        "    def pause_to_reflect(self, now: Optional[datetime] = None):\n",
        "        \"\"\"\n",
        "        Reflect on recent observations and generate 'insights'.\n",
        "        :param now: (optional) The current time.\n",
        "        :return: The list of new insights. [No use for this version.]\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            logger.info(\"Character is reflecting\")\n",
        "\n",
        "        new_insights = []\n",
        "        topics = self._get_topics_of_reflection()\n",
        "        # print(\"\\nTopics: \", topics)\n",
        "        for topic in topics:\n",
        "            insights = self._get_insights_on_topic(topic, now=now)\n",
        "            for insight in insights:\n",
        "                text, par_list = insight\n",
        "                importance_cur, recency_cur = 0.0, 0.0\n",
        "                valid = 0\n",
        "                for par in par_list:\n",
        "                    if par < len(self.memory_retriever.memory_stream):\n",
        "                        if hasattr(self.memory_retriever.memory_stream[par], 'metadata'):\n",
        "                            importance_cur += self.memory_retriever.memory_stream[par].metadata['importance']\n",
        "                            valid += 1\n",
        "                            buffer_idx = self.memory_retriever.memory_stream[par].metadata.get('buffer_idx', None)  # Get buffer_idx if available\n",
        "                            if buffer_idx is None:\n",
        "                                # Assign buffer_idx if it's not present\n",
        "                                buffer_idx = len(self.memory_retriever.memory_stream) + 1\n",
        "                                self.memory_retriever.memory_stream[par] = buffer_idx  # Update metadata\n",
        "                if valid == 0:\n",
        "                    importance_cur = 0.0\n",
        "                else:\n",
        "                    importance_cur /= valid\n",
        "                ltm = importance_cur, now, text\n",
        "                self.add_memory(ltm, now=now)\n",
        "            new_insights.extend(insights)\n",
        "        print(\"\\nNew Insight Memory:\", new_insights)\n",
        "\n",
        "        return new_insights\n",
        "\n",
        "    def obtain_forget_prob_list(self):\n",
        "        \"\"\"\n",
        "        Obtain the forgetting probability of each memory.\n",
        "        :return: (List) The distribution of forgetting probability.\n",
        "        \"\"\"\n",
        "\n",
        "        def score_func(importance, last_accessed_time):\n",
        "            \"\"\"\n",
        "            Given the importance score and last accessed time, calculate the score of this memory.\n",
        "            :param importance: The importance score.\n",
        "            :param last_accessed_time: The last accessed time.\n",
        "            :return: Score of this memory.\n",
        "            \"\"\"\n",
        "            hours_passed = (self.now - last_accessed_time).total_seconds() / 3600\n",
        "            recency = (1.0 - self.decay_rate) ** hours_passed\n",
        "\n",
        "            return max(recency ** 1.5, 0.01) * (importance + recency) / 2\n",
        "\n",
        "        score_list = []\n",
        "        for ind, mem in enumerate(self.memory_retriever.memory_stream):\n",
        "            # print(\"........MEM>>>>>>>: \", mem)\n",
        "            if hasattr(mem, 'metadata'):\n",
        "                score = score_func(mem.metadata['importance'], mem.metadata['last_accessed_at'])\n",
        "                score_list.append(score)\n",
        "        score_list = 1.0 - np.array(score_list)\n",
        "        return score_list / np.sum(score_list)\n",
        "\n",
        "    def pause_to_forget(self):\n",
        "        \"\"\"\n",
        "        Forget parts of long term memories.\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            logger.info(\"Character is forgetting.\")\n",
        "\n",
        "        prob_list = self.obtain_forget_prob_list()\n",
        "        i = 0\n",
        "        if len(prob_list) != 0:\n",
        "            for idx, memory in enumerate(self.memory_retriever.memory_stream):\n",
        "                if hasattr(memory, 'metadata'):\n",
        "                    if (self.now - self.memory_retriever.memory_stream[idx].metadata['last_accessed_at']).total_seconds() / 3600 <= 24:\n",
        "                        continue\n",
        "                    if random.random() < prob_list[i]:\n",
        "                        self.memory_retriever.memory_stream[idx].page_content = '[FORGET]'\n",
        "                        self.memory_retriever.memory_stream[idx].metadata['importance'] = 1.0\n",
        "                        self.memory_retriever.memory_stream[idx].metadata['last_accessed_at'] = self.now\n",
        "                    i=i+1\n",
        "\n",
        "    def add_memory(self, ltm, now=None):\n",
        "        \"\"\"\n",
        "        Store the long term memory.\n",
        "        :param ltm: The long term memory that is ready to be stored.\n",
        "        :param now: Current time.\n",
        "        :return: List of IDs of the added texts. [No use in this version.]\n",
        "        \"\"\"\n",
        "        importance, last_accessed_at, text = ltm\n",
        "        if not self.reflecting:\n",
        "            self.aggregate_importance += importance\n",
        "        memory_idx = len(self.memory_retriever.memory_stream)\n",
        "        document = Document(\n",
        "            page_content='[{}] '.format(memory_idx) + str(text),\n",
        "            metadata={\"importance\": importance, \"last_accessed_at\": last_accessed_at}\n",
        "        )\n",
        "        # print(\"\\nDocuments: Page_content: \",document.page_content, \", Metadata: \", document.metadata)\n",
        "        result = self.memory_retriever.add_documents([document], current_time=now)\n",
        "        return result\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], ltm_list: list) -> None:\n",
        "        \"\"\"\n",
        "        Store the long term memories. Execute reflection and forgetting.\n",
        "        :param inputs: [No use for this version.]\n",
        "        :param ltm_list: The list of long term memory with tuple format (importance score[float], now[datetime], memory[string]).\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "\n",
        "        now = self.now\n",
        "        for ltm in ltm_list:\n",
        "            self.add_memory(ltm, now)\n",
        "\n",
        "        # When the aggregation of importance is above the threshold, execute the reflection function once.\n",
        "        if (\n",
        "                self.reflection_threshold is not None\n",
        "                and self.aggregate_importance > self.reflection_threshold\n",
        "                and not self.reflecting\n",
        "        ):\n",
        "            self.reflecting = True\n",
        "            self.pause_to_reflect(now=now)\n",
        "            # Hack to clear the importance from reflection\n",
        "            self.aggregate_importance = 0.0\n",
        "            self.reflecting = False\n",
        "\n",
        "        # Execute the forget function once.\n",
        "        if True:\n",
        "            self.forgetting = True\n",
        "            self.pause_to_forget()\n",
        "            self.forgetting = False\n",
        "\n",
        "    def print_memory(self):\n",
        "        \"\"\"\n",
        "        [Tool for Debug] Print the long term memories.\n",
        "        \"\"\"\n",
        "        for ind, mem in enumerate(self.memory_retriever.memory_stream):\n",
        "            if hasattr(mem, 'metadata'):\n",
        "                hours_passed = (self.now - mem.metadata['last_accessed_at']).total_seconds() / 3600\n",
        "                recency = (1.0 - self.decay_rate) ** hours_passed\n",
        "                # uncomment this line when you want to check the memory contents\n",
        "                # print('[%d] (importance: %f, recency: %f) %s' % (\n",
        "                #     ind, mem.metadata['importance'], recency, mem.page_content))\n",
        "\n",
        "    def update_now(self, now: datetime):\n",
        "        \"\"\"\n",
        "        Update the current time.\n",
        "        :param now: Current time.\n",
        "        \"\"\"\n",
        "        self.now = now\n",
        "        self.memory_retriever.now = now\n",
        "        meminer = []\n",
        "        for memo in self.memory_retriever.memory_stream:\n",
        "            if hasattr(memo, 'metadata'):\n",
        "                meminer.append(memo.page_content)\n",
        "        print(\"\\n\\nLong Term Memory Content :\", meminer)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"\n",
        "        Clear all the memories in long term memory.\n",
        "        \"\"\"\n",
        "        self.memory_retriever.memory_stream = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2EpR_qXlKx8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "from langchain import LLMChain\n",
        "from langchain.base_language import BaseLanguageModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.schema import BaseMemory\n",
        "\n",
        "\n",
        "class RecAgentMemory(BaseMemory):\n",
        "    \"\"\"\n",
        "    RecAgentMemory is the proposed memory module for RecAgent. We replace `GenerativeAgentMemory` with this class.\n",
        "    Similarly, it has three necessary methods to implement:\n",
        "    - load_memory_variables: given inputs, return the corresponding information in the memory.\n",
        "    - save_context: accept observations and store them as memory.\n",
        "    - clear: clear the memory content.\n",
        "\n",
        "    We have three key components, which is consistent with human's brain.\n",
        "    - SensoryMemory: Receive observations, abstract significant information, and pass to short-term memory.\n",
        "    - ShortTermMemory: Receive sensory memories, enhance them with new observations or retrieved memories,\n",
        "                       and then transfer the enhanced short-term memories with an insight to long-term memory,\n",
        "                       or discard the less important memory in cases of capacity overload.\n",
        "    - LongTermMemory: Receive short-term memories, store and forget memories, and retrival memories to short-term memory.\n",
        "\n",
        "    \"\"\"\n",
        "    llm: BaseLanguageModel = None\n",
        "    verbose: bool = False\n",
        "    now: datetime = None\n",
        "\n",
        "    # Comment those lines when you don't want to use the memory module\n",
        "    sensoryMemory: SensoryMemory = None\n",
        "    shortTermMemory: ShortTermMemory = None\n",
        "    longTermMemory: LongTermMemory = None\n",
        "\n",
        "    importance_weight: float = 0.9\n",
        "    \"\"\"How much weight to assign the memory importance.\"\"\"\n",
        "\n",
        "    # input keys\n",
        "    queries_key: str = \"queries\"\n",
        "    most_recent_memories_token_key: str = \"recent_memories_token\"\n",
        "    add_memory_key: str = \"add_memory\"\n",
        "    # output keys\n",
        "    relevant_memories_key: str = \"relevant_memories\"\n",
        "    relevant_memories_simple_key: str = \"relevant_memories_simple\"\n",
        "    most_recent_memories_key: str = \"most_recent_memories\"\n",
        "    now_key: str = \"now\"\n",
        "\n",
        "    def __init__(self, llm, memory_retriever, now, verbose=False, reflection_threshold=None):\n",
        "        super(RecAgentMemory, self).__init__()\n",
        "\n",
        "        self.llm = llm\n",
        "        self.now = now\n",
        "        # Comment those lines when you don't want to use the memory module\n",
        "        self.sensoryMemory = SensoryMemory(llm)\n",
        "        self.shortTermMemory = ShortTermMemory(llm)\n",
        "        self.longTermMemory = LongTermMemory(llm=llm, memory_retriever=memory_retriever, now=self.now, verbose=verbose,\n",
        "                                             reflection_threshold=reflection_threshold)\n",
        "\n",
        "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
        "        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        return []\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Return 'most_recent_memories' with fetched memories (not recent memories).\n",
        "        :param inputs: The dict that contains the key 'observation'.\n",
        "        :return: The fetched memories.\n",
        "        \"\"\"\n",
        "\n",
        "        ltm_memory_list, memories_tuple = self.longTermMemory.fetch_memories_with_list(inputs['observation'],\n",
        "                                                                                       self.shortTermMemory)\n",
        "        self.save_context_after_retrieval(memories_tuple)\n",
        "        if len(ltm_memory_list) == 0:\n",
        "            memory_tmp = ''\n",
        "        else:\n",
        "            memory_tmp = [memory[1] for memory in ltm_memory_list]\n",
        "        memory_tmp = ''.join(memory_tmp)\n",
        "        # memory_tmp = '' #unused line\n",
        "\n",
        "        output = {'most_recent_memories': memory_tmp}\n",
        "        return output\n",
        "\n",
        "    def _score_memory_importance(self, memory_content: str) -> float:\n",
        "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            Please give an importance score between 1 to 10 for the following observation. Higher score indicates the observation is more important. More rules that should be followed are\n",
        "            \\n(1) The observation that includes entering social media is not important. e.g., David Smith takes action by entering the world of social media.\n",
        "            \\n(2) The observation that describes chatting with someone but no specific book title is not important. e.g., David Smith observed that David Miller expressed interest in chatting about books.\n",
        "            \\n(3) The observation that includes 'chatting' is not important. e.g., David Smith observed that David Miller expressed interest in chatting about books, indicating a shared passion for books.\n",
        "            \\n(4) The observation that includes 'enter the recommender system' is not important. e.g. David Smith enters the Recommender System to explore book recommendations based on his interests and preferences.\n",
        "            \\n(5) The observation that recommends or mentions specific books is important.\n",
        "            \\n(6) More informative indicates more important, especially when two people are chatting.\n",
        "            Please respond with a single integer.\n",
        "            \\nObservation:{memory_content}\n",
        "            \\nRating:\n",
        "            \"\"\"\n",
        "        )\n",
        "        score = self.chain(prompt).run(memory_content=memory_content).strip()\n",
        "        if self.verbose:\n",
        "            logger.info(f\"Importance score: {score}\")\n",
        "        match = re.search(r\"^\\D*(\\d+)\", score)\n",
        "        if match:\n",
        "            return (float(match.group(1)) / 10) * self.importance_weight\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def add_memory(self, memory_content: str, now: Optional[datetime] = None):\n",
        "        \"\"\"\n",
        "        The Simulator can add memory by using this function.\n",
        "        :param memory_content: The content of memory.\n",
        "        :param now: Current time.\n",
        "        \"\"\"\n",
        "        self.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.add_memory_key: memory_content,\n",
        "                self.now_key: now,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    def save_context_after_retrieval(self, memories_tuple):\n",
        "        \"\"\"\n",
        "        The RecAgent can transfer short-term memory to long-term memory.\n",
        "        :param memories_tuple:  (Tuple(List[str], List[float], List[str])) memories_tuple: contains the short-term memories, importances and the insights.\n",
        "        :return None\n",
        "        \"\"\"\n",
        "        ltm_memory_list, ltm_importance_scores, insight_memory_list = memories_tuple\n",
        "        insight_memory_list = [memory[0] for memory in insight_memory_list]\n",
        "        insight_scores_list = [self._score_memory_importance(memory) for memory in insight_memory_list]\n",
        "\n",
        "        all_memories = ltm_memory_list + insight_memory_list\n",
        "        all_memory_scores = ltm_importance_scores + insight_scores_list\n",
        "        save_ltm_memory = [(all_memory_scores[i], self.now, all_memories[i])\n",
        "                           for i in range(len(all_memories))]\n",
        "        self.longTermMemory.save_context({}, save_ltm_memory)\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
        "        \"\"\"\n",
        "        The RecAgent can add memory by using this function.\n",
        "        :param inputs: Will be directly pass to LongTermMemory. [No use for this version.]\n",
        "        :param outputs: The core memory dict that is passed from RecAgent. It has to obtain the key 'add_memory' to save the memory content.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # If the 'outputs' does not contain the memory, then exit the function.\n",
        "        # print(\"Entering Memory.............\\n\\n\")\n",
        "        if 'add_memory' not in outputs:\n",
        "            return\n",
        "        # Comments all those lines when you don't want to use memory module\n",
        "        # Add the observation into the buffer of sensory memory, and obtain a list of short term memory if the buffer is full.\n",
        "        obs = outputs['add_memory']\n",
        "        stm_memory_list = self.sensoryMemory.add_ssm(obs)\n",
        "        # print(\"stm_memory_list:\", stm_memory_list)\n",
        "        if stm_memory_list is None:\n",
        "            return\n",
        "        else:\n",
        "            ltm_memory_list, ltm_importance_scores = [], []\n",
        "            insight_memory_list = []\n",
        "            for stm_memory in stm_memory_list:\n",
        "                memory_content, memory_importance, insight_content \\\n",
        "                    = self.shortTermMemory.add_stm_memory(stm_memory[1], stm_memory[0], op='add')\n",
        "                # print(\"\\nmemory_content:\", memory_content)\n",
        "                # print(\"\\nmemory_importance:\", memory_importance)\n",
        "                # print(\"\\ninsight_content:\", insight_content)\n",
        "                ltm_memory_list.extend(memory_content)\n",
        "                ltm_importance_scores.extend(memory_importance)\n",
        "                insight_memory_list.extend(insight_content)\n",
        "\n",
        "            insight_memory_list = [memory[0] for memory in insight_memory_list]\n",
        "            insight_scores_list = [self._score_memory_importance(memory) for memory in insight_memory_list]\n",
        "\n",
        "            all_memories = ltm_memory_list + insight_memory_list\n",
        "            all_memory_scores = ltm_importance_scores + insight_scores_list\n",
        "            # print(\"\\nall_memories:\", all_memories)\n",
        "            # print(\"\\nall_memory_scores:\", all_memory_scores)\n",
        "            # Ensure that all lists have the same length before creating save_ltm_memory\n",
        "            if len(all_memories) == len(all_memory_scores):\n",
        "                save_ltm_memory = [(all_memory_scores[i], self.now, all_memories[i])\n",
        "                       for i in range(len(all_memories))]\n",
        "                # Store the long term memories.\n",
        "                self.longTermMemory.save_context(inputs, save_ltm_memory)\n",
        "            else:\n",
        "                # Handle the case where the lists have different lengths\n",
        "                print(\"Error: Lists have different lengths.\")\n",
        "\n",
        "\n",
        "    def update_now(self, now: datetime):\n",
        "        \"\"\"\n",
        "        Update the current time.\n",
        "        :param now: Current time.\n",
        "        \"\"\"\n",
        "        self.now = now\n",
        "        # Make comments when you don't want to use the memory module\n",
        "        self.longTermMemory.update_now(self.now)\n",
        "\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"\n",
        "        Clear all the (long term) memory in RecAgentMemory.\n",
        "        \"\"\"\n",
        "        # Make comments when you don't want to use the memory module\n",
        "        self.longTermMemory.clear()\n",
        "        # self.clear() # unused line\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJsyBFWJ6-RO"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from datetime import datetime\n",
        "\n",
        "class RoleAgent:\n",
        "    run_location: str = \"web\"\n",
        "\n",
        "    def __init__(self, id, name, age, gender, traits, status, interest, relationships, feature, memory_retriever, llm, memory, event, avatar_url, idle_url, watching_url, chatting_url, posting_url):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.gender = gender\n",
        "        self.traits = traits\n",
        "        self.status = status\n",
        "        self.interest = interest\n",
        "        self.relationships = relationships\n",
        "        self.feature = feature\n",
        "        self.memory_retriever = memory_retriever\n",
        "        self.llm = llm\n",
        "        self.memory = memory\n",
        "        self.event = event\n",
        "        self.avatar_url = avatar_url\n",
        "        self.idle_url = idle_url\n",
        "        self.watching_url = watching_url\n",
        "        self.chatting_url = chatting_url\n",
        "        self.posting_url = posting_url\n",
        "        self.role = \"user\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_recagent(cls, recagent_instance):\n",
        "        return cls(**recagent_instance.__dict__)\n",
        "\n",
        "    async def get_response(self, message):\n",
        "        print(\"Received message:\", message)\n",
        "        response = input(\"Enter your response: \")\n",
        "        return response\n",
        "\n",
        "    async def take_action(self, now):\n",
        "        order = await self.get_response(\n",
        "            f\"It's {now}.\\n\"\n",
        "            \"Please choose one action below: \\n\"\n",
        "            \"(1) Enter the Recommender, please input 1. \\n\"\n",
        "            \"(2) Enter the Social Media, please input 2. \\n\"\n",
        "            \"(3) Do Nothing, please input 3. \\n\")\n",
        "        while order not in [\"1\", \"2\", \"3\"]:\n",
        "            order = await self.get_response(\n",
        "                \"Your input is wrong, please choose one action below: \\n\"\n",
        "                \"(1) Enter the Recommender, please input 1. \\n\"\n",
        "                \"(2) Enter the Social Media, please input 2. \\n\"\n",
        "                \"(3) Do Nothing, please input 3. \\n\")\n",
        "\n",
        "        action = await self.get_response(\"You can input some text to explain your choice. \\n\")\n",
        "        choice = {\"1\": \"[RECOMMENDER]\", \"2\": \"[SOCIAL]\", \"3\": \"[NOTHING]\"}[order]\n",
        "        phase = {\n",
        "            \"1\": \"enter the Recommender System\",\n",
        "            \"2\": \"enter the Social Media\",\n",
        "            \"3\": \"do nothing\",\n",
        "        }[order]\n",
        "        result = choice + \":: %s wants to %s because %s\" % (self.name, phase, action)\n",
        "\n",
        "        return choice, result\n",
        "\n",
        "    async def take_recommender_action(self, observation, now):\n",
        "        \"\"\"\n",
        "        Require the user choose one action below by inputting:\n",
        "        (1) Buy movies among the recommended items.\n",
        "        (2) Next page.\n",
        "        (3) Search items.\n",
        "        (4) Leave the recommender system.\n",
        "        :return\n",
        "        choice(str): the token that represents the choice made by the user, one of in '[BUY]', '[NEXT]',\n",
        "                     '[SEARCH]', and '[NOTHING]'.\n",
        "        action(str): integrate the choice and the reason into one sentence.\n",
        "        \"\"\"\n",
        "        order = await self.get_response(\n",
        "            observation+\n",
        "            \"\\nPlease choose one action below: \\n\"\n",
        "            \"(1) Buy movies among the recommended items, please input 1. \\n\"\n",
        "            \"(2) Next page, please input 2. \\n\"\n",
        "            \"(3) Search items, please input 3. \\n\"\n",
        "            \"(4) Leave the recommender system, input 4. \\n\"\n",
        "        )\n",
        "\n",
        "        # If the input is not conforming to the prescribed form, we let the user input again.\n",
        "        while order not in [\"1\", \"2\", \"3\", \"4\"]:\n",
        "            order = await self.get_response(\n",
        "                \"Your input is wrong, please choose one action below: \\n\"\n",
        "                \"(1) Buy movies among the recommended items, please input 1. \\n\"\n",
        "                \"(2) Next page, please input 2. \\n\"\n",
        "                \"(3) Search items, please input 3. \\n\"\n",
        "                \"(4) Leave the recommender system, input 4. \\n\"\n",
        "            )\n",
        "\n",
        "        # Change the input number to the choice token.\n",
        "        choice = {\"1\": \"[BUY]\", \"2\": \"[NEXT]\", \"3\": \"[SEARCH]\", \"4\": \"[LEAVE]\"}[order]\n",
        "\n",
        "        if order == \"1\":\n",
        "            films = await self.get_response(\n",
        "                \"Please input movie names in the list returned by the recommender system, only movie names, separated by semicolons. \\n\"\n",
        "            )\n",
        "            # Construct the list of films with '<*>' format.\n",
        "            film_list = [\"<%s>\" % film for film in films.split(\",\")]\n",
        "            action = str(film_list)\n",
        "        elif order == \"2\":\n",
        "            action = f\"{self.name} looks at the next page\"\n",
        "        elif order == \"3\":\n",
        "            items = await self.get_response(\"Please input the single, specific item name you want to search. \\n\")\n",
        "            # Construct the list of items with '<*>' format.\n",
        "            item_list = [\"<%s>\" % item for item in items.split(\",\")]\n",
        "            action = str(item_list)\n",
        "        elif order == \"4\":\n",
        "            action = f\"{self.name} leaves the recommender system\"\n",
        "        else:\n",
        "            raise ValueError(\"Unexpected order value.\")\n",
        "\n",
        "        result = f\"{choice}:: {action}.\"\n",
        "\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} took action: {result}\",\n",
        "            },\n",
        "        )\n",
        "        return choice, action\n",
        "\n",
        "\n",
        "    async def generate_feeling(self, observation: str, now) -> str:\n",
        "        feeling = await self.get_response(\"Please input your feelings, which should be split by semicolon: \\n\")\n",
        "\n",
        "        results = feeling.split(\",\")\n",
        "        feelings = \"\".join(results)\n",
        "        self.memory.save_context({}, {self.memory.add_memory_key: f\"{self.name} felt: {feelings}\"})\n",
        "        return feelings\n",
        "\n",
        "\n",
        "    async def search_item(self, observation: str, now) -> str:\n",
        "        search = await self.get_response(\"Please input your search: \\n\")\n",
        "        self.memory.save_context({}, {self.memory.add_memory_key: f\"{self.name} wants to search and watch {search} in recommender system.\"})\n",
        "        return search\n",
        "\n",
        "\n",
        "    async def take_social_action(self, observation: str, now) -> Tuple[str, str]:\n",
        "        order = await self.get_response(\n",
        "            observation +\n",
        "            \"\\nPlease choose one action below: \\n\"\n",
        "            \"(1) Chat with one acquaintance, input 1. \\n\"\n",
        "            \"(2) Publish posting to all acquaintances, input 2. \\n\"\n",
        "        )\n",
        "\n",
        "        while order not in [\"1\", \"2\"]:\n",
        "            order = await self.get_response(\n",
        "                \"Please choose one action below: \\n\"\n",
        "                \"(1) Chat with one acquaintance, input 1. \\n\"\n",
        "                \"(2) Publish posting to all acquaintances, input 2. \\n\"\n",
        "            )\n",
        "\n",
        "        choice = {\"1\": \"[CHAT]\", \"2\": \"[POST]\"}[order]\n",
        "\n",
        "        if order == \"1\":\n",
        "            action = await self.get_response(\"Please input one acquaintance to chat: \\n\")\n",
        "        elif order == \"2\":\n",
        "            action = \" \"\n",
        "        else:\n",
        "            raise ValueError(\"Unexpected order value.\")\n",
        "\n",
        "        result = f\"{choice}:: {action}\"\n",
        "        self.memory.save_context({}, {self.memory.add_memory_key: f\"{self.name} took action: {result}\"})\n",
        "        return choice, action\n",
        "\n",
        "    async def generate_role_dialogue(self, agent2, observation, now=None):\n",
        "        role_text = await self.get_response(\n",
        "            'Please input your chatting text (Input \"goodbye\" if you want to quit): \\n'\n",
        "        )\n",
        "        role_dia = \"%s said %s\" % (self.name, role_text)\n",
        "        contin = True\n",
        "\n",
        "        if role_text == \"goodbye\":\n",
        "            contin = False\n",
        "\n",
        "        return contin, role_dia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTu3M1_SPKnB"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class SocialNetwork:\n",
        "    def __init__(self):\n",
        "        self.agents = {}  # agent_id -> agent info (dict)\n",
        "        self.posts = []   # list of all posts\n",
        "\n",
        "    def add_agent(self, agent_id, agent_name, interests=None):\n",
        "        \"\"\"Add an agent to the social network.\"\"\"\n",
        "        if agent_id in self.agents:\n",
        "            print(f\"Agent ID {agent_id} already exists.\")\n",
        "            return\n",
        "        self.agents[agent_id] = {\n",
        "            'agent_name': agent_name,\n",
        "            'interests': set(interests) if interests else set()\n",
        "        }\n",
        "\n",
        "\n",
        "    def create_post(self, agent_id, round_number, public_posting, summary, book_genre):\n",
        "        \"\"\"Agent creates a post in the social network.\"\"\"\n",
        "        if agent_id not in self.agents:\n",
        "            print(f\"Agent ID {agent_id} does not exist.\")\n",
        "            return\n",
        "        post = {\n",
        "            'agent_id': agent_id,\n",
        "            'agent_name': self.agents[agent_id]['agent_name'],\n",
        "            'round_number': round_number,\n",
        "            'public_posting': public_posting,\n",
        "            'summary': summary,\n",
        "            'book_genre': book_genre,\n",
        "            'timestamp': datetime.now()\n",
        "        }\n",
        "        self.posts.append(post)\n",
        "        print(self.format_post(post))\n",
        "\n",
        "    def get_all_posts_except(self, agent_id):\n",
        "        \"\"\"Return all posts except those from the given agent.\"\"\"\n",
        "        return [post for post in self.posts if post['agent_id'] != agent_id]\n",
        "\n",
        "    def get_ranked_posts_for_agent(self, agent_id):\n",
        "        \"\"\"Return posts ranked for a given agent based on overlapping genres and recency.\"\"\"\n",
        "        if agent_id not in self.agents:\n",
        "           print(f\"Agent ID {agent_id} does not exist.\")\n",
        "           return []\n",
        "\n",
        "        # Normalize agent interests to lowercase\n",
        "        interests = set(i.strip().lower() for i in self.agents[agent_id]['interests'])\n",
        "\n",
        "        def post_score(post):\n",
        "            score = 0\n",
        "            # Ensure book_genre is a list\n",
        "            book_genres = post['book_genre']\n",
        "            if isinstance(book_genres, str):\n",
        "               # if stored as comma-separated string, split:\n",
        "               book_genres = [g.strip() for g in book_genres.split(',')]\n",
        "            book_genres = set(g.strip().lower() for g in book_genres)\n",
        "\n",
        "            # Count genre overlap\n",
        "            genre_overlap = interests.intersection(book_genres)\n",
        "\n",
        "            if genre_overlap:\n",
        "               score += 2  # or use score += len(genre_overlap) for proportional bonus\n",
        "\n",
        "            # Recency bonus\n",
        "            days_since = (datetime.now() - post['timestamp']).days\n",
        "\n",
        "            if days_since <= 7:\n",
        "               score += 1\n",
        "\n",
        "            return score, post['timestamp']\n",
        "\n",
        "        posts = self.get_all_posts_except(agent_id)\n",
        "\n",
        "        ranked_posts = sorted(\n",
        "            posts,\n",
        "            key=lambda post: (post_score(post)[0], post_score(post)[1]),\n",
        "            reverse=True\n",
        "            )\n",
        "        return ranked_posts\n",
        "\n",
        "    @staticmethod\n",
        "    def format_post(post):\n",
        "        return (\n",
        "            f\"Agent ID: {post['agent_id']}    Agent Name: {post['agent_name']}\\n\"\n",
        "            f\"Round: {post['round_number']}    Time: {post['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "            f\"Public Posting: {post['public_posting']}    Genre: {post['book_genre']}\\n\"\n",
        "            f\"Summary: {post['summary']}\\n\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkV4YkI5iTCh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, List, Optional, Tuple, ClassVar\n",
        "\n",
        "from langchain_experimental.generative_agents.memory import (\n",
        "    GenerativeAgentMemory,\n",
        "    BaseMemory,\n",
        ")\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_experimental.generative_agents import (\n",
        "    GenerativeAgent,\n",
        "    GenerativeAgentMemory,\n",
        ")\n",
        "\n",
        "from datetime import datetime\n",
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "\n",
        "class RecAgent(GenerativeAgent):\n",
        "    id: int\n",
        "    \"\"\"The agent's unique identifier\"\"\"\n",
        "\n",
        "    gender: str\n",
        "    \"\"\"The agent's gender\"\"\"\n",
        "\n",
        "    traits: str\n",
        "    \"\"\"The agent's traits\"\"\"\n",
        "\n",
        "    interest: str\n",
        "    \"\"\"The agent's movie interest\"\"\"\n",
        "\n",
        "    feature: str\n",
        "    \"\"\"The agent's action feature\"\"\"\n",
        "\n",
        "\n",
        "    relationships: Dict[str, str] = {}\n",
        "    \"\"\"The agent's relationship with other agents\"\"\"\n",
        "\n",
        "    watched_history: List[str] = []\n",
        "    \"\"\"The agent's history of watched movies\"\"\"\n",
        "\n",
        "    heared_history: List[str] = []\n",
        "    \"\"\"The agent's history of heared movies\"\"\"\n",
        "\n",
        "    BUFFERSIZE: ClassVar[int] = 10\n",
        "    \"\"\"The size of the agent's history buffer\"\"\"\n",
        "\n",
        "    max_dialogue_token_limit: int = 600\n",
        "    \"\"\"The maximum number of tokens to use in a dialogue\"\"\"\n",
        "\n",
        "    event: Event\n",
        "    \"\"\"The agent action\"\"\"\n",
        "\n",
        "    active_prob: float = 0.5\n",
        "    \"\"\"The probability of the agent being active\"\"\"\n",
        "\n",
        "    no_action_round: int = 0\n",
        "    \"\"\"The number of rounds that the agent has not taken action\"\"\"\n",
        "\n",
        "    memory: BaseMemory\n",
        "    \"\"\"The memory module in RecAgent.\"\"\"\n",
        "\n",
        "    role: str = \"agent\"\n",
        "\n",
        "    avatar_url: str\n",
        "\n",
        "    idle_url: str\n",
        "\n",
        "    watching_url: str\n",
        "\n",
        "    chatting_url: str\n",
        "\n",
        "    posting_url: str\n",
        "\n",
        "    @classmethod\n",
        "    def from_roleagent(cls, roleagent_instance: \"RecAgent\"):\n",
        "        # 使用RoleRecAgent实例的属性来创建一个RecAgent实例\n",
        "        new_instance = cls(\n",
        "            id=roleagent_instance.id,\n",
        "            name=roleagent_instance.name,\n",
        "            age=roleagent_instance.age,\n",
        "            gender=roleagent_instance.gender,\n",
        "            traits=roleagent_instance.traits,\n",
        "            status=roleagent_instance.status,\n",
        "            interest=roleagent_instance.interest,\n",
        "            relationships=roleagent_instance.relationships,\n",
        "            feature=roleagent_instance.feature,\n",
        "            memory_retriever=roleagent_instance.memory_retriever,\n",
        "            llm=roleagent_instance.llm,\n",
        "            memory=roleagent_instance.memory,\n",
        "            event=roleagent_instance.event,\n",
        "            avatar_url=roleagent_instance.avatar_url,\n",
        "            idle_url=roleagent_instance.idle_url,\n",
        "            watching_url=roleagent_instance.watching_url,\n",
        "            chatting_ulr=roleagent_instance.chatting_url,\n",
        "            posting_url=roleagent_instance.posting_url,\n",
        "        )\n",
        "        return new_instance\n",
        "\n",
        "    def __lt__(self, other: \"RecAgent\"):\n",
        "        return self.event.end_time < other.event.end_time\n",
        "\n",
        "    def chain(self, prompt: PromptTemplate) -> LLMChain:\n",
        "        return LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "\n",
        "    def get_active_prob(self, method) -> float:\n",
        "        if method == \"marginal\":\n",
        "            return self.active_prob * (self.no_action_round + 1)\n",
        "        else:\n",
        "            return self.active_prob\n",
        "\n",
        "    def update_from_dict(self, data_dict: dict):\n",
        "        for key, value in data_dict.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "    def get_summary(\n",
        "        self,\n",
        "        now: Optional[datetime] = None,\n",
        "        observation: str = None,\n",
        "    ) -> str:\n",
        "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"Given the following observation about {agent_name}: '{observation}', please summarize the relevant details from his profile. His profile information is as follows:\\n\"\n",
        "            + \"Name: {agent_name}\\n\"\n",
        "            + \"Age: {agent_age}\\n\"\n",
        "            + \"Gender:{agent_gender}\\n\"\n",
        "            + \"Traits: {agent_traits}\\n\"\n",
        "            + \"Status: {agent_status}\\n\"\n",
        "            + \"Book Interest: {agent_interest}\\n\"\n",
        "            + \"Feature: {agent_feature}\\n\"\n",
        "            + \"Interpersonal Relationships: {agent_relationships}\\n\"\n",
        "            + \"Please avoid repeating the observation in the summary.\\nSummary:\"\n",
        "        )\n",
        "        kwargs: Dict[str, Any] = dict(\n",
        "            observation=observation,\n",
        "            agent_name=self.name,\n",
        "            agent_age=self.age,\n",
        "            agent_gender=self.gender,\n",
        "            agent_traits=self.traits,\n",
        "            agent_status=self.status,\n",
        "            agent_interest=self.interest,\n",
        "            agent_feature=self.feature,\n",
        "            agent_relationships=self.relationships,\n",
        "        )\n",
        "\n",
        "        result = self.chain(prompt=prompt).run(**kwargs).strip()\n",
        "\n",
        "        age = self.age if self.age is not None else \"N/A\"\n",
        "        return (\n",
        "            f\"Name: {self.name} (age: {age}) Interest: {self.interest}\" + f\"\\n{result}\"\n",
        "        )\n",
        "\n",
        "    def _generate_reaction(\n",
        "        self, observation: str, suffix: str, now: Optional[datetime] = None\n",
        "    ) -> str:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"{agent_summary_description}\"\n",
        "            + \"\\nIt is {current_time}.\"\n",
        "            + \"\\n{agent_name} recently heared {heared_history} on social media.\"\n",
        "            + \"\\n{agent_name} recently read {watched_history} on recommender system.\"\n",
        "            + \"\\nOther than that {agent_name} doesn't know any books.\"\n",
        "            + \"\\nMost recent observations: {most_recent_memories}\"\n",
        "            + \"\\nObservation: {observation}\"\n",
        "            + \"\\nAll occurrences of book names should be enclosed with <>\"\n",
        "            + \"\\n\\n\"\n",
        "            + suffix\n",
        "        )\n",
        "        now = datetime.now() if now is None else now\n",
        "        agent_summary_description = self.get_summary(now=now, observation=observation)\n",
        "\n",
        "        current_time_str = (\n",
        "            datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "            if now is None\n",
        "            else now.strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "        )\n",
        "        kwargs: Dict[str, Any] = dict(\n",
        "            agent_summary_description=agent_summary_description,\n",
        "            current_time=current_time_str,\n",
        "            agent_name=self.name,\n",
        "            observation=observation,\n",
        "            watched_history=(\n",
        "                self.watched_history if len(self.watched_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "            heared_history=(\n",
        "                self.heared_history if len(self.heared_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "        )\n",
        "        consumed_tokens = self.llm.get_num_tokens(\n",
        "            prompt.format(most_recent_memories=\"\", **kwargs)\n",
        "        )\n",
        "        kwargs[self.memory.most_recent_memories_key] = consumed_tokens\n",
        "        result = self.chain(prompt=prompt).run(**kwargs).strip()\n",
        "        # print(\"\\n\\n Agent Result Description: \", result)\n",
        "        return result\n",
        "\n",
        "    def _generate_reaction_bewteen_two(\n",
        "        self,\n",
        "        agent2: \"RecAgent\",\n",
        "        observation: str,\n",
        "        suffix: str,\n",
        "        now: Optional[datetime] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"React to a given observation or dialogue act.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"{agent_summary_description}\"\n",
        "            + \"\\n {agent_summary_description2}\"\n",
        "            + \"\\nIt is {current_time}.\"\n",
        "            + \"\\n{agent_name} recently heared {heared_history} on social media.\"\n",
        "            + \"\\n{agent_name} recently read {watched_history} on recommender system.\"\n",
        "            + \"\\nOther than that {agent_name} doesn't know any books.\"\n",
        "            + \"\\n{agent_name} would only mention the books had recently read, but not any other books.\"\n",
        "            + \"\\n{agent_name2} recently heared {heared_history2} on social media.\"\n",
        "            + \"\\n{agent_name2} recently read {watched_history2} on recommender system.\"\n",
        "            + \"\\nOther than that {agent_name2} doesn't know any books.\"\n",
        "            + \"\\n{agent_name} would only mention the books had recently read, but not any other books.\"\n",
        "            + \"\\nMost recent observations of {agent_name}: {most_recent_memories}\"\n",
        "            + \"\\nMost recent observations of {agent_name2}: {most_recent_memories2}\"\n",
        "            + \"\\nObservation: {observation}\"\n",
        "            + \"\\nAll occurrences of book names should be enclosed with <>\"\n",
        "            + \"\\n\\n\"\n",
        "            + suffix\n",
        "        )\n",
        "        now = datetime.now() if now is None else now\n",
        "        agent_summary_description = self.get_summary(now=now, observation=observation)\n",
        "        # print(\"\\n_generate_reaction_bewteen_two: agent_summary_description: \", agent_summary_description)\n",
        "        agent_summary_description2 = agent2.get_summary(\n",
        "            now=now, observation=observation\n",
        "        )\n",
        "        # print(\"\\n_generate_reaction_bewteen_two: agent2_summary_description: \", agent_summary_description2)\n",
        "        current_time_str = (\n",
        "            datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "            if now is None\n",
        "            else now.strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "        )\n",
        "        kwargs: Dict[str, Any] = dict(\n",
        "            agent_summary_description=agent_summary_description,\n",
        "            current_time=current_time_str,\n",
        "            agent_name=self.name,\n",
        "            observation=observation,\n",
        "            watched_history=(\n",
        "                self.watched_history if len(self.watched_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "            heared_history=(\n",
        "                self.heared_history if len(self.heared_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "            agent_summary_description2=agent_summary_description2,\n",
        "            agent_name2=agent2.name,\n",
        "            watched_history2=(\n",
        "                agent2.watched_history if len(agent2.watched_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "            heared_history2=(\n",
        "                agent2.heared_history if len(agent2.heared_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            (\n",
        "                result_memories2,\n",
        "                memories_tuple,\n",
        "            ) = agent2.memory.longTermMemory.fetch_memories_with_list(\n",
        "                observation, agent2.memory.shortTermMemory\n",
        "            )\n",
        "            result_memories2 = [memory[1] for memory in result_memories2]\n",
        "            most_recent_memories2 = '; '.join(result_memories2)\n",
        "            agent2.memory.save_context_after_retrieval(memories_tuple)\n",
        "        except:\n",
        "            most_recent_memories2 = \"\"\n",
        "\n",
        "        kwargs[\"most_recent_memories2\"] = most_recent_memories2\n",
        "        consumed_tokens = self.llm.get_num_tokens(\n",
        "            prompt.format(most_recent_memories=\"\", **kwargs)\n",
        "        )\n",
        "        kwargs[self.memory.most_recent_memories_key] = consumed_tokens\n",
        "        result = self.chain(prompt=prompt).run(**kwargs).strip()\n",
        "        return result\n",
        "\n",
        "    def get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
        "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
        "        retriever = (\n",
        "            self.memory.longTermMemory.memory_retriever\n",
        "            if type(self.memory) == RecAgentMemory\n",
        "            else self.memory.memory_retriever\n",
        "        )\n",
        "        result = []\n",
        "        for doc in retriever.memory_stream[::-1]:\n",
        "            if consumed_tokens >= self.max_dialogue_token_limit:\n",
        "                break\n",
        "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
        "            if consumed_tokens < self.max_dialogue_token_limit:\n",
        "                result.append(doc)\n",
        "        if type(self.memory) == RecAgentMemory:\n",
        "            result = self.memory.longTermMemory.format_memories_simple(result)\n",
        "        else:\n",
        "            result = self.memory.format_memories_simple(result)\n",
        "        return result\n",
        "\n",
        "    def take_action(self, now) -> Tuple[str, str]:\n",
        "        \"\"\"Take one of the actions below.\n",
        "        (1) Enter the Recommender.\n",
        "        (2) Enter the Social Media.\n",
        "        (3) Do Nothing.\n",
        "        \"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"What action would {agent_name} like to take? Respond in one line.\"\n",
        "            + \"\\nIf {agent_name} wants to enter the Recommender System, write:\\n [RECOMMENDER]:: {agent_name} enters the Recommender System\"\n",
        "            + \"\\nIf {agent_name} wants to enter the Social Media, write:\\n [SOCIAL]:: {agent_name} enters the Social Media\"\n",
        "            + \"\\nIf {agent_name} wants to do nothing, write:\\n [NOTHING]:: {agent_name} does nothing\"\n",
        "        )\n",
        "        observation = f\"{self.name} must take only ONE of the actions below:(1) Enter the Recommender System. If so, {self.name} will be recommended some books, from which {self.name} can read some books, or search for books by himself.\\n(2) Enter the Social Media. {self.name} can chat with friends or publish a post to all friends of {self.name}. If {self.name} recently read some books they might want to share with others.\\n(3) Do Nothing.\"\n",
        "\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        result = full_result.strip().split(\"\\n\")[0]\n",
        "\n",
        "        choice = result.split(\"::\")[0]\n",
        "        # action = result.split(\"::\")[1]\n",
        "\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} take action: \" f\"{result}\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        return choice, result\n",
        "\n",
        "    def positive_behavior_update(self, observation: str, now) -> str:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"Agent Name: {agent_name}\\n\"\n",
        "            + \"Observation: {observation}\\n\"\n",
        "            + \"Recently Read Book Titles: {read_history}\\n\"\n",
        "            + \"Recently Heard Book Titles from Social Media: {heard_history}\\n\"\n",
        "            + \"Current Positive Behavioral Preferences: {agent_pos}\\n\"\n",
        "            + \"Analyze the agent's recently read and heard book titles. Identify any common authors, content themes (e.g., romance, adventure, political), popularity status, or average historical ratings of these two lists.\\n\"\n",
        "            + \"Provide ONLY a concise summary of the updated positive behavioral preference profile based on your analysis.\"\n",
        "            )\n",
        "\n",
        "        kwargs: Dict[str, Any] = dict(\n",
        "            agent_name=self.name,\n",
        "            observation=observation,\n",
        "            agent_pos=self.positive_behavior,\n",
        "            read_history=(\n",
        "                self.watched_history if len(self.watched_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "            heard_history=(\n",
        "                self.heared_history if len(self.heared_history) > 0 else \"nothing\"\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        positive_behavior = self.chain(prompt=prompt).run(**kwargs).strip()\n",
        "        print(\"positive behavior: \", positive_behavior)\n",
        "\n",
        "        return positive_behavior\n",
        "\n",
        "\n",
        "    def take_recommender_action(self, observation, now) -> Tuple[str, str]:\n",
        "        \"\"\"Take one of the four actions below.\n",
        "        (1) Read books among the recommended items.\n",
        "        (2) Next page.\n",
        "        (3) Search items.\n",
        "        (4) Leave the recommender system.\n",
        "        \"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"{agent_name} must choose one of the four actions below:\\n\"\n",
        "            \"(1) Read ONLY ONE book from the list returned by the recommender system.\\n\"\n",
        "            \"(2) See the next page.\\n\"\n",
        "            \"(3) Search for a specific item.\\n\"\n",
        "            \"(4) Leave the recommender system.\"\n",
        "            + \"\\nIf {agent_name} has recently heard about a particular book on social media, {agent_name} usually want to search for that book on the recommender system.\"\n",
        "            + \"\\nTo read a book from the recommended list that match {agent_name}'s interests, write:\\n[BUY]:: Index of the book starting from 1 (e.g., [BUY]:: 3)\"\n",
        "            + \"\\nTo see the next page, write:\\n[NEXT]:: {agent_name} views the next page.\"\n",
        "            + \"\\nTo search for a specific item, write:\\n[SEARCH]:: single, specific book name to search for.\"\n",
        "            + \"\\nTo leave the recommender system, write:\\n[LEAVE]:: {agent_name} leaves the recommender system.\"\n",
        "        )\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "\n",
        "        result = full_result.strip()\n",
        "        if result.find(\"::\") != -1:\n",
        "            choice, action = result.split(\"::\")\n",
        "            choice = choice.strip()\n",
        "            match = re.search(r'(\\d+)', action)\n",
        "\n",
        "            if match:\n",
        "                num = int(match.group(1))\n",
        "                if 1 <= num <= 5:\n",
        "                    action = num\n",
        "                else:\n",
        "                    action = 1\n",
        "\n",
        "        else:\n",
        "            choice = \"[LEAVE]\"\n",
        "            action = f\"{self.name} leaves the recommender system.\"\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} took action: {result}\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        return choice, action\n",
        "\n",
        "    def generate_feeling(self, observation: str, now) -> str:\n",
        "        \"\"\"Feel about each item bought.\"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"{agent_name}, how did you feel about the book you just read? Describe your feelings in one line.\"\n",
        "            + \"NOTE: Please answer in the first-person perspective.\"\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        results = [result.strip() for result in re.split(r'[.,]', full_result)]\n",
        "        feelings = \"\"\n",
        "        for result in results:\n",
        "            if \"language model\" in result:\n",
        "                break\n",
        "            feelings += result + \". \"\n",
        "\n",
        "        # Remove trailing space and period\n",
        "        feelings = feelings.strip(\". \")\n",
        "\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} felt: \" f\"{feelings}\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        return feelings\n",
        "\n",
        "    def generate_rec_rating(self, observation: str, now) -> str:\n",
        "\n",
        "        call_to_action_template = (\n",
        "        \"Assuming you are {agent_name}. After interacting with the book the feeling are generated. \"\n",
        "        \"Based on user profile and generated feelings, please very critically rate this book on a scale from 1 to 5, where 1 means you really dislike it and 5 means you really like it. \"\n",
        "        \"Consider that your rating should critically reflect both your profile and immediate feelings generated for this book. If your generated feeling is less positive then the rating will be generally low, your score might also be lower. \"\n",
        "        \"Please provide your rating in the following format: 'Rating: [Your Score]'.\\n\\n\")\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        rating_regex = r\"Rating: (\\d)\"\n",
        "        extracted_rating = re.search(rating_regex, full_result)\n",
        "        rating = 0\n",
        "        if extracted_rating:\n",
        "            rating = extracted_rating.group(1)\n",
        "            # print(f\"Extracted Rating: {rating}\")\n",
        "        return rating\n",
        "\n",
        "    def search_item(self, observation, now) -> str:\n",
        "        \"\"\"Search item by the item name.\"\"\"\n",
        "\n",
        "        call_to_action_template = (\n",
        "            \"If you were {agent_name}, what books would you be interested in and search for in the system? Respond only a single name you want to search and read in {heared_history}.\"\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        result = full_result.strip().split(\"\\n\")[0]\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} wants to search and read {result} in recommender system.\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    def take_social_action(self, observation, now) -> Tuple[str, str]:\n",
        "        \"\"\"Take one of the four actions below.\n",
        "        (1) Chat with one acquaintance. [CHAT]:: TO [acquaintance]: what to say.\n",
        "        (2) Publish posting to all acquaintances. [POST]:: what to say.\n",
        "        \"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"{agent_name} must take one of the two actions below:\\n(1)Chat with one acquaintance about movies recently watched on recommender system: {watched_history}, or movies heared about on social media: {heared_history}.\\n(2) Publish posting to all acquaintances about movies recently watched on recommender system: {watched_history}, or heared about on social media: {heared_history}.\"\n",
        "            + \"\\nWhat action would {agent_name} like to take and how much time does the action cost?\"\n",
        "            + \"\\n{agent_name} should chat with more different people. If {agent_name} want to chat with one acquaintance, write:\\n[CHAT]:: acquaintance's name\\n[TIME]:: hours for chat. Select a number from 0.5, 1 and 2.\"\n",
        "            + \"\\nIf {agent_name} want to publish posting to all acquaintances, write:\\n[POST]:: what to post\\n[TIME]:: 1\"\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        # print(\"\\nTake Social Action Full Result: \", full_result)\n",
        "        try:\n",
        "            result, duration = full_result.split(\"\\n\")\n",
        "        except:\n",
        "            result = full_result\n",
        "            duration = 1\n",
        "        choice = result.split(\"::\")[0]\n",
        "        action = result.split(\"::\")[1].strip()\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} took action: {result}\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        if choice == \"[CHAT]\":\n",
        "            duration = duration[9:].strip(\".\")\n",
        "            duration = int(duration) if duration.isdigit() else 1\n",
        "        else:\n",
        "            duration = None\n",
        "\n",
        "        return choice, action, duration\n",
        "\n",
        "\n",
        "    def generate_dialogue_response(\n",
        "        self, observation: str, now: Optional[datetime] = None\n",
        "    ) -> Tuple[bool, str]:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"What would {agent_name} say? To end the conversation, write:\"\n",
        "            ' GOODBYE: \"what to say\". Otherwise to continue the conversation,'\n",
        "            ' write: SAY: \"what to say next\"\\n\\n'\n",
        "        )\n",
        "        full_result = self._generate_reaction(\n",
        "            observation, call_to_action_template, now=now\n",
        "        )\n",
        "        result = full_result.strip().split(\"\\n\")[0]\n",
        "        if \"GOODBYE:\" in result:\n",
        "            farewell = self._clean_response(result.split(\"GOODBYE:\")[-1])\n",
        "            self.memory.save_context(\n",
        "                {},\n",
        "                {\n",
        "                    self.memory.add_memory_key: f\"{self.name} observed \"\n",
        "                    f\"{observation} and said {farewell}\",\n",
        "                    self.memory.now_key: now,\n",
        "                },\n",
        "            )\n",
        "            return False, f\"{self.name} said {farewell}\"\n",
        "        if \"SAY:\" in result:\n",
        "            response_text = self._clean_response(result.split(\"SAY:\")[-1])\n",
        "            self.memory.save_context(\n",
        "                {},\n",
        "                {\n",
        "                    self.memory.add_memory_key: f\"{self.name} observed \"\n",
        "                    f\"{observation} and said {response_text}\",\n",
        "                    self.memory.now_key: now,\n",
        "                },\n",
        "            )\n",
        "            return True, f\"{self.name} said {response_text}\"\n",
        "        else:\n",
        "            return False, result\n",
        "\n",
        "    def generate_dialogue(\n",
        "        self, agent2, observation: str, now: Optional[datetime] = None\n",
        "    ) -> Tuple[bool, str]:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"What will be said between {agent_name} and {agent_name2}? {agent_name} initiates the conversation first. Please simulate their conversation.\"\n",
        "            \"{agent_name} and {agent_name2} should not say anything about movies they have not watched or heard about.\"\n",
        "            \"Write the dialogue in the following format:\"\n",
        "            \"[{agent_name}]:\"\n",
        "            \"[{agent_name2}]:\"\n",
        "        )\n",
        "        full_result = self._generate_reaction_bewteen_two(\n",
        "            agent2, observation, call_to_action_template, now=now\n",
        "        )\n",
        "        # print(\"\\n\\n Generate dialogue full result: \", full_result)\n",
        "\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} had a dialogue with {agent2.name}: {full_result} \",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "        agent2.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                agent2.memory.add_memory_key: f\"{agent2.name} had a dialogue with {self.name}: {full_result} \",\n",
        "                agent2.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "        return full_result\n",
        "\n",
        "    def social_network_post(self, observation, now) -> str:\n",
        "        \"\"\"Posting for all online friends\"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"{agent_name} recently reads a book on recommender systems. \"\n",
        "            \"If {agent_name} feelings after reading the book strongly align with {agent_name} positive behavioral preferences, \"\n",
        "            \"{agent_name} will make a post about the book on a social platform.\\n\"\n",
        "            \"Follow this format only:\\n\"\n",
        "            \"Public Posting: [YES/NO]\\n\"\n",
        "            \"If NO, then summary: None\\n\"\n",
        "            \"If YES, then provide a summary:\\n\"\n",
        "            \"Follow those steps for writing the summary:\\n\"\n",
        "            \"- Begin with a brief personal reaction or feeling.\\n\"\n",
        "            \"- Mention the book's title and author.\\n\"\n",
        "            \"- Give a short summary or share what you liked or disliked (in 1 sentence, avoid spoilers).\\n\"\n",
        "            \"- Conclude with a recommendation or suggest who might enjoy the book.\\n\"\n",
        "            \"- Make your post sound friendly and engaging.\\n\"\n",
        "            \"Summary:[write a summary based on the given steps]\"\n",
        "            )\n",
        "        result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        # print(\"Social Network Post Result: \", result)\n",
        "        return result\n",
        "\n",
        "    def publish_posting(self, observation, now) -> str:\n",
        "        \"\"\"Publish posting to all acquaintances.\"\"\"\n",
        "\n",
        "        call_to_action_template = (\n",
        "            \"Posts should be related to {observation} on recommender systems. \"\n",
        "            \"{agent_name} should not say anything about movies that have not watched or heard about.\"\n",
        "            + \"\\nIf you were {agent_name}, what will you post? Respond in one line.\"\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "        result = self._generate_reaction(observation, call_to_action_template, now)\n",
        "        self.memory.save_context(\n",
        "            {},\n",
        "            {\n",
        "                self.memory.add_memory_key: f\"{self.name} is publishing posting to all acquaintances. {self.name} posted {result}\",\n",
        "                self.memory.now_key: now,\n",
        "            },\n",
        "        )\n",
        "        return result\n",
        "\n",
        "    def update_watched_history(self, items, now=None):\n",
        "        \"\"\"Update history by the items bought. If the number of items in the history achieves the BUFFERSIZE, delete the oldest item.\"\"\"\n",
        "        item = []\n",
        "        # self.watched_history.extend(items)\n",
        "        item.extend(items)\n",
        "        if self.BUFFERSIZE:\n",
        "                movie_title_tokens = []\n",
        "                for token in item:\n",
        "                    if token == \";\":\n",
        "                        break\n",
        "                    if token not in {'<', '>'}:\n",
        "                        movie_title_tokens.append(token)\n",
        "\n",
        "                item = ''.join(movie_title_tokens)\n",
        "            # self.watched_history = self.watched_history[-self.BUFFERSIZE :]\n",
        "        self.watched_history.append(item)\n",
        "        # print(\"\\nRead History: \", self.watched_history)\n",
        "\n",
        "    def update_heared_history(self, items, now=None):\n",
        "        \"\"\"Update history by the items heard. If the number of items in the history achieves the BUFFERSIZE, delete the oldest item.\"\"\"\n",
        "        self.heared_history.extend(items)\n",
        "        if len(self.heared_history) > self.BUFFERSIZE:\n",
        "            self.heared_history = self.heared_history[-self.BUFFERSIZE :]\n",
        "        # print(\"\\nHeared History: \", self.heared_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56ZhkokTUuac"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "import concurrent.futures\n",
        "# import json\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "import math\n",
        "import faiss\n",
        "import re\n",
        "import dill\n",
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "import threading\n",
        "import heapq\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "\n",
        "class Simulator:\n",
        "    \"\"\"\n",
        "    Simulator class for running the simulation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: CfgNode, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.round_cnt = 0\n",
        "        self.round_msg: List[Message] = []\n",
        "        self.active_agents: List[int] = []  # active agents in current round\n",
        "        self.active_agent_threshold = config[\"active_agent_threshold\"]\n",
        "        self.active_method = config[\"active_method\"]\n",
        "        # self.file_name_path: List[str] = []\n",
        "        self.play_event = threading.Event()\n",
        "        self.working_agents: List[RecAgent] = []  # busy agents\n",
        "        self.now = datetime.now().replace(hour=8, minute=0, second=0)\n",
        "        self.interval = parse_interval(config[\"interval\"])\n",
        "        # self.round_entropy = []\n",
        "        self.socialnetwork = SocialNetwork()\n",
        "        self.rec_cnt = [0] * config[\"agent_num\"]\n",
        "        self.hit = []\n",
        "        self.ndcg = []\n",
        "        self.av_hits = []\n",
        "        self.av_ndcg = []\n",
        "        self.pairs = []\n",
        "        self.t_en = []\n",
        "        self.agent_interpage = [0] * config[\"agent_num\"]\n",
        "        # self.rec_stat = RecommenderStat(\n",
        "        #     tot_user_num=0,\n",
        "        #     cur_user_num=0,\n",
        "        #     tot_item_num=0,\n",
        "        #     inter_num=0,\n",
        "        #     rec_model=config[\"rec_model\"],\n",
        "        #     pop_items=[],\n",
        "        # )\n",
        "        self.social_stat = SocialStat(\n",
        "            tot_user_num=0,\n",
        "            cur_user_num=0,\n",
        "            tot_link_num=0,\n",
        "            chat_num=0,\n",
        "            cur_chat_num=0,\n",
        "            post_num=0,\n",
        "            pop_items=[],\n",
        "            network_density=0,\n",
        "        )\n",
        "\n",
        "    def get_file_name_path(self):\n",
        "        return self.file_name_path\n",
        "\n",
        "    def load_simulator(self):\n",
        "        \"\"\"Load and initiate the simulator.\"\"\"\n",
        "        self.round_cnt = 0\n",
        "        self.data = Data(self.config)\n",
        "        self.agents = self.agent_creation()\n",
        "        self.recsys = Recommender(self.config, self.logger, self.data)\n",
        "        # used for recommendation models\n",
        "        self.recsys.create_train_data()\n",
        "        self.recsys.load_best_model()\n",
        "        self.recsys.get_full_rankings(use_test=True)\n",
        "        self.logger.info(\"Simulator loaded.\")\n",
        "\n",
        "    def save(self, save_dir_name):\n",
        "        \"\"\"Save the simulator status of current round\"\"\"\n",
        "        ensure_dir(save_dir_name)\n",
        "        ID = generate_id(self.config[\"simulator_dir\"])\n",
        "        file_name = f\"{ID}-Round[{self.round_cnt}]-AgentNum[{self.config['agent_num']}]-{datetime.now().strftime('%Y-%m-%d-%H_%M_%S')}\"\n",
        "        self.file_name_path.append(file_name)\n",
        "        save_file_name = os.path.join(save_dir_name, file_name + \".pkl\")\n",
        "        # with open(save_file_name, \"wb\") as f:\n",
        "        #     dill.dump(self.__dict__, f)\n",
        "        self.logger.info(\"Current simulator Save in: \\n\" + str(save_file_name) + \"\\n\")\n",
        "        self.logger.info(\n",
        "            \"Simulator File Path (root -> node): \\n\" + str(self.file_name_path) + \"\\n\"\n",
        "        )\n",
        "        cpkt_path = os.path.join(self.config[\"ckpt_path\"], file_name + \".pth\")\n",
        "        self.recsys.save_model(cpkt_path)\n",
        "        self.logger.info(\n",
        "            \"Current Recommender Model Save in: \\n\" + str(cpkt_path) + \"\\n\"\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def restore(cls, restore_file_name, config, logger):\n",
        "        \"\"\"Restore the simulator status from the specific file\"\"\"\n",
        "        with open(restore_file_name + \".pkl\", \"rb\") as f:\n",
        "            obj = cls.__new__(cls)\n",
        "            obj.__dict__ = dill.load(f)\n",
        "            obj.config, obj.logger = config, logger\n",
        "            return obj\n",
        "\n",
        "    def relevance_score_fn(self, score: float) -> float:\n",
        "        \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
        "        # This will differ depending on a few things:\n",
        "        # - the distance / similarity metric used by the VectorStore\n",
        "        # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
        "        # This function converts the euclidean norm of normalized embeddings\n",
        "        # (0 is most similar, sqrt(2) most dissimilar)\n",
        "        # to a similarity function (0 to 1)\n",
        "        return 1.0 - score / math.sqrt(2)\n",
        "\n",
        "    def create_new_memory_retriever(self):\n",
        "        \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
        "        # Define your embedding model\n",
        "        embeddings_model = OpenAIEmbeddings()\n",
        "        # Initialize the vectorstore as empty\n",
        "        embedding_size = 1536\n",
        "        index = faiss.IndexFlatL2(embedding_size)\n",
        "        vectorstore = FAISS(\n",
        "            embeddings_model.embed_query,\n",
        "            index,\n",
        "            InMemoryDocstore({}),\n",
        "            {},\n",
        "            relevance_score_fn=self.relevance_score_fn,\n",
        "        )\n",
        "\n",
        "        # If choose RecAgentMemory, you must use RecAgentRetriever rather than TimeWeightedVectorStoreRetriever.\n",
        "        RetrieverClass = (\n",
        "            RecAgentRetriever\n",
        "            if self.config[\"recagent_memory\"] == \"recagent\"\n",
        "            else TimeWeightedVectorStoreRetriever\n",
        "        )\n",
        "\n",
        "        return RetrieverClass(\n",
        "            vectorstore=vectorstore, memory_stream=[\"importance\"], now=self.now, k=5\n",
        "        )\n",
        "\n",
        "    def check_active(self, index: int):\n",
        "        # If agent's previous action is completed, reset the event\n",
        "        agent = self.agents[index]\n",
        "        if isinstance(agent, RoleAgent):\n",
        "            return True\n",
        "\n",
        "        if (\n",
        "            self.active_agent_threshold\n",
        "            and len(self.active_agents) >= self.active_agent_threshold\n",
        "        ):\n",
        "            return False\n",
        "        # If the book does not end, the agent continues reading the book.\n",
        "        if agent.event.action_type == \"reading\":\n",
        "            self.round_msg.append(\n",
        "                Message(\n",
        "                    agent_id=agent.id,\n",
        "                    action=\"READ\",\n",
        "                    content=f\"{agent.name} is reading book.\",\n",
        "                )\n",
        "            )\n",
        "            return False\n",
        "\n",
        "        active_prob = agent.get_active_prob(self.active_method)\n",
        "        if np.random.random() > active_prob:\n",
        "            agent.no_action_round += 1\n",
        "            return False\n",
        "        self.active_agents.append(index)\n",
        "        return True\n",
        "\n",
        "    def pause(self):\n",
        "        self.play_event.clear()\n",
        "\n",
        "    def play(self):\n",
        "        self.play_event.set()\n",
        "\n",
        "    def one_step(self, agent_id):\n",
        "        \"\"\"Run one step of an agent.\"\"\"\n",
        "        self.play_event.wait()\n",
        "        if not self.check_active(agent_id):\n",
        "            # print(\"Not Active\")\n",
        "            return [\n",
        "                Message(agent_id=agent_id, action=\"NO_ACTION\", content=\"No action.\")\n",
        "            ]\n",
        "        agent = self.agents[agent_id]\n",
        "        name = agent.name\n",
        "        message = []\n",
        "        page = 0\n",
        "        book_rating = None\n",
        "\n",
        "        choice, observation = agent.take_action(self.now)\n",
        "\n",
        "        with lock:\n",
        "            heapq.heappush(self.working_agents, agent)\n",
        "        if \"RECOMMENDER\" in choice:\n",
        "            ids = []\n",
        "            self.rec_cnt[agent_id] += 1\n",
        "            self.logger.info(f\"{name} enters the recommender system.\")\n",
        "            message.append(\n",
        "                Message(\n",
        "                    agent_id=agent_id,\n",
        "                    action=\"RECOMMENDER\",\n",
        "                    content=f\"{name} enters the recommender system.\",\n",
        "                )\n",
        "            )\n",
        "            self.round_msg.append(\n",
        "                Message(\n",
        "                    agent_id=agent_id,\n",
        "                    action=\"RECOMMENDER\",\n",
        "                    content=f\"{name} enters the recommender system.\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "            leave = False\n",
        "\n",
        "            # choice the ratio of ground truth items and random items\n",
        "            # gt_ratio, rd_ratio, total_items = 1, 1, 10\n",
        "            # item_ids, rec_items, gt_items = self.recsys.get_full_manual_items(agent_id, gt_ratio, rd_ratio, total_items)\n",
        "\n",
        "            # from recommender system (MF, NueMF, LightGCN, MultiVAE)\n",
        "            # self.recsys.get_full_rankings() # Is needed!\n",
        "\n",
        "            # without continual page\n",
        "            item_ids = self.recsys.full_rankings[agent_id][page*self.recsys.page_size:(page+1)*self.recsys.page_size]\n",
        "            # start_idx = self.agent_interpage[agent_id] # continual page\n",
        "            # end_idx = start_idx + self.recsys.page_size # continual page\n",
        "            # item_ids = self.recsys.full_rankings[agent_id][start_idx:end_idx] # continual page\n",
        "            # print(\"Item IDs: \", item_ids)\n",
        "\n",
        "            rec_items = self.recsys.get_rec_discription(item_ids)\n",
        "            self.recsys.update_user_interactions(agent_id, item_ids)\n",
        "            # item_ids, rec_items = self.recsys.get_full_sort_items(agent_id)\n",
        "            cnt = 0\n",
        "            searched_name = None\n",
        "            while not leave:\n",
        "                self.logger.info(\n",
        "                          f\"{name} is recommended {rec_items}.\"\n",
        "                )\n",
        "                #     f\"{name} is recommended {rec_items[page*self.recsys.page_size:(page+1)*self.recsys.page_size]}.\"\n",
        "                # )\n",
        "                message.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"RECOMMENDER\",\n",
        "                        # content=f\"{name} is recommended {rec_items[page*self.recsys.page_size:(page+1)*self.recsys.page_size]}.\",\n",
        "                        content=f\"{name} is recommended {rec_items}.\",\n",
        "                    )\n",
        "                )\n",
        "                self.round_msg.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"RECOMMENDER\",\n",
        "                        # content=f\"{name} is recommended {rec_items[page*self.recsys.page_size:(page+1)*self.recsys.page_size]}.\",\n",
        "                        content=f\"{name} is recommended {rec_items}.\",\n",
        "                    )\n",
        "                )\n",
        "                observation = f\"{name} is browsing the recommender system.\"\n",
        "                if searched_name is not None:\n",
        "                    observation = (\n",
        "                        observation\n",
        "                        # + f\" {name} has searched for {searched_name} in recommender system and recommender system returns item list:{rec_items[page*self.recsys.page_size:(page+1)*self.recsys.page_size]} as search results.\"\n",
        "                        + f\" {name} has searched for {searched_name} in recommender system and recommender system returns item list:{self.recsys.data.search_items(searched_name, k=5)} as search results.\"\n",
        "                    )\n",
        "                else:\n",
        "                    observation = (\n",
        "                        observation\n",
        "                        + f\" {name} is recommended {rec_items}.\"\n",
        "                    )\n",
        "                while True:\n",
        "                    # print(\"Observation: \", observation)\n",
        "                    choice, action = agent.take_recommender_action(observation, self.now)\n",
        "                    ids.extend(item_ids)\n",
        "\n",
        "\n",
        "                    if \"BUY\" in choice and (\n",
        "                        agent.event.action_type == \"idle\"\n",
        "                        or agent.event.action_type == \"posting\"\n",
        "                        ):\n",
        "                       page += 1\n",
        "                      #  self.agent_interpage[agent_id] = start_idx + 1 # continual page\n",
        "                       # item_names = rec_items[page * self.recsys.page_size + action - 1]\n",
        "                       item_names = rec_items[action - 1]\n",
        "                       # print(\"\\n\\nItem Names: \", item_names, \"\\n\")\n",
        "                       # item_id = item_ids[page * self.recsys.page_size + action - 1]\n",
        "                       item_id = item_ids[action - 1]\n",
        "                       duration = 2\n",
        "                       agent.event = update_event(\n",
        "                           original_event=agent.event,\n",
        "                           start_time=self.now,\n",
        "                           duration=duration,\n",
        "                           target_agent=None,\n",
        "                           action_type=\"reading\",\n",
        "                       )\n",
        "\n",
        "                       self.logger.info(f\"{name} reads {item_names}\")\n",
        "                       message.append(\n",
        "                           Message(\n",
        "                               agent_id=agent_id,\n",
        "                               action=\"RECOMMENDER\",\n",
        "                               content=f\"{name} reads {item_names}.\",\n",
        "                           )\n",
        "                        )\n",
        "                       self.round_msg.append(\n",
        "                           Message(\n",
        "                              agent_id=agent_id,\n",
        "                              action=\"RECOMMENDER\",\n",
        "                              content=f\"{name} reads {item_names}.\",\n",
        "                            )\n",
        "                        )\n",
        "                       agent.update_watched_history(item_names)\n",
        "                       self.recsys.update_history_by_id(\n",
        "                           agent_id,\n",
        "                           [item_id],\n",
        "                           )\n",
        "\n",
        "\n",
        "                       self.hit.append([self.recsys.data.hit_at_k([item_id], ids, a) for a in range(1, 11)])\n",
        "                       self.ndcg.append([self.recsys.data.ndcg_at_k([item_id], ids, b) for b in range(1, 11)])\n",
        "\n",
        "                       self.recsys.update_positive_by_id(agent_id, item_id)\n",
        "\n",
        "                       item_descriptions = self.data.get_item_description_by_name(\n",
        "                           [item_names]\n",
        "                           )\n",
        "                       if len(item_descriptions) == 0:\n",
        "                          self.logger.info(f\"{name} leaves the recommender system.\")\n",
        "                          message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"{name} leaves the recommender system.\",\n",
        "                            )\n",
        "                            )\n",
        "                          self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"{name} leaves the recommender system.\",\n",
        "                            )\n",
        "                            )\n",
        "                          leave = True\n",
        "                          continue\n",
        "\n",
        "                       observation = f\"{name} has just finished reading {item_names};;{item_descriptions[0]}.\"\n",
        "                       feelings = agent.generate_feeling(\n",
        "                            observation, self.now + timedelta(hours=duration)\n",
        "                            )\n",
        "                      #  # Social network post analysis\n",
        "                      #  public_post = (\n",
        "                      #       observation\n",
        "                      #       + f\"Feelings after reading the book:\"\n",
        "                      #       + feelings)\n",
        "                      #  social_network_post = agent.social_network_post(\n",
        "                      #       public_post, self.now + timedelta(hours=duration)\n",
        "                      #       )\n",
        "                      #  yes_match = re.search(r'Public Posting:\\s*(YES|NO)', social_network_post)\n",
        "                      #  public_posting = yes_match.group(1) if yes_match else None\n",
        "\n",
        "                      #  # Extract summary only if YES\n",
        "                      #  summary = None\n",
        "                      #  if public_posting == \"YES\":\n",
        "                      #     summary_match = re.search(r'Summary:\\s*(.+)', social_network_post, re.DOTALL)\n",
        "                      #     summary = summary_match.group(1).strip() if summary_match else None\n",
        "                      #     book_genre = self.recsys.data.get_genres_by_id([item_id])\n",
        "                      #     self.socialnetwork.create_post(agent_id, self.round_cnt, public_posting, summary, book_genre)\n",
        "                      #  # End analysis of social network post\n",
        "\n",
        "                       self.logger.info(f\"{name} feels: {feelings}\")\n",
        "\n",
        "                       message.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} feels: {feelings}\",\n",
        "                            )\n",
        "                            )\n",
        "                       self.round_msg.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} feels: {feelings}\",\n",
        "                            )\n",
        "                            )\n",
        "                       # print(\"Item ID: \", item_id)\n",
        "                       historical_rating = self.recsys.data.user_avg_rating[agent_id]\n",
        "                       # print(\"Historical Rating: \", historical_rating)\n",
        "                       user_profile = self.recsys.data.get_user_profile(agent_id)\n",
        "                       # print(\"User Profile: \", user_profile)\n",
        "                       feel_rating = (\n",
        "                            user_profile\n",
        "                            + feelings\n",
        "                            + f\" {name} has a historical rating:{historical_rating}.\"\n",
        "                            )\n",
        "                       book_rating = agent.generate_rec_rating(feel_rating, self.now)\n",
        "                       self.recsys.add_review(agent_id, book_rating, feelings)\n",
        "                       self.pairs.append(self.recsys.calculation_of_rating(agent_id, item_names, book_rating))\n",
        "                       searched_name = None\n",
        "                       leave = True\n",
        "                       break\n",
        "\n",
        "                    elif \"NEXT\" in choice:\n",
        "                        # self.agent_interpage[agent_id] = start_idx + 1 # continual page\n",
        "                        self.logger.info(f\"{name} looks next page.\")\n",
        "                        page += 1\n",
        "                        # without continual page\n",
        "                        nitem_ids = self.recsys.full_rankings[agent_id][page*self.recsys.page_size:(page+1)*self.recsys.page_size]\n",
        "\n",
        "                        nrec_items = self.recsys.get_rec_discription(item_ids)\n",
        "\n",
        "                        # nitem_ids, nrec_items, ngt_items = self.recsys.get_full_manual_items(agent_id, gt_ratio, rd_ratio, total_items)\n",
        "                        for i in range(len(nitem_ids)):\n",
        "                            self.recsys.add_train_data(\n",
        "                                agent_id, nitem_ids, 0\n",
        "                                )\n",
        "\n",
        "                        message.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} looks next page.\",\n",
        "                            )\n",
        "                            )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"{name} looks next page.\",\n",
        "                                )\n",
        "                            )\n",
        "                        rec_items = nrec_items\n",
        "                        item_ids = nitem_ids\n",
        "                        # Update observation for new recommendations and loop again (do not break)\n",
        "                        observation = f\"{name} is browsing the recommender system and looks next page. {name} is recommended {rec_items}.\"\n",
        "\n",
        "                        if page == 5:\n",
        "                           page = 0\n",
        "                           self.logger.info(f\"{name} scroll maximum pages.\")\n",
        "                           self.logger.info(f\"{name} leaves the recommender system.\")\n",
        "                           message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"{name} scroll maximum pages. {name} leaves the recommender system.\",\n",
        "                            )\n",
        "                            )\n",
        "                           self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"No more items. {name} leaves the recommender system.\",\n",
        "                            )\n",
        "                            )\n",
        "                           for post in self.socialnetwork.get_ranked_posts_for_agent(agent_id):\n",
        "                               print(self.socialnetwork.format_post(post))\n",
        "                           leave = True\n",
        "                           break\n",
        "                        else:\n",
        "                            continue\n",
        "                    elif \"SEARCH\" in choice:\n",
        "                        # self.agent_interpage[agent_id] = start_idx + 1 # continual page\n",
        "                        page += 1\n",
        "                        observation = f\"{name} is searching in recommender system.\"\n",
        "                        item_name = agent.search_item(observation, self.now)\n",
        "                        self.logger.info(f\"{name} searches {item_name}.\")\n",
        "                        message.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} searches {item_name}.\",\n",
        "                        )\n",
        "                            )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} searches {item_name}.\",\n",
        "                        )\n",
        "                            )\n",
        "                        item_names = extract_item_names(item_name)\n",
        "                        if item_names == []:\n",
        "                            agent.memory.add_memory(\n",
        "                            f\"There are no items related in the system.\", now=self.now\n",
        "                            )\n",
        "                            self.logger.info(\"There are no related items in the system.\")\n",
        "                            message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"There are no related products in the system.\",\n",
        "                            )\n",
        "                            )\n",
        "                            self.round_msg.append(\n",
        "                                Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"There are no related products in the system.\",\n",
        "                            )\n",
        "                                )\n",
        "                            leave = True\n",
        "                            continue\n",
        "                        item_name = item_names[0]\n",
        "                        search_items = self.recsys.get_search_items(item_name)\n",
        "                        self.logger.info(f\"Recommender returned {search_items}.\")\n",
        "                        message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"Recommender returned {search_items}.\",\n",
        "                        )\n",
        "                            )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"Recommender returned {search_items}.\",\n",
        "                        )\n",
        "                            )\n",
        "                        if len(search_items) != 0:\n",
        "                           rec_items = search_items\n",
        "                           item_ids = self.data.get_item_ids_exact(search_items)\n",
        "                           page = 0\n",
        "                           searched_name = item_name\n",
        "                        else:\n",
        "                           agent.memory.add_memory(\n",
        "                            f\"There are no items related to {item_name} in the system.\",\n",
        "                            now=self.now,\n",
        "                            )\n",
        "                           self.logger.info(\"There are no related items in the system.\")\n",
        "                           message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"There are no related products in the system.\",\n",
        "                            )\n",
        "                            )\n",
        "                           self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"RECOMMENDER\",\n",
        "                                content=f\"There are no related products in the system.\",\n",
        "                            )\n",
        "                            )\n",
        "                        break\n",
        "                else:\n",
        "                    self.logger.info(f\"{name} leaves the recommender system.\")\n",
        "                    message.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} leaves the recommender system.\",\n",
        "                        )\n",
        "                    )\n",
        "                    self.round_msg.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} leaves the recommender system.\",\n",
        "                        )\n",
        "                    )\n",
        "                    leave = True\n",
        "                cnt += 1\n",
        "                if cnt == 5:\n",
        "                    self.logger.info(f\"{name} leaves the recommender system.\")\n",
        "                    message.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} leaves the recommender system.\",\n",
        "                        )\n",
        "                    )\n",
        "                    self.round_msg.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"RECOMMENDER\",\n",
        "                            content=f\"{name} leaves the recommender system.\",\n",
        "                        )\n",
        "                    )\n",
        "                    leave = True\n",
        "            N_expose = page * self.config['page_size']\n",
        "            N_view = 1 if book_rating is not None else 0\n",
        "            N_like = 1 if book_rating is not None and int(book_rating) > 3 else 0\n",
        "            if page == 0:\n",
        "                N_exit = 5\n",
        "            else:\n",
        "                N_exit = page\n",
        "            S_sat = 5\n",
        "            self.recsys.add_user(agent_id, N_expose, N_view, N_like, N_exit, S_sat)\n",
        "            # entropy = get_entropy(ids, self.data)\n",
        "            # self.round_entropy.append(entropy)\n",
        "            # self.recsys.round_record[agent_id].append(ids)\n",
        "\n",
        "        elif \"SOCIAL\" in choice:\n",
        "            contact = self.data.get_all_contacts(agent_id)\n",
        "            # print(\"\\n\\nAll contacts in SOCIAL Media: \", contacts)\n",
        "            num_agent = ['Emily Johnson', 'Sarah Johnson', 'David Miller', 'Sarah Garcia', ' John Smith', 'Emily Miller', 'Sarah Smith', 'William Brown', 'John Davis', 'Christopher Wilson']\n",
        "            # num_agent = ['David Smith', 'David Miller', 'James Brown', 'Sarah Miller', 'John Taylor', 'Sarah Williams', 'James Jones', 'Jane Brown', 'David Jones', 'James Brown']\n",
        "            for ng in num_agent:\n",
        "                contacts = [con for con in contact if con == ng]\n",
        "            if len(contacts) == 0:\n",
        "                self.logger.info(f\"{name} has no acquaintance.\")\n",
        "                message.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"SOCIAL\",\n",
        "                        content=f\"{name} has no acquaintance.\",\n",
        "                    )\n",
        "                )\n",
        "                self.round_msg.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"SOCIAL\",\n",
        "                        content=f\"{name} has no acquaintance.\",\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                self.social_stat.cur_user_num += 1\n",
        "                self.logger.info(f\"{name} is going to social media.\")\n",
        "                message.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"SOCIAL\",\n",
        "                        content=f\"{name} is going to social media.\",\n",
        "                    )\n",
        "                )\n",
        "                self.round_msg.append(\n",
        "                    Message(\n",
        "                        agent_id=agent_id,\n",
        "                        action=\"SOCIAL\",\n",
        "                        content=f\"{name} is going to social media.\",\n",
        "                    )\n",
        "                )\n",
        "                observation = f\"{name} is going to social media. {name} and {contacts} are acquaintances. {name} can chat with acquaintances, or post to all acquaintances. What will {name} do?\"\n",
        "                choice, action, duration = agent.take_social_action(\n",
        "                    observation, self.now\n",
        "                )\n",
        "                print(\"\\nSocial Media Choice: \",choice)\n",
        "                print(\"\\nSocial Media Action: \",action)\n",
        "                if \"CHAT\" in choice:\n",
        "                    agent_name2 = action.strip(\" \\t\\n'\\\"\")\n",
        "                    # print(\"agent_name2:\", agent_name2)\n",
        "                    agent_id2 = self.data.get_user_ids([agent_name2])[0]\n",
        "                    agent2 = self.agents[agent_id2]\n",
        "                    # If agent2 is watching moives, he cannot be interupted.\n",
        "                    if agent2.event.action_type == \"reading\":\n",
        "                        print(\"\\n\\nWatching Movie...........\\n\")\n",
        "                        agent.memory.add_memory(\n",
        "                            f\"{agent.name} wants to chat with {agent_name2}, but {agent_name2} is reading. So {agent.name} does nothing.\",\n",
        "                            now=self.now,\n",
        "                        )\n",
        "                        self.logger.info(\n",
        "                            f\"{name} wants to chat with {agent_name2}, but {agent_name2} is reading. So {name} does nothing.\"\n",
        "                        )\n",
        "                        message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"LEAVE\",\n",
        "                                content=f\"{name} wants to chat with {agent_name2}, but {agent_name2} is reading. So {name} does nothing.\",\n",
        "                            )\n",
        "                        )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"LEAVE\",\n",
        "                                content=f\"{name} wants to chat with {agent_name2}, but {agent_name2} is reading. So {name} does nothing.\",\n",
        "                            )\n",
        "                        )\n",
        "                        print(\"\\nSocial Message: \", message)\n",
        "                        return message\n",
        "\n",
        "                    #  If agent2 is chatting with agent1, skipping this round\n",
        "                    if is_chatting(agent, agent2):\n",
        "                        print(\"\\n\\nChatting with Someone...........\\n\")\n",
        "                        self.logger.info(f\"{name} is chatting with {agent_name2}\")\n",
        "                        message.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"CHAT\",\n",
        "                                content=f\"{name} is chatting with {agent_name2}\",\n",
        "                            )\n",
        "                        )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=agent_id,\n",
        "                                action=\"CHAT\",\n",
        "                                content=f\"{name} is chatting with {agent_name2}.\",\n",
        "                            )\n",
        "                        )\n",
        "                        print(\"\\n\\nIs Chatting:\", message)\n",
        "                        return message\n",
        "                    agent.event = update_event(\n",
        "                        original_event=agent.event,\n",
        "                        start_time=self.now,\n",
        "                        duration=duration,\n",
        "                        target_agent=agent_name2,\n",
        "                        action_type=\"chatting\",\n",
        "                    )\n",
        "                    agent2.event = update_event(\n",
        "                        original_event=agent2.event,\n",
        "                        start_time=self.now,\n",
        "                        duration=duration,\n",
        "                        target_agent=name,\n",
        "                        action_type=\"chatting\",\n",
        "                    )\n",
        "                    self.logger.info(f\"{name} is chatting with {agent_name2}.\")\n",
        "                    self.social_stat.chat_num += 1\n",
        "                    message.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"CHAT\",\n",
        "                            content=f\"{name} is chatting with {agent_name2}.\",\n",
        "                        )\n",
        "                    )\n",
        "                    self.round_msg.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"CHAT\",\n",
        "                            content=f\"{name} is chatting with {agent_name2}.\",\n",
        "                        )\n",
        "                    )\n",
        "                    # If the system has a role, and it is her term now.\n",
        "                    if self.config[\"play_role\"] and self.data.role_id == agent_id:\n",
        "                        print(\"\\n\\nPlay Role...........\\n\")\n",
        "                        conversation = \"\"\n",
        "                        observation = f\"{name} is going to chat with {agent2.name}.\"\n",
        "                        # Obtain the response from the role.\n",
        "                        contin, result, role_dia = agent.generate_role_dialogue(\n",
        "                            agent2, observation\n",
        "                        )\n",
        "                        conversation += role_dia + result\n",
        "                        self.logger.info(role_dia)\n",
        "                        self.logger.info(result)\n",
        "                        # If both of them do not stop, an extra round will be held.\n",
        "                        while contin:\n",
        "                            contin, result, role_dia = agent.generate_role_dialogue(\n",
        "                                agent2, observation, conversation\n",
        "                            )\n",
        "                            conversation += role_dia + result\n",
        "                            self.logger.info(role_dia)\n",
        "                            self.logger.info(result)\n",
        "                    else:\n",
        "                        print(\"\\n\\nLast Else...........\\n\")\n",
        "                        observation = f\"{name} is going to chat with {agent2.name}.\"\n",
        "                        # If an agent wants to chat with the role.\n",
        "                        if self.config[\"play_role\"] and agent_id2 == self.data.role_id:\n",
        "                            print(\"\\nEntering IF play role\")\n",
        "                            conversation = \"\"\n",
        "                            observation = f\"{name} is going to chat with {agent2.name}.\"\n",
        "                            # Obtain the response from the agent(LLM).\n",
        "                            contin, result = agent.generate_dialogue_response(\n",
        "                                observation\n",
        "                            )\n",
        "                            agent_dia = \"%s %s\" % (agent.name, result)\n",
        "                            self.logger.info(agent_dia)\n",
        "                            # Obtain the response from the role.\n",
        "                            role_contin, role_dia = agent2.generate_dialogue_response(\n",
        "                                observation\n",
        "                            )\n",
        "                            self.logger.info(role_dia)\n",
        "                            contin = contin and role_contin\n",
        "                            conversation += agent_dia + role_dia\n",
        "                            # If both of them do not stop, an extra round will be held.\n",
        "                            while contin:\n",
        "                                observation = (\n",
        "                                    f\"{name} is going to chat with {agent2.name}.\"\n",
        "                                )\n",
        "                                contin, result = agent.generate_dialogue_response(\n",
        "                                    observation\n",
        "                                )\n",
        "                                agent_dia = \"%s %s\" % (agent.name, result)\n",
        "                                self.logger.info(agent_dia)\n",
        "                                (\n",
        "                                    role_contin,\n",
        "                                    role_dia,\n",
        "                                ) = agent2.generate_dialogue_response(observation)\n",
        "                                self.logger.info(role_dia)\n",
        "                                contin = contin and role_contin\n",
        "                                conversation += agent_dia + role_dia\n",
        "                        else:\n",
        "                            # Otherwise, two agents(LLM) will generate dialogues.\n",
        "                            print(\"\\nEntering Else....:\")\n",
        "                            conversation = agent.generate_dialogue(agent2, observation)\n",
        "                            # print(\"\\n Conversation: \", conversation)\n",
        "                        self.logger.info(conversation)\n",
        "\n",
        "                    msgs = []\n",
        "                    matches = re.findall(r\"\\[([^]]+)\\]:\\s*(.*)\", conversation)\n",
        "                    print(\"\\n\\n Matches..: \", matches)\n",
        "                    for match in matches:\n",
        "                        speaker = match[0]\n",
        "                        content = match[1]\n",
        "                        if speaker == agent.name:\n",
        "                            id = agent_id\n",
        "                            id2 = agent_id2\n",
        "                        else:\n",
        "                            id = agent_id2\n",
        "                            id2 = agent_id\n",
        "                        item_names = extract_item_names(content, \"SOCIAL\")\n",
        "                        self.data.add_mention_cnt(item_names)\n",
        "                        if item_names != []:\n",
        "                            self.agents[id2].update_heared_history(item_names)\n",
        "                            # New lines\n",
        "                            aitem_id = self.recsys.data.get_item_ids(item_names)\n",
        "                            self.recsys.update_positive_by_id(agent_id, aitem_id)\n",
        "                        msgs.append(\n",
        "                            Message(\n",
        "                                agent_id=id,\n",
        "                                action=\"CHAT\",\n",
        "                                content=f\"{speaker} says:{content}\",\n",
        "                            )\n",
        "                        )\n",
        "                        self.round_msg.append(\n",
        "                            Message(\n",
        "                                agent_id=id,\n",
        "                                action=\"CHAT\",\n",
        "                                content=f\"{speaker} says:{content}\",\n",
        "                            )\n",
        "                        )\n",
        "                    message.extend(msgs)\n",
        "\n",
        "                else:\n",
        "                    print(\"\\n\\nPublic Posting\")\n",
        "                    self.social_stat.post_num += 1\n",
        "                    self.logger.info(f\"{name} is posting.\")\n",
        "                    observation = f\"{name} want to post for all acquaintances.\"\n",
        "                    observation = agent.publish_posting(observation, self.now)\n",
        "                    item_names = extract_item_names(observation, \"SOCIAL\")\n",
        "                    self.logger.info(agent.name + \" posted: \" + observation)\n",
        "                    if agent.event.action_type == \"idle\":\n",
        "                        agent.event = update_event(\n",
        "                            original_event=agent.event,\n",
        "                            start_time=self.now,\n",
        "                            duration=0.1,\n",
        "                            target_agent=None,\n",
        "                            action_type=\"posting\",\n",
        "                        )\n",
        "                    message.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"POST\",\n",
        "                            content=agent.name + \" posts: \" + observation,\n",
        "                        )\n",
        "                    )\n",
        "                    self.round_msg.append(\n",
        "                        Message(\n",
        "                            agent_id=agent_id,\n",
        "                            action=\"POST\",\n",
        "                            content=agent.name + \" posts: \" + observation,\n",
        "                        )\n",
        "                    )\n",
        "                    for i in self.agents.keys():\n",
        "                        if self.agents[i].name in contacts:\n",
        "                            self.agents[i].memory.add_memory(\n",
        "                                agent.name + \" posts: \" + observation, now=self.now\n",
        "                            )\n",
        "                            self.agents[i].update_heared_history(item_names)\n",
        "                            # New lines\n",
        "                            aitem_id = self.recsys.data.get_item_ids(item_names)\n",
        "                            self.recsys.update_positive_by_id(agent_id, aitem_id)\n",
        "\n",
        "                            message.append(\n",
        "                                Message(\n",
        "                                    agent_id=self.agents[i].id,\n",
        "                                    action=\"POST\",\n",
        "                                    content=self.agents[i].name\n",
        "                                    + \" observes that\"\n",
        "                                    + agent.name\n",
        "                                    + \" posts: \"\n",
        "                                    + observation,\n",
        "                                )\n",
        "                            )\n",
        "                            self.round_msg.append(\n",
        "                                Message(\n",
        "                                    agent_id=self.agents[i].id,\n",
        "                                    action=\"POST\",\n",
        "                                    content=self.agents[i].name\n",
        "                                    + \" observes that\"\n",
        "                                    + agent.name\n",
        "                                    + \" posts: \"\n",
        "                                    + observation,\n",
        "                                )\n",
        "                            )\n",
        "\n",
        "                    self.logger.info(f\"{contacts} get this post.\")\n",
        "\n",
        "        else:\n",
        "            self.logger.info(f\"{name} does nothing.\")\n",
        "            message.append(\n",
        "                Message(\n",
        "                    agent_id=agent_id, action=\"LEAVE\", content=f\"{name} does nothing.\"\n",
        "                )\n",
        "            )\n",
        "            self.round_msg.append(\n",
        "                Message(\n",
        "                    agent_id=agent_id, action=\"LEAVE\", content=f\"{name} does nothing.\"\n",
        "                )\n",
        "            )\n",
        "        # print(\"\\nFinal Message: \", message, \"\\n\")\n",
        "\n",
        "        return message\n",
        "\n",
        "    def update_working_agents(self):\n",
        "        with lock:\n",
        "            agent: RecAgent = None\n",
        "            while len(self.working_agents) > 0:\n",
        "                agent = heapq.heappop(self.working_agents)\n",
        "                if agent.event.end_time <= self.now:\n",
        "                    agent.event = reset_event(self.now)\n",
        "                else:\n",
        "                    break\n",
        "            if agent is not None and agent.event.end_time > self.now:\n",
        "                heapq.heappush(self.working_agents, agent)\n",
        "\n",
        "    def round(self):\n",
        "        \"\"\"\n",
        "        Run one step for all agents.\n",
        "        \"\"\"\n",
        "        messages = []\n",
        "        futures = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        accuracies = []\n",
        "        f1s = []\n",
        "        self.hit = []\n",
        "        self.ndcg = []\n",
        "        read = []\n",
        "        hear = []\n",
        "\n",
        "        # The user's role takes one step first.\n",
        "        if self.config[\"play_role\"]:\n",
        "            role_msg = self.one_step(self.data.role_id)\n",
        "            messages.extend(role_msg)\n",
        "            # print(\"Enter in the play_role: \", messages)\n",
        "\n",
        "        if self.config[\"execution_mode\"] == \"parallel\":\n",
        "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                for i in tqdm(range(1, self.config[\"agent_num\"])):\n",
        "                    futures.append(executor.submit(self.one_step, i))\n",
        "                    # print(\"one step stopped..................\", futures)\n",
        "                    # time.sleep(10)\n",
        "\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                # try:\n",
        "                msgs = future.result()\n",
        "                messages.append(msgs)\n",
        "                #     print(f\"Result: {messages}\")\n",
        "                # except Exception as e:\n",
        "                #     print(f\"Exception: {e}\")\n",
        "\n",
        "        else:\n",
        "            for i in tqdm(range(1, self.config[\"agent_num\"])):\n",
        "                msgs = self.one_step(i)\n",
        "                messages.append(msgs)\n",
        "        self.now = add_interval(self.now, self.interval)\n",
        "\n",
        "        for i, agent in self.agents.items():\n",
        "            agent.memory.update_now(self.now)\n",
        "            # Comment this line whenever you don't want to use the memory\n",
        "            agent.memory.longTermMemory.print_memory()\n",
        "            # print(\"\\n\")\n",
        "            read_books = self.recsys.data.get_item_ids(agent.watched_history)\n",
        "\n",
        "            item_set = self.recsys.interaction_dict.get(agent.id, set())\n",
        "            all_item = list(item_set)\n",
        "            precision, recall, accuracy, f1 = self.recsys.calculate_user_metrics(agent.id, read_books, all_item)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            accuracies.append(accuracy)\n",
        "            f1s.append(f1)\n",
        "            read_list = self.recsys.data.get_item_ids(agent.watched_history)\n",
        "            hear_list = self.recsys.data.get_item_ids(agent.heared_history)\n",
        "            read.append(get_entropy(read_list, self.recsys.data))\n",
        "            hear.append(get_entropy(hear_list, self.recsys.data))\n",
        "\n",
        "            if self.round_cnt % 16 == 0:\n",
        "               for k in [1, 3, 5, 10]:\n",
        "                   precisonk, recallk = self.recsys.precisionandrecallk(agent.id, read_books, k)\n",
        "                   print(f\"Precision@{k}: {precisonk}, Recall@{k}: {recallk}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "        avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "        avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0\n",
        "        avg_f1 = sum(f1s) / len(f1s) if f1s else 0\n",
        "\n",
        "        mean_hits = np.mean(np.array(self.hit), axis=0)\n",
        "        mean_ndcg = np.mean(np.array(self.ndcg), axis=0)\n",
        "        self.av_hits.append(mean_hits)\n",
        "        self.av_ndcg.append(mean_ndcg)\n",
        "\n",
        "        print(\" \".join([f\"HIT@{k}: {mean_hits[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "        print(\" \".join([f\"NDCG@{k}: {mean_ndcg[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "        print(\" \".join([f\"Average HIT@{k}: {np.mean(self.av_hits, axis=0)[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "        print(\" \".join([f\"Average NDCG@{k}: {np.mean(self.av_ndcg, axis=0)[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "        print(\"Average Precision: \", avg_precision, \"Average Recall: \", avg_recall, \"Average Accuracy:\", avg_accuracy,\n",
        "              \"Average F1-Score: \", avg_f1)\n",
        "        print(\"Entropy: \", self.recsys.get_entropy())\n",
        "        print(\"Read Entropy: \", np.mean(read))\n",
        "        print(\"Hear Entropy: \", np.mean(hear))\n",
        "        print(\"Total Entropy: \", np.mean(read) + np.mean(hear))\n",
        "        self.t_en.append(np.mean(read) + np.mean(hear))\n",
        "        if self.round_cnt == 20:\n",
        "          print(\"Total Entropys: \", self.t_en)\n",
        "          df = pd.DataFrame(self.recsys.rating_feeling)\n",
        "          df.to_csv('/content/drive/MyDrive/S4065511/data/rating_feeling.csv', index=False)\n",
        "        print(\"Length of user rating pairs: \", len(self.pairs))\n",
        "        mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, spearman = self.recsys.calc_mse_rmse_rating_percentages(self.pairs)\n",
        "        metrics = self.recsys.satisfaction_metrics()\n",
        "        print(\"Total MSE: \", mse)\n",
        "        print(\"Total RMSE: \", rmse)\n",
        "        print(\"Total Log Likelihood: \", loglike)\n",
        "        print(\"Total per Observe Log Likelihood: \", ob_loglike)\n",
        "        print(\"Total Ground Truth Rating Percentages: \", gt_pct)\n",
        "        print(\"Total Predicted Rating Percentages: \", pred_pct)\n",
        "        print(\"Total Spearman Correlation: \", spearman)\n",
        "        print(\"Total Satisfaction Metrics (Pview, Nlike, Plike, Nexit, Ssat): \", metrics)\n",
        "\n",
        "        self.update_working_agents()\n",
        "        return messages\n",
        "\n",
        "    def create_agent(self, i, api_key) -> RecAgent:\n",
        "        \"\"\"\n",
        "        Create an agent with the given id.\n",
        "        \"\"\"\n",
        "        LLM = get_llm(config=self.config, logger=self.logger, api_key=api_key)\n",
        "        MemoryClass = (\n",
        "            RecAgentMemory\n",
        "            if self.config[\"recagent_memory\"] == \"recagent\"\n",
        "            else GenerativeAgentMemory\n",
        "        )\n",
        "\n",
        "        agent_memory = MemoryClass(\n",
        "            llm=LLM,\n",
        "            memory_retriever=self.create_new_memory_retriever(),\n",
        "            now=self.now,\n",
        "            verbose=False,\n",
        "            reflection_threshold=10,\n",
        "        )\n",
        "        agent = RecAgent(\n",
        "            id=i,\n",
        "            name=self.data.users[i][\"name\"],\n",
        "            age=self.data.users[i][\"age\"],\n",
        "            gender=self.data.users[i][\"gender\"],\n",
        "            traits=self.data.users[i][\"traits\"],\n",
        "            status=self.data.users[i][\"status\"],\n",
        "            interest=self.data.users[i][\"interest\"],\n",
        "            # positive_behavior=self.data.users[i][\"positive_behavior\"],\n",
        "            # negative_behavior=self.data.users[i][\"negative_behavior\"],\n",
        "            relationships=self.data.get_relationship_names(i),\n",
        "            feature=get_feature_description(self.data.users[i][\"feature\"]),\n",
        "            memory_retriever=self.create_new_memory_retriever(),\n",
        "            llm=LLM,\n",
        "            memory=agent_memory,\n",
        "            event=reset_event(self.now),\n",
        "            avatar_url=get_avatar_url(\n",
        "                id=i, gender=self.data.users[i][\"gender\"], type=\"origin\"\n",
        "            ),\n",
        "            idle_url=get_avatar_url(\n",
        "                id=i, gender=self.data.users[i][\"gender\"], type=\"idle\"\n",
        "            ),\n",
        "            watching_url=get_avatar_url(\n",
        "                id=i, gender=self.data.users[i][\"gender\"], type=\"watching\"\n",
        "            ),\n",
        "            chatting_url=get_avatar_url(\n",
        "                id=i, gender=self.data.users[i][\"gender\"], type=\"chatting\"\n",
        "            ),\n",
        "            posting_url=get_avatar_url(\n",
        "                id=i, gender=self.data.users[i][\"gender\"], type=\"posting\"\n",
        "            ),\n",
        "        )\n",
        "        # observations = self.data.users[i][\"observations\"].strip(\".\").split(\".\")\n",
        "        # for observation in observations:\n",
        "        #     agent.memory.add_memory(observation, now=self.now)\n",
        "        return agent\n",
        "\n",
        "\n",
        "    def agent_creation(self):\n",
        "        \"\"\"\n",
        "        Create agents in parallel\n",
        "        \"\"\"\n",
        "        agents = {}\n",
        "        api_keys = list(self.config[\"api_keys\"])\n",
        "        agent_num = int(self.config[\"agent_num\"])\n",
        "        # Add ONE user controllable user into the simulator if the flag is true.\n",
        "        # We block the main thread when the user is creating the role.\n",
        "        if self.config[\"play_role\"]:\n",
        "            role_id = self.data.get_user_num()\n",
        "            api_key = api_keys[role_id % len(api_keys)]\n",
        "            agent = self.create_user_role(role_id, api_key)\n",
        "            agents[role_id] = agent\n",
        "            self.data.role_id = role_id\n",
        "        if self.active_method == \"random\":\n",
        "            active_probs = [self.config[\"active_prob\"]] * agent_num\n",
        "        else:\n",
        "            active_probs = np.random.pareto(self.config[\"active_prob\"] * 10, agent_num)\n",
        "            active_probs = active_probs / active_probs.max()\n",
        "\n",
        "        if self.config[\"execution_mode\"] == \"parallel\":\n",
        "            futures = []\n",
        "            start_time = time.time()\n",
        "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                for i in range(1, agent_num):\n",
        "                    api_key = api_keys[i % len(api_keys)]\n",
        "                    futures.append(executor.submit(self.create_agent, i, api_key))\n",
        "                for future in tqdm(concurrent.futures.as_completed(futures)):\n",
        "                    agent = future.result()\n",
        "                    agent.active_prob = active_probs[agent.id]\n",
        "                    agents[agent.id] = agent\n",
        "                    self.socialnetwork.add_agent(agent.id, agent.name, agent.interest)\n",
        "                    print(f\"Agent Creation {agent.id}: {agent}\")\n",
        "            end_time = time.time()\n",
        "            self.logger.info(\n",
        "                f\"Time for creating {agent_num} agents: {end_time-start_time}\"\n",
        "            )\n",
        "        else:\n",
        "            for i in tqdm(range(1, agent_num)):\n",
        "                api_key = api_keys[i % len(api_keys)]\n",
        "                agent = self.create_agent(i, api_key)\n",
        "                agent.active_prob = active_probs[agent.id]\n",
        "                agents[agent.id] = agent\n",
        "\n",
        "        return agents"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
