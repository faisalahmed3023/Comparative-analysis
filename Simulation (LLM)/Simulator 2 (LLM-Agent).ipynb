{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl7zkr8F0zlk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "\n",
        "def fix_seeds(seed=101):\n",
        "\trandom.seed(seed)\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed) # In order to disable hash randomization and make the experiment reproducible.\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "\ttorch.backends.cudnn.benchmark = False\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\n",
        "def describe_interactions(df):\n",
        "    print('number of users: ', len(df.user_id.unique()))\n",
        "    print('number of movie: ', len(df.item_id.unique()))\n",
        "    print('number of interactions: ', len(df))\n",
        "    print('max user id', df.user_id.max())\n",
        "    print('max movie id', df.item_id.max())\n",
        "    print(' ')\n",
        "\n",
        "def int_to_user_dict(interaction):\n",
        "    \"\"\"\n",
        "    convert a list of interactions into a dictionary\n",
        "    that maps each user to a list of their interactions\n",
        "    input: df with columns ['user_id', 'movie_id']\n",
        "    output: dict with key: user_id, value: list of movie_id\n",
        "    \"\"\"\n",
        "    user_dict = {}\n",
        "    for u, v in interaction:\n",
        "        if(u not in user_dict.keys()):\n",
        "            user_dict[u] = [v]\n",
        "        else:\n",
        "            user_dict[u].append(v)\n",
        "    # Sort according to key.\n",
        "    user_dict = dict(sorted(user_dict.items(), key=lambda x: x[0]))\n",
        "    return user_dict\n",
        "\n",
        "def save_user_dict_to_txt(user_dict, base_path, filename):\n",
        "    with open(base_path + filename, 'w') as f:\n",
        "        for u, v in user_dict.items():\n",
        "            f.write(str(int(u)))\n",
        "            for i in v:\n",
        "                f.write(' ' + str(int(i)))\n",
        "            f.write('\\n')\n",
        "\n",
        "def ndcg_at_k(r, k=20):\n",
        "    \"\"\"Calculate Normalized Discounted Cumulative Gain (NDCG) at k.\"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "\n",
        "    def dcg(scores):\n",
        "        \"\"\"Calculate Discounted Cumulative Gain (DCG).\"\"\"\n",
        "        return np.sum(scores / np.log2(np.arange(2, scores.size + 2)))\n",
        "\n",
        "    # Convert the sorted list to a NumPy array\n",
        "    dcg_max = dcg(np.asarray(sorted(r, reverse=True)))\n",
        "    if not dcg_max:\n",
        "        return 0.0\n",
        "\n",
        "    return dcg(r) / dcg_max\n",
        "\n",
        "#%%\n",
        "# Fixed seed\n",
        "seed = 101\n",
        "fix_seeds(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa2PzZfZ0zoK",
        "outputId": "8a717460-b59a-455d-8a69-1b0bbd4154dd"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os.path as op\n",
        "\n",
        "\n",
        "def helper_load_train(filename):\n",
        "    user_dict_list = {}\n",
        "    item_dict = set()\n",
        "    item_dict_list = {}\n",
        "    trainUser, trainItem = [], []\n",
        "\n",
        "    with open(filename) as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            # print(line)\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            line = [int(i) for i in line]\n",
        "            user = line[0]\n",
        "            items = line[1:]\n",
        "            item_dict.update(items)\n",
        "            # LightGCN\n",
        "            trainUser.extend([user] * len(items))\n",
        "            trainItem.extend(items)\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            user_dict_list[user] = items\n",
        "\n",
        "            for item in items:\n",
        "                if item in item_dict_list.keys():\n",
        "                    item_dict_list[item].append(user)\n",
        "                else:\n",
        "                    item_dict_list[item] = [user]\n",
        "\n",
        "    return user_dict_list, item_dict, item_dict_list, trainUser, trainItem\n",
        "\n",
        "\n",
        "music = pd.read_csv('book_profiles.csv')\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "users = pd.read_csv('user_profiles.csv')\n",
        "movie_detail = pd.read_csv('book_detail.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAOCKPU60zoZ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "sys_prompt = \"\"\"\n",
        "I want you to act as an agent. You will act as a movie reading taste analyst roleplaying the user using the first person pronoun \"I\".\n",
        "\"\"\"\n",
        "\n",
        "prompt_modify = \"\"\"\n",
        "Given a user's rating history:\n",
        "\n",
        "Here, the input <INPUT1>, <INPUT2>, <INPUT3>, <INPUT4>, <INPUT5> format must be: [movie titles]\n",
        "user gives high ratings for following movie titles: <INPUT4> <INPUT5>\n",
        "\n",
        "user gives a rating of 1 for following movie titles: <INPUT1>\n",
        "user gives a rating of 2 for following movie titles: <INPUT2>\n",
        "user gives a rating of 3 for following movie titles: <INPUT3>\n",
        "user gives a rating of 4 for following movie titles: <INPUT4>\n",
        "user gives a rating of 5 for following movie titles: <INPUT5>\n",
        "\n",
        "My first request is \"I need help creating movie watching taste for a user given the movie-rating history. (in no particular order)\"  Generate as many TASTE-REASON pairs as possible, taste should focus on the movie titles.\n",
        "Strictly follow the output format below:\n",
        "\n",
        "TASTE: <-descriptive taste->\n",
        "REASON: <-brief reason->\n",
        "\n",
        "TASTE: <-descriptive taste->\n",
        "REASON: <-brief reason->\n",
        ".....\n",
        "\n",
        "Secondly, analyze user tend to give what kinds of movies high ratings, and tend to give what kinds of movies low ratings.\n",
        "Strictly follow the output format below:\n",
        "HIGH RATINGS: <-conclusion of movies of high ratings(above 3)->\n",
        "LOW RATINGS: <-conclusion of movies of low ratings(between 1 to 3)->\n",
        "Answer should not be a combination of above two parts and not contain other words and should not contain movie titles.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "prompt_information_house = \"\"\"\n",
        "Given a user's rating history:\n",
        "\n",
        "Here, the input <INPUT4>, <INPUT5> format must be: [movie titles]\n",
        "\n",
        "user gives high ratings for following movie titles: <INPUT4>, <INPUT5>\n",
        "\n",
        "My first request is \"I need help creating movie watching taste for a user given the movie-rating history. (in no particular order)\"\n",
        "Generate two specific and most inclusive TASTE-REASON pairs as possible, taste should focus on the movies' genres and don't use obcure words like \"have diverse taste\".\n",
        "Don't conclude the taste using any time-related word like 90's or classic.\n",
        "Strictly follow the output format below:\n",
        "\n",
        "TASTE: <-descriptive taste->\n",
        "REASON: <-brief reason->\n",
        "\n",
        "TASTE: <-descriptive taste->\n",
        "REASON: <-brief reason->\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def get_completion(prompt, sys_prompt, model=\"gpt-4o-mini\", temperature=0):\n",
        "    messages = [{\"role\":\"user\", \"content\" : prompt}, {\"role\":\"system\", \"content\" : sys_prompt}]\n",
        "    response = ''\n",
        "    except_waiting_time = 0.1\n",
        "    while response == '':\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "                request_timeout=50\n",
        "            )\n",
        "            k_tokens = response[\"usage\"][\"total_tokens\"]/1000\n",
        "            p_tokens = response[\"usage\"][\"prompt_tokens\"]/1000\n",
        "            r_tokens = response[\"usage\"][\"completion_tokens\"]/1000\n",
        "            print(\"Tokens used: {:.2f}k\".format(k_tokens))\n",
        "            print(\"Prompt tokens: {:.2f}k\".format(p_tokens))\n",
        "            print(\"Response tokens: {:.2f}k\".format(r_tokens))\n",
        "\n",
        "        except Exception as e:\n",
        "            #print(e)\n",
        "            #print(\"Sleep for {:.2f}s\".format(except_waiting_time))\n",
        "            time.sleep(except_waiting_time)\n",
        "            if except_waiting_time < 2:\n",
        "                except_waiting_time *= 2\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "\n",
        "async def polish_data(idx, prompt, sys_prompt, loop, executor, model=\"gpt-4o-mini\", temperature=0):\n",
        "    # print(\"begin {}\".format(idx))\n",
        "    start_time = time.time()\n",
        "    polish_text = await loop.run_in_executor(executor, get_completion, prompt, sys_prompt, model, temperature)\n",
        "    end_time = time.time()\n",
        "    print(polish_text)\n",
        "    # print(\"end {}\".format(idx))\n",
        "    #print(idx, polish_text)\n",
        "    #print(polish_text)\n",
        "    # polish_text_path = op.join(\"like_persona_description_information_house/\", \"persona_{}.txt\".format(idx))\n",
        "    polish_text_path = op.join(\"like_persona_description_modify/\", \"persona_{}.txt\".format(idx))\n",
        "    #print(polish_text_path)\n",
        "    print(idx, end_time - start_time)\n",
        "    with open(polish_text_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(polish_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbkEWfto0zoh",
        "outputId": "218808b8-a327-4787-f88b-35ba4e361708"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import os.path as op\n",
        "import os\n",
        "\n",
        "#%%\n",
        "def generate_init_info(s):\n",
        "    taste = re.findall(r'TASTE:(.+)', s)\n",
        "    reason = re.findall(r'REASON:(.+)', s)\n",
        "    high_rating = re.findall(r'HIGH RATINGS:(.+)', s)\n",
        "    low_rating = re.findall(r'LOW RATINGS:(.+)', s)\n",
        "    # return taste, reason, movie\n",
        "    return \"| \".join(taste), \"| \".join(reason), \"| \".join(high_rating), \"| \".join(low_rating)\n",
        "\n",
        "\n",
        "base_path = \"like_persona_description_modify\"\n",
        "\n",
        "# Get all file names under the folder.\n",
        "len_file_names = len(sorted(os.listdir(base_path)))\n",
        "file_names = [\"persona_\"+str(i)+\".txt\" for i in range(len_file_names)]\n",
        "\n",
        "# df = pd.DataFrame(index=range(len(file_names)), columns=[\"avatar_name\", \"age\", \"occupation\", \"traits\", \"description\"])\n",
        "\n",
        "df = pd.DataFrame(index=range(len(file_names)), columns=[\"taste\", \"reason\", \"high_rating\", \"low_rating\"])\n",
        "# df = pd.DataFrame(index=range(len(file_names)), columns=[\"taste\", \"reason\"])\n",
        "\n",
        "#%%\n",
        "avatars_info = {}\n",
        "for idx, file_name in enumerate(file_names):\n",
        "    with open(base_path + \"/\" + file_name, \"r\") as f:\n",
        "        persona = f.read()\n",
        "    taste, reason, high_rating, low_rating = generate_init_info(persona)\n",
        "    # taste, reason = generate_init_info(persona)\n",
        "    avatars_info[idx] = {\n",
        "        \"taste\": taste,\n",
        "        \"reason\": reason,\n",
        "        \"high_rating\": high_rating,\n",
        "        \"low_rating\": low_rating\n",
        "    }\n",
        "    print(idx)\n",
        "\n",
        "    df.loc[idx] = [taste, reason, high_rating, low_rating]\n",
        "    # df.loc[idx] = [taste, reason]\n",
        "    # break\n",
        "\n",
        "#%%\n",
        "df.to_csv(\"all_personas_description_modify.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4IIsmOB0zoi",
        "outputId": "e008776a-0dbd-4e09-c581-065f59e01f4f"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import os.path as op\n",
        "import os\n",
        "\n",
        "#%%\n",
        "def generate_init_info(s):\n",
        "    taste = re.findall(r'TASTE:(.+)', s)\n",
        "    reason = re.findall(r'REASON:(.+)', s)\n",
        "    # high_rating = re.findall(r'HIGH RATINGS:(.+)', s)\n",
        "    # low_rating = re.findall(r'LOW RATINGS:(.+)', s)\n",
        "    # return taste, reason, movie\n",
        "    return \"| \".join(taste), \"| \".join(reason) #, \"| \".join(high_rating), \"| \".join(low_rating)\n",
        "\n",
        "base_path = \"like_persona_description_information_house\"\n",
        "\n",
        "# Get all file names under the folder.\n",
        "len_file_names = len(sorted(os.listdir(base_path)))\n",
        "file_names = [\"persona_\"+str(i)+\".txt\" for i in range(len_file_names)]\n",
        "\n",
        "# df = pd.DataFrame(index=range(len(file_names)), columns=[\"avatar_name\", \"age\", \"occupation\", \"traits\", \"description\"])\n",
        "\n",
        "# df = pd.DataFrame(index=range(len(file_names)), columns=[\"taste\", \"reason\", \"high_rating\", \"low_rating\"])\n",
        "df = pd.DataFrame(index=range(len(file_names)), columns=[\"taste\", \"reason\"])\n",
        "\n",
        "#%%\n",
        "avatars_info = {}\n",
        "for idx, file_name in enumerate(file_names):\n",
        "    with open(base_path + \"/\" + file_name, \"r\") as f:\n",
        "        persona = f.read()\n",
        "    # taste, reason, high_rating, low_rating = generate_init_info(persona)\n",
        "    taste, reason = generate_init_info(persona)\n",
        "    avatars_info[idx] = {\n",
        "        \"taste\": taste,\n",
        "        \"reason\": reason,\n",
        "        # \"high_rating\": high_rating,\n",
        "        # \"low_rating\": low_rating\n",
        "    }\n",
        "    print(idx)\n",
        "\n",
        "    # df.loc[idx] = [taste, reason, high_rating, low_rating]\n",
        "    df.loc[idx] = [taste, reason]\n",
        "    # break\n",
        "\n",
        "#%%\n",
        "df.to_csv(\"all_personas_like_information_house.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxLYhwER0zok"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "global global_k_tokens\n",
        "global global_start_time\n",
        "global global_steps\n",
        "global global_last_tokens_record\n",
        "global global_interval\n",
        "global global_finished_users\n",
        "global global_finished_pages\n",
        "global global_error_cast\n",
        "global lock\n",
        "\n",
        "global_k_tokens = 0\n",
        "global_start_time = 0\n",
        "global_steps = 0\n",
        "global_last_tokens_record = 0\n",
        "global_interval = 10\n",
        "global_finished_users = 0\n",
        "global_finished_pages = 0\n",
        "global_error_cast = 0\n",
        "\n",
        "lock = threading.Lock() # global lock for threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gfv4W3r0zom"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from termcolor import colored, cprint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def fix_seeds(seed=101):\n",
        "\trandom.seed(seed)\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed) # In order to disable hash randomization and make the experiment reproducible.\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "\ttorch.backends.cudnn.benchmark = False\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\n",
        "def get_accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "def get_recall(y_true, y_pred):\n",
        "    return np.sum(y_true & y_pred) / np.sum(y_true)\n",
        "\n",
        "def get_precision(y_true, y_pred):\n",
        "    return np.sum(y_true & y_pred) / np.sum(y_pred)\n",
        "\n",
        "def get_f1(y_true, y_pred):\n",
        "\tp = get_precision(y_true, y_pred)\n",
        "\tr = get_recall(y_true, y_pred)\n",
        "\tif p + r == 0:\n",
        "\t\treturn 0\n",
        "\telse:\n",
        "\t\treturn 2 * p * r / (p + r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biTYmOv80zon"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--vis', nargs='?', default=-1,\n",
        "                        help='we only want test value.')\n",
        "    parser.add_argument('--seed', type=int, default=101,\n",
        "                        help='Random seed.')\n",
        "    parser.add_argument('--clear_checkpoints', action=\"store_true\",\n",
        "                        help='Whether clear the earlier checkpoints.')\n",
        "    parser.add_argument(\"--candidate\", action=\"store_true\",\n",
        "                        help=\"whether using the candidate set\")\n",
        "    parser.add_argument('--test_only', action=\"store_true\",\n",
        "                        help='Whether to test only.')\n",
        "    parser.add_argument('--data_path', nargs='?', default='Movielens-1M/',\n",
        "                        help='Input data path.')\n",
        "    parser.add_argument('--dataset', nargs='?', default='agent4rec',\n",
        "                        help='Choose a dataset')\n",
        "    parser.add_argument('--embed_size', type=int, default=64,\n",
        "                        help='Embedding size.')\n",
        "    parser.add_argument('--batch_size', type=int, default=2048,\n",
        "                        help='Batch size.')\n",
        "    parser.add_argument('--lr', type=float, default=5e-3,\n",
        "                        help='Learning rate.')\n",
        "    parser.add_argument('--regs', type=float, default=1e-5,\n",
        "                        help='Regularization.')\n",
        "    parser.add_argument('--epoch', type=int, default=2000,\n",
        "                        help='Number of epoch.')\n",
        "    parser.add_argument('--Ks', type = int, default= 20,\n",
        "                        help='Evaluate on Ks optimal items.')\n",
        "    parser.add_argument('--verbose', type=int, default=5,\n",
        "                        help='Interval of evaluation.')\n",
        "    parser.add_argument('--saveID', type=str, default=\"\",\n",
        "                        help='Specify model save path.')\n",
        "    parser.add_argument('--patience', type=int, default=10,\n",
        "                        help='Early stopping point.')\n",
        "    parser.add_argument('--checkpoint', type=str, default='',\n",
        "                        help='Specify model save path.')\n",
        "    parser.add_argument('--modeltype', type=str, default= 'MF',\n",
        "                        help='Specify model save path.')\n",
        "    parser.add_argument('--cuda', type=int, default=0,\n",
        "                        help='Specify which gpu to use.')\n",
        "    parser.add_argument('--IPStype', type=str, default='cn',\n",
        "                        help='Specify the mode of weighting')\n",
        "    parser.add_argument('--n_layers', type=int, default=0,\n",
        "                        help='Number of GCN layers')\n",
        "    parser.add_argument('--max2keep', type=int, default=1,\n",
        "                        help='max checkpoints to keep')\n",
        "    parser.add_argument('--infonce', type=int, default=0,\n",
        "                        help='whether to use infonce loss or not')\n",
        "    parser.add_argument('--neg_sample',type=int,default=1)\n",
        "    parser.add_argument('--num_workers', type=int, default=8,\n",
        "                        help='number of workers in data loader')\n",
        "    parser.add_argument(\"--train_norm\", action=\"store_true\",\n",
        "                        help=\"train_norm\")\n",
        "    parser.add_argument(\"--pred_norm\", action=\"store_true\",\n",
        "                        help=\"pred_norm\")\n",
        "\n",
        "    parser.add_argument(\"--nodrop\", action=\"store_true\",\n",
        "                        help=\"whether to drop out the enhanced training dataset\")\n",
        "    parser.add_argument(\"--no_wandb\", action=\"store_true\",\n",
        "                        help=\"whether to use wandb\")\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # INFONCE\n",
        "    if(args.modeltype == 'InfoNCE'):\n",
        "        parser.add_argument('--tau', type=float, default=0.1,\n",
        "                        help='temperature parameter')\n",
        "\n",
        "    # MultVAE\n",
        "    if(args.modeltype == 'MultVAE'):\n",
        "        parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
        "                        help='total anneal steps')\n",
        "        parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
        "                        help='anneal cap')\n",
        "        parser.add_argument('--p_dim0', type=int, default=200,\n",
        "                        help='p_dim0')\n",
        "        parser.add_argument('--p_dim1', type=int, default=600,\n",
        "                        help='p_dim1')\n",
        "\n",
        "    args_full, _ = parser.parse_known_args()\n",
        "    special_args = list(set(vars(args_full).keys()) - set(vars(args).keys()))\n",
        "    special_args.sort()\n",
        "\n",
        "    return args_full, special_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtUR11T30zoo"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "import numpy as np\n",
        "from inspect import signature\n",
        "from functools import wraps\n",
        "import heapq\n",
        "import itertools\n",
        "import time\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def ensureDir(dir_path):\n",
        "    d = os.path.dirname(dir_path)\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)\n",
        "\n",
        "\n",
        "\n",
        "def get_data_format(data_format):\n",
        "    if data_format == \"UIRT\":\n",
        "        columns = [\"user\", \"item\", \"rating\", \"time\"]\n",
        "\n",
        "    elif data_format == \"UIR\":\n",
        "        columns = [\"user\", \"item\", \"rating\"]\n",
        "\n",
        "    elif data_format == \"UIT\":\n",
        "        columns = [\"user\", \"item\", \"time\"]\n",
        "\n",
        "    elif data_format == \"UI\":\n",
        "        columns = [\"user\", \"item\"]\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"please choose a correct data format. \")\n",
        "\n",
        "    return columns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def csr_to_user_dict(train_matrix):\n",
        "    \"\"\"convert a scipy.sparse.csr_matrix to a dict,\n",
        "    where the key is row number, and value is the\n",
        "    non-empty index in each row.\n",
        "    \"\"\"\n",
        "    train_dict = {}\n",
        "    for idx, value in enumerate(train_matrix):\n",
        "        if len(value.indices):\n",
        "            train_dict[idx] = value.indices.copy().tolist()\n",
        "    return train_dict\n",
        "\n",
        "\n",
        "def csr_to_user_dict_bytime(time_matrix,train_matrix):\n",
        "    train_dict = {}\n",
        "    time_matrix = time_matrix\n",
        "    user_pos_items = csr_to_user_dict(train_matrix)\n",
        "    for u, items in user_pos_items.items():\n",
        "        sorted_items = sorted(items, key=lambda x: time_matrix[u,x])\n",
        "        train_dict[u] = np.array(sorted_items, dtype=np.int32).tolist()\n",
        "\n",
        "    return train_dict\n",
        "\n",
        "\n",
        "\n",
        "def noise_validator(noise, allowed_noises):\n",
        "    '''Validates the noise provided'''\n",
        "    try:\n",
        "        if noise in allowed_noises:\n",
        "            return True\n",
        "        elif noise.split('-')[0] == 'mask' and float(noise.split('-')[1]):\n",
        "            t = float(noise.split('-')[1])\n",
        "            if t >= 0.0 and t <= 1.0:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "    except:\n",
        "        return False\n",
        "    pass\n",
        "\n",
        "\n",
        "def randint_choice(high, size=None, replace=True, p=None, exclusion=None):\n",
        "    \"\"\"Return random integers from `0` (inclusive) to `high` (exclusive).\n",
        "    \"\"\"\n",
        "    a = np.arange(high)\n",
        "    if exclusion is not None:\n",
        "        if p is None:\n",
        "            p = np.ones_like(a)\n",
        "        else:\n",
        "            p = np.array(p, copy=True)\n",
        "        p = p.flatten()\n",
        "        p[exclusion] = 0\n",
        "    if p is not None:\n",
        "        p = p / np.sum(p)\n",
        "    sample = np.random.choice(a, size=size, replace=replace, p=p)\n",
        "    return sample\n",
        "\n",
        "\n",
        "def batch_randint_choice(high, size, replace=True, p=None, exclusion=None):\n",
        "    \"\"\"Return random integers from `0` (inclusive) to `high` (exclusive).\n",
        "    :param high: integer\n",
        "    :param size: 1-D array_like\n",
        "    :param replace: bool\n",
        "    :param p: 2-D array_like\n",
        "    :param exclusion: a list of 1-D array_like\n",
        "    :return: a list of 1-D array_like sample\n",
        "    \"\"\"\n",
        "\n",
        "    # if p is not None and (len(p) != len(size) or len(p[0]) != high):\n",
        "    if p is not None and (len(p) != len(size) and len(p) != high):\n",
        "        raise ValueError(\"The shape of 'p' is not compatible with the shapes of 'array' and 'size'!\")\n",
        "\n",
        "    if exclusion is not None and len(exclusion) != len(size):\n",
        "        raise ValueError(\"The shape of 'exclusion' is not compatible with the shape of 'size'!\")\n",
        "\n",
        "    def choice_one(idx):\n",
        "        # p_tmp = p[idx] if p is not None else None\n",
        "        p_tmp = p if p is not None else None\n",
        "        exc = exclusion[idx] if exclusion is not None else None\n",
        "        return randint_choice(high, size[idx], replace=replace, p=p_tmp, exclusion=exc)\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = executor.map(choice_one, range(len(size)))\n",
        "\n",
        "    return [result for result in results]\n",
        "\n",
        "\n",
        "def typeassert(*type_args, **type_kwargs):\n",
        "    def decorate(func):\n",
        "        sig = signature(func)\n",
        "        bound_types = sig.bind_partial(*type_args, **type_kwargs).arguments\n",
        "\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            bound_values = sig.bind(*args, **kwargs)\n",
        "            for name, value in bound_values.arguments.items():\n",
        "                if name in bound_types:\n",
        "                    if not isinstance(value, bound_types[name]):\n",
        "                        raise TypeError('Argument {} must be {}'.format(name, bound_types[name]))\n",
        "            return func(*args, **kwargs)\n",
        "        return wrapper\n",
        "    return decorate\n",
        "\n",
        "\n",
        "def max_top_k(a, top_k=50):\n",
        "    ele_idx = heapq.nlargest(top_k, zip(a, itertools.count()))\n",
        "    return np.array([ele for ele, idx in ele_idx], dtype=np.intc)\n",
        "\n",
        "\n",
        "def argmax_top_k(a, top_k=50):\n",
        "    ele_idx = heapq.nlargest(top_k, zip(a, itertools.count()))\n",
        "    return np.array([idx for ele, idx in ele_idx], dtype=np.intc)\n",
        "\n",
        "\n",
        "def pad_sequences(sequences, value=0., max_len=None,\n",
        "                  padding='post', truncating='post', dtype=np.int32):\n",
        "    \"\"\"Pads sequences to the same length.\n",
        "\n",
        "    Args:\n",
        "        sequences (list): A list of lists, where each element is a sequence.\n",
        "        value (int or float): Padding value. Defaults to `0.`.\n",
        "        max_len (int or None): Maximum length of all sequences.\n",
        "        padding (str): `\"pre\"` or `\"post\"`: pad either before or after each\n",
        "            sequence. Defaults to `post`.\n",
        "        truncating (str): `\"pre\"` or `\"post\"`: remove values from sequences\n",
        "            larger than `max_len`, either at the beginning or at the end of\n",
        "            the sequences. Defaults to `post`.\n",
        "        dtype (int or float): Type of the output sequences. Defaults to `np.int32`.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Numpy array with shape `(len(sequences), max_len)`.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `padding` or `truncating` is not understood.\n",
        "    \"\"\"\n",
        "    if max_len is None:\n",
        "        max_len = np.max([len(x) for x in sequences])\n",
        "\n",
        "    x = np.full([len(sequences), max_len], value, dtype=dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if not len(s):\n",
        "            continue  # empty list/array was found\n",
        "        if truncating == 'pre':\n",
        "            trunc = s[-max_len:]\n",
        "        elif truncating == 'post':\n",
        "            trunc = s[:max_len]\n",
        "        else:\n",
        "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
        "\n",
        "        if padding == 'post':\n",
        "            x[idx, :len(trunc)] = trunc\n",
        "        elif padding == 'pre':\n",
        "            x[idx, -len(trunc):] = trunc\n",
        "        else:\n",
        "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def timer(func):\n",
        "    \"\"\"The timer decorator\n",
        "    \"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(\"%s function cost: %fs\" % (func.__name__, end_time - start_time))\n",
        "        return result\n",
        "    return wrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNsQiMu80zop"
      },
      "outputs": [],
      "source": [
        "import random as rd\n",
        "import collections\n",
        "from types import new_class\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse import csr_matrix\n",
        "import time\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "\n",
        "\n",
        "# Helper function used when loading data from files\n",
        "def helper_load(filename):\n",
        "    user_dict_list = {}\n",
        "    item_dict = set()\n",
        "\n",
        "    with open(filename) as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            line = [int(i) for i in line]\n",
        "            user = line[0]\n",
        "            items = line[1:]\n",
        "            item_dict.update(items)\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            user_dict_list[user] = items\n",
        "\n",
        "    return user_dict_list, item_dict,\n",
        "\n",
        "def helper_load_train(filename):\n",
        "    user_dict_list = {}\n",
        "    item_dict = set()\n",
        "    item_dict_list = {}\n",
        "    trainUser, trainItem = [], []\n",
        "\n",
        "    with open(filename) as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            # print(line)\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            line = [int(i) for i in line]\n",
        "            user = line[0]\n",
        "            items = line[1:]\n",
        "            item_dict.update(items)\n",
        "            # LightGCN\n",
        "            trainUser.extend([user] * len(items))\n",
        "            trainItem.extend(items)\n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "            user_dict_list[user] = items\n",
        "\n",
        "            for item in items:\n",
        "                if item in item_dict_list.keys():\n",
        "                    item_dict_list[item].append(user)\n",
        "                else:\n",
        "                    item_dict_list[item] = [user]\n",
        "\n",
        "    return user_dict_list, item_dict, item_dict_list, trainUser, trainItem\n",
        "# It loads the data and creates a train_loader\n",
        "\n",
        "class Data:\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.path = args.data_path + args.dataset + '/cf_data/'\n",
        "        self.small_path=args.data_path + args.dataset+\".mid\"+\"/\"\n",
        "        self.train_file = self.path + 'train.txt'\n",
        "        self.valid_file = self.path + 'valid.txt'\n",
        "        self.test_file = self.path + 'test.txt'\n",
        "\n",
        "        if(args.nodrop):\n",
        "            self.train_nodrop_file = self.path + 'train_nodrop.txt'\n",
        "        self.nodrop = args.nodrop\n",
        "\n",
        "        self.candidate = args.candidate\n",
        "        if(args.candidate):\n",
        "            self.test_neg_file = self.path + 'test_neg.txt'\n",
        "        self.batch_size = args.batch_size\n",
        "        self.neg_sample = args.neg_sample\n",
        "        self.IPStype = args.IPStype\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "        self.modeltype = args.modeltype\n",
        "\n",
        "        self.user_pop_max = 0\n",
        "        self.item_pop_max = 0\n",
        "        self.infonce = args.infonce\n",
        "        self.num_workers = args.num_workers\n",
        "        self.dataset = args.dataset\n",
        "        self.candidate = args.candidate\n",
        "\n",
        "        # Number of total users and items\n",
        "        self.n_users, self.n_items, self.n_observations = 0, 0, 0\n",
        "        self.users = []\n",
        "        self.items = []\n",
        "        self.population_list = []\n",
        "        self.weights = []\n",
        "\n",
        "        # List of dictionaries of users and its observed items in corresponding dataset\n",
        "        # {user1: [item1, item2, item3...], user2: [item1, item3, item4],...}\n",
        "        # {item1: [user1, user2], item2: [user1, user3], ...}\n",
        "        self.train_user_list = collections.defaultdict(list)\n",
        "        self.valid_user_list = collections.defaultdict(list)\n",
        "        if(self.dataset == \"tencent_synthetic\" or self.dataset == \"kuairec_ood\"):\n",
        "            self.test_ood_user_list_1 = collections.defaultdict(list)\n",
        "            self.test_ood_user_list_2 = collections.defaultdict(list)\n",
        "            self.test_ood_user_list_3 = collections.defaultdict(list)\n",
        "        else:\n",
        "            self.test_user_list = collections.defaultdict(list)\n",
        "\n",
        "        # Used to track early stopping point\n",
        "        self.best_valid_recall = -np.inf\n",
        "        self.best_valid_epoch, self.patience = 0, 0\n",
        "\n",
        "        self.train_item_list = collections.defaultdict(list)\n",
        "        self.Graph = None\n",
        "        self.trainUser, self.trainItem, self.UserItemNet = [], [], []\n",
        "        self.n_interactions = 0\n",
        "        if(self.dataset == \"tencent_synthetic\" or self.dataset == \"kuairec_ood\"):\n",
        "            self.test_ood_item_list_1 = []\n",
        "            self.test_ood_item_list_2 = []\n",
        "            self.test_ood_item_list_3 = []\n",
        "        else:\n",
        "            self.test_item_list = []\n",
        "\n",
        "        #Dataloader\n",
        "        self.train_data = None\n",
        "        self.train_loader = None\n",
        "\n",
        "        self.load_data()\n",
        "        # model-specific attributes\n",
        "        self.add_special_model_attr(args)\n",
        "\n",
        "        self.get_dataloader()\n",
        "\n",
        "    def add_special_model_attr(self, args):\n",
        "        pass\n",
        "\n",
        "    # self.trainUser and self.trainItem are respectively the users and items in the training set, in the form of an interaction list.\n",
        "    def load_data(self):\n",
        "        self.train_user_list, train_item, self.train_item_list, self.trainUser, self.trainItem = helper_load_train(\n",
        "            self.train_file)\n",
        "        self.valid_user_list, valid_item = helper_load(self.valid_file)\n",
        "\n",
        "        self.test_user_list, self.test_item_list = helper_load(self.test_file)\n",
        "\n",
        "        if(self.nodrop):\n",
        "            self.train_nodrop_user_list, self.train_nodrop_item_list = helper_load(self.train_nodrop_file)\n",
        "\n",
        "        if(self.candidate):\n",
        "            self.test_neg_user_list, self.test_neg_item_list = helper_load(self.test_neg_file)\n",
        "        else:\n",
        "            self.test_neg_user_list, self.test_neg_item_list = None, None\n",
        "        self.pop_dict_list = []\n",
        "\n",
        "\n",
        "        temp_lst = [train_item, valid_item, self.test_item_list]\n",
        "\n",
        "        self.users = list(set(self.train_user_list.keys()))\n",
        "        self.items = list(set().union(*temp_lst))\n",
        "        self.items.sort()\n",
        "        # print(self.items)\n",
        "        self.n_users = len(self.users)\n",
        "        self.n_items = len(self.items)\n",
        "\n",
        "\n",
        "        print(\"n_users: \", self.n_users)\n",
        "        print(\"n_items: \", self.n_items)\n",
        "\n",
        "        for i in range(self.n_users):\n",
        "            self.n_observations += len(self.train_user_list[i])\n",
        "            self.n_interactions += len(self.train_user_list[i])\n",
        "            if i in self.valid_user_list.keys():\n",
        "                self.n_interactions += len(self.valid_user_list[i])\n",
        "            if(self.dataset == \"tencent_synthetic\" or self.dataset == \"kuairec_ood\"):\n",
        "                if i in self.test_ood_user_list_1.keys():\n",
        "                    self.n_interactions += len(self.test_ood_user_list_1[i])\n",
        "                if i in self.test_ood_user_list_2.keys():\n",
        "                    self.n_interactions += len(self.test_ood_user_list_2[i])\n",
        "                if i in self.test_ood_user_list_3.keys():\n",
        "                    self.n_interactions += len(self.test_ood_user_list_3[i])\n",
        "            else:\n",
        "                if i in self.test_user_list.keys():\n",
        "                    self.n_interactions += len(self.test_user_list[i])\n",
        "\n",
        "\n",
        "\n",
        "        # Population matrix\n",
        "        pop_dict = {}\n",
        "        for item, users in self.train_item_list.items():\n",
        "            pop_dict[item] = len(users) + 1\n",
        "        for item in range(0, self.n_items):\n",
        "            if item not in pop_dict.keys():\n",
        "                pop_dict[item] = 1\n",
        "\n",
        "            self.population_list.append(pop_dict[item])\n",
        "\n",
        "        pop_user = {key: len(value) for key, value in self.train_user_list.items()}\n",
        "        pop_item = {key: len(value) for key, value in self.train_item_list.items()}\n",
        "        self.pop_item = pop_item\n",
        "        self.pop_user = pop_user\n",
        "        # Convert to a unique value.\n",
        "        sorted_pop_user = list(set(list(pop_user.values())))\n",
        "        sorted_pop_item = list(set(list(pop_item.values())))\n",
        "        sorted_pop_user.sort()\n",
        "        sorted_pop_item.sort()\n",
        "        self.n_user_pop = len(sorted_pop_user)\n",
        "        self.n_item_pop = len(sorted_pop_item)\n",
        "\n",
        "        user_idx = {}\n",
        "        item_idx = {}\n",
        "        for i, item in enumerate(sorted_pop_user):\n",
        "            user_idx[item] = i\n",
        "        for i, item in enumerate(sorted_pop_item):\n",
        "            item_idx[item] = i\n",
        "\n",
        "        self.user_pop_idx = np.zeros(self.n_users, dtype=int)\n",
        "        self.item_pop_idx = np.zeros(self.n_items, dtype=int)\n",
        "        # Convert the originally sparse popularity into dense popularity.\n",
        "        for key, value in pop_user.items():\n",
        "            self.user_pop_idx[key] = user_idx[value]\n",
        "        for key, value in pop_item.items():\n",
        "            # print(key, value)\n",
        "            self.item_pop_idx[key] = item_idx[value]\n",
        "\n",
        "        user_pop_max = max(self.user_pop_idx)\n",
        "        item_pop_max = max(self.item_pop_idx)\n",
        "\n",
        "        self.user_pop_max = user_pop_max\n",
        "        self.item_pop_max = item_pop_max\n",
        "\n",
        "        self.weights = self.get_weight()\n",
        "        self.weight_dict={i:self.weights[i] for i in range(len(self.weights))}\n",
        "        self.sorted_weight=sorted(self.weight_dict.items(),key=lambda x: x[1])\n",
        "\n",
        "        self.sample_items = np.array(self.items, dtype=int)\n",
        "\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        self.train_data = TrainDataset(self.modeltype, self.users, self.train_user_list, self.user_pop_idx, self.item_pop_idx, \\\n",
        "                                        self.neg_sample, self.n_observations, self.n_items, self.sample_items, self.weights, self.infonce, self.items)\n",
        "\n",
        "        self.train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, drop_last=True)\n",
        "\n",
        "    def get_weight(self):\n",
        "\n",
        "        if 's' in self.IPStype:\n",
        "            pop = self.population_list\n",
        "            pop = np.clip(pop, 1, max(pop))\n",
        "            pop = pop / max(pop)\n",
        "            return pop\n",
        "\n",
        "\n",
        "        pop = self.population_list\n",
        "        pop = np.clip(pop, 1, max(pop))\n",
        "        pop = pop / np.linalg.norm(pop, ord=np.inf)\n",
        "        pop = 1 / pop\n",
        "\n",
        "        if 'c' in self.IPStype:\n",
        "            pop = np.clip(pop, 1, np.median(pop))\n",
        "        if 'n' in self.IPStype:\n",
        "            pop = pop / np.linalg.norm(pop, ord=np.inf)\n",
        "\n",
        "        return pop\n",
        "\n",
        "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
        "        coo = X.tocoo().astype(np.float32)\n",
        "        row = torch.Tensor(coo.row).long()\n",
        "        col = torch.Tensor(coo.col).long()\n",
        "        index = torch.stack([row, col])\n",
        "        data = torch.FloatTensor(coo.data)\n",
        "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
        "\n",
        "    def getSparseGraph(self):\n",
        "\n",
        "        if self.Graph is None:\n",
        "            try:\n",
        "                pre_adj_mat = sp.load_npz(self.path + '/s_pre_adj_mat.npz')\n",
        "                print(\"finish loading adjacency matrix\")\n",
        "                norm_adj = pre_adj_mat\n",
        "            # If there is no preprocessed adjacency matrix, generate one.\n",
        "            except:\n",
        "                print(\"generating adjacency matrix\")\n",
        "                s = time.time()\n",
        "                adj_mat = sp.dok_matrix((self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32)\n",
        "                adj_mat = adj_mat.tolil()\n",
        "                self.trainItem = np.array(self.trainItem)\n",
        "                self.trainUser = np.array(self.trainUser)\n",
        "                self.UserItemNet = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem)),\n",
        "                                                shape=(self.n_users, self.n_items))\n",
        "                R = self.UserItemNet.tolil()\n",
        "                adj_mat[:self.n_users, self.n_users:] = R\n",
        "                adj_mat[self.n_users:, :self.n_users] = R.T\n",
        "                adj_mat = adj_mat.tocsr()\n",
        "                sp.save_npz(self.path + '/adj_mat.npz', adj_mat)\n",
        "                print(\"successfully saved adj_mat...\")\n",
        "\n",
        "                adj_mat = adj_mat.todok()\n",
        "\n",
        "                rowsum = np.array(adj_mat.sum(axis=1))\n",
        "                d_inv = np.power(rowsum, -0.5).flatten()\n",
        "                d_inv[np.isinf(d_inv)] = 0.\n",
        "                d_mat = sp.diags(d_inv)\n",
        "\n",
        "                norm_adj = d_mat.dot(adj_mat)\n",
        "                norm_adj = norm_adj.dot(d_mat)\n",
        "                norm_adj = norm_adj.tocsr()\n",
        "                end = time.time()\n",
        "                print(f\"costing {end - s}s, saved norm_mat...\")\n",
        "                sp.save_npz(self.path + '/s_pre_adj_mat.npz', norm_adj)\n",
        "            self.Graph = self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
        "            self.Graph = self.Graph.coalesce()\n",
        "\n",
        "        return self.Graph\n",
        "\n",
        "    def get_not_candidate(self):\n",
        "        if self.candidate:\n",
        "            not_candidate_dict = {}\n",
        "            with open('data/' + self.dataset + '/not_candidate.txt', 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    line = line.strip('\\n').split(' ')\n",
        "                    if len(line) == 0:\n",
        "                        continue\n",
        "                    line = [int(i) for i in line]\n",
        "                    user = line[0]\n",
        "                    items = line[1:]\n",
        "                    not_candidate_dict[user] = items\n",
        "\n",
        "            return not_candidate_dict\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "class TrainDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, modeltype, users, train_user_list, user_pop_idx, item_pop_idx, neg_sample, \\\n",
        "                n_observations, n_items, sample_items, weights, infonce, items):\n",
        "        self.modeltype = modeltype\n",
        "        self.users = users\n",
        "        self.train_user_list = train_user_list\n",
        "        self.user_pop_idx = user_pop_idx\n",
        "        self.item_pop_idx = item_pop_idx\n",
        "        self.neg_sample = neg_sample\n",
        "        self.n_observations = n_observations\n",
        "        self.n_items = n_items\n",
        "        self.sample_items = sample_items\n",
        "        self.weights = weights\n",
        "        self.infonce = infonce\n",
        "        self.items = items\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        index = index % len(self.users)\n",
        "        user = self.users[index]\n",
        "        if self.train_user_list[user] == []:\n",
        "            pos_items = 0\n",
        "        else:\n",
        "            pos_item = rd.choice(self.train_user_list[user])\n",
        "\n",
        "        user_pop = self.user_pop_idx[user]\n",
        "        pos_item_pop = self.item_pop_idx[pos_item]\n",
        "        pos_weight = self.weights[pos_item]\n",
        "\n",
        "        if self.infonce == 1 and self.neg_sample == -1:\n",
        "\n",
        "            return user, pos_item, user_pop, pos_item_pop, pos_weight\n",
        "\n",
        "        elif self.infonce == 1 and self.neg_sample != -1:\n",
        "            neg_items = randint_choice(self.n_items, size=self.neg_sample, exclusion=self.train_user_list[user])\n",
        "            neg_items_pop = self.item_pop_idx[neg_items]\n",
        "\n",
        "            return user, pos_item, user_pop, pos_item_pop, pos_weight, torch.tensor(neg_items).long(), neg_items_pop\n",
        "\n",
        "        else:\n",
        "            while True:\n",
        "                idx = rd.randint(0, self.n_items -1)\n",
        "                neg_item = self.items[idx]\n",
        "\n",
        "                if neg_item not in self.train_user_list[user]:\n",
        "                    break\n",
        "\n",
        "            neg_item_pop = self.item_pop_idx[neg_item]\n",
        "            return user, pos_item, user_pop, pos_item_pop, pos_weight, neg_item, neg_item_pop\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak6NKmf10zot"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def _get_pairwise_all_likefism_data(dataset):\n",
        "    user_input_pos, user_input_neg, num_idx_pos, num_idx_neg, item_input_pos, item_input_neg = [], [], [], [], [], []\n",
        "    num_items = dataset.num_items\n",
        "    num_users = dataset.num_users\n",
        "    train_matrix = dataset.train_matrix\n",
        "    for u in range(num_users):\n",
        "        items_by_u = train_matrix[u].indices.copy().tolist()\n",
        "        num_items_by_u = len(items_by_u)\n",
        "        if num_items_by_u > 1:\n",
        "            negative_items = randint_choice(num_items, num_items_by_u, replace=True, exclusion = items_by_u)\n",
        "\n",
        "            for index, i in enumerate(items_by_u):\n",
        "                j = negative_items[index]\n",
        "                user_input_neg.append(items_by_u)\n",
        "                num_idx_neg.append(num_items_by_u)\n",
        "                item_input_neg.append(j)\n",
        "\n",
        "                items_by_u.remove(i)\n",
        "                user_input_pos.append(items_by_u)\n",
        "                num_idx_pos.append(num_items_by_u-1)\n",
        "                item_input_pos.append(i)\n",
        "\n",
        "    return user_input_pos, user_input_neg, num_idx_pos, num_idx_neg, item_input_pos, item_input_neg\n",
        "\n",
        "def _get_pointwise_all_likefism_data(dataset, num_negatives, train_dict):\n",
        "    user_input,num_idx,item_input,labels = [],[],[],[]\n",
        "    num_users = dataset.num_users\n",
        "    num_items = dataset.num_items\n",
        "    for u in range(num_users):\n",
        "        items_by_user = train_dict[u].copy()\n",
        "        items_set = set(items_by_user)\n",
        "        size = len(items_by_user)\n",
        "        for i in items_by_user:\n",
        "            # negative instances\n",
        "            for _ in range(num_negatives):\n",
        "                j = np.random.randint(num_items)\n",
        "                while j in items_set:\n",
        "                    j = np.random.randint(num_items)\n",
        "                user_input.append(items_by_user)\n",
        "                item_input.append(j)\n",
        "                num_idx.append(size)\n",
        "                labels.append(0)\n",
        "            items_by_user.remove(i)\n",
        "            user_input.append(items_by_user)\n",
        "            item_input.append(i)\n",
        "            num_idx.append(size-1)\n",
        "            labels.append(1)\n",
        "    return user_input,num_idx,item_input,labels\n",
        "\n",
        "def _get_pairwise_all_likefossil_data(dataset, high_order, train_dict):\n",
        "    user_input_id,user_input_pos,user_input_neg, num_idx_pos, num_idx_neg, item_input_pos,item_input_neg,item_input_recents = [],[], [], [],[],[],[],[]\n",
        "    for u in range(dataset.num_users):\n",
        "        items_by_user = train_dict[u].copy()\n",
        "        num_items_by_u = len(items_by_user)\n",
        "        if  num_items_by_u > high_order:\n",
        "            negative_items = randint_choice(dataset.num_items, num_items_by_u, replace=True, exclusion = items_by_user)\n",
        "            for idx in range(high_order,len(train_dict[u])):\n",
        "                i = train_dict[u][idx] # item id\n",
        "                item_input_recent = []\n",
        "                for t in range(1,high_order+1):\n",
        "                    item_input_recent.append(train_dict[u][idx-t])\n",
        "                item_input_recents.append(item_input_recent)\n",
        "                j = negative_items[idx]\n",
        "                user_input_neg.append(items_by_user)\n",
        "                num_idx_neg.append(num_items_by_u)\n",
        "                item_input_neg.append(j)\n",
        "\n",
        "                items_by_user.remove(i)\n",
        "                user_input_id.append(u)\n",
        "                user_input_pos.append(items_by_user)\n",
        "                num_idx_pos.append(num_items_by_u-1)\n",
        "                item_input_pos.append(i)\n",
        "\n",
        "    return user_input_id,user_input_pos,user_input_neg, num_idx_pos, num_idx_neg, item_input_pos,item_input_neg,item_input_recents\n",
        "\n",
        "def _get_pointwise_all_likefossil_data(dataset, high_order, num_negatives, train_dict):\n",
        "    user_input_id,user_input,num_idx,item_input,item_input_recents,labels = [],[],[],[],[],[]\n",
        "    for u in range(dataset.num_users):\n",
        "        items_by_user = train_dict[u].copy()\n",
        "        items_set = set(items_by_user)\n",
        "        size = len(items_by_user)\n",
        "        for idx in range(high_order,len(train_dict[u])):\n",
        "            i = train_dict[u][idx] # item id\n",
        "            item_input_recent = []\n",
        "            for t in range(1,high_order+1):\n",
        "                item_input_recent.append(train_dict[u][idx-t])\n",
        "            # negative instances\n",
        "            for _ in range(num_negatives):\n",
        "                j = np.random.randint(dataset.num_items)\n",
        "                while j in items_set:\n",
        "                    j = np.random.randint(dataset.num_items)\n",
        "                user_input_id.append(u)\n",
        "                user_input.append(items_by_user)\n",
        "                item_input_recents.append(item_input_recent)\n",
        "                item_input.append(j)\n",
        "                num_idx.append(size)\n",
        "                labels.append(0)\n",
        "            items_by_user.remove(i)\n",
        "            user_input.append(items_by_user)\n",
        "            user_input_id.append(u)\n",
        "            item_input_recents.append(item_input_recent)\n",
        "            item_input.append(i)\n",
        "            num_idx.append(size-1)\n",
        "            labels.append(1)\n",
        "    return user_input_id,user_input,num_idx,item_input,item_input_recents,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-t3kY_N0zou"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sampler(object):\n",
        "    \"\"\"Base class for all Samplers.\n",
        "\n",
        "    Every Sampler subclass has to provide an __iter__ method, providing a way\n",
        "    to iterate over indices of dataset elements, and a __len__ method that\n",
        "    returns the length of the returned iterators.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __iter__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class SequentialSampler(Sampler):\n",
        "    \"\"\"Samples elements sequentially, always in the same order.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source):\n",
        "        \"\"\"Initializes a new `SequentialSampler` instance.\n",
        "\n",
        "        Args:\n",
        "            data_source (_Dataset): Dataset to sample from.\n",
        "        \"\"\"\n",
        "        super(SequentialSampler, self).__init__()\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(len(self.data_source)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)\n",
        "\n",
        "\n",
        "class RandomSampler(Sampler):\n",
        "    \"\"\"Samples elements randomly, without replacement.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source):\n",
        "        \"\"\"Initializes a new `SequentialSampler` instance.\n",
        "\n",
        "        Args:\n",
        "            data_source (_Dataset): Dataset to sample from.\n",
        "        \"\"\"\n",
        "        super(RandomSampler, self).__init__()\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        perm = np.random.permutation(len(self.data_source)).tolist()\n",
        "        return iter(perm)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)\n",
        "\n",
        "\n",
        "class BatchSampler(Sampler):\n",
        "    \"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sampler, batch_size, drop_last):\n",
        "        \"\"\"Initializes a new `BatchSampler` instance.\n",
        "\n",
        "        Args:\n",
        "            sampler (Sampler): Base sampler.\n",
        "            batch_size (int): Size of mini-batch.\n",
        "            drop_last (bool): If `True`, the sampler will drop the last batch\n",
        "                if its size would be less than `batch_size`.\n",
        "        \"\"\"\n",
        "        super(BatchSampler, self).__init__()\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of \"\n",
        "                             \"torch.utils.data.Sampler, but got sampler={}\"\n",
        "                             .format(sampler))\n",
        "        if not isinstance(batch_size, int) or isinstance(batch_size, bool) or \\\n",
        "                batch_size <= 0:\n",
        "            raise ValueError(\"batch_size should be a positive integeral value, \"\n",
        "                             \"but got batch_size={}\".format(batch_size))\n",
        "        if not isinstance(drop_last, bool):\n",
        "            raise ValueError(\"drop_last should be a boolean value, but got \"\n",
        "                             \"drop_last={}\".format(drop_last))\n",
        "        self.sampler = sampler\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "    def __iter__(self):\n",
        "        batch = []\n",
        "        for idx in self.sampler:\n",
        "            batch.append(idx)\n",
        "            if len(batch) == self.batch_size:\n",
        "                yield batch\n",
        "                batch = []\n",
        "        if len(batch) > 0 and not self.drop_last:\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.drop_last:\n",
        "            return len(self.sampler) // self.batch_size\n",
        "        else:\n",
        "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "\n",
        "class _Dataset(object):\n",
        "    \"\"\"Pack the given data to one dataset.\n",
        "\n",
        "    Args:\n",
        "        data (list or tuple): a list of 'data'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        for d in data:\n",
        "            if len(d) != len(data[0]):\n",
        "                raise ValueError(\"The length of the given data are not equal!\")\n",
        "            # assert len(d) == len(data[0])\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [data[idx] for data in self.data]\n",
        "\n",
        "\n",
        "class _DataLoaderIter(object):\n",
        "    \"\"\"Iterates once over the dataset, as specified by the sampler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loader):\n",
        "        self.dataset = loader.dataset\n",
        "        self.batch_sampler = loader.batch_sampler\n",
        "        self.sample_iter = iter(self.batch_sampler)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "\n",
        "    def __next__(self):\n",
        "        indices = next(self.sample_iter)  # may raise StopIteration\n",
        "        batch = [self.dataset[i] for i in indices]\n",
        "\n",
        "        transposed = [list(samples) for samples in zip(*batch)]\n",
        "        if len(transposed) == 1:\n",
        "            transposed = transposed[0]\n",
        "        return transposed\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "class DataIterator(object):\n",
        "    \"\"\"`DataIterator` provides iterators over the dataset.\n",
        "\n",
        "    This class combines some data sets and provides a batch iterator over them.\n",
        "    For example::\n",
        "\n",
        "        users = list(range(10))\n",
        "        items = list(range(10, 20))\n",
        "        labels = list(range(20, 30))\n",
        "\n",
        "        data_iter = DataIterator(users, items, labels, batch_size=4, shuffle=False)\n",
        "        for bat_user, bat_item, bat_label in data_iter:\n",
        "            print(bat_user, bat_item, bat_label)\n",
        "\n",
        "        data_iter = DataIterator(users, items, batch_size=4, shuffle=True, drop_last=True)\n",
        "        for bat_user, bat_item in data_iter:\n",
        "            print(bat_user, bat_item)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *data, batch_size=1, shuffle=False, drop_last=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            *data: Variable length data list.\n",
        "            batch_size (int): How many samples per batch to load. Defaults to `1`.\n",
        "            shuffle (bool): Set to `True` to have the data reshuffled at every\n",
        "                epoch. Defaults to `False`.\n",
        "            drop_last (bool): Set to `True` to drop the last incomplete batch,\n",
        "                if the dataset size is not divisible by the batch size.\n",
        "                If `False` and the size of dataset is not divisible by the\n",
        "                batch size, then the last batch will be smaller.\n",
        "                Defaults to `False`.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the length of the given data are not equal.\n",
        "        \"\"\"\n",
        "        dataset = _Dataset(list(data))\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "        if shuffle:\n",
        "            sampler = RandomSampler(dataset)\n",
        "        else:\n",
        "            sampler = SequentialSampler(dataset)\n",
        "\n",
        "        self.batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return _DataLoaderIter(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOpdoyvN0zov"
      },
      "outputs": [],
      "source": [
        "from cmath import cos\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from scipy.special import lambertw\n",
        "import random\n",
        "# from data import Data\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# based on LightGCN\n",
        "# n_layers = 0: MF\n",
        "class AbstractModel(nn.Module):\n",
        "    def __init__(self, args, data):\n",
        "        super(AbstractModel, self).__init__()\n",
        "        print(\"AbstractModel\")\n",
        "\n",
        "        # basic information\n",
        "        self.args = args\n",
        "        self.name = args.modeltype\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "        # self.saveID = args.saveID\n",
        "        self.data = data\n",
        "\n",
        "        # graph\n",
        "        self.Graph = data.getSparseGraph()\n",
        "\n",
        "        # basic hyper-parameters\n",
        "        self.emb_dim = args.embed_size\n",
        "        self.decay = args.regs\n",
        "        self.train_norm = args.train_norm\n",
        "        self.pred_norm = args.pred_norm\n",
        "        self.n_layers = args.n_layers\n",
        "        self.modeltype = args.modeltype\n",
        "        self.batch_size = args.batch_size\n",
        "\n",
        "        self.init_embedding()\n",
        "\n",
        "    def init_embedding(self):\n",
        "        self.embed_user = nn.Embedding(self.data.n_users, self.emb_dim)\n",
        "        self.embed_item = nn.Embedding(self.data.n_items, self.emb_dim)\n",
        "\n",
        "        nn.init.xavier_normal_(self.embed_user.weight)\n",
        "        nn.init.xavier_normal_(self.embed_item.weight)\n",
        "\n",
        "    def compute(self):\n",
        "        users_emb = self.embed_user.weight\n",
        "        items_emb = self.embed_item.weight\n",
        "        all_emb = torch.cat([users_emb, items_emb])\n",
        "\n",
        "        embs = [all_emb]\n",
        "        g_droped = self.Graph\n",
        "\n",
        "        for layer in range(self.n_layers):\n",
        "            # print(g_droped.device, all_emb.device)\n",
        "            all_emb = torch.sparse.mm(g_droped, all_emb)\n",
        "            embs.append(all_emb)\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "\n",
        "        light_out = torch.mean(embs, dim=1)\n",
        "        users, items = torch.split(light_out, [self.data.n_users, self.data.n_items])\n",
        "\n",
        "        return users, items\n",
        "\n",
        "    #! must be implemented\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # Prediction function used when evaluation\n",
        "    def predict(self, users, items=None):\n",
        "        if items is None:\n",
        "            items = list(range(self.data.n_items))\n",
        "\n",
        "        all_users, all_items = self.compute()\n",
        "\n",
        "        users = all_users[torch.tensor(users)]\n",
        "        items = all_items[torch.tensor(items)]\n",
        "\n",
        "        if(self.pred_norm == True):\n",
        "            users = F.normalize(users, dim = -1)\n",
        "            items = F.normalize(items, dim = -1)\n",
        "\n",
        "        items = items.clone().detach().transpose(0, 1) # Convert items to tensor and then transpose\n",
        "        # items = torch.transpose(items, 0, 1)\n",
        "        rate_batch = torch.matmul(users, items) # user * item\n",
        "\n",
        "        return rate_batch.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz0B0Wia0zox"
      },
      "outputs": [],
      "source": [
        "class AbstractEvaluator(object):\n",
        "    \"\"\"Base class for all evaluator.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def metrics_info(self):\n",
        "        \"\"\"Get all metrics information.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all metrics information such as\n",
        "            `\"Precision@10    Precision@20    NDCG@10    NDCG@20\"`.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def evaluate(self, model):\n",
        "        \"\"\"Evaluate `model`.\n",
        "\n",
        "        Args:\n",
        "            model: The model need to be evaluated. This model must have\n",
        "                a method `predict_for_eval(self, users)`, where the argument\n",
        "                `users` is a list of users and the return is a 2-D array that\n",
        "                contains `users` rating/ranking scores on all items.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all results, such as\n",
        "            `\"0.18663847    0.11239596    0.35824192    0.21479650\"`.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMPj2jfv0zoy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "\n",
        "def hit(rank, ground_truth):\n",
        "    # HR is equal to Recall when dataset is loo split.\n",
        "    last_idx = sys.maxsize\n",
        "    for idx, item in enumerate(rank):\n",
        "        if item == ground_truth:\n",
        "            last_idx = idx\n",
        "            break\n",
        "    result = np.zeros(len(rank), dtype=np.float32)\n",
        "    result[last_idx:] = 1.0\n",
        "    return result\n",
        "\n",
        "\n",
        "def precision(rank, ground_truth):\n",
        "    # Precision is meaningless when dataset is loo split.\n",
        "    hits = [1 if item in ground_truth else 0 for item in rank]\n",
        "    result = np.cumsum(hits, dtype=np.float32)/np.arange(1, len(rank)+1)\n",
        "    return result\n",
        "\n",
        "\n",
        "def recall(rank, ground_truth):\n",
        "    # Recall is equal to HR when dataset is loo split.\n",
        "    hits = [1 if item in ground_truth else 0 for item in rank]\n",
        "    result = np.cumsum(hits, dtype=np.float32) / len(ground_truth)\n",
        "    return result\n",
        "\n",
        "\n",
        "def map(rank, ground_truth):\n",
        "    # Reference: https://blog.csdn.net/u010138758/article/details/69936041\n",
        "    # MAP is equal to MRR when dataset is loo split.\n",
        "    # According to the definition, it seems that there is no such thing as MAP@N in MAP.\n",
        "    pre = precision(rank, ground_truth)\n",
        "    pre = [pre[idx] if item in ground_truth else 0 for idx, item in enumerate(rank)]\n",
        "    sum_pre = np.cumsum(pre, dtype=np.float32)\n",
        "    # relevant_num = np.cumsum([1 if item in ground_truth else 0 for item in rank])\n",
        "    relevant_num = [min(idx + 1, len(ground_truth)) for idx, _ in enumerate(rank)]\n",
        "    result = [p/r_num if r_num!=0 else 0 for p, r_num in zip(sum_pre, relevant_num)]\n",
        "    return result\n",
        "\n",
        "\n",
        "def ndcg(rank, ground_truth):\n",
        "    len_rank = len(rank)\n",
        "    idcg_len = min(len(ground_truth), len_rank)\n",
        "    idcg = np.cumsum(1.0 / np.log2(np.arange(2, len_rank + 2)))\n",
        "    idcg[idcg_len:] = idcg[idcg_len - 1]\n",
        "\n",
        "    dcg = np.cumsum([1.0/np.log2(idx+2) if item in ground_truth else 0.0 for idx, item in enumerate(rank)])\n",
        "    result = dcg/idcg\n",
        "    return result\n",
        "\n",
        "\n",
        "def mrr(rank, ground_truth):\n",
        "    # MRR is equal to MAP when dataset is loo split.\n",
        "    last_idx = sys.maxsize\n",
        "    for idx, item in enumerate(rank):\n",
        "        if item in ground_truth:\n",
        "            last_idx = idx\n",
        "            break\n",
        "    result = np.zeros(len(rank), dtype=np.float32)\n",
        "    result[last_idx:] = 1.0/(last_idx+1)\n",
        "    return result\n",
        "\n",
        "\n",
        "metric_dict = {\"Precision\": precision,\n",
        "               \"Recall\": recall,\n",
        "               \"MAP\": map,\n",
        "               \"NDCG\": ndcg,\n",
        "               \"MRR\": mrr}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry8dlEZ60zo0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@author: Zhongchuan Sun\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class UniEvaluator(AbstractEvaluator):\n",
        "    \"\"\"Python implementation `UniEvaluator` for item ranking task.\n",
        "\n",
        "    Evaluation metrics of `UniEvaluator` are configurable and can\n",
        "    automatically fit both leave-one-out and fold-out data splitting\n",
        "    without specific indication:\n",
        "\n",
        "    * **First**, evaluation metrics of this class are configurable via the\n",
        "      argument `metric`. Now there are five configurable metrics: `Precision`,\n",
        "      `Recall`, `MAP`, `NDCG` and `MRR`.\n",
        "\n",
        "    * **Second**, this class and its evaluation metrics can automatically fit\n",
        "      both leave-one-out and fold-out data splitting without specific indication.\n",
        "      In **leave-one-out** evaluation, 1) `Recall` is equal to `HitRatio`;\n",
        "      2) The implementation of `NDCG` is compatible with fold-out; 3) `MAP` and\n",
        "      `MRR` have same numeric values; 4) `Precision` is meaningless.\n",
        "    \"\"\"\n",
        "\n",
        "    @typeassert(user_train_dict=dict, user_test_dict=(dict, None.__class__))\n",
        "    def __init__(self, user_train_dict, user_test_dict, user_neg_test=None,\n",
        "                 metric=None, top_k=50, batch_size=1024, num_thread=8):\n",
        "        \"\"\"Initializes a new `UniEvaluator` instance.\n",
        "\n",
        "        Args:\n",
        "            user_train_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **training items**.\n",
        "            user_test_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **test items**.\n",
        "            metric (None or list of str): If `metric == None`, metric will\n",
        "                be set to `[\"Precision\", \"Recall\", \"MAP\", \"NDCG\", \"MRR\"]`.\n",
        "                Otherwise, `metric` must be one or a sublist of metrics\n",
        "                mentioned above. Defaults to `None`.\n",
        "            top_k (int or list of int): `top_k` controls the Top-K item ranking\n",
        "                performance. If `top_k` is an integer, K ranges from `1` to\n",
        "                `top_k`; If `top_k` is a list of integers, K are only assigned\n",
        "                these values. Defaults to `50`.\n",
        "            batch_size (int): An integer to control the test batch size.\n",
        "                Defaults to `1024`.\n",
        "            num_thread (int): An integer to control the test thread number.\n",
        "                Defaults to `8`.\n",
        "\n",
        "        Raises:\n",
        "             ValueError: If `metric` or one of its element is invalid.\n",
        "        \"\"\"\n",
        "        super(UniEvaluator, self).__init__()\n",
        "        print(\"Check UniEva\")\n",
        "        if metric is None:\n",
        "            metric = [\"Precision\", \"Recall\", \"MAP\", \"NDCG\", \"MRR\"]\n",
        "            print(metric)\n",
        "        elif isinstance(metric, str):\n",
        "            metric = [metric]\n",
        "        elif isinstance(metric, (set, tuple, list)):\n",
        "            pass\n",
        "        else:\n",
        "            raise TypeError(\"The type of 'metric' (%s) is invalid!\" % (metric.__class__.__name__))\n",
        "\n",
        "        for m in metric:\n",
        "            if m not in metric_dict:\n",
        "                raise ValueError(\"There is not the metric named '%s'!\" % (metric))\n",
        "\n",
        "        self.user_pos_train = user_train_dict\n",
        "        self.user_pos_test = {user: set(items) for user, items in user_test_dict.items()}\n",
        "        self.user_neg_test = user_neg_test\n",
        "        self.metrics_num = len(metric)\n",
        "        self.metrics = metric\n",
        "        self.num_thread = num_thread\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.max_top = top_k if isinstance(top_k, int) else max(top_k)\n",
        "        if isinstance(top_k, int):\n",
        "            self.top_show = np.arange(top_k) + 1\n",
        "        else:\n",
        "            self.top_show = np.sort(top_k)\n",
        "\n",
        "    def metrics_info(self):\n",
        "        \"\"\"Get all metrics information.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all metrics information such as\n",
        "                `\"Precision@10    Precision@20    NDCG@10    NDCG@20\"`.\n",
        "        \"\"\"\n",
        "        metrics_show = ['\\t'.join([(\"%s@\"%metric + str(k)).ljust(12) for k in self.top_show])\n",
        "                        for metric in self.metrics]\n",
        "        metric = '\\t'.join(metrics_show)\n",
        "        return \"metrics:\\t%s\" % metric\n",
        "\n",
        "    def evaluate(self, model, test_users=None):\n",
        "        \"\"\"Evaluate `model`.\n",
        "\n",
        "        Args:\n",
        "            model: The model need to be evaluated. This model must have\n",
        "                a method `predict_for_eval(self, users)`, where the argument\n",
        "                `users` is a list of users and the return is a 2-D array that\n",
        "                contains `users` rating/ranking scores on all items.\n",
        "\n",
        "        Returns:\n",
        "            str: A single-line string consist of all results, such as\n",
        "                `\"0.18663847    0.11239596    0.35824192    0.21479650\"`.\n",
        "        \"\"\"\n",
        "        # B: batch size\n",
        "        # N: the number of items\n",
        "        test_users = test_users if test_users is not None else list(self.user_pos_test.keys())\n",
        "        if not isinstance(test_users, (list, tuple, set, np.ndarray)):\n",
        "            raise TypeError(\"'test_user' must be a list, tuple, set or numpy array!\")\n",
        "\n",
        "        test_users = DataIterator(test_users, batch_size=self.batch_size,\n",
        "                                  shuffle=False, drop_last=False)\n",
        "        batch_result = []\n",
        "        for batch_users in tqdm(test_users):\n",
        "            if self.user_neg_test is not None:\n",
        "                candidate_items = [list(self.user_pos_test[u]) + self.user_neg_test[u] for u in batch_users]\n",
        "                test_items = [set(range(len(self.user_pos_test[u]))) for u in batch_users]\n",
        "\n",
        "                ranking_score = model.predict(batch_users, candidate_items)  # (B,N)\n",
        "                ranking_score = pad_sequences(ranking_score, value=-np.inf, dtype=np.float32)\n",
        "\n",
        "                ranking_score = np.array(ranking_score)\n",
        "            else:\n",
        "                test_items = [self.user_pos_test[u] for u in batch_users]\n",
        "                ranking_score = model.predict(batch_users, None)  # (B,N)\n",
        "                ranking_score = np.array(ranking_score)\n",
        "\n",
        "                # set the ranking scores of training items to -inf,\n",
        "                # then the training items will be sorted at the end of the ranking list.\n",
        "                for idx, user in enumerate(batch_users):\n",
        "                    train_items = self.user_pos_train[user]\n",
        "                    ranking_score[idx][train_items] = -np.inf\n",
        "\n",
        "            result = self.eval_score_matrix(ranking_score, test_items, self.metrics,\n",
        "                                            top_k=self.max_top, thread_num=self.num_thread)  # (B,k*metric_num)\n",
        "            batch_result.append(result)\n",
        "\n",
        "        # concatenate the batch results to a matrix\n",
        "        all_user_result = np.concatenate(batch_result, axis=0)  # (num_users, metrics_num*max_top)\n",
        "        final_result = np.mean(all_user_result, axis=0)  # (1, metrics_num*max_top)\n",
        "\n",
        "        final_result = np.reshape(final_result, newshape=[self.metrics_num, self.max_top])  # (metrics_num, max_top)\n",
        "        final_result = final_result[:, self.top_show - 1]\n",
        "        final_result = np.reshape(final_result, newshape=[-1])\n",
        "        buf = '\\t'.join([(\"%.8f\" % x).ljust(12) for x in final_result])\n",
        "        return buf\n",
        "\n",
        "    @typeassert(score_matrix=np.ndarray, test_items=list)\n",
        "    def eval_score_matrix(self, score_matrix, test_items, metric, top_k, thread_num):\n",
        "        def _eval_one_user(idx):\n",
        "            scores = score_matrix[idx]  # all scores of the test user\n",
        "            test_item = test_items[idx]\n",
        "\n",
        "            ranking = argmax_top_k(scores, top_k)  # Top-K items\n",
        "            result = [metric_dict[m](ranking, test_item) for m in metric]\n",
        "\n",
        "            result = np.array(result, dtype=np.float32).flatten()\n",
        "            return result\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=thread_num) as executor:\n",
        "            batch_result = executor.map(_eval_one_user, range(len(test_items)))\n",
        "\n",
        "        result = list(batch_result)  # generator to list\n",
        "        return np.array(result)  # list to ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj6J51cX0zo3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class GroupedEvaluator(AbstractEvaluator):\n",
        "    \"\"\"`GroupedEvaluator` evaluates models in user groups.\n",
        "\n",
        "    This class evaluates the ranking performance of models in user groups,\n",
        "    which are split according to the numbers of users' interactions in\n",
        "    **training data**. This function can be activated by the argument\n",
        "    `group_view`, which must be a list of integers.\n",
        "    For example, if `group_view = [10,30,50,100]`, users will be split into\n",
        "    four groups: `(0, 10]`, `(10, 30]`, `(30, 50]` and `(50, 100]`. And the\n",
        "    users whose interacted items more than `100` will be discard.\n",
        "    \"\"\"\n",
        "    @typeassert(user_train_dict=dict, user_test_dict=dict, group_view=list)\n",
        "    def __init__(self, user_train_dict, user_test_dict, user_neg_test=None,\n",
        "                 metric=None, group_view=None, top_k=50, batch_size=1024, num_thread=8):\n",
        "        \"\"\"Initializes a new `GroupedEvaluator` instance.\n",
        "\n",
        "        Args:\n",
        "            user_train_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **training items**.\n",
        "            user_test_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **test items**.\n",
        "            metric (None or list of str): If `metric == None`, metric will\n",
        "                be set to `[\"Precision\", \"Recall\", \"MAP\", \"NDCG\", \"MRR\"]`.\n",
        "                Otherwise, `metric` must be one or a sublist of metrics\n",
        "                mentioned above. Defaults to `None`.\n",
        "            group_view (list of int): A list of integers.\n",
        "            top_k (int or list of int): `top_k` controls the Top-K item ranking\n",
        "                performance. If `top_k` is an integer, K ranges from `1` to\n",
        "                `top_k`; If `top_k` is a list of integers, K are only assigned\n",
        "                these values. Defaults to `50`.\n",
        "            batch_size (int): An integer to control the test batch size.\n",
        "                Defaults to `1024`.\n",
        "            num_thread (int): An integer to control the test thread number.\n",
        "                Defaults to `8`.\n",
        "\n",
        "        Raises:\n",
        "             TypeError: If `group_view` is not a list.\n",
        "             ValueError: If user splitting with `group_view` is not suitable.\n",
        "        \"\"\"\n",
        "        super(GroupedEvaluator, self).__init__()\n",
        "\n",
        "        if not isinstance(group_view, list):\n",
        "            raise TypeError(\"The type of 'group_view' must be `list`!\")\n",
        "\n",
        "        self.evaluator = UniEvaluator(user_train_dict, user_test_dict, user_neg_test,\n",
        "                                      metric=metric, top_k=top_k,\n",
        "                                      batch_size=batch_size,\n",
        "                                      num_thread=num_thread)\n",
        "        self.user_pos_train = user_train_dict\n",
        "        self.user_pos_test = user_test_dict\n",
        "\n",
        "        group_list = [0] + group_view\n",
        "        group_info = [(\"(%d,%d]:\" % (g_l, g_h)).ljust(12)\n",
        "                      for g_l, g_h in zip(group_list[:-1], group_list[1:])]\n",
        "\n",
        "        all_test_user = list(self.user_pos_test.keys())\n",
        "        num_interaction = [len(self.user_pos_train[u]) for u in all_test_user]\n",
        "        group_idx = np.searchsorted(group_list[1:], num_interaction)\n",
        "        user_group = pd.DataFrame(list(zip(all_test_user, group_idx)),\n",
        "                                  columns=[\"user\", \"group\"])\n",
        "        grouped = user_group.groupby(by=[\"group\"])\n",
        "\n",
        "        self.grouped_user = OrderedDict()\n",
        "        for idx, users in grouped:\n",
        "            if idx < len(group_info):\n",
        "                self.grouped_user[group_info[idx]] = users[\"user\"].tolist()\n",
        "\n",
        "        if not self.grouped_user:\n",
        "            raise ValueError(\"The splitting of user groups is not suitable!\")\n",
        "\n",
        "    def metrics_info(self):\n",
        "        \"\"\"Get all metrics information.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all metrics information such as\n",
        "            `\"Precision@10    Precision@20    NDCG@10    NDCG@20\"`.\n",
        "        \"\"\"\n",
        "        return self.evaluator.metrics_info()\n",
        "\n",
        "    def evaluate(self, model):\n",
        "        \"\"\"Evaluate `model` in user groups.\n",
        "\n",
        "        Args:\n",
        "            model: The model need to be evaluated. This model must have\n",
        "                a method `predict_for_eval(self, users)`, where the argument\n",
        "                `users` is a list of users and the return is a 2-D array that\n",
        "                contains `users` rating/ranking scores on all items.\n",
        "\n",
        "        Returns:\n",
        "            str: A multi-line string consist of all results of groups, such as:\n",
        "                `\"(0,10]:   0.00648002   0.00421617   0.00301847   0.00261693\\n\n",
        "                (10,30]:  0.00686600   0.00442968   0.00310077   0.00249169\\n\n",
        "                (30,50]:  0.00653595   0.00326797   0.00217865   0.00163399\\n\n",
        "                (50,100]: 0.00423729   0.00211864   0.00141243   0.00105932\"`\n",
        "        \"\"\"\n",
        "        result_to_show = \"\"\n",
        "        for group, users in self.grouped_user.items():\n",
        "            tmp_result = self.evaluator.evaluate(model, users)\n",
        "            result_to_show = \"%s\\n%s\\t%s\" % (result_to_show, group, tmp_result)\n",
        "\n",
        "        return result_to_show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_84jy4M0zo4"
      },
      "outputs": [],
      "source": [
        "class ProxyEvaluator(AbstractEvaluator):\n",
        "    \"\"\"`ProxyEvaluator` is the interface to evaluate models.\n",
        "\n",
        "    `ProxyEvaluator` contains various evaluation protocols:\n",
        "\n",
        "    * **First**, evaluation metrics of this class are configurable via the\n",
        "      argument `metric`. Now there are five configurable metrics: `Precision`,\n",
        "      `Recall`, `MAP`, `NDCG` and `MRR`.\n",
        "\n",
        "    * **Second**, this class and its evaluation metrics can automatically fit\n",
        "      both leave-one-out and fold-out data splitting without specific indication.\n",
        "      In **leave-one-out** evaluation, 1) `Recall` is equal to `HitRatio`;\n",
        "      2) The implementation of `NDCG` is compatible with fold-out; 3) `MAP` and\n",
        "      `MRR` have same numeric values; 4) `Precision` is meaningless.\n",
        "\n",
        "    * **Furthermore**, the ranking performance of models can be viewed in user\n",
        "      groups, which are split according to the numbers of users' interactions\n",
        "      in **training data**. This function can be activated by the argument\n",
        "      `group_view`. Specifically, if `group_view == None`, the ranking performance\n",
        "      will be viewed without groups; If `group_view` is a list of integers,\n",
        "      the ranking performance will be view in groups.\n",
        "      For example, if `group_view = [10,30,50,100]`, users will be split into\n",
        "      four groups: `(0, 10]`, `(10, 30]`, `(30, 50]` and `(50, 100]`. And the\n",
        "      users whose interacted items more than `100` will be discarded.\n",
        "\n",
        "    * **Finally and importantly**, all the functions mentioned above depend on\n",
        "      `UniEvaluator`, which is implemented by **python** and **cpp**.\n",
        "      And both of the two versions are **multi-threaded**.\n",
        "    \"\"\"\n",
        "\n",
        "    @typeassert(user_train_dict=dict, user_test_dict=dict)\n",
        "    def __init__(self, dataset, user_train_dict, user_test_dict, user_neg_test=None, metric=None,\n",
        "                 group_view=None, top_k=50, batch_size=1024, num_thread=8,dump_dict=None,pop_mask=None):\n",
        "        \"\"\"Initializes a new `ProxyEvaluator` instance.\n",
        "\n",
        "        Args:\n",
        "            user_train_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **training items**.\n",
        "            user_test_dict (dict): Each key is user ID and the corresponding\n",
        "                value is the list of **test items**.\n",
        "            metric (None or list of str): If `metric == None`, metric will\n",
        "                be set to `[\"Precision\", \"Recall\", \"MAP\", \"NDCG\", \"MRR\"]`.\n",
        "                Otherwise, `metric` must be one or a sublist of metrics\n",
        "                mentioned above. Defaults to `None`.\n",
        "            group_view (None or list of int): If `group_view == None`, the ranking\n",
        "                performance will be viewed without groups. If `group_view` is a\n",
        "                list of integers, ranking performance will be viewed in groups.\n",
        "                Defaults to `None`.\n",
        "            top_k (int or list of int): `top_k` controls the Top-K item ranking\n",
        "                performance. If `top_k` is an integer, K ranges from `1` to\n",
        "                `top_k`; If `top_k` is a list of integers, K are only assigned\n",
        "                these values. Defaults to `50`.\n",
        "            batch_size (int): An integer to control the test batch size.\n",
        "                Defaults to `1024`.\n",
        "            num_thread (int): An integer to control the test thread number.\n",
        "                Defaults to `8`.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If `metric` or one of its element is not in\n",
        "                `[\"Precision\", \"Recall\", \"MAP\", \"NDCG\", \"MRR\"]`.\n",
        "\n",
        "        TODO:\n",
        "            * Check the validation of `num_thread` in cpp implementation.\n",
        "        \"\"\"\n",
        "        super(ProxyEvaluator, self).__init__()\n",
        "        if group_view is not None:\n",
        "            print(\"Grouped Evaluator\")\n",
        "            self.evaluator = GroupedEvaluator(user_train_dict, user_test_dict, user_neg_test,\n",
        "                                              metric=metric, group_view=group_view,\n",
        "                                              top_k=top_k, batch_size=batch_size,\n",
        "                                              num_thread=num_thread)\n",
        "        else:\n",
        "            self.evaluator = UniEvaluator(user_train_dict, user_test_dict, user_neg_test,\n",
        "                                          metric=metric, top_k=top_k,\n",
        "                                          batch_size=batch_size,\n",
        "                                          num_thread=num_thread)\n",
        "            # print(\"Pass\")\n",
        "\n",
        "    def metrics_info(self):\n",
        "        \"\"\"Get all metrics information.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all metrics information such as\n",
        "                `\"Precision@10    Precision@20    NDCG@10    NDCG@20\"`.\n",
        "        \"\"\"\n",
        "        return self.evaluator.metrics_info()\n",
        "\n",
        "    def evaluate(self, model):\n",
        "        \"\"\"Evaluate `model`.\n",
        "\n",
        "        Args:\n",
        "            model: The model need to be evaluated. This model must have\n",
        "                a method `predict_for_eval(self, users)`, where the argument\n",
        "                `users` is a list of users and the return is a 2-D array that\n",
        "                contains `users` rating/ranking scores on all items.\n",
        "\n",
        "        Returns:\n",
        "            str: A string consist of all results, such as\n",
        "                `\"0.18663847    0.11239596    0.35824192    0.21479650\"`.\n",
        "        \"\"\"\n",
        "        return self.evaluator.evaluate(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqwYmgLS0zo5"
      },
      "outputs": [],
      "source": [
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv6g0uuO0zo6"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "# distutils: language = c++\n",
        "\"\"\"\n",
        "Author: Zhongchuan Sun\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "\n",
        "def get_float_type():\n",
        "    cdef int size_of_float = sizeof(float) * 8\n",
        "    if size_of_float == 32:\n",
        "        return np.float32\n",
        "    elif size_of_float == 64:\n",
        "        return np.float64\n",
        "    else:\n",
        "        raise EnvironmentError(f\"The size of 'float' is {size_of_float}, but expected 32 or 64 bits.\")\n",
        "\n",
        "def get_int_type():\n",
        "    cdef int size_of_int = sizeof(int) * 8\n",
        "    if size_of_int == 16:\n",
        "        return np.int16\n",
        "    elif size_of_int == 32:\n",
        "        return np.int32\n",
        "    else:\n",
        "        raise EnvironmentError(f\"The size of 'int' is {size_of_int}, but expected 16 or 32 bits.\")\n",
        "\n",
        "float_type = get_float_type()\n",
        "int_type = get_int_type()\n",
        "\n",
        "def is_ndarray(np.ndarray array, dtype):\n",
        "    if not isinstance(array, np.ndarray):\n",
        "        return False\n",
        "    if array.dtype != dtype:\n",
        "        return False\n",
        "    if array.base is not NULL:\n",
        "        return False\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al8ne1zz0zo8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "from sys import get_coroutine_origin_tracking_depth\n",
        "from sys import exit\n",
        "random.seed(101)\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import matplotlib.patches as mpatches\n",
        "#from scipy.linalg import svd\n",
        "import itertools\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# from evaluator import ProxyEvaluator\n",
        "import collections\n",
        "import os\n",
        "\n",
        "def merge_user_list(user_lists):\n",
        "    out = collections.defaultdict(list)\n",
        "    # Loop over each user list\n",
        "    for user_list in user_lists:\n",
        "        # Loop over each user in the user list\n",
        "        for key, item in user_list.items():\n",
        "            out[key] = out[key] + item\n",
        "    return out\n",
        "\n",
        "\n",
        "def merge_user_list_no_dup(user_lists):\n",
        "    out = collections.defaultdict(list)\n",
        "    for user_list in user_lists:\n",
        "        for key, item in user_list.items():\n",
        "            out[key] = out[key] + item\n",
        "\n",
        "    for key in out.keys():\n",
        "        out[key]=list(set(out[key]))\n",
        "    return out\n",
        "\n",
        "\n",
        "def save_checkpoint(model, epoch, checkpoint_dir, buffer, max_to_keep=10):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': model.state_dict(),\n",
        "    }\n",
        "\n",
        "    filename = os.path.join(checkpoint_dir, 'epoch={}.checkpoint.pth.tar'.format(epoch))\n",
        "    torch.save(state, filename)\n",
        "    buffer.append(filename)\n",
        "    if len(buffer)>max_to_keep:\n",
        "        os.remove(buffer[0])\n",
        "        del(buffer[0])\n",
        "\n",
        "    return buffer\n",
        "\n",
        "\n",
        "def restore_checkpoint(model, checkpoint_dir, device, force=False, pretrain=False):\n",
        "    \"\"\"\n",
        "    If a checkpoint exists, restores the PyTorch model from the checkpoint.\n",
        "    Returns the model and the current epoch.\n",
        "    \"\"\"\n",
        "    cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "\n",
        "    if not cp_files:\n",
        "        print('No saved model parameters found')\n",
        "        if force:\n",
        "            raise Exception(\"Checkpoint not found\")\n",
        "        else:\n",
        "            return model, 0,\n",
        "\n",
        "    epoch_list = []\n",
        "\n",
        "    regex = re.compile(r'\\d+')\n",
        "\n",
        "    for cp in cp_files:\n",
        "        epoch_list.append([int(x) for x in regex.findall(cp)][0])\n",
        "\n",
        "    epoch = max(epoch_list)\n",
        "\n",
        "\n",
        "    if not force:\n",
        "        print(\"Which epoch to load from? Choose in range [0, {}).\"\n",
        "              .format(epoch), \"Enter 0 to train from scratch.\")\n",
        "        print(\">> \", end = '')\n",
        "        # inp_epoch = int(input())\n",
        "        inp_epoch = epoch\n",
        "        if inp_epoch not in range(epoch + 1):\n",
        "            raise Exception(\"Invalid epoch number\")\n",
        "        if inp_epoch == 0:\n",
        "            print(\"Checkpoint not loaded\")\n",
        "            clear_checkpoint(checkpoint_dir)\n",
        "            return model, 0,\n",
        "    else:\n",
        "        print(\"Which epoch to load from? Choose in range [0, {}).\".format(epoch))\n",
        "        inp_epoch = int(input())\n",
        "        if inp_epoch not in range(0, epoch):\n",
        "            raise Exception(\"Invalid epoch number\")\n",
        "\n",
        "    filename = os.path.join(checkpoint_dir,\n",
        "                            'epoch={}.checkpoint.pth.tar'.format(inp_epoch))\n",
        "\n",
        "    print(\"Loading from checkpoint {}?\".format(filename))\n",
        "\n",
        "    checkpoint = torch.load(filename, map_location = str(device))\n",
        "\n",
        "    try:\n",
        "        if pretrain:\n",
        "            model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "        print(\"=> Successfully restored checkpoint (trained for {} epochs)\"\n",
        "              .format(checkpoint['epoch']))\n",
        "    except:\n",
        "        print(\"=> Checkpoint not successfully restored\")\n",
        "        raise\n",
        "\n",
        "    return model, inp_epoch\n",
        "\n",
        "\n",
        "def restore_best_checkpoint(epoch, model, checkpoint_dir, device):\n",
        "    \"\"\"\n",
        "    Restore the best performance checkpoint\n",
        "    \"\"\"\n",
        "    cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "\n",
        "    filename = os.path.join(checkpoint_dir,\n",
        "                            'epoch={}.checkpoint.pth.tar'.format(epoch))\n",
        "\n",
        "    print(\"Loading from checkpoint {}?\".format(filename))\n",
        "\n",
        "    checkpoint = torch.load(filename, map_location = str(device))\n",
        "\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    print(\"=> Successfully restored checkpoint (trained for {} epochs)\"\n",
        "          .format(checkpoint['epoch']))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def clear_checkpoint(checkpoint_dir):\n",
        "    filelist = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth.tar\")]\n",
        "    for f in filelist:\n",
        "        os.remove(os.path.join(checkpoint_dir, f))\n",
        "\n",
        "    print(\"Checkpoint successfully removed\")\n",
        "\n",
        "\n",
        "def evaluation(args, data, model, epoch, base_path, evaluator, name=\"valid\"):\n",
        "    # Evaluate with given evaluator\n",
        "\n",
        "    ret = evaluator.evaluate(model)\n",
        "    # ret, _ = evaluator.evaluate(model)\n",
        "    ret = [float(value) for value in ret.split()]\n",
        "\n",
        "    # n_ret = {\"recall\": ret[1], \"hit_ratio\": ret[5], \"precision\": ret[0], \"ndcg\": ret[3], \"mrr\":ret[4], \"map\":ret[2]}\n",
        "    n_ret = {\"recall\": ret[1], \"precision\": ret[0], \"ndcg\": ret[3], \"mrr\":ret[4], \"map\":ret[2]}\n",
        "\n",
        "\n",
        "    perf_str = name+':{}'.format(n_ret)\n",
        "    print(perf_str)\n",
        "    with open(base_path + 'stats.txt', 'a') as f:\n",
        "        f.write(perf_str + \"\\n\")\n",
        "    # Check if need to early stop (on validation)\n",
        "    is_best=False\n",
        "    early_stop=False\n",
        "    if name==\"test\":\n",
        "    # if name==\"valid\":\n",
        "        if ret[1] > data.best_valid_recall:\n",
        "            data.best_valid_epoch = epoch\n",
        "            data.best_valid_recall = ret[1]\n",
        "            data.patience = 0\n",
        "            is_best=True\n",
        "        else:\n",
        "            data.patience += 1\n",
        "            if data.patience >= args.patience:\n",
        "                print_str = \"The best performance epoch is % d \" % data.best_valid_epoch\n",
        "                print(print_str)\n",
        "                early_stop=True\n",
        "\n",
        "    return is_best, early_stop, n_ret\n",
        "\n",
        "\n",
        "def Item_pop(args, data, model):\n",
        "\n",
        "    for K in range(5):\n",
        "\n",
        "        eval_pop = ProxyEvaluator(data, data.train_user_list, data.pop_dict_list[K], top_k=[(K+1)*10],\n",
        "                                   dump_dict=merge_user_list([data.train_user_list, data.valid_user_list]))\n",
        "\n",
        "        ret, _ = eval_pop.evaluate(model)\n",
        "\n",
        "        print_str = \"Overlap for K = % d is % f\" % ( (K+1)*10, ret[1] )\n",
        "\n",
        "        print(print_str)\n",
        "\n",
        "        with open('stats.txt', 'a') as f:\n",
        "            f.write(print_str + \"\\n\")\n",
        "\n",
        "\n",
        "def ensureDir(dir_path):\n",
        "\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "\n",
        "def split_grp_view(data,grp_idx):\n",
        "    n=len(grp_view)\n",
        "    split_data=[{} for _ in range(n)]\n",
        "\n",
        "    for key,item in data.items():\n",
        "        for it in item:\n",
        "            if key not in split_data[grp_idx[it]].keys():\n",
        "                split_data[grp_idx[it]][key]=[]\n",
        "            split_data[grp_idx[it]][key].append(it)\n",
        "    return split_data\n",
        "\n",
        "\n",
        "def checktensor(tensor):\n",
        "    t=tensor.detach().cpu().numpy()\n",
        "    if np.max(np.isnan(t)):\n",
        "        idx=np.argmax(np.isnan(t))\n",
        "        return idx\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def get_rotation_matrix(axis, theta):\n",
        "    \"\"\"\n",
        "    Find the rotation matrix associated with counterclockwise rotation\n",
        "    about the given axis by theta radians.\n",
        "    Credit: http://stackoverflow.com/users/190597/unutbu\n",
        "\n",
        "    Args:\n",
        "        axis (list): rotation axis of the form [x, y, z]\n",
        "        theta (float): rotational angle in radians\n",
        "\n",
        "    Returns:\n",
        "        array. Rotation matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    axis = np.asarray(axis)\n",
        "    theta = np.asarray(theta)\n",
        "    axis = axis/math.sqrt(np.dot(axis, axis))\n",
        "    a = math.cos(theta/2.0)\n",
        "    b, c, d = -axis*math.sin(theta/2.0)\n",
        "    aa, bb, cc, dd = a*a, b*b, c*c, d*d\n",
        "    bc, ad, ac, ab, bd, cd = b*c, a*d, a*c, a*b, b*d, c*d\n",
        "    return np.array([[aa+bb-cc-dd, 2*(bc+ad), 2*(bd-ac)],\n",
        "                     [2*(bc-ad), aa+cc-bb-dd, 2*(cd+ab)],\n",
        "                     [2*(bd+ac), 2*(cd-ab), aa+dd-bb-cc]])\n",
        "\n",
        "\n",
        "grads = {}\n",
        "def save_grad(name):\n",
        "    def hook(grad):\n",
        "        torch.clamp(grad, -1, 1)\n",
        "        grads[name] = grad\n",
        "    return hook\n",
        "\n",
        "\n",
        "def fix_seeds(seed=101):\n",
        "\trandom.seed(seed)\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed) # In order to disable hash randomization and make the experiment reproducible.\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "\ttorch.backends.cudnn.benchmark = False\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\n",
        "def align_loss(x, y, alpha=2):\n",
        "    return (x - y).norm(p=2, dim=1).pow(alpha).mean()\n",
        "\n",
        "def uniform_loss(x, t=2):\n",
        "    return torch.pdist(x, p=2).pow(2).mul(-t).exp().mean().log()\n",
        "\n",
        "def visualize_and_save_log(file_dir, dataset_name, show=False):\n",
        "    # Read file_dir line by line and keep only\n",
        "    if(dataset_name == \"tencent_synthetic\"):\n",
        "        pass\n",
        "    else:\n",
        "        valid_recall, valid_ndcg, test_recall, test_ndcg = [], [], [], []\n",
        "\n",
        "        with open(file_dir, 'r') as f:\n",
        "            # count = 0\n",
        "            for line in f:\n",
        "                line = line.split(' ')\n",
        "                if(\"valid\" in line[0]):\n",
        "                    valid_recall.append(float(line[1][:-1]))\n",
        "                    valid_ndcg.append(float(line[7][:-1]))\n",
        "                if(\"test\" in line[0]):\n",
        "                    test_recall.append(float(line[1][:-1]))\n",
        "                    test_ndcg.append(float(line[7][:-1]))\n",
        "\n",
        "        epochs = list(range(0, len(valid_recall)))\n",
        "        epochs = [i*5 for i in epochs]\n",
        "        # Define table.\n",
        "        result = pd.DataFrame({'epochs': epochs, 'valid_recall': valid_recall, 'test_recall': test_recall, 'valid_ndcg': valid_ndcg, 'test_ndcg': test_ndcg})\n",
        "        # df is all rows except the last one.\n",
        "        df = result.iloc[:-1, :]\n",
        "\n",
        "        fig=plt.figure()\n",
        "        x = df.epochs\n",
        "        y1 = df.valid_recall\n",
        "        y2 = df.test_recall\n",
        "        print(max(y1), max(y2), 1.1*max(y1), 1.1*max(y2))\n",
        "        # ax1 displays y1, ax2 displays y2.\n",
        "        ax1=fig.subplots()\n",
        "        ax2=ax1.twinx()    # Using twinx(), get ax2 symmetric to ax1, sharing the same x-axis but with asymmetric y-axis coordinates.\n",
        "        ax1.plot(x,y1,'g-', label='valid_recall')\n",
        "        ax2.plot(x,y2,'b--', label='test_recall')\n",
        "        # Coordinate axis range\n",
        "        ax1.set_ylim(min(y1), 1.15*(max(y1)-min(y1))+min(y1))\n",
        "        ax2.set_ylim(min(y2), 1.15*(max(y2)-min(y2))+min(y2))\n",
        "\n",
        "        ax1.set_xlabel('epochs')\n",
        "        ax1.set_ylabel('valid_recall')\n",
        "        ax2.set_ylabel('test_recall')\n",
        "        # legend\n",
        "        ax1.legend(loc='upper left')\n",
        "        ax2.legend(loc='upper right')\n",
        "\n",
        "        base_path = file_dir[:-9]\n",
        "        save_path = base_path + \"/train_log.png\"\n",
        "        plt.savefig(save_path)\n",
        "        if(show):\n",
        "            plt.show()\n",
        "        save_path = base_path + \"/train_log.csv\"\n",
        "        result.to_csv(save_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7Et9c320zpA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import datetime\n",
        "import json\n",
        "import wandb\n",
        "\n",
        "# define the abstract class for recommender system\n",
        "class AbstractRS(nn.Module):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super(AbstractRS, self).__init__()\n",
        "\n",
        "        # basic information\n",
        "        self.args = args\n",
        "        self.special_args = special_args\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "        self.test_only = args.test_only\n",
        "        self.candidate = args.candidate\n",
        "\n",
        "        self.Ks = args.Ks\n",
        "        self.patience = args.patience\n",
        "        self.modeltype = args.modeltype\n",
        "        self.neg_sample = args.neg_sample\n",
        "        self.inbatch = self.args.infonce == 1 and self.args.neg_sample == -1\n",
        "\n",
        "        # basic hyperparameters\n",
        "        self.n_layers = args.n_layers\n",
        "        self.lr = args.lr\n",
        "        self.batch_size = args.batch_size\n",
        "        self.max_epoch = args.epoch\n",
        "        self.verbose = args.verbose\n",
        "\n",
        "        # load the data\n",
        "        self.dataset_name = args.dataset\n",
        "        try:\n",
        "            print('from models.'+ args.modeltype + ' import ' + args.modeltype + '_Data')\n",
        "            exec('from models.'+ args.modeltype + ' import ' + args.modeltype + '_Data') # load special dataset\n",
        "            self.data = eval(args.modeltype + '_Data(args)')\n",
        "        except:\n",
        "            print(\"no special dataset\")\n",
        "            self.data = Data(args) # load data from the path\n",
        "\n",
        "        self.n_users = self.data.n_users\n",
        "        self.n_items = self.data.n_items\n",
        "        self.train_user_list = self.data.train_user_list\n",
        "        self.valid_user_list = self.data.valid_user_list\n",
        "        # = torch.tensor(self.data.population_list).cuda(self.device)\n",
        "        self.user_pop = torch.tensor(self.data.user_pop_idx).type(torch.LongTensor)\n",
        "        self.item_pop = torch.tensor(self.data.item_pop_idx).type(torch.LongTensor)\n",
        "        self.user_pop_max = self.data.user_pop_max\n",
        "        self.item_pop_max = self.data.item_pop_max\n",
        "\n",
        "        # load the model\n",
        "        self.running_model = args.modeltype + '_batch' if self.inbatch else args.modeltype\n",
        "        # exec('from models.'+ args.modeltype + ' import ' + self.running_model) # import the model first\n",
        "        exec(args.modeltype) # import the model first\n",
        "        self.model = eval(self.running_model + '(args, self.data)') # initialize the model with the graph\n",
        "        # self.model.cuda(self.device) removed\n",
        "\n",
        "\n",
        "        # preparing for saving\n",
        "        self.preperation_for_saving(args, special_args)\n",
        "\n",
        "        # preparing for evaluation\n",
        "        # self.not_candidate_dict = self.data.get_not_candidate() # load the not candidate dict\n",
        "        self.evaluators, self.eval_names = self.get_evaluators(self.data) # load the evaluators\n",
        "\n",
        "\n",
        "    # the whole pipeline of the training process\n",
        "    def execute(self):\n",
        "\n",
        "        self.save_args() # save the args\n",
        "        # write args\n",
        "        perf_str = str(self.args)\n",
        "        with open(self.base_path + 'stats.txt','a') as f:\n",
        "            f.write(perf_str+\"\\n\")\n",
        "\n",
        "        self.model, self.start_epoch = self.restore_checkpoint(self.model, self.base_path, self.device) # restore the checkpoint\n",
        "\n",
        "        start_time = time.time()\n",
        "        # train the model if not test only\n",
        "        if not self.test_only:\n",
        "            print(\"start training\")\n",
        "            self.train()\n",
        "            # test the model\n",
        "            print(\"start testing\")\n",
        "            self.model = self.restore_best_checkpoint(self.data.best_valid_epoch, self.model, self.base_path, self.device)\n",
        "        end_time = time.time()\n",
        "        self.model.eval() # evaluate the best model\n",
        "        print_str = \"The best epoch is % d, total training cost is %.1f\" % (max(self.data.best_valid_epoch, self.start_epoch), end_time - start_time)\n",
        "        with open(self.base_path +'stats.txt', 'a') as f:\n",
        "            f.write(print_str + \"\\n\")\n",
        "\n",
        "        n_rets = {}\n",
        "        for i,evaluator in enumerate(self.evaluators[:]):\n",
        "            _, __, n_ret = evaluation(self.args, self.data, self.model, self.data.best_valid_epoch, self.base_path, evaluator, self.eval_names[i])\n",
        "            n_rets[self.eval_names[i]] = n_ret\n",
        "\n",
        "        self.recommend_top_k()\n",
        "        self.document_hyper_params_results(self.base_path, n_rets)\n",
        "\n",
        "\n",
        "    def save_args(self):\n",
        "        # save the args\n",
        "        with open(self.base_path + '/args.txt', 'w') as f:\n",
        "            json.dump(self.args.__dict__, f, indent=2)\n",
        "\n",
        "    # define the training process\n",
        "    def train(self) -> None:\n",
        "        # TODO\n",
        "        self.set_optimizer() # get the optimizer\n",
        "        self.flag = False\n",
        "        for epoch in range(self.start_epoch, self.max_epoch):\n",
        "            # print(self.model.embed_user.weight)\n",
        "            if self.flag: # early stop\n",
        "                break\n",
        "            # All models\n",
        "            t1=time.time()\n",
        "            losses = self.train_one_epoch(epoch) # train one epoch\n",
        "            t2=time.time()\n",
        "            self.document_running_loss(losses, epoch, t2-t1) # report the loss\n",
        "            if (epoch + 1) % self.verbose == 0: # evaluate the model\n",
        "                self.eval_and_check_early_stop(epoch)\n",
        "\n",
        "        visualize_and_save_log(self.base_path +'stats.txt', self.dataset_name)\n",
        "\n",
        "    #! must be implemented by the subclass\n",
        "    def train_one_epoch(self, epoch):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def preperation_for_saving(self, args, special_args):\n",
        "        self.formatted_today=datetime.date.today().strftime('%m%d') + '_'\n",
        "\n",
        "        tn = '1' if args.train_norm else '0'\n",
        "        pn = '1' if args.pred_norm else '0'\n",
        "        self.train_pred_mode = 't' + tn + 'p' + pn\n",
        "\n",
        "        if(self.test_only == False):\n",
        "            prefix = self.formatted_today + args.saveID\n",
        "        else:\n",
        "            prefix = args.saveID\n",
        "        self.saveID = prefix + '_' + self.train_pred_mode + \"_Ks=\" + str(args.Ks) + '_patience=' + str(args.patience)\\\n",
        "            + \"_n_layers=\" + str(args.n_layers) + \"_batch_size=\" + str(args.batch_size)\\\n",
        "                + \"_neg_sample=\" + str(args.neg_sample) + \"_lr=\" + str(args.lr)\n",
        "\n",
        "        for arg in special_args:\n",
        "            print(arg, getattr(args, arg))\n",
        "            self.saveID += \"_\" + arg + \"=\" + str(getattr(args, arg))\n",
        "\n",
        "        self.modify_saveID()\n",
        "\n",
        "        if self.modeltype == 'LightGCN' and self.n_layers == 0:\n",
        "            self.base_path = 'recommenders/weights/{}/MF/{}'.format(self.dataset_name, self.saveID)\n",
        "        elif self.n_layers > 0 and self.modeltype != \"LightGCN\":\n",
        "            self.base_path = 'recommenders/weights/{}/{}-LGN/{}'.format(self.dataset_name, self.running_model, self.saveID)\n",
        "        else:\n",
        "            self.base_path = 'recommenders/weights/{}/{}/{}'.format(self.dataset_name, self.running_model, self.saveID)\n",
        "        self.checkpoint_buffer=[]\n",
        "        ensureDir(self.base_path)\n",
        "\n",
        "    def modify_saveID(self):\n",
        "        pass\n",
        "\n",
        "    def set_optimizer(self):\n",
        "        self.optimizer = torch.optim.Adam([param for param in self.model.parameters() if param.requires_grad == True], lr=self.lr)\n",
        "\n",
        "    def document_running_loss(self, losses:list, epoch, t_one_epoch, prefix=\"\"):\n",
        "        loss_str = ', '.join(['%.5f']*len(losses)) % tuple(losses)\n",
        "        perf_str = prefix + 'Epoch %d [%.1fs]: train==[' % (\n",
        "                epoch, t_one_epoch) + loss_str + ']'\n",
        "        with open(self.base_path + 'stats.txt','a') as f:\n",
        "                f.write(perf_str+\"\\n\")\n",
        "\n",
        "    def document_hyper_params_results(self, base_path, n_rets):\n",
        "        overall_path = '/'.join(base_path.split('/')[:-1]) + '/'\n",
        "        hyper_params_results_path = overall_path + self.formatted_today + self.dataset_name + '_' + self.modeltype + '_' + self.args.saveID + '_hyper_params_results.csv'\n",
        "\n",
        "        results = {'notation': self.formatted_today, 'train_pred_mode':self.train_pred_mode, 'best_epoch': max(self.data.best_valid_epoch, self.start_epoch), 'max_epoch': self.max_epoch, 'Ks': self.Ks, 'n_layers': self.n_layers, 'batch_size': self.batch_size, 'neg_sample': self.neg_sample, 'lr': self.lr}\n",
        "        for special_arg in self.special_args:\n",
        "            results[special_arg] = getattr(self.args, special_arg)\n",
        "\n",
        "        for k, v in n_rets.items():\n",
        "            if('test_id' not in k):\n",
        "                # for metric in ['recall', 'ndcg', 'hit_ratio']:\n",
        "                #     results[k + '_' + metric] = round(v[metric], 4)\n",
        "                for metric in ['recall', 'ndcg']:\n",
        "                    results[k + '_' + metric] = round(v[metric], 4)\n",
        "        frame_columns = list(results.keys())\n",
        "        # load former xlsx\n",
        "        if os.path.exists(hyper_params_results_path):\n",
        "            # hyper_params_results = pd.read_excel(hyper_params_results_path)\n",
        "            hyper_params_results = pd.read_csv(hyper_params_results_path)\n",
        "        else:\n",
        "            # Create a new dataframe using the results.\n",
        "            hyper_params_results = pd.DataFrame(columns=frame_columns)\n",
        "\n",
        "        hyper_params_results = hyper_params_results._append(results, ignore_index=True)\n",
        "        # to csv\n",
        "        hyper_params_results.to_csv(hyper_params_results_path, index=False, float_format='%.4f')\n",
        "        # hyper_params_results.to_excel(hyper_params_results_path, index=False)\n",
        "\n",
        "    def recommend_top_k(self):\n",
        "        test_users = list(self.data.test_user_list.keys())\n",
        "        if(self.candidate == False):\n",
        "            dump_dict = merge_user_list([self.data.train_user_list,self.data.valid_user_list])\n",
        "        recommended_top_k = {}\n",
        "        recommended_scores = {}\n",
        "        test_users = DataIterator(test_users, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
        "        for batch_id, batch_users in enumerate(test_users):\n",
        "            if self.data.test_neg_user_list is not None:\n",
        "                candidate_items = {u:list(self.data.test_user_list[u]) + self.data.test_neg_user_list[u] if u in self.data.test_neg_user_list.keys() else list(self.data.test_user_list[u]) for u in batch_users}\n",
        "\n",
        "                ranking_score = self.model.predict(batch_users, None)  # (B,N)\n",
        "                if not is_ndarray(ranking_score, float_type):\n",
        "                    ranking_score = np.array(ranking_score, dtype=float_type)\n",
        "\n",
        "                all_items = set(range(ranking_score.shape[1]))\n",
        "                for idx, user in enumerate(batch_users):\n",
        "                    # print(max(set(candidate_items[user])), )\n",
        "                    not_user_candidates = list(all_items - set(candidate_items[user]))\n",
        "                    ranking_score[idx,not_user_candidates] = -np.inf\n",
        "\n",
        "                    pos_items = self.data.valid_user_list[user]\n",
        "                    pos_items = [ x for x in pos_items if not x in self.data.test_user_list[user] ]\n",
        "                    ranking_score[idx][pos_items] = -np.inf\n",
        "\n",
        "                    recommended_top_k[user] = argmax_top_k(ranking_score[idx], self.Ks)\n",
        "                    # ground_truth = self.data.test_user_list[user]\n",
        "                    # hits = [1 if item in ground_truth else 0 for item in recommended_top_k[user]]\n",
        "                    # print(sum(hits)/self.Ks)\n",
        "                    recommended_scores[user] = ranking_score[idx][recommended_top_k[user]]\n",
        "                    # print('finish one user')\n",
        "            else:\n",
        "                ranking_score = self.model.predict(batch_users, None)  # (B,N)\n",
        "                if not is_ndarray(ranking_score, float_type):\n",
        "                    ranking_score = np.array(ranking_score, dtype=float_type)\n",
        "                # set the ranking scores of training items to -inf,\n",
        "                # then the training items will be sorted at the end of the ranking list.\n",
        "\n",
        "                for idx, user in enumerate(batch_users):\n",
        "                    dump_items = dump_dict[user]\n",
        "                    dump_items = [ x for x in dump_items if not x in self.data.test_user_list[user] ]\n",
        "                    ranking_score[idx][dump_items] = -np.inf\n",
        "\n",
        "                    recommended_top_k[user] = argmax_top_k(ranking_score[idx], self.Ks)\n",
        "                    # recommended_scores[user] = ranking_score[idx][recommended_top_k[user]]\n",
        "                    recommended_scores[user] = ranking_score[idx]\n",
        "            print('finish recommend one batch', batch_id)\n",
        "\n",
        "        recommended_top_k = dict(sorted(recommended_top_k.items(), key=lambda x: x[0]))\n",
        "        # with open(self.base_path + '/recommend_top_k.txt', 'w') as f:\n",
        "        #     for u, v in recommended_top_k.items():\n",
        "        #         f.write(str(int(u)))\n",
        "        #         for i in range(self.Ks):\n",
        "        #             f.write(' ' + str(int(v[i])) + '+' + str(round(recommended_scores[u][i], 4)))\n",
        "        #         f.write('\\n')\n",
        "        with open(self.base_path + '/recommend_top_k.txt', 'w') as f:\n",
        "            for u, v in recommended_top_k.items():\n",
        "                f.write(str(int(u)))\n",
        "                for i in range(self.Ks):\n",
        "                    f.write(' ' + str(int(v[i])))\n",
        "                f.write('\\n')\n",
        "        print('finish recommend top k')\n",
        "\n",
        "\n",
        "\n",
        "    # define the evaluation process\n",
        "    def eval_and_check_early_stop(self, epoch):\n",
        "        self.model.eval()\n",
        "\n",
        "        for i,evaluator in enumerate(self.evaluators):\n",
        "            is_best, temp_flag, n_ret = evaluation(self.args, self.data, self.model, epoch, self.base_path, evaluator, self.eval_names[i])\n",
        "            if(not self.args.no_wandb):\n",
        "                wandb.log(\n",
        "                    data = {f\"Recall@{self.Ks}\": n_ret['recall'],\n",
        "                            f\"Hit Ratio@{self.Ks}\": n_ret['recall'],\n",
        "                            f\"Precision@{self.Ks}\": n_ret['precision'],\n",
        "                            f\"NDCG@{self.Ks}\": n_ret['ndcg']},\n",
        "                    step = epoch\n",
        "                )\n",
        "            if is_best:\n",
        "                checkpoint_buffer=save_checkpoint(self.model, epoch, self.base_path, self.checkpoint_buffer, self.args.max2keep)\n",
        "\n",
        "            # early stop?\n",
        "            if temp_flag:\n",
        "                self.flag = True\n",
        "        # checkpoint_buffer=save_checkpoint(self.model, epoch, self.base_path, self.checkpoint_buffer, self.args.max2keep)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "    # load the checkpoint\n",
        "    def restore_checkpoint(self, model, checkpoint_dir, device, force=False, pretrain=False):\n",
        "        \"\"\"\n",
        "        If a checkpoint exists, restores the PyTorch model from the checkpoint.\n",
        "        Returns the model and the current epoch.\n",
        "        \"\"\"\n",
        "        cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                    if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "\n",
        "        if not cp_files:\n",
        "            print('No saved model parameters found')\n",
        "            if force:\n",
        "                raise Exception(\"Checkpoint not found\")\n",
        "            else:\n",
        "                return model, 0,\n",
        "\n",
        "        epoch_list = []\n",
        "\n",
        "        regex = re.compile(r'\\d+')\n",
        "\n",
        "        for cp in cp_files:\n",
        "            epoch_list.append([int(x) for x in regex.findall(cp)][0])\n",
        "\n",
        "        epoch = max(epoch_list)\n",
        "\n",
        "\n",
        "        if not force:\n",
        "            print(\"Which epoch to load from? Choose in range [0, {}).\"\n",
        "                .format(epoch), \"Enter 0 to train from scratch.\")\n",
        "            print(\">> \", end = '')\n",
        "            # inp_epoch = int(input())\n",
        "\n",
        "            if self.args.clear_checkpoints:\n",
        "                print(\"Clear checkpoint\")\n",
        "                clear_checkpoint(checkpoint_dir)\n",
        "                return model, 0,\n",
        "\n",
        "            inp_epoch = epoch\n",
        "            if inp_epoch not in range(epoch + 1):\n",
        "                raise Exception(\"Invalid epoch number\")\n",
        "            if inp_epoch == 0:\n",
        "                print(\"Checkpoint not loaded\")\n",
        "                clear_checkpoint(checkpoint_dir)\n",
        "                return model, 0,\n",
        "        else:\n",
        "            print(\"Which epoch to load from? Choose in range [0, {}).\".format(epoch))\n",
        "            inp_epoch = int(input())\n",
        "            if inp_epoch not in range(0, epoch):\n",
        "                raise Exception(\"Invalid epoch number\")\n",
        "\n",
        "        filename = os.path.join(checkpoint_dir,\n",
        "                                'epoch={}.checkpoint.pth.tar'.format(inp_epoch))\n",
        "\n",
        "        print(\"Loading from checkpoint {}?\".format(filename))\n",
        "\n",
        "        # checkpoint = torch.load(filename, map_location = str(device))\n",
        "        checkpoint = torch.load(filename, map_location=torch.device('cpu'))\n",
        "        # print(\"finish load\")\n",
        "\n",
        "        try:\n",
        "            if pretrain:\n",
        "                model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> Successfully restored checkpoint (trained for {} epochs)\"\n",
        "                .format(checkpoint['epoch']))\n",
        "        except:\n",
        "            print(\"=> Checkpoint not successfully restored\")\n",
        "            raise\n",
        "\n",
        "        return model, inp_epoch\n",
        "\n",
        "    def restore_best_checkpoint(self, epoch, model, checkpoint_dir, device):\n",
        "        \"\"\"\n",
        "        Restore the best performance checkpoint\n",
        "        \"\"\"\n",
        "        cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                    if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "\n",
        "        filename = os.path.join(checkpoint_dir,\n",
        "                                'epoch={}.checkpoint.pth.tar'.format(epoch))\n",
        "\n",
        "        print(\"Loading from checkpoint {}?\".format(filename))\n",
        "\n",
        "        # checkpoint = torch.load(filename, map_location = str(device))\n",
        "        checkpoint = torch.load(filename, map_location=torch.device('cpu'))\n",
        "\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        print(\"=> Successfully restored checkpoint (trained for {} epochs)\"\n",
        "            .format(checkpoint['epoch']))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_evaluators(self, data, pop_mask=None):\n",
        "        #if not self.args.pop_test:\n",
        "        K_value = self.args.Ks\n",
        "        if self.args.nodrop: # whether using the enhanced dataset\n",
        "            eval_train_user_list = data.train_nodrop_user_list\n",
        "        else:\n",
        "            eval_train_user_list = data.train_user_list\n",
        "\n",
        "        # if self.args.candidate:\n",
        "        #     eval_valid = ProxyEvaluator(data,data.train_user_list,data.valid_user_list,top_k=[K_value],dump_dict=merge_user_list([data.train_user_list, data.test_user_list]))\n",
        "        #     eval_test = ProxyEvaluator(data,data.train_user_list,data.test_user_list,top_k=[K_value],dump_dict=merge_user_list([data.train_user_list, data.valid_user_list]), user_neg_test = data.test_neg_user_list)\n",
        "\n",
        "        # else:\n",
        "        #     eval_valid = ProxyEvaluator(data,data.train_user_list,data.valid_user_list,top_k=[K_value],dump_dict=merge_user_list([data.train_user_list, data.test_user_list]))\n",
        "        #     eval_test = ProxyEvaluator(data,data.train_user_list,data.test_user_list,top_k=[K_value],dump_dict=merge_user_list([data.train_user_list, data.valid_user_list]))\n",
        "\n",
        "\n",
        "        if self.args.candidate:\n",
        "            eval_valid = ProxyEvaluator(data,eval_train_user_list,data.valid_user_list,top_k=[K_value],dump_dict=merge_user_list([eval_train_user_list, data.test_user_list]))\n",
        "            eval_test = ProxyEvaluator(data,eval_train_user_list,data.test_user_list,top_k=[K_value],dump_dict=merge_user_list([eval_train_user_list, data.valid_user_list]), user_neg_test = data.test_neg_user_list)\n",
        "\n",
        "        else:\n",
        "            eval_valid = ProxyEvaluator(data,eval_train_user_list,data.valid_user_list,top_k=[K_value],dump_dict=merge_user_list([eval_train_user_list, data.test_user_list]))\n",
        "            eval_test = ProxyEvaluator(data,eval_train_user_list,data.test_user_list,top_k=[K_value],dump_dict=merge_user_list([eval_train_user_list, data.valid_user_list]))\n",
        "\n",
        "        evaluators=[eval_valid, eval_test]\n",
        "        eval_names=[\"valid\", \"test\"]\n",
        "\n",
        "        return evaluators, eval_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23iUN47D0zpD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class MF_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "\n",
        "        # Assuming `self.model` is defined and initialized in `AbstractRS`\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, running_mf_loss, running_reg_loss, num_batches = 0, 0, 0, 0\n",
        "\n",
        "        pbar = tqdm(enumerate(self.data.train_loader), mininterval=2, total = len(self.data.train_loader))\n",
        "        for batch_i, batch in pbar:\n",
        "\n",
        "            # batch = [x.cuda(self.device) for x in batch]\n",
        "            users, pos_items, users_pop, pos_items_pop, pos_weights  = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
        "\n",
        "            if self.args.infonce == 0 or self.args.neg_sample != -1:\n",
        "                neg_items = batch[5]\n",
        "                neg_items_pop = batch[6]\n",
        "\n",
        "            self.model.train()\n",
        "            mf_loss, reg_loss = self.model(users, pos_items, neg_items)\n",
        "            loss = mf_loss + reg_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            running_reg_loss += reg_loss.detach().item()\n",
        "            running_mf_loss += mf_loss.detach().item()\n",
        "            num_batches += 1\n",
        "        return [running_loss/num_batches, running_mf_loss/num_batches, running_reg_loss/num_batches]\n",
        "\n",
        "\n",
        "class MF(AbstractModel):\n",
        "    def __init__(self, args, data):\n",
        "        super().__init__(args, data)\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items):\n",
        "        all_users, all_items = self.embed_user.weight, self.embed_item.weight\n",
        "\n",
        "        users_emb = all_users[users]\n",
        "        pos_emb = all_items[pos_items]\n",
        "        neg_emb = all_items[neg_items]\n",
        "\n",
        "        userEmb0 = self.embed_user(users)\n",
        "        posEmb0 = self.embed_item(pos_items)\n",
        "        negEmb0 = self.embed_item(neg_items)\n",
        "\n",
        "\n",
        "        pos_scores = torch.sum(torch.mul(users_emb, pos_emb), dim=1)  # users, pos_items, neg_items have the same shape\n",
        "        neg_scores = torch.sum(torch.mul(users_emb, neg_emb), dim=1)\n",
        "\n",
        "        regularizer = 0.5 * torch.norm(userEmb0) ** 2 + 0.5 * torch.norm(posEmb0) ** 2 + 0.5 * torch.norm(negEmb0) ** 2\n",
        "        regularizer = regularizer / self.batch_size\n",
        "\n",
        "        maxi = torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10)\n",
        "        mf_loss = torch.negative(torch.mean(maxi))\n",
        "        reg_loss = self.decay * regularizer\n",
        "\n",
        "        return mf_loss, reg_loss\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        if items is None:\n",
        "            items = list(range(self.data.n_items))\n",
        "\n",
        "        all_users, all_items = self.embed_user.weight, self.embed_item.weight\n",
        "\n",
        "        users = all_users[torch.tensor(users)]\n",
        "        items = all_items[torch.tensor(items)]\n",
        "\n",
        "        items = torch.transpose(items, 0, 1)\n",
        "        rate_batch = torch.matmul(users, items) # user * item\n",
        "\n",
        "        return rate_batch.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkxMdi150zpc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class InfoNCE_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "        self.neg_sample =  args.neg_sample if args.neg_sample!=-1 else self.batch_size-1\n",
        "\n",
        "        # Initialize optimizer (example with Adam optimizer)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, running_mf_loss, running_reg_loss, num_batches = 0, 0, 0, 0\n",
        "\n",
        "        pbar = tqdm(enumerate(self.data.train_loader), mininterval=2, total = len(self.data.train_loader))\n",
        "        for batch_i, batch in pbar:\n",
        "\n",
        "            # batch = [x.cuda(self.device) for x in batch]\n",
        "            users, pos_items, users_pop, pos_items_pop, pos_weights  = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
        "\n",
        "            self.model.train()\n",
        "            if(self.inbatch):\n",
        "                mf_loss, reg_loss = self.model(users, pos_items)\n",
        "            else:\n",
        "                neg_items = batch[5]\n",
        "                neg_items_pop = batch[6]\n",
        "                mf_loss, reg_loss = self.model(users, pos_items, neg_items)\n",
        "\n",
        "            loss = mf_loss + reg_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            running_reg_loss += reg_loss.detach().item()\n",
        "            running_mf_loss += mf_loss.detach().item()\n",
        "            num_batches += 1\n",
        "        return [running_loss/num_batches, running_mf_loss/num_batches, running_reg_loss/num_batches]\n",
        "\n",
        "class InfoNCE(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "        self.tau = args.tau\n",
        "        self.decay = args.decay\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items=None):\n",
        "        users = users if isinstance(users, torch.Tensor) else torch.tensor(users)\n",
        "        pos_items = pos_items if isinstance(pos_items, torch.Tensor) else torch.tensor(pos_items)\n",
        "        if neg_items is not None:\n",
        "            neg_items = neg_items if isinstance(neg_items, torch.Tensor) else torch.tensor(neg_items)\n",
        "\n",
        "\n",
        "        all_users, all_items = self.compute()\n",
        "\n",
        "        userEmb0 = self.embed_user(users)\n",
        "        posEmb0 = self.embed_item(pos_items)\n",
        "        # negEmb0 = self.embed_item(neg_items)\n",
        "\n",
        "        users_emb = all_users[users]\n",
        "        pos_emb = all_items[pos_items]\n",
        "        # neg_emb = all_items[neg_items]\n",
        "\n",
        "        if neg_items is not None:\n",
        "            negEmb0 = self.embed_item(neg_items)\n",
        "            neg_emb = all_items[neg_items]\n",
        "\n",
        "            if(self.train_norm):\n",
        "                users_emb = F.normalize(users_emb, dim = -1)\n",
        "                pos_emb = F.normalize(pos_emb, dim = -1)\n",
        "                neg_emb = F.normalize(neg_emb, dim = -1)\n",
        "\n",
        "            pos_ratings = torch.sum(users_emb*pos_emb, dim = -1)\n",
        "            # neg_ratings = torch.matmul(torch.unsqueeze(users_emb, 1),\n",
        "            #                             neg_emb.permute(0, 2, 1)).squeeze(dim=1)\n",
        "            neg_ratings = torch.matmul(users_emb, neg_emb.transpose(0, 1))\n",
        "            numerator = torch.exp(pos_ratings / self.tau)\n",
        "            denominator = numerator + torch.sum(torch.exp(neg_ratings / self.tau), dim = 1)\n",
        "        else:\n",
        "            users_emb = F.normalize(users_emb, dim=1)\n",
        "            pos_emb = F.normalize(pos_emb, dim=1)\n",
        "            ratings = torch.matmul(users_emb, torch.transpose(pos_emb, 0, 1))\n",
        "            ratings_diag = torch.diag(ratings)\n",
        "            numerator = torch.exp(ratings_diag / self.tau)\n",
        "            denominator = torch.sum(torch.exp(ratings / self.tau), dim=1)\n",
        "\n",
        "        ssm_loss = torch.mean(torch.negative(torch.log(numerator / denominator)))\n",
        "\n",
        "        regularizer = 0.5 * torch.norm(userEmb0) ** 2 + 0.5 * torch.norm(posEmb0) ** 2\n",
        "        if neg_items is not None:\n",
        "            regularizer += 0.5 * torch.norm(negEmb0) ** 2\n",
        "        reg_loss = self.decay * regularizer / self.batch_size\n",
        "        ssm_loss = torch.mean(torch.negative(torch.log(numerator/denominator)))\n",
        "\n",
        "        return ssm_loss, reg_loss\n",
        "\n",
        "class InfoNCE_batch(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "        self.tau = args.tau\n",
        "        self.decay = args.decay\n",
        "\n",
        "    def forward(self, users, pos_items):\n",
        "        users = users if isinstance(users, torch.Tensor) else torch.tensor(users)\n",
        "        pos_items = pos_items if isinstance(pos_items, torch.Tensor) else torch.tensor(pos_items)\n",
        "\n",
        "        all_users, all_items = self.compute()\n",
        "\n",
        "        userEmb0 = self.embed_user(users)\n",
        "        posEmb0 = self.embed_item(pos_items)\n",
        "\n",
        "        users_emb = all_users[users]\n",
        "        pos_emb = all_items[pos_items]\n",
        "\n",
        "        users_emb = F.normalize(users_emb, dim=1)\n",
        "        pos_emb = F.normalize(pos_emb, dim=1)\n",
        "\n",
        "        ratings = torch.matmul(users_emb, torch.transpose(pos_emb, 0, 1))\n",
        "        ratings_diag = torch.diag(ratings)\n",
        "\n",
        "        numerator = torch.exp(ratings_diag / self.tau)\n",
        "        denominator = torch.sum(torch.exp(ratings / self.tau), dim=1)\n",
        "        ssm_loss = torch.mean(torch.negative(torch.log(numerator / denominator)))\n",
        "\n",
        "        regularizer = 0.5 * torch.norm(userEmb0) ** 2 + 0.5 * torch.norm(posEmb0) ** 2\n",
        "        reg_loss = self.decay * regularizer / self.batch_size\n",
        "\n",
        "        return ssm_loss, reg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwrB6_mV0zpf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class LightGCN_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, running_mf_loss, running_reg_loss, num_batches = 0, 0, 0, 0\n",
        "\n",
        "        pbar = tqdm(enumerate(self.data.train_loader), mininterval=2, total = len(self.data.train_loader))\n",
        "        for batch_i, batch in pbar:\n",
        "\n",
        "            # batch = [x.cuda(self.device) for x in batch]\n",
        "            users, pos_items, users_pop, pos_items_pop, pos_weights  = batch[0], batch[1], batch[2], batch[3], batch[4]\n",
        "\n",
        "            if self.args.infonce == 0 or self.args.neg_sample != -1:\n",
        "                neg_items = batch[5]\n",
        "                neg_items_pop = batch[6]\n",
        "\n",
        "            self.model.train()\n",
        "            mf_loss, reg_loss = self.model(users, pos_items, neg_items)\n",
        "            loss = mf_loss + reg_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            # print(self.model.embed_user.weight)\n",
        "            # print(\"?\")\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            running_reg_loss += reg_loss.detach().item()\n",
        "            running_mf_loss += mf_loss.detach().item()\n",
        "            num_batches += 1\n",
        "        return [running_loss/num_batches, running_mf_loss/num_batches, running_reg_loss/num_batches]\n",
        "\n",
        "\n",
        "class LightGCN(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items):\n",
        "        all_users, all_items = self.compute()\n",
        "\n",
        "        users_emb = all_users[users]\n",
        "        pos_emb = all_items[pos_items]\n",
        "        neg_emb = all_items[neg_items]\n",
        "        userEmb0 = self.embed_user(users)\n",
        "        posEmb0 = self.embed_item(pos_items)\n",
        "        negEmb0 = self.embed_item(neg_items)\n",
        "\n",
        "        if(self.train_norm == True):\n",
        "            users_emb = F.normalize(users_emb, dim = -1)\n",
        "            pos_emb = F.normalize(pos_emb, dim = -1)\n",
        "            neg_emb = F.normalize(neg_emb, dim = -1)\n",
        "\n",
        "        pos_scores = torch.sum(torch.mul(users_emb, pos_emb), dim=1)  # users, pos_items, neg_items have the same shape\n",
        "        neg_scores = torch.sum(torch.mul(users_emb, neg_emb), dim=1)\n",
        "\n",
        "        regularizer = 0.5 * torch.norm(userEmb0) ** 2 + 0.5 * torch.norm(posEmb0) ** 2 + 0.5 * torch.norm(negEmb0) ** 2\n",
        "        regularizer = regularizer / self.batch_size\n",
        "\n",
        "        maxi = torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10)\n",
        "        mf_loss = torch.negative(torch.mean(maxi))\n",
        "        reg_loss = self.decay * regularizer\n",
        "\n",
        "        return mf_loss, reg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lYT4Lbx0zph"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# import random\n",
        "import random as rd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def naive_sparse2tensor(data):\n",
        "    return torch.FloatTensor(data.toarray())\n",
        "\n",
        "class MultVAE_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "        self.data = MultVAE_Data(args)\n",
        "        self.total_anneal_steps = args.total_anneal_steps\n",
        "        self.anneal_cap = args.anneal_cap\n",
        "        self.update_count = 0\n",
        "        self.set_optimizer()\n",
        "\n",
        "    def set_optimizer(self):\n",
        "        self.optimizer = torch.optim.Adam([param for param in self.model.parameters() if param.requires_grad == True], lr=self.lr)\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar, anneal=1.0):\n",
        "        # BCE = F.binary_cross_entropy(recon_x, x)\n",
        "        BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
        "        KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
        "\n",
        "        return BCE + anneal * KLD\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, num_batches = 0, 0\n",
        "\n",
        "        n_users = self.data.n_users\n",
        "        idxlist = np.arange(n_users)\n",
        "        np.random.shuffle(idxlist)\n",
        "        pbar = tqdm(enumerate(range(0, n_users, self.batch_size)))\n",
        "        for batch_i, start_idx in pbar:\n",
        "            end_idx = min(start_idx + self.batch_size, n_users)\n",
        "            batch = self.data.ui_mat[idxlist[start_idx:end_idx]]\n",
        "            batch = naive_sparse2tensor(batch)\n",
        "\n",
        "            if self.total_anneal_steps > 0:\n",
        "                anneal = min(self.anneal_cap,\n",
        "                                1. * self.update_count / self.total_anneal_steps)\n",
        "            else:\n",
        "                anneal = self.anneal_cap\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = self.model(batch)\n",
        "\n",
        "            loss = self.loss_function(recon_batch, batch, mu, logvar, anneal)\n",
        "            loss.backward()\n",
        "            running_loss += loss.detach().item()\n",
        "            num_batches += 1\n",
        "            self.optimizer.step()\n",
        "\n",
        "            self.update_count += 1\n",
        "        return [running_loss/num_batches]\n",
        "\n",
        "\n",
        "class MultVAE_Data(Data):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "    def add_special_model_attr(self, args):\n",
        "        try:\n",
        "            self.ui_mat = sp.load_npz(self.path + '/ui_mat.npz')\n",
        "            print(\"successfully loaded ui_mat...\")\n",
        "        except FileNotFoundError:\n",
        "            self.trainItem = np.array(self.trainItem)\n",
        "            self.trainUser = np.array(self.trainUser)\n",
        "            self.ui_mat = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem)),\n",
        "                                    shape=(self.n_users, self.n_items))\n",
        "            sp.save_npz(self.path + '/ui_mat.npz', self.ui_mat)\n",
        "            print(\"successfully saved ui_mat...\")\n",
        "\n",
        "\n",
        "class MultVAE(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "        self.data = MultVAE_Data(args)\n",
        "        self.p_dims = [args.p_dim0, args.p_dim1, data.n_items]\n",
        "        self.q_dims = self.p_dims[::-1]\n",
        "\n",
        "        # Last dimension of q- network is for mean and variance\n",
        "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
        "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
        "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
        "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
        "\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input):\n",
        "        mu, logvar = self.encode(input)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def encode(self, input):\n",
        "        h = F.normalize(input)\n",
        "        h = self.drop(h)\n",
        "\n",
        "        for i, layer in enumerate(self.q_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.q_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "            else:\n",
        "                mu = h[:, :self.q_dims[-1]]\n",
        "                logvar = h[:, self.q_dims[-1]:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(0.5 * logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = z\n",
        "        for i, layer in enumerate(self.p_layers):\n",
        "            h = layer(h)\n",
        "            if i != len(self.p_layers) - 1:\n",
        "                h = F.tanh(h)\n",
        "        return h\n",
        "\n",
        "    def init_weights(self):\n",
        "        for layer in self.q_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "        for layer in self.p_layers:\n",
        "            # Xavier Initialization for weights\n",
        "            size = layer.weight.size()\n",
        "            fan_out = size[0]\n",
        "            fan_in = size[1]\n",
        "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
        "            layer.weight.data.normal_(0.0, std)\n",
        "\n",
        "            # Normal Initialization for Biases\n",
        "            layer.bias.data.normal_(0.0, 0.001)\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        if items is None:\n",
        "            items = list(range(self.data.n_items))\n",
        "\n",
        "        batch = naive_sparse2tensor(self.data.ui_mat[users])\n",
        "        rate_batch, _, _ = self.forward(batch)\n",
        "\n",
        "        return rate_batch.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYmqDcSc0zpi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class Pop_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        return None\n",
        "\n",
        "class Pop(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "\n",
        "    def forward(self):\n",
        "        return None\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        if items is None:\n",
        "            items = list(range(self.data.n_items))\n",
        "\n",
        "        rating_matrix = np.zeros((len(users), len(items)))\n",
        "        for i, user in enumerate(users):\n",
        "            random_idx = np.random.choice(self.data.pop_candidates, 2*self.args.Ks, replace=False) # Select 20 items from pop_candidates each time.\n",
        "            # print(sorted(random_idx))\n",
        "            rating_matrix[i, random_idx] = 1\n",
        "        # print(rating_matrix.sum())\n",
        "\n",
        "\n",
        "        return rating_matrix\n",
        "\n",
        "class Pop_Data(Data):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "    def add_special_model_attr(self, args):\n",
        "        sorted_items = sorted(self.pop_item.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.pop_candidates = [x[0] for x in sorted_items[:30*args.Ks]]\n",
        "        print(\"pop_candidates: \", sorted(self.pop_candidates))\n",
        "        # pop_matrix = np.zeros((1, self.n_items))\n",
        "        # Randomly select 20 items from pop_candidates.\n",
        "        # rating_matrix = np.zeros((self.n_users, self.n_items))\n",
        "        # for i, user in enumerate(range(self.n_users)):\n",
        "        #     print(i, user)\n",
        "        #     random_idx = np.random.choice(self.pop_candidates, 20, replace=False)\n",
        "        #     rating_matrix[i, random_idx] = 1\n",
        "\n",
        "        # Take the indices of the top 20 items in the rating_matrix.\n",
        "        # np.argsort(-rating_matrix, axis=1)\n",
        "        # print(\"??\")\n",
        "        # print(pop_matrix)\n",
        "        # print(self.pop_candidates)\n",
        "        # # return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOs2cC5b0zpl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Random_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        return None\n",
        "\n",
        "class Random(AbstractModel):\n",
        "    def __init__(self, args, data) -> None:\n",
        "        super().__init__(args, data)\n",
        "\n",
        "    def forward(self):\n",
        "        return None\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        if items is None:\n",
        "            items = list(range(self.data.n_items))\n",
        "\n",
        "        return np.random.rand(len(users), len(items))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BghBbd-ILwvD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class FM_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, running_fm_loss, running_reg_loss, num_batches = 0, 0, 0, 0\n",
        "        pbar = tqdm(enumerate(self.data.train_loader), mininterval=2, total=len(self.data.train_loader))\n",
        "\n",
        "        for batch_i, batch in pbar:\n",
        "            # batch = users, pos_items, neg_items, ...\n",
        "            users, pos_items, _, _, _, neg_items, _ = batch  # adjust depending on dataset output\n",
        "\n",
        "            self.model.train()\n",
        "            fm_loss, reg_loss = self.model(users, pos_items, neg_items)  # pass all 3\n",
        "            loss = fm_loss + reg_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            running_fm_loss += fm_loss.detach().item()\n",
        "            running_reg_loss += reg_loss.detach().item()\n",
        "            num_batches += 1\n",
        "\n",
        "        return [\n",
        "            running_loss / num_batches,\n",
        "            running_fm_loss / num_batches,\n",
        "            running_reg_loss / num_batches,\n",
        "            ]\n",
        "\n",
        "\n",
        "class FM(AbstractModel):\n",
        "    def __init__(self, args, data):\n",
        "        super().__init__(args, data)\n",
        "        self.n_features = data.n_users + data.n_items\n",
        "        self.k = args.embed_size\n",
        "\n",
        "        # FM parameters\n",
        "        self.w0 = nn.Parameter(torch.zeros(1))\n",
        "        self.w = nn.Parameter(torch.zeros(self.n_features))\n",
        "        self.V = nn.Parameter(torch.randn(self.n_features, self.k) * 0.01)\n",
        "\n",
        "    def _build_x(self, user, item):\n",
        "        \"\"\"Create one-hot features for a batch of (user, item) pairs\"\"\"\n",
        "        batch_size = user.size(0)\n",
        "        x = torch.zeros(batch_size, self.n_features, device=user.device)\n",
        "        x[torch.arange(batch_size), user] = 1.0\n",
        "        x[torch.arange(batch_size), self.data.n_users + item] = 1.0\n",
        "        return x\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items):\n",
        "        # Build one-hot vectors\n",
        "        x_pos = self._build_x(users, pos_items)\n",
        "        x_neg = self._build_x(users, neg_items)\n",
        "\n",
        "        # Linear term\n",
        "        linear_pos = self.w0 + torch.matmul(x_pos, self.w)\n",
        "        linear_neg = self.w0 + torch.matmul(x_neg, self.w)\n",
        "\n",
        "        # Pairwise interactions\n",
        "        inter_pos = 0.5 * torch.sum(\n",
        "            torch.pow(torch.matmul(x_pos, self.V), 2) -\n",
        "            torch.matmul(torch.pow(x_pos, 2), torch.pow(self.V, 2)), dim=1\n",
        "        )\n",
        "        inter_neg = 0.5 * torch.sum(\n",
        "            torch.pow(torch.matmul(x_neg, self.V), 2) -\n",
        "            torch.matmul(torch.pow(x_neg, 2), torch.pow(self.V, 2)), dim=1\n",
        "        )\n",
        "\n",
        "        # Scores\n",
        "        pos_scores = linear_pos + inter_pos\n",
        "        neg_scores = linear_neg + inter_neg\n",
        "\n",
        "        # BPR loss\n",
        "        maxi = torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10)\n",
        "        fm_loss = -torch.mean(maxi)\n",
        "\n",
        "        # Regularization\n",
        "        reg_loss = self.decay * (\n",
        "            0.5 * torch.norm(self.w) ** 2 + 0.5 * torch.norm(self.V) ** 2\n",
        "        ) / self.batch_size\n",
        "\n",
        "        return fm_loss, reg_loss\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        if not torch.is_tensor(users):\n",
        "           users = torch.tensor(users, device=self.w.device)\n",
        "\n",
        "        if items is None:\n",
        "           items = torch.arange(self.data.n_items, device=users.device)\n",
        "\n",
        "        batch_size = users.shape[0]\n",
        "        n_items = items.shape[0]\n",
        "\n",
        "        # Repeat users for all items\n",
        "        user_expand = users.unsqueeze(1).repeat(1, n_items).flatten()\n",
        "        item_expand = items.unsqueeze(0).repeat(batch_size, 1).flatten()\n",
        "\n",
        "        # Linear terms\n",
        "        linear_u = self.w[user_expand]\n",
        "        linear_i = self.w[self.data.n_users + item_expand]\n",
        "        linear = self.w0 + linear_u + linear_i\n",
        "\n",
        "        # Interaction terms (only between user and item embeddings)\n",
        "        vu = self.V[user_expand]                # [batch_size * n_items, k]\n",
        "        vi = self.V[self.data.n_users + item_expand]  # [batch_size * n_items, k]\n",
        "        inter = torch.sum(vu * vi, dim=1)\n",
        "\n",
        "        scores = (linear + inter).view(batch_size, n_items)\n",
        "\n",
        "        return scores.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fNVfstedV9r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class SASRec_RS(AbstractRS):\n",
        "    def __init__(self, args, special_args) -> None:\n",
        "        super().__init__(args, special_args)\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=args.lr)\n",
        "\n",
        "    def train_one_epoch(self, epoch):\n",
        "        running_loss, running_rec_loss, running_reg_loss, num_batches = 0, 0, 0, 0\n",
        "        pbar = tqdm(enumerate(self.data.train_loader), mininterval=2, total=len(self.data.train_loader))\n",
        "\n",
        "        for batch_i, batch in pbar:\n",
        "            # Expecting TrainDataset to yield (user, pos_item, user_pop, pos_item_pop, pos_weight, neg_item, neg_item_pop)\n",
        "            # We'll extract user, pos_items, neg_items to feed SASRec\n",
        "            users = torch.tensor(batch[0], dtype=torch.long, device=self.model.device)\n",
        "            pos_items = torch.tensor(batch[1], dtype=torch.long, device=self.model.device)\n",
        "            # some datasets return neg as python int, ensure tensor\n",
        "            if len(batch) > 5:\n",
        "                neg_items = torch.tensor(batch[5], dtype=torch.long, device=self.model.device)\n",
        "            else:\n",
        "                # fallback: sample negatives on the fly\n",
        "                neg_items = torch.randint(0, self.data.n_items, (len(users),), device=self.model.device).long()\n",
        "\n",
        "            self.model.train()\n",
        "            rec_loss, reg_loss = self.model(users, pos_items, neg_items)\n",
        "            loss = rec_loss + reg_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_rec_loss += rec_loss.item()\n",
        "            running_reg_loss += reg_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        return [running_loss / num_batches, running_rec_loss / num_batches, running_reg_loss / num_batches]\n",
        "\n",
        "\n",
        "class SASRec(AbstractModel):\n",
        "    \"\"\"A lightweight SASRec-like sequential recommender.\n",
        "\n",
        "    Behavior:\n",
        "      - It uses each user's last `max_seq_len` interactions from self.data.train_user_list\n",
        "      - For each batch of users it constructs padded sequences and attention masks\n",
        "      - The model encodes the sequence with TransformerEncoder layers and uses the\n",
        "        representation of the last non-pad position as the user sequential state\n",
        "      - Final score = dot(seq_repr, item_embedding)\n",
        "\n",
        "    Forward signature mirrors MF/FM: forward(users, pos_items, neg_items)\n",
        "    Returns: (bpr_loss, reg_loss)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, args, data):\n",
        "        super().__init__(args, data)\n",
        "        # hyperparams (falls back to reasonable defaults)\n",
        "        self.hidden_dim = args.embed_size\n",
        "        self.num_blocks = args.num_blocks\n",
        "        self.num_heads = args.num_heads\n",
        "        self.max_seq_len = args.max_seq_len\n",
        "        self.dropout = args.dropout\n",
        "\n",
        "        # item embeddings (learnable)\n",
        "        self.item_embedding = nn.Embedding(self.data.n_items, self.hidden_dim, padding_idx=None)\n",
        "        # positional embeddings\n",
        "        self.pos_embedding = nn.Embedding(self.max_seq_len, self.hidden_dim)\n",
        "\n",
        "        # transformer encoder blocks\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.hidden_dim, nhead=self.num_heads,\n",
        "                                                   dim_feedforward=4 * self.hidden_dim,\n",
        "                                                   dropout=self.dropout, activation='gelu', batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.num_blocks)\n",
        "\n",
        "        # layernorm and dropout\n",
        "        self.layer_norm = nn.LayerNorm(self.hidden_dim)\n",
        "        self.dropout_layer = nn.Dropout(self.dropout)\n",
        "\n",
        "        # init\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.pos_embedding.weight)\n",
        "\n",
        "    def _build_user_seq(self, users):\n",
        "        \"\"\"Return (seq_tensor, seq_mask, seq_lengths)\n",
        "        seq_tensor: [B, L] long tensor of item indices (padded with 0)\n",
        "        seq_mask: [B, L] bool tensor (True where padded)\n",
        "        seq_lengths: [B] actual lengths\n",
        "\n",
        "        We use item index 0 as pad only if 0 exists; to avoid collision we will create mask using -1\n",
        "        \"\"\"\n",
        "        B = len(users)\n",
        "        L = self.max_seq_len\n",
        "        seqs = torch.zeros((B, L), dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "        mask = torch.zeros((B, L), dtype=torch.bool, device=self.item_embedding.weight.device)\n",
        "        lengths = torch.zeros(B, dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "\n",
        "        for i, u in enumerate(users.tolist() if isinstance(users, torch.Tensor) else users):\n",
        "            hist = self.data.train_user_list.get(int(u), [])\n",
        "            if len(hist) == 0:\n",
        "                # leave zeros (item id 0) and mark mask all True\n",
        "                lengths[i] = 0\n",
        "                mask[i, :] = True\n",
        "            else:\n",
        "                seq = hist[-L:]\n",
        "                seq_len = len(seq)\n",
        "                lengths[i] = seq_len\n",
        "                # pad left: place seq at positions L - seq_len : L\n",
        "                start = L - seq_len\n",
        "                seqs[i, start:] = torch.tensor(seq, dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "                mask[i, :start] = True\n",
        "        return seqs, mask, lengths\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items):\n",
        "        \"\"\"Train step: builds sequences for users, encodes them, computes BPR loss.\n",
        "        users, pos_items, neg_items are 1D long tensors (or lists of ids)\n",
        "        \"\"\"\n",
        "        # ensure tensors\n",
        "        if not torch.is_tensor(users):\n",
        "            users = torch.tensor(users, dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "        if not torch.is_tensor(pos_items):\n",
        "            pos_items = torch.tensor(pos_items, dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "        if not torch.is_tensor(neg_items):\n",
        "            neg_items = torch.tensor(neg_items, dtype=torch.long, device=self.item_embedding.weight.device)\n",
        "\n",
        "        # Build sequence batch\n",
        "        seqs, pad_mask, lengths = self._build_user_seq(users)\n",
        "\n",
        "        # Embeddings\n",
        "        seq_emb = self.item_embedding(seqs)  # [B, L, d]\n",
        "        pos = torch.arange(self.max_seq_len, device=seqs.device).unsqueeze(0).expand(seqs.size(0), -1)\n",
        "        pos_emb = self.pos_embedding(pos)\n",
        "        seq_emb = seq_emb + pos_emb\n",
        "        seq_emb = self.dropout_layer(seq_emb)\n",
        "\n",
        "        # Create attention mask for transformer: True for positions to be masked -> use key_padding_mask\n",
        "        key_padding_mask = pad_mask\n",
        "\n",
        "        # Transformer encoding\n",
        "        # transformer expects (batch, seq, feat) when batch_first=True\n",
        "        encoded = self.transformer_encoder(seq_emb, src_key_padding_mask=key_padding_mask)\n",
        "        encoded = self.layer_norm(encoded)\n",
        "\n",
        "        # Get representation for each user: use representation of last non-pad position\n",
        "        B, L, D = encoded.size()\n",
        "        last_indices = (lengths - 1).clamp(min=0)  # if length 0 -> index 0 (will be pad)\n",
        "        # gather\n",
        "        seq_repr = encoded[torch.arange(B, device=encoded.device), last_indices]  # [B, D]\n",
        "\n",
        "        # item embeddings for pos and neg\n",
        "        pos_embs = self.item_embedding(pos_items)\n",
        "        neg_embs = self.item_embedding(neg_items)\n",
        "\n",
        "        # Scores via dot product\n",
        "        pos_scores = torch.sum(seq_repr * pos_embs, dim=1)\n",
        "        neg_scores = torch.sum(seq_repr * neg_embs, dim=1)\n",
        "\n",
        "        # BPR-like loss\n",
        "        loss_term = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10))\n",
        "\n",
        "        # Regularization on embeddings and transformer weights (a light version)\n",
        "        reg = 0.0\n",
        "        reg += 0.5 * torch.norm(self.item_embedding.weight) ** 2\n",
        "        reg += 0.5 * torch.norm(self.pos_embedding.weight) ** 2\n",
        "        reg = reg * (self.decay / max(1, users.size(0)))\n",
        "\n",
        "        return loss_term, reg\n",
        "\n",
        "    def predict(self, users, items=None):\n",
        "        \"\"\"Return scores shaped [len(users), len(items)] similar to MF.predict\n",
        "        users can be list or tensor\n",
        "        items default all items\n",
        "        \"\"\"\n",
        "        device = self.item_embedding.weight.device\n",
        "        if items is None:\n",
        "            items = torch.arange(self.data.n_items, device=device)\n",
        "        else:\n",
        "            items = torch.tensor(items, device=device)\n",
        "\n",
        "        if not torch.is_tensor(users):\n",
        "            users = torch.tensor(users, device=device)\n",
        "\n",
        "        # build sequences for batch users\n",
        "        seqs, pad_mask, lengths = self._build_user_seq(users)\n",
        "        seq_emb = self.item_embedding(seqs) + self.pos_embedding(torch.arange(self.max_seq_len, device=device).unsqueeze(0))\n",
        "        encoded = self.transformer_encoder(seq_emb, src_key_padding_mask=pad_mask)\n",
        "        encoded = self.layer_norm(encoded)\n",
        "        last_indices = (lengths - 1).clamp(min=0)\n",
        "        seq_repr = encoded[torch.arange(len(users), device=device), last_indices]  # [B, D]\n",
        "\n",
        "        # compute item embeddings\n",
        "        item_embs = self.item_embedding(items)  # [n_items, D]\n",
        "\n",
        "        # score matrix = seq_repr @ item_embs.T\n",
        "        scores = torch.matmul(seq_repr, item_embs.transpose(0, 1))\n",
        "        return scores.detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu33nKDl0zpn"
      },
      "outputs": [],
      "source": [
        "class abstract_avatar:\n",
        "    def __init__(self, args, avatar_id):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.avatar_id = avatar_id\n",
        "        self.use_wandb = args.use_wandb\n",
        "        self.memory = None\n",
        "\n",
        "    def _reaction(self):\n",
        "        \"\"\"\n",
        "        Summarize the feelings of the avatar for recommended item list.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reflection(self):\n",
        "        \"\"\"\n",
        "        Reflect on the observation bank\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def up_date_taste(self):\n",
        "        \"\"\"\n",
        "        Update the taste of the avatar\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frG3XTss0zpo"
      },
      "outputs": [],
      "source": [
        "class abstract_memory:\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.memory_size = 0\n",
        "\n",
        "    def add_memory(self):\n",
        "        \"\"\"\n",
        "        Add one new memory to the memory bank\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def time_weighting(self):\n",
        "        \"\"\"\n",
        "        Weighting the memory according to the time\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def importance_weighting(self):\n",
        "        \"\"\"\n",
        "        Weighting the importance of memory according to\n",
        "        the results of recommendation and the personal taste\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reflect(self):\n",
        "        \"\"\"\n",
        "        Generate a high level understanding of previous memories\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzTLcnPu0zpp"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from copy import deepcopy\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain.schema import BaseRetriever, Document\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _get_hours_passed(time: datetime.datetime, ref_time: datetime.datetime) -> float:\n",
        "    \"\"\"Get the hours passed between two datetime objects.\"\"\"\n",
        "    return (time - ref_time).total_seconds() / 3600\n",
        "\n",
        "class AvatarRetriver(BaseModel):\n",
        "    \"\"\"Retriever combining embedding similarity with recency.\"\"\"\n",
        "\n",
        "    vectorstore: VectorStore\n",
        "    \"\"\"The vectorstore to store documents and determine salience.\"\"\"\n",
        "\n",
        "    search_kwargs: dict = Field(default_factory=lambda: dict(k=100))\n",
        "    \"\"\"Keyword arguments to pass to the vectorstore similarity search.\"\"\"\n",
        "\n",
        "    # TODO: abstract as a queue\n",
        "    memory_stream: List[Document] = Field(default_factory=list)\n",
        "    \"\"\"The memory_stream of documents to search through.\"\"\"\n",
        "\n",
        "    decay_rate: float = Field(default=0.01)\n",
        "    \"\"\"The exponential decay factor used as (1.0-decay_rate)**(hrs_passed).\"\"\"\n",
        "\n",
        "    k: int = 10\n",
        "    \"\"\"The maximum number of documents to retrieve in a given call.\"\"\"\n",
        "\n",
        "    other_score_keys: List[str] = []\n",
        "    \"\"\"Other keys in the metadata to factor into the score, e.g. 'importance'.\"\"\"\n",
        "\n",
        "    default_salience: Optional[float] = None\n",
        "    \"\"\"The salience to assign memories not retrieved from the vector store.\n",
        "\n",
        "    None assigns no salience to documents not fetched from the vector store.\n",
        "    \"\"\"\n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def _get_combined_score(\n",
        "        self,\n",
        "        document: Document,\n",
        "        vector_relevance: Optional[float],\n",
        "        current_time: datetime.datetime,\n",
        "    ) -> float:\n",
        "        \"\"\"Return the combined score for a document.\"\"\"\n",
        "        hours_passed = _get_hours_passed(\n",
        "            current_time,\n",
        "            document.metadata[\"last_accessed_at\"],\n",
        "        )\n",
        "        score = (1.0 - self.decay_rate) ** hours_passed\n",
        "        for key in self.other_score_keys:\n",
        "            if key in document.metadata:\n",
        "                score += document.metadata[key]\n",
        "        if vector_relevance is not None:\n",
        "            score += vector_relevance\n",
        "        return score\n",
        "\n",
        "    def _get_combined_score_list(\n",
        "        self,\n",
        "        document: Document,\n",
        "        vector_relevance: Optional[float],\n",
        "        current_time: datetime.datetime,\n",
        "    ) -> float:\n",
        "        \"\"\"Return the combined score for a document.\"\"\"\n",
        "        hours_passed = _get_hours_passed(\n",
        "            current_time,\n",
        "            document.metadata[\"last_accessed_at\"],\n",
        "        )\n",
        "        if hours_passed < 0:\n",
        "            hours_passed = 0\n",
        "        # score_time = (1.0 - self.decay_rate) ** hours_passed\n",
        "        score_time = 1\n",
        "        if score_time > 1:\n",
        "            score_time = 1\n",
        "        list_scores = []\n",
        "        list_scores.append(score_time)\n",
        "        for key in self.other_score_keys:\n",
        "            if key in document.metadata:\n",
        "                # score += document.metadata[key]\n",
        "                list_scores.append(document.metadata[key])\n",
        "        if vector_relevance is not None:\n",
        "            # score += vector_relevance\n",
        "            list_scores.append(1-vector_relevance)\n",
        "        return list_scores\n",
        "\n",
        "    def get_salient_docs(self, query: str) -> Dict[int, Tuple[Document, float]]:\n",
        "        \"\"\"Return documents that are salient to the query.\"\"\"\n",
        "        docs_and_scores: List[Tuple[Document, float]]\n",
        "        docs_and_scores = self.vectorstore.similarity_search_with_relevance_scores(\n",
        "            query, **self.search_kwargs\n",
        "        )\n",
        "        results = {}\n",
        "        for fetched_doc, relevance in docs_and_scores:\n",
        "            print(fetched_doc)\n",
        "            if \"buffer_idx\" in fetched_doc.metadata:\n",
        "                buffer_idx = fetched_doc.metadata[\"buffer_idx\"]\n",
        "                doc = self.memory_stream[buffer_idx]\n",
        "                results[buffer_idx] = (doc, relevance)\n",
        "        return results\n",
        "\n",
        "    def get_relevant_documents(self, query: str, current_time: Optional[Any]) -> List[Document]:\n",
        "        \"\"\"Return documents that are relevant to the query.\"\"\"\n",
        "        print(query)\n",
        "        if current_time is None:\n",
        "            current_time = datetime.datetime.now()\n",
        "        docs_and_scores = {\n",
        "            doc.metadata[\"buffer_idx\"]: (doc, self.default_salience)\n",
        "            for doc in self.memory_stream[-self.k :]\n",
        "        }\n",
        "\n",
        "        print(\"docs_and_scores\", docs_and_scores)\n",
        "        print(self.get_salient_docs(query))\n",
        "        # If a doc is considered salient, update the salience score\n",
        "        docs_and_scores.update(self.get_salient_docs(query))\n",
        "        rescored_docs = [\n",
        "            (doc, self._get_combined_score_list(doc, relevance, current_time))\n",
        "            for doc, relevance in docs_and_scores.values()\n",
        "        ]\n",
        "\n",
        "        score_array = [b for a,b in rescored_docs]\n",
        "        score_array_np = np.array(score_array)\n",
        "        delta_np = score_array_np.max(axis=0)-score_array_np.min(axis=0)\n",
        "        delta_np = np.where(delta_np == 0, 1, delta_np)\n",
        "        x_norm = (score_array_np-score_array_np.min(axis=0))/delta_np\n",
        "        # Weight importance score less\n",
        "        x_norm[:,0] = x_norm[:,0]*0.9\n",
        "        x_norm[:,1] = x_norm[:,1]*0.9\n",
        "        x_norm_sum = x_norm.sum(axis=1)\n",
        "        rescored_docs = [\n",
        "            (doc, score)\n",
        "            for (doc, _), score in zip(rescored_docs,x_norm_sum)\n",
        "        ]\n",
        "\n",
        "        rescored_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "        result = []\n",
        "        # Ensure frequently accessed memories aren't forgotten\n",
        "        for doc, _ in rescored_docs[: self.k]:\n",
        "            # TODO: Update vector store doc once `update` method is exposed.\n",
        "            buffered_doc = self.memory_stream[doc.metadata[\"buffer_idx\"]]\n",
        "            buffered_doc.metadata[\"last_accessed_at\"] = current_time\n",
        "            result.append(buffered_doc)\n",
        "        return result\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"Return documents that are relevant to the query.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def add_documents(self, documents: List[Document], **kwargs: Any) -> List[str]:\n",
        "        \"\"\"Add documents to vectorstore.\"\"\"\n",
        "        current_time = kwargs.get(\"current_time\")\n",
        "        if current_time is None:\n",
        "            current_time = datetime.datetime.now()\n",
        "        # Avoid mutating input documents\n",
        "        dup_docs = [deepcopy(d) for d in documents]\n",
        "        for i, doc in enumerate(dup_docs):\n",
        "            if \"last_accessed_at\" not in doc.metadata:\n",
        "                doc.metadata[\"last_accessed_at\"] = current_time\n",
        "            if \"created_at\" not in doc.metadata:\n",
        "                doc.metadata[\"created_at\"] = current_time\n",
        "            doc.metadata[\"buffer_idx\"] = len(self.memory_stream) + i\n",
        "        self.memory_stream.extend(dup_docs)\n",
        "        return self.vectorstore.add_documents(dup_docs, **kwargs)\n",
        "\n",
        "    async def aadd_documents(\n",
        "        self, documents: List[Document], **kwargs: Any\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Add documents to vectorstore.\"\"\"\n",
        "        current_time = kwargs.get(\"current_time\")\n",
        "        if current_time is None:\n",
        "            current_time = datetime.datetime.now()\n",
        "        # Avoid mutating input documents\n",
        "        dup_docs = [deepcopy(d) for d in documents]\n",
        "        for i, doc in enumerate(dup_docs):\n",
        "            if \"last_accessed_at\" not in doc.metadata:\n",
        "                doc.metadata[\"last_accessed_at\"] = current_time\n",
        "            if \"created_at\" not in doc.metadata:\n",
        "                doc.metadata[\"created_at\"] = current_time\n",
        "            doc.metadata[\"buffer_idx\"] = len(self.memory_stream) + i\n",
        "        self.memory_stream.extend(dup_docs)\n",
        "        return await self.vectorstore.aadd_documents(dup_docs, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHICybG00zpr"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from langchain.schema import BaseMemory, Document\n",
        "import openai\n",
        "import logging\n",
        "import re\n",
        "from langchain.schema import BaseMemory, Document\n",
        "from langchain.utils import mock_now\n",
        "import time\n",
        "import datetime\n",
        "from copy import deepcopy\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.schema import BaseRetriever, Document\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "import numpy as np\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import faiss\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.language_model import BaseLanguageModel\n",
        "\n",
        "import wandb\n",
        "\n",
        "from termcolor import cprint\n",
        "\n",
        "\n",
        "class AvatarMemory(BaseMemory):\n",
        "    llm: BaseLanguageModel\n",
        "    \"\"\"The core language model.\"\"\"\n",
        "    memory_retriever: AvatarRetriver\n",
        "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
        "    reflection_threshold: Optional[float] = None\n",
        "    \"\"\"When aggregate_importance exceeds reflection_threshold, stop to reflect.\"\"\"\n",
        "    importance_weight: float = 0.15\n",
        "    \"\"\"How much weight to assign the memory importance.\"\"\"\n",
        "    aggregate_importance: float = 0.0  # : :meta private:\n",
        "    \"\"\"Track the sum of the 'importance' of recent memories.\n",
        "    Triggers reflection when it reaches reflection_threshold.\"\"\"\n",
        "    reflecting: bool = False\n",
        "    now_key: str = \"now\"\n",
        "    max_tokens_limit: int = 1200  # : :meta private:\n",
        "\n",
        "    user_k_tokens: float = 0.0\n",
        "    use_wandb: bool = False\n",
        "\n",
        "\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -> None:\n",
        "        \"\"\"Save the context of this model run to memory.\"\"\"\n",
        "        # TODO\n",
        "\n",
        "    @property\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        \"\"\"Input keys this memory class will load dynamically.\"\"\"\n",
        "        # TODO\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"Clear memory contents.\"\"\"\n",
        "        # TODO\n",
        "\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
        "        \"\"\"Return key-value pairs given the text input to the chain.\"\"\"\n",
        "        # TODO\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_list(text: str) -> List[str]:\n",
        "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
        "        lines = re.split(r\"\\n\", text.strip())\n",
        "        lines = [line for line in lines if line.strip()]  # remove empty lines\n",
        "        return [re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", line).strip() for line in lines]\n",
        "\n",
        "    def fetch_memories(\n",
        "        self, observation: str, now: Optional[datetime.datetime] = None\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Fetch related memories.\"\"\"\n",
        "        print(\"Observation:\", observation)\n",
        "        #print(now)\n",
        "        return self.memory_retriever.get_relevant_documents(observation,now)\n",
        "\n",
        "    def format_memories_detail(self, relevant_memories: List[Document]) -> str:\n",
        "        content = []\n",
        "        for mem in relevant_memories:\n",
        "            content.append(self._format_memory_detail(mem, prefix=\"- \"))\n",
        "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
        "\n",
        "    def _format_memory_detail(self, memory: Document, prefix: str = \"\") -> str:\n",
        "        created_time = memory.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "        return f\"{prefix}{memory.page_content.strip()}\"\n",
        "\n",
        "    def format_memories_simple(self, relevant_memories: List[Document]) -> str:\n",
        "        return \"; \".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
        "\n",
        "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
        "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
        "        result = []\n",
        "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
        "            if consumed_tokens >= self.max_tokens_limit:\n",
        "                break\n",
        "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
        "            if consumed_tokens < self.max_tokens_limit:\n",
        "                result.append(doc)\n",
        "        return self.format_memories_simple(result)\n",
        "\n",
        "    def get_completion(self, prompt, llm=\"gpt-4o-mini\", temperature=0):\n",
        "        global global_k_tokens\n",
        "        global global_start_time\n",
        "        global global_steps\n",
        "        global global_last_tokens_record\n",
        "        global global_interval\n",
        "        global global_finished_users\n",
        "        global global_finished_pages\n",
        "        global global_error_cast\n",
        "        global lock\n",
        "\n",
        "\n",
        "        messages = [{\"role\":\"user\", \"content\" : prompt}]\n",
        "        response = ''\n",
        "        except_waiting_time = 1\n",
        "        total_waiting_time = 0\n",
        "        max_waiting_time = 16\n",
        "        current_sleep_time = 0.5\n",
        "        while response == '':\n",
        "            try:\n",
        "                if(self.use_wandb): # whether to use wandb\n",
        "                    start_time = time.time()\n",
        "\n",
        "                    if((start_time - global_start_time)//global_interval > global_steps):\n",
        "                        if(lock.acquire(False)):\n",
        "                            print(\"??\", lock, (start_time - global_start_time)//global_interval, global_interval, global_steps)\n",
        "                            print(\"\\nMemory Start Identifier\", start_time, global_start_time, (start_time - global_start_time), global_steps)\n",
        "                            # vars.lock = True\n",
        "                            global_steps += 1\n",
        "                            wandb.log(\n",
        "                                data = {\"Real-time Traffic\": global_k_tokens - global_last_tokens_record,\n",
        "                                        \"Total Traffic\": global_k_tokens,\n",
        "                                        \"Finished Users\": global_finished_users,\n",
        "                                        \"Finished Pages\": global_finished_pages,\n",
        "                                        \"Error Cast\": global_error_cast/1000\n",
        "                                },\n",
        "                                step = global_steps\n",
        "                            )\n",
        "                            global_last_tokens_record = global_k_tokens\n",
        "                            # vars.lock = False\n",
        "                            lock.release()\n",
        "                            print(\"\\nMemory End Identifier\", time.time(), global_start_time, (time.time() - global_start_time), global_steps)\n",
        "\n",
        "                response = openai.ChatCompletion.create(\n",
        "                    model=llm,\n",
        "                    messages=messages,\n",
        "                    temperature=temperature,\n",
        "                    request_timeout = 20,\n",
        "                    max_tokens=1000\n",
        "                )\n",
        "\n",
        "                print(\"===================================\")\n",
        "                print(f'{response[\"usage\"][\"total_tokens\"]} = {response[\"usage\"][\"prompt_tokens\"]} + {response[\"usage\"][\"completion_tokens\"]} tokens counted by the OpenAI API.')\n",
        "                k_tokens = response[\"usage\"][\"total_tokens\"]/1000\n",
        "                self.user_k_tokens += k_tokens\n",
        "                global_k_tokens += k_tokens\n",
        "                if(response[\"usage\"][\"prompt_tokens\"] > 2000):\n",
        "                    cprint(prompt, color=\"white\")\n",
        "\n",
        "            except Exception as e:\n",
        "                global_error_cast += 1\n",
        "                total_waiting_time += except_waiting_time\n",
        "                time.sleep(current_sleep_time)\n",
        "                if except_waiting_time < max_waiting_time:\n",
        "                    except_waiting_time *= 2\n",
        "                    current_sleep_time = np.random.randint(0, except_waiting_time-1)\n",
        "\n",
        "        return response.choices[0].message[\"content\"]\n",
        "\n",
        "    def _user_taste_reflection(self, last_k: int = 10) -> List[str]:\n",
        "        \"\"\"Return the user's taste about recent movies.\"\"\"\n",
        "        prompt = \"\"\"\n",
        "            The user has read following movie recently:\n",
        "            <INPUT>\\n\\n\n",
        "            Given only the information above, conclude the user's taste of movie using five adjective words, which should be conclusive, descriptive, and movie-genre related.\n",
        "            The output format must be:\n",
        "            user's recent taste are: <word1>,<word2>,<word3>,<word4>,<word5>.\n",
        "            \"\"\"\n",
        "\n",
        "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
        "        # print(observations)\n",
        "        observation_str = \"\\n\".join(\n",
        "            [self._format_memory_detail(o) for o in observations]\n",
        "        )\n",
        "        prompt_filled = prompt.replace(\"<INPUT>\", observation_str)\n",
        "        result = self.get_completion(prompt=prompt_filled, llm=\"gpt-4o-mini\", temperature=0.2)\n",
        "        # print(result)\n",
        "        return result\n",
        "    # \"gpt-3.5-turbo\"\n",
        "    def _user_satisfaction_reflection(self, last_k: int = 10) -> List[str]:\n",
        "        \"\"\"Return the user's feeling about recent movies.\"\"\"\n",
        "        prompt = \"\"\"\n",
        "            <INPUT>\\n\\n\n",
        "            Given only the information above, describe your feeling of the recommendation result using a sentence.\n",
        "            The output format must be:\n",
        "            [unsatisfied/satisfied] with the recommendation result because [reason].\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "        observations = \"what's your interaction history with each page of recommender?\"\n",
        "        relevant_memories = self.fetch_memories(observations)\n",
        "        observation_str = self.format_memories_detail(relevant_memories)\n",
        "        prompt_filled = prompt.replace(\"<INPUT>\", observation_str)\n",
        "        result = self.get_completion(prompt=prompt_filled, llm=\"gpt-4o-mini\", temperature=0.2)\n",
        "\n",
        "        # print(result)\n",
        "        return result\n",
        "        # return \"satisfaction reflected\"\n",
        "\n",
        "    def _user_feeling_reflection(self, last_k: int = 10) -> List[str]:\n",
        "        \"\"\"Return the user's feeling about recent books.\"\"\"\n",
        "        #user persona: <INPUT 1>\n",
        "        prompt = \"\"\"\n",
        "            user persona: a 22-year-old woman working in a clerical/administrative role. She is intelligent, imaginative, and adventurous. With a passion for movies, Emily has a diverse taste and enjoys a wide range of genres. Her favorite movie's producer name include \"\"Led Zeppelin,\"\" \"\"Pink Floyd,\"\" \"\"Wu-Tang Clan,\"\" \"\"Mos Def,\"\" and movie's actor name include \"\"Hocus Pocus,\"\" \"\"10,000 Days (Wings, Part 2).\"\"  Emily's movie preferences reflect a wide range of movie genres and artists, from classic rock bands to hip-hop artist. She appreciates complex compositions and innovative sounds, gravitating towards artists who push the boundaries of traditional movie.\"\n",
        "            3,3,\"Hocus Pocus; 10,000 Days (Wings, Part 2)\", Classic-rock-bands; Hip-hop,Male,45-49,clerical/admin,55421,\"<Part 1>\n",
        "\n",
        "            This user has read following movies recently:\n",
        "            <INPUT 2>\\n\\n\n",
        "            Given only the information above, describe the user's feeling of each of the movie he/she watch recently.\n",
        "            \"\"\"\n",
        "\n",
        "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
        "        observation_str = \"\\n\".join(\n",
        "            [self._format_memory_detail(o) for o in observations]\n",
        "        )\n",
        "        prompt_filled = prompt.replace(\"<INPUT 2>\", observation_str)\n",
        "        result = self.get_completion(prompt=prompt_filled, llm=\"gpt-4o-mini\", temperature=0.2)\n",
        "        # print(result)\n",
        "        return result\n",
        "\n",
        "    def pause_to_reflect_taste(self, now: Optional[datetime.datetime] = None) -> List[str]:\n",
        "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
        "        taste = self._user_taste_reflection()\n",
        "        self.add_memory(taste, now=now)\n",
        "        return 'taste reflected:\\n'+ taste\n",
        "\n",
        "    def pause_to_reflect_satisfaction(self, now: Optional[datetime.datetime] = None) -> List[str]:\n",
        "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
        "        satisfaction = self._user_satisfaction_reflection()\n",
        "        self.add_memory(satisfaction, now=now)\n",
        "        return 'satisfaction reflected:\\n'+ satisfaction\n",
        "\n",
        "    def pause_to_reflect_feeling(self, now: Optional[datetime.datetime] = None) -> List[str]:\n",
        "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
        "        feeling = self._user_feeling_reflection()\n",
        "        self.add_memory(feeling, now=now)\n",
        "        return 'feeling reflected:\\n'+ feeling\n",
        "\n",
        "    def add_memory(\n",
        "        self, memory_content: str, now: Optional[datetime.datetime] = None\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Add an observation or memory to the agent's memory bank.\"\"\"\n",
        "        importance_score = 1\n",
        "        self.aggregate_importance += importance_score\n",
        "        document = Document(\n",
        "            page_content=memory_content, metadata={\"importance\": importance_score}\n",
        "        )\n",
        "        result = self.memory_retriever.add_documents([document], current_time=now)\n",
        "\n",
        "        # After an agent has processed a certain amount of memories (as measured by\n",
        "        # aggregate importance), it is time to reflect on recent events to add\n",
        "        # more synthesized memories to the agent's memory stream.\n",
        "        if (\n",
        "            self.reflection_threshold is not None\n",
        "            and self.aggregate_importance > self.reflection_threshold\n",
        "            and not self.reflecting\n",
        "        ):\n",
        "            self.reflecting = True\n",
        "            self.reflect(now=now)\n",
        "            # Hack to clear the importance from reflection\n",
        "            self.aggregate_importance = 0.0\n",
        "            self.reflecting = False\n",
        "        return result\n",
        "\n",
        "    def update_memory(self, reaction):\n",
        "        \"\"\"\n",
        "        Update the memory bank with the reaction\n",
        "        \"\"\"\n",
        "        return\n",
        "\n",
        "\n",
        "    def time_weighting(self):\n",
        "        \"\"\"\n",
        "        Weighting the memory according to the time\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def importance_weighting(self):\n",
        "        \"\"\"\n",
        "        Weighting the importance of memory according to\n",
        "        the results of recommendation and the personal taste\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def reflect(self, now: Optional[datetime.datetime] = None):\n",
        "        \"\"\"\n",
        "        Generate a high level understanding of previous memories\n",
        "        \"\"\"\n",
        "        # self.pause_to_reflect_taste(now=now)\n",
        "        # self.pause_to_reflect_feeling(now=now)\n",
        "        self.pause_to_reflect_satisfaction(now=now)\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmEGhVUK0zpv"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored, cprint\n",
        "import openai\n",
        "import os\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import faiss\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import pandas as pd\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "class Avatar(abstract_avatar):\n",
        "    def __init__(self, args, avatar_id, init_property, init_statistic):\n",
        "        super().__init__(args, avatar_id)\n",
        "\n",
        "        self.parse_init_property(init_property)\n",
        "        self.parse_init_statistic(init_statistic)\n",
        "\n",
        "        self.log_file = f\"storage/{args.dataset}/{args.modeltype}/{args.simulation_name}/running_logs/{avatar_id}.txt\"\n",
        "        if os.path.exists(self.log_file):\n",
        "            os.remove(self.log_file)\n",
        "        self.init_memory()\n",
        "\n",
        "    def parse_init_property(self, init_property):\n",
        "        self.taste = init_property[\"taste\"].split(\"| \")\n",
        "        self.high_rating = init_property[\"high_rating\"]\n",
        "\n",
        "\n",
        "    def parse_init_statistic(self, init_statistic):\n",
        "        \"\"\"\n",
        "        Parse the init statistic of the avatar\n",
        "        \"\"\"\n",
        "# activity_dict\n",
        "        activity_dict = {   1:\"An Incredibly Elusive Occasional Viewer, so seldom attracted by movie recommendations that it's almost a legendary event when you do watch a movie. Your movie-watching habits are extraordinarily infrequent. And you will exit the recommender system immediately even if you just feel little unsatisfied.\",\n",
        "                            2:\"An Occasional Viewer, seldom attracted by movie recommendations. Only curious about watching movies that strictly align the taste. The movie-watching habits are not very infrequent. And you tend to exit the recommender system if you have a few unsatisfied memories.\",\n",
        "                            3:\"A Movie Enthusiast with an insatiable appetite for films, willing to watch nearly every movie recommended to you. Movies are a central part of your life, and movie recommendations are integral to your existence. You are tolerant of recommender system, which means you are not easy to exit recommender system even if you have some unsatisfied memory.\"}\n",
        "        # activity_dict = {   1: \"An Incredibly Elusive Occasional Listener, so seldom attracted by music recommendations that it's almost a legendary event when you do listen to a new song. Your music-listening habits are extraordinarily infrequent, and you will exit the recommender system immediately even if you feel a little unsatisfied.\",\n",
        "        #                     2: \"An Occasional Listener, seldom attracted by music recommendations. Only curious about listening to music that strictly aligns with your taste. Your music-listening habits are not very infrequent, and you tend to exit the recommender system if you have a few unsatisfactory experiences.\",\n",
        "        #                     3: \"A Music Enthusiast with an insatiable appetite for new tunes, willing to listen to nearly every song recommended to you. Music is a central part of your life, and music recommendations are integral to your existence. You are tolerant of the recommender system, which means you are not easy to exit even if you have some unsatisfactory experiences.\"}\n",
        "        # activity_dict = {     1: \"An Incredibly Elusive Occasional Reader, rarely drawn to book recommendations. It's almost a legendary event when you pick up a new book. Your reading habits are extraordinarily infrequent, and you tend to stop engaging with the recommendation system quickly if the books don't immediately capture your interest.\",\n",
        "        #                       2: \"An Occasional Reader, rarely attracted by book recommendations. You are selective and only interested in books that strictly align with your tastes. Your reading habits are not very frequent, and you may stop using the recommendation system after encountering a few books that don't meet your expectations.\",\n",
        "        #                       3: \"A Book Enthusiast with an insatiable appetite for new reads, eager to explore almost every book recommended to you. Books are a central part of your life, and recommendations are integral to your reading journey. You are patient with the recommendation system, and it takes more than a few unsatisfactory books to deter you.\"}\n",
        "# conformity_dict\n",
        "        conformity_dict = { 1:\"A Dedicated Follower who gives ratings heavily relies on movie historical ratings, rarely expressing independent opinions. Usually give ratings that are same as historical ratings. \",\n",
        "                            2:\"A Balanced Evaluator who considers both historical ratings and personal preferences when giving ratings to movies. Sometimes give ratings that are different from historical rating.\",\n",
        "                            3:\"A Maverick Critic who completely ignores historical ratings and evaluates movies solely based on own taste. Usually give ratings that are a lot different from historical ratings.\"}\n",
        "        # conformity_dict = {   1: \"A Dedicated Follower who gives ratings heavily relying on historical music ratings, rarely expressing independent opinions. Usually gives ratings that are the same as historical ratings.\",\n",
        "        #                       2: \"A Balanced Evaluator who considers both historical ratings and personal preferences when giving ratings to music. Sometimes gives ratings that are different from historical ratings.\",\n",
        "        #                       3: \"A Maverick Critic who completely ignores historical ratings and evaluates music solely based on personal taste. Usually gives ratings that are significantly different from historical ratings.\"}\n",
        "        # conformity_dict = {   1: \"A Dedicated Follower who heavily relies on popular reviews and historical ratings when rating books. You rarely express independent opinions and usually rate books similarly to the average ratings.\",\n",
        "        #                       2: \"A Balanced Evaluator who considers both popular reviews and personal preferences when rating books. You sometimes give ratings that differ from the average ratings based on your own experience.\",\n",
        "        #                       3: \"A Maverick Critic who completely ignores popular reviews and historical ratings, evaluating books solely based on personal taste. You usually give ratings that are significantly different from the average ratings.\"}\n",
        "# diversity_dict\n",
        "        diversity_dict = {  1:\"An Exceedingly Discerning Selective Viewer who watches movies with a level of selectivity that borders on exclusivity. The movie choices are meticulously curated to match personal taste, leaving no room for even a hint of variety.\",\n",
        "                            2:\"A Niche Explorer who occasionally explores different genres and mostly sticks to preferred movie types.\",\n",
        "                            3:\"A Cinematic Trailblazer, a relentless seeker of the unique and the obscure in the world of movies. The movie choices are so diverse and avant-garde that they defy categorization.\"}\n",
        "        # diversity_dict = {   1: \"An Exceedingly Discerning Selective Listener who listens to music with a level of selectivity that borders on exclusivity. The music choices are meticulously curated to match personal taste, leaving no room for even a hint of variety.\",\n",
        "        #                      2: \"A Niche Explorer who occasionally explores different genres but mostly sticks to preferred music types.\",\n",
        "        #                      3: \"A Musical Trailblazer, a relentless seeker of the unique and the obscure in the world of music. The music choices are so diverse and avant-garde that they defy categorization.\"}\n",
        "        # diversity_dict = {    1: \"An Exceedingly Discerning Selective Reader who reads books with a level of selectivity that borders on exclusivity. Your book choices are meticulously curated to match your specific taste, leaving little room for variety.\",\n",
        "        #                       2: \"A Niche Explorer who occasionally explores different genres but mostly sticks to preferred types of books.\",\n",
        "        #                       3: \"A Literary Trailblazer, a relentless seeker of unique and obscure works in the world of literature. Your reading choices are so diverse and avant-garde that they defy categorization.\"}\n",
        "        self.conformity_group = init_statistic[\"conformity\"]\n",
        "        self.activity_group = init_statistic[\"activity\"]\n",
        "        self.diversity_group = init_statistic[\"diversity\"]\n",
        "        self.conformity_dsc = conformity_dict[self.conformity_group]\n",
        "        self.activity_dsc = activity_dict[self.activity_group]\n",
        "        self.diversity_dsc = diversity_dict[self.diversity_group]\n",
        "\n",
        "    def init_memory(self):\n",
        "        \"\"\"\n",
        "        Initialize the memory of the avatar\n",
        "        \"\"\"\n",
        "        t1 = time.time()\n",
        "        def score_normalizer(val: float) -> float:\n",
        "            return 1 - 1 / (1 + np.exp(val))\n",
        "\n",
        "        embeddings_model = OpenAIEmbeddings(request_timeout = 20)\n",
        "        embedding_size = 1536\n",
        "        index = faiss.IndexFlatL2(embedding_size)\n",
        "        vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {}, relevance_score_fn=score_normalizer)\n",
        "\n",
        "        LLM = ChatOpenAI(max_tokens=1000, temperature=0.3, request_timeout = 30)\n",
        "        self.avatar_retriever = AvatarRetriver(vectorstore=vectorstore, k=5)\n",
        "        self.memory = AvatarMemory(memory_retriever=self.avatar_retriever, llm=LLM, reflection_threshold=3, use_wandb = self.use_wandb)\n",
        "        t2 = time.time()\n",
        "\n",
        "\n",
        "        cprint(f\"Avatar {self.avatar_id} is initialized with memory\", color='green', attrs=['bold'])\n",
        "        cprint(f\"Time cost: {t2-t1}s\", color='green', attrs=['bold'])\n",
        "\n",
        "\n",
        "\n",
        "    def _reaction(self, messages=None, timeout=30):\n",
        "        \"\"\"\n",
        "        Summarize the feelings of the avatar for recommended item list.\n",
        "        \"\"\"\n",
        "        global global_k_tokens\n",
        "        global global_start_time\n",
        "        global global_steps\n",
        "        global global_last_tokens_record\n",
        "        global global_interval\n",
        "        global global_finished_users\n",
        "        global global_finished_pages\n",
        "        global global_error_cast\n",
        "        global lock\n",
        "        response = ''\n",
        "        except_waiting_time = 1\n",
        "        max_waiting_time = 16\n",
        "        current_sleep_time = 0.5\n",
        "        while response == '':\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "                time_local = time.localtime(start_time)\n",
        "                l_start = time.strftime(\"%Y-%m-%d %H:%M:%S\",time_local)\n",
        "\n",
        "                if(self.use_wandb): # whether to use wandb\n",
        "                    if((start_time - global_start_time)//global_interval > global_steps):\n",
        "                        print(\"\\nStart Identifier\", start_time, global_start_time, (start_time - global_start_time), global_steps)\n",
        "                        if(lock.acquire(False)):\n",
        "                            print(\"\\nStart Identifier\", start_time, global_start_time, (start_time - global_start_time), global_steps)\n",
        "                            global_steps += 1\n",
        "                            wandb.log(\n",
        "                                data = {\"Real-time Traffic\": global_k_tokens - global_last_tokens_record,\n",
        "                                        \"Total Traffic\": global_k_tokens,\n",
        "                                        \"Finished Users\": global_finished_users,\n",
        "                                        \"Finished Pages\": global_finished_pages,\n",
        "                                        \"Error Cast\": global_error_cast/1000,\n",
        "                                },\n",
        "                                step = global_steps\n",
        "                            )\n",
        "                            global_last_tokens_record = global_k_tokens\n",
        "                            lock.release()\n",
        "                            print(\"\\nEnd Identifier\", time.time(), global_start_time, (time.time() - global_start_time), global_steps)\n",
        "\n",
        "                completion = openai.ChatCompletion.create(\n",
        "                    model=\"gpt-4o-mini\",\n",
        "                    messages=messages,\n",
        "                    temperature=0.2,\n",
        "                    request_timeout = timeout,\n",
        "                    max_tokens=1000\n",
        "                    )\n",
        "\n",
        "                l_end = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()))\n",
        "                k_tokens = completion[\"usage\"][\"total_tokens\"]/1000\n",
        "                print(f\"User {self.avatar_id} used {k_tokens} tokens from {l_start} to {l_end}\")\n",
        "                self.memory.user_k_tokens += k_tokens\n",
        "                global_k_tokens += k_tokens\n",
        "                response = completion[\"choices\"][0][\"message\"][\"content\"]\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                global_error_cast += 1\n",
        "                time.sleep(current_sleep_time)\n",
        "                if except_waiting_time < max_waiting_time:\n",
        "                    except_waiting_time *= 2\n",
        "                current_sleep_time = np.random.randint(0, except_waiting_time-1)\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def make_next_decision(self, remember=False, current_page=None):\n",
        "        # controlling the memory element\n",
        "\n",
        "        sys_prompt = (\"You excel at role-playing. Picture yourself as a user exploring a movie recommendation system. You have the following social traits: \" \\\n",
        "                    +f\"\\nYour activity trait is described as: {self.activity_dsc}\"\n",
        "                    +f\"\\nNow you are in Page {current_page}. You may get tired with the increase of the pages you have browsed. (above 2 pages is a little bit tired, above 3 pages is very tired)\"\n",
        "                    ) \n",
        "\n",
        "        prompt = (\"Firstly, generate an overall feeling based on your memory, in accordance with your activity trait and your satisfaction on recommender system.\"\n",
        "                +\"\\nIf your overall feeling is positive, write: POSITIVE: [reason]\"\n",
        "                +\"\\nIf it's negative, write: NEGATIVE: [reason]\"\n",
        "                +\"\\nNow, note that you must have to interact with 5 pages then you can decide to exit or your overall positive feeling is fully satisfied.\"\n",
        "                +\"\\nAgain, you will exit the recommender system if you get so tired.\"\n",
        "                +\"\\nTo leave, write: [EXIT]; Reason: [brief reason]\"\n",
        "                +\"\\nTo continue browsing, write: [NEXT]; Reason: [brief reason]\"\n",
        "            )\n",
        "        messages = [{\"role\": \"system\",\n",
        "                    \"content\": sys_prompt},\n",
        "                    {\"role\": \"user\",\n",
        "                    \"content\": prompt}]\n",
        "\n",
        "        self.write_log(\"\\n\" + sys_prompt, color=\"blue\")\n",
        "        self.write_log(\"\\n\" + prompt, color=\"blue\")\n",
        "        response = self._reaction(messages)\n",
        "        print(\"Next Decision Response: \", response)\n",
        "        self.write_log(\"\\n\" + response, color=\"white\")\n",
        "\n",
        "        return response\n",
        "\n",
        "    def response_to_question(self, question, remember=False):\n",
        "        relevant_memories = self.memory.memory_retriever.memory_stream\n",
        "        formated_relevant_memories = self.memory.format_memories_detail(relevant_memories)\n",
        "        sys_prompt = (f\"You excel at role-playing. Picture yourself as user {self.avatar_id} who has just finished exploring a movie recommendation system. You have the following social traits:\"\n",
        "                +f\"\\nYour activity trait is described as: {self.activity_dsc}\"\n",
        "                +f\"\\nYour conformity trait is described as: {self.conformity_dsc}\"\n",
        "                +f\"\\nYour diversity trait is described as: {self.diversity_dsc}\"\n",
        "                +f\"\\nBeyond that, your movie tastes are: {'; '.join(self.taste).replace('I ','')}. \"\n",
        "                +\"\\nThe activity characteristic pertains to the frequency of your movie-watching habits. The conformity characteristic measures the degree to which your ratings are influenced by historical ratings. The diversity characteristic gauges your likelihood of watching movie that may not align with your usual taste.\"\n",
        "                )\n",
        "        prompt = f\"\"\"\n",
        "        Relevant context from user {self.avatar_id}'s memory:\n",
        "        {formated_relevant_memories}\n",
        "        Act as user {self.avatar_id}, assume you are having a interview, reponse the following question:\n",
        "        {question}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        messages = [{\"role\": \"system\",\n",
        "                    \"content\": sys_prompt},\n",
        "                    {\"role\": \"user\",\n",
        "                    \"content\": prompt}]\n",
        "\n",
        "        self.write_log(\"\\n\" + sys_prompt, color=\"blue\")\n",
        "        self.write_log(\"\\n\" + prompt, color=\"blue\")\n",
        "        response = self._reaction(messages)\n",
        "        self.write_log(\"\\n\" + response, color=\"blue\")\n",
        "        #\n",
        "        if(remember):\n",
        "            self.memory.add_memory(f\"I was asked '{question}', and I responsed: '{response}'\"\n",
        "                                , now=datetime.datetime.now())\n",
        "        return response\n",
        "\n",
        "    def reaction_to_forced_items(self, recommended_items_str):\n",
        "        \"\"\"\n",
        "        Summarize the feelings of the avatar for recommended item list.\n",
        "        \"\"\"\n",
        "\n",
        "        sys_prompt = (\"Assume you are a user browsing movie recommendation system who has the following characteristics: \"\n",
        "                +f\"\\nYour movie tastes are: {'; '.join(self.taste).replace('I ','')}. \")\n",
        "        prompt = (\n",
        "                \"##recommended list## \\n\"\n",
        "                +recommended_items_str\n",
        "                +\"\\nPlease choose movies in the ##recommended list## that you want to read and explain why. After reading the book, evaluate each book based on your characteristics, taste and historical ratings to give a rating from 1 to 5.\"\n",
        "                +\"\\nYou only watch movies which aligh with your taste.\"\n",
        "                +\"\\nUse this format: MOVIE: [movie title]; WATCH: [yes or no]; REASON: [brief reason]; RATING: [integer between 1-5];\"\n",
        "                \"\\nYou must judge all the movies. If you don't want to watch a movie, use WATCH: no; REASON: [brief reason]\"\n",
        "                +\"\\nEach response should be on one line. Do not include any additional information or explanations and stay grounded in reality.\"\n",
        "        )\n",
        "        messages = [{\"role\": \"system\",\n",
        "                    \"content\": sys_prompt},\n",
        "                    {\"role\": \"user\",\n",
        "                    \"content\": prompt}]\n",
        "\n",
        "        reaction = self._reaction(messages, timeout=20)\n",
        "\n",
        "        return reaction\n",
        "\n",
        "    def reaction_to_recommended_items(self, recommended_items_str, current_page):\n",
        "        \"\"\"\n",
        "        Summarize the feelings of the avatar for recommended item list.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            high_rating = self.high_rating.replace('You are','')\n",
        "        except:\n",
        "            high_rating = ''\n",
        "\n",
        "        sys_prompt = (\"You excel at role-playing. Picture yourself as a user exploring a movie recommendation system. You have the following social traits:\"\n",
        "                +f\"\\nYour activity trait is described as: {self.activity_dsc}\"\n",
        "                +f\"\\nYour conformity trait is described as: {self.conformity_dsc}\"\n",
        "                +f\"\\nYour diversity trait is described as: {self.diversity_dsc}\"\n",
        "                +f\"\\nBeyond that, your movie tastes are: {'; '.join(self.taste).replace('I ','')}. \"\n",
        "                +f\"\\nAnd your rating tendency is {high_rating}\"#+f\"{low_rating}\"\n",
        "                +\"\\nThe activity characteristic pertains to the frequency of your movie-watching habits. The conformity characteristic measures the degree to which your ratings are influenced by historical ratings. The diversity characteristic gauges your likelihood of watching movies that may not align with your usual taste.\"\n",
        "                )\n",
        "        # uncomment this one to use the memory effect.\n",
        "        # if self.memory.memory_retriever.memory_stream:\n",
        "        #     observation = \"What movies have you watch on the previous pages of the current recommender system?\"\n",
        "        #     relevant_memories = self.memory.fetch_memories(observation)\n",
        "        #     formated_relevant_memories = self.memory.format_memories_detail(relevant_memories)\n",
        "        #     sys_prompt = sys_prompt +f\"\\nRelevant context from your memory:{formated_relevant_memories}\"\n",
        "\n",
        "        # prompt = (\n",
        "        #         \"#### Recommended List #### \\n\"\n",
        "        #         + f\"PAGE {current_page}\\n\"\n",
        "        #         +recommended_items_str\n",
        "        #         +\"\\nPlease respond to all the books in the ## Recommended List ## and provide explanations.\"\n",
        "        #         +\"\\nFirstly, determine which books align with your taste and which do not, and provide reasons. You must respond to all the recommended books using this format:\"\n",
        "        #         +\"\\nBOOK: [book title]; ALIGN: [yes or no]; REASON: [brief reason]\"\n",
        "        #         +\"\\nSecondly, among the books that align with your tastes, decide the number of books you want to read based on your activity and diversity traits. Use this format:\"\n",
        "        #         +\"\\nNUM: [number of book you choose to read]; READ: [all book's title you choose to read]; REASON: [brief reason];\"\n",
        "        #         +\"\\nThirdly, assume it's your first time reading the books you've chosen, and rate them on a scale of 1-5 to reflect different degrees of liking, considering your feeling and conformity trait. Use this format:\"\n",
        "        #         +\"\\n BOOK: [book title you choose to read]; RATING: [integer between 1-5]; FEELING: [aftermath sentence]; \"\n",
        "        #         +\"\\n Do not include any additional information or explanations and stay grounded.\"\n",
        "        # )\n",
        "        prompt = (\n",
        "                \"#### Recommended List #### \\n\"\n",
        "                + f\"PAGE {current_page}\\n\"\n",
        "                +recommended_items_str\n",
        "                +\"\\nPlease respond to all the movies in the ## Recommended List ## and provide explanations.\"\n",
        "                +\"\\nFirstly, determine which movies align with your taste and which do not, and provide reasons. You must respond to all the recommended movies using this format:\"\n",
        "                +\"\\nMOVIE: [movie title]; ALIGN: [yes or no]; REASON: [brief reason]\"\n",
        "                +\"\\nSecondly, among the movies that align with your tastes, chose only one movie you want to watch based on your activity and diversity traits. Use this format:\"\n",
        "                +\"\\nNUM: [one movie you choose to watch]; WATCH: [one movie's title you choose to watch]; REASON: [brief reason];\"\n",
        "                +\"\\nThirdly, assume it's your first time watching the movies you've chosen, and rate them on a scale of 1-5 to reflect different degrees of liking, considering your feeling and conformity trait. Use this format:\"\n",
        "                +\"\\n MOVIE: [movie title you choose to watch]; RATING: [integer between 1-5]; FEELING: [aftermath sentence]; \"\n",
        "                +\"\\n Do not include any additional information or explanations and stay grounded.\"\n",
        "        )\n",
        "\n",
        "        messages = [{\"role\": \"system\",\n",
        "                    \"content\": sys_prompt},\n",
        "                    {\"role\": \"user\",\n",
        "                    \"content\": prompt}]\n",
        "\n",
        "        self.write_log(\"\\n\" + sys_prompt, color=\"blue\")\n",
        "        self.write_log(\"\\n\" + prompt, color=\"blue\")\n",
        "        reaction = self._reaction(messages, timeout=10) # reaction\n",
        "        self.write_log(\"\\n\" + reaction, color=\"yellow\")\n",
        "\n",
        "        # @ 2 Add user satisfaction information for this page.\n",
        "\n",
        "        # =========================\n",
        "        pattern1 = re.compile(r'MOVIE: (.+?); RATING: (\\d+); FEELING: (.*)')\n",
        "        match1 = pattern1.findall(reaction)\n",
        "        pattern2 = re.compile(r'MOVIE: (.+?); ALIGN: (.+?); REASON: (.*)')\n",
        "        match2 = pattern2.findall(reaction)\n",
        "        musica_musict_pairs = [f\"{book}\" for book, align, reason in match2]\n",
        "        all_movies = \", \".join(musica_musict_pairs)\n",
        "        watched_movies = [f\"{book}\" for book, rating, feeling in match1]\n",
        "        watched_movies_ratings = [rating.strip(';') for book, rating, feeling in match1]\n",
        "        # like_movies = [f\"{book}\" for book, rating, feeling in match1 if int(rating.strip(';')) == 10]\n",
        "        # dislike_movies = [f\"{book}\" for book, rating, feeling in match1 if (int(rating.strip(';')) < 9)]\n",
        "        # like_movies = [f\"{book}\" for book, rating, feeling in match1 if int(7 <= rating.strip(';')) <= 10]\n",
        "        like_movies = [f\"{book}\" for book, rating, feeling in match1 if int(rating.strip(';')) == 5]\n",
        "        dislike_movies = [f\"{book}\" for book, rating, feeling in match1 if (int(rating.strip(';')) < 3)]\n",
        "        dislike_movies.extend([f\"{book}\" for book, align, reason in match2 if align.strip(';').lower() == 'no'])\n",
        "        self.memory.add_memory(f\"The recommender recommended the following movies to me on page {current_page}: {all_movies}, among them, I watch {watched_movies} and rate them {watched_movies_ratings} respectively. I dislike the rest movies: {dislike_movies}.\"\n",
        "            , now=datetime.datetime.now()\n",
        "        )\n",
        "\n",
        "        # User makes the next decision.\n",
        "        next_decision = self.make_next_decision(current_page=current_page)\n",
        "        if('[EXIT]' in next_decision or '[exit]' in next_decision):\n",
        "            self.exit_flag = True\n",
        "            self.memory.add_memory(f\"After browsing {current_page} pages, I decided to leave the recommendation system.\"\n",
        "                , now=datetime.datetime.now())\n",
        "\n",
        "        else:\n",
        "            self.memory.add_memory(f\"Turn to page {current_page+1} of the recommendation.\"\n",
        "                , now=datetime.datetime.now())\n",
        "        #===========================\n",
        "\n",
        "        return reaction\n",
        "\n",
        "    def write_log(self, log, color=None, attrs=None, print=False):\n",
        "        with open(self.log_file, 'a') as f:\n",
        "            f.write(log + '\\n')\n",
        "            f.flush()\n",
        "        if(print):\n",
        "            cprint(log, color=color, attrs=attrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAgaNIY30zpx"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.append(sys.path[0] + \"/recommenders\")\n",
        "sys.path.remove(sys.path[0] + \"/recommenders\")\n",
        "\n",
        "class abstract_arena:\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.data_path = args.data_path\n",
        "        self.dataset = args.dataset\n",
        "        self.val_users = args.val_users\n",
        "        self.val_ratio = args.val_ratio\n",
        "        self.simulation_name = args.simulation_name\n",
        "        self.device = torch.device('cpu')\n",
        "        self.n_avatars = args.n_avatars\n",
        "        self.modeltype = args.modeltype\n",
        "        self.items_per_page = args.items_per_page\n",
        "        self.execution_mode = args.execution_mode\n",
        "        self.rec_gt = args.rec_gt\n",
        "        self.model_path = \"recommenders/weights/\" + args.dataset + \"/\" + args.modeltype + \"/\" + args.model_path\n",
        "\n",
        "        # self.model_path = \"recommenders/weights/\" + args.dataset + \"/\" + args.modeltype + \"/\" + args.model_path\n",
        "        print(\"============================\")\n",
        "        print(self.model_path)\n",
        "\n",
        "    def excute(self):\n",
        "        \"\"\"\n",
        "        The whole process of the simulation\n",
        "        \"\"\"\n",
        "        self.load_saved_args(self.model_path)\n",
        "        self.prepare_dir()\n",
        "        self.load_data()\n",
        "        self.load_recommender()\n",
        "        self.initialize_all_avatars()\n",
        "        self.get_full_rankings()\n",
        "        self.load_additional_info()\n",
        "        if (self.val_users):\n",
        "            self.validate_all_avatars()\n",
        "        else:\n",
        "            self.simulate_all_avatars()\n",
        "            # self.save_results()\n",
        "\n",
        "    def load_saved_args(self, model_path):\n",
        "        \"\"\"\n",
        "        load the recommender args, which is saved when training the recommender\n",
        "        \"\"\"\n",
        "        self.saved_args = Namespace()\n",
        "        # If the path exists, read.\n",
        "        if(os.path.exists(model_path + '/args.txt')):\n",
        "            with open(model_path + '/args.txt', 'r') as f:\n",
        "                self.saved_args.__dict__ = json.load(f)\n",
        "        else:\n",
        "            with open(\"recommenders/weights/default_args.txt\", 'r') as f:\n",
        "                self.saved_args.__dict__ = json.load(f)\n",
        "        # View current directory.\n",
        "        # self.saved_args.data_path = 'datasets/' # Modify the table of contents.\n",
        "        self.saved_args.data_path = self.data_path\n",
        "        self.saved_args.dataset = self.dataset\n",
        "        self.saved_args.cuda = self.args.cuda\n",
        "        self.saved_args.modeltype = self.modeltype\n",
        "        # self.saved_args.nodrop = self.args.nodrop\n",
        "\n",
        "    def prepare_dir(self):\n",
        "        # make dir\n",
        "        def ensureDir(dir_path):\n",
        "            if not os.path.exists(dir_path):\n",
        "                os.makedirs(dir_path)\n",
        "        self.storage_base_path = f\"storage/{self.dataset}/{self.modeltype}/\" + self.simulation_name\n",
        "        ensureDir(self.storage_base_path)\n",
        "        # ensureDir(self.storage_base_path + \"/avatars\")\n",
        "        ensureDir(self.storage_base_path + \"/running_logs\")\n",
        "        ensureDir(self.storage_base_path + \"/rankings\")\n",
        "        # ensureDir(self.storage_base_path + \"/new_train\")\n",
        "        if os.path.exists(self.storage_base_path + \"/system_log.txt\"):\n",
        "            os.remove(self.storage_base_path + \"/system_log.txt\")\n",
        "\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        load the data for simulation\n",
        "        \"\"\"\n",
        "        sys.path.append(sys.path[0] + \"/recommenders\")\n",
        "        try:\n",
        "            exec('from recommenders.models.'+ self.saved_args.modeltype + ' import ' + self.saved_args.modeltype + '_Data') # load special dataset\n",
        "            print('from recommenders.models.'+ self.saved_args.modeltype + ' import ' + self.saved_args.modeltype + '_Data')\n",
        "            self.data = eval(self.saved_args.modeltype + '_Data(self.saved_args)')\n",
        "        except:\n",
        "            print(\"no special dataset\")\n",
        "            self.data = Data(self.saved_args) # load data from the path\n",
        "            print(\"finish loading data\")\n",
        "        sys.path.remove(sys.path[0] + \"/recommenders\")\n",
        "        # import pickle\n",
        "        # with open(f'datasets/{self.dataset}/simulation/movie_dict.pkl', 'rb') as f:\n",
        "        #     self.movie_detail = pickle.load(f)\n",
        "        # self.movie_detail = pd.read_csv(f'{self.dataset}/simulation/book_detail.csv')\n",
        "        self.movie_detail = pd.read_csv(f'{self.data_path}/{self.dataset}/book_detail.csv')\n",
        "\n",
        "    def load_recommender(self):\n",
        "        \"\"\"\n",
        "        load the recommender for simulation\n",
        "        \"\"\"\n",
        "        sys.path.append(sys.path[0] + \"/recommenders\")\n",
        "        self.running_model = self.saved_args.modeltype\n",
        "        # exec('from recommenders.models.'+ self.saved_args.modeltype + ' import ' + self.running_model) # import the model first\n",
        "        exec(self.running_model) # import the model first\n",
        "        self.model = eval(self.running_model + '(self.saved_args, self.data)') # initialize the model with the graph\n",
        "        print(\"finish generating recommender\")\n",
        "        sys.path.remove(sys.path[0] + \"/recommenders\")\n",
        "\n",
        "        # load the checkpoint\n",
        "        def restore_checkpoint(model, checkpoint_dir, device):\n",
        "            \"\"\"\n",
        "            If a checkpoint exists, restores the PyTorch model from the checkpoint.\n",
        "            Returns the model and the current epoch.\n",
        "            \"\"\"\n",
        "            cp_files = [file_ for file_ in os.listdir(checkpoint_dir)\n",
        "                        if file_.startswith('epoch=') and file_.endswith('.checkpoint.pth.tar')]\n",
        "            if not cp_files:\n",
        "                print('No saved model parameters found')\n",
        "            epoch_list = []\n",
        "            regex = re.compile(r'\\d+')\n",
        "            for cp in cp_files:\n",
        "                epoch_list.append([int(x) for x in regex.findall(cp)][0])\n",
        "            loading_epoch = max(epoch_list)\n",
        "\n",
        "            filename = os.path.join(checkpoint_dir,\n",
        "                                    'epoch={}.checkpoint.pth.tar'.format(loading_epoch))\n",
        "            # print(\"Loading from checkpoint {}?\".format(filename))\n",
        "\n",
        "            checkpoint = torch.load(filename, map_location = str(device))\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            print(\"=> Successfully restored checkpoint (trained for {} epochs)\"\n",
        "                    .format(checkpoint['epoch']))\n",
        "\n",
        "            return model, loading_epoch\n",
        "\n",
        "        if(self.args.modeltype != \"Random\" and self.args.modeltype != \"Pop\"):\n",
        "            print(\"loading checkpoint\")\n",
        "            self.model, self.loading_epoch = restore_checkpoint(self.model, self.model_path, self.device) # restore the checkpoint\n",
        "        # self.model, self.loading_epoch = restore_checkpoint(self.model, self.model_path, self.device) # restore the checkpoint\n",
        "\n",
        "    def get_full_rankings(self, filename = \"full_rankings\", batch_size = 512):\n",
        "        \"\"\"\n",
        "        document the full rankings of the items,\n",
        "        according to a specific cf model\n",
        "        \"\"\"\n",
        "        # if(os.path.exists(self.storage_base_path + '/{}_{}.npy'.format(filename, self.n_avatars))):\n",
        "        #     print(\"loading full rankings from storage\")\n",
        "        #     self.full_rankings = np.load(self.storage_base_path + '/{}_{}.npy'.format(filename, self.n_avatars))\n",
        "        #     print(\"finish loading full rankings\")\n",
        "        #     print(type(self.full_rankings))\n",
        "        # else:\n",
        "        # dump_dict = merge_user_list([self.data.train_user_list,self.data.valid_user_list])\n",
        "        print(\"nodrop?\", self.data.nodrop)\n",
        "        # @ Use valid data for simulation.\n",
        "        if(self.data.nodrop):\n",
        "            dump_dict = merge_user_list([self.data.train_nodrop_user_list, self.data.test_user_list])\n",
        "        else:\n",
        "            dump_dict = merge_user_list([self.data.train_user_list, self.data.test_user_list])\n",
        "        # dump_dict = merge_user_list([self.data.train_user_list, self.data.test_user_list])\n",
        "        score_matrix = np.zeros((len(self.simulated_avatars_id), self.data.n_items))\n",
        "        simulated_avatars_iter = DataIterator(self.simulated_avatars_id, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "        for batch_id, batch_users in tqdm(enumerate(simulated_avatars_iter)):\n",
        "            ranking_score = self.model.predict(batch_users, None)  # (B,N)\n",
        "            if not is_ndarray(ranking_score, float_type):\n",
        "                ranking_score = np.array(ranking_score, dtype=float_type)\n",
        "            # set the ranking scores of training items to -inf,\n",
        "            # then the training items will be sorted at the end of the ranking list.\n",
        "\n",
        "            for idx, user in enumerate(batch_users):\n",
        "                dump_items = dump_dict[user]\n",
        "                # dump_items = [ x for x in dump_items if not x in self.data.test_user_list[user] ]\n",
        "                ranking_score[idx][dump_items] = -np.inf\n",
        "\n",
        "                score_matrix[batch_id*batch_size+idx] = ranking_score[idx]\n",
        "\n",
        "            print('finish recommend one batch', batch_id)\n",
        "            # break\n",
        "\n",
        "        print('finish generating score matrix')\n",
        "        self.full_rankings = np.argsort(-score_matrix, axis=1)\n",
        "        if(self.rec_gt):\n",
        "            # for user in self.simulated_avatars_id:\n",
        "            #     for idx, item in enumerate(self.data.train_user_list[user]):\n",
        "            #         self.full_rankings[user][idx] = item\n",
        "            gt_dict = pd.read_pickle('scripts/user_ground_truth.pkl')\n",
        "            for user in self.simulated_avatars_id:\n",
        "                for idx, item in enumerate(gt_dict[user]):\n",
        "                    self.full_rankings[user][idx] = item\n",
        "        np.save(self.storage_base_path + '/rankings/' + '/{}_{}.npy'.format(filename, self.n_avatars), self.full_rankings)\n",
        "\n",
        "        print('finish get full rankings')\n",
        "\n",
        "    def initialize_all_avatars(self):\n",
        "        \"\"\"\n",
        "        initialize all avatars\n",
        "        \"\"\"\n",
        "        # all_avatars = sorted(list(self.data.test_user_list.keys()))\n",
        "        # self.simulated_avatars_id = all_avatars[:self.n_avatars]\n",
        "        self.simulated_avatars_id = list(range(self.n_avatars))\n",
        "        # print('simulated avatars', self.simulated_avatars_id)\n",
        "        # self.simulated_avatars_id = sorted(random.sample(all_avatars, self.n_avatars))\n",
        "\n",
        "    def page_generator(self):\n",
        "        \"\"\"\n",
        "        generate one page items for one avatar\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def validate_all_avatars(self):\n",
        "        \"\"\"\n",
        "        validate the users\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def simulate_all_avatars(self):\n",
        "        \"\"\"\n",
        "        excute the simulation for all avatars\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def simulate_one_avatar(self):\n",
        "        \"\"\"\n",
        "        excute the simulation for one avatar\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"\n",
        "        save the results of the simulation\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def load_additional_info(self):\n",
        "        \"\"\"\n",
        "        load additional information for the simulation\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6OBGz6V6CGX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from scipy.stats import spearmanr\n",
        "from collections import defaultdict\n",
        "\n",
        "def calculate_entropy(movie_types):\n",
        "    type_freq = {}\n",
        "    for movie_type in movie_types:\n",
        "        if movie_type in type_freq:\n",
        "            type_freq[movie_type] += 1\n",
        "        else:\n",
        "            type_freq[movie_type] = 1\n",
        "\n",
        "    total_movies = len(movie_types)\n",
        "\n",
        "    entropy = 0\n",
        "    for key in type_freq:\n",
        "        prob = type_freq[key] / total_movies\n",
        "        entropy -= prob * math.log2(prob)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def get_entropy(inters, data):\n",
        "    genres = data.get_genres_by_id(inters)\n",
        "    entropy = calculate_entropy(genres)\n",
        "    return entropy\n",
        "\n",
        "class evaluator_data:\n",
        "    \"\"\"\n",
        "    Data class for loading data from local files.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.items = {}\n",
        "        self.users = {}\n",
        "        self.db = None\n",
        "        self.tot_relationship_num = 0\n",
        "        self.netwerk_density = 0.0\n",
        "        self.role_id = -1\n",
        "        self.interrating = {}\n",
        "        self.user_ratings = {}\n",
        "        self.item_ratings = {}\n",
        "        self.load_items()\n",
        "        self.load_users()\n",
        "        self.load_interactions_rating()\n",
        "\n",
        "    def load_items(self):\n",
        "        \"\"\"\n",
        "        Load items from local file.\n",
        "        \"\"\"\n",
        "        file_path = \"book_detail.csv\"\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                item_id, title, genre, rating = row\n",
        "                self.items[int(item_id)] = {\n",
        "                    \"name\": title.strip(),\n",
        "                    \"genre\": genre,\n",
        "                    \"historical rating\": float(rating),\n",
        "                    \"inter_cnt\": 0,\n",
        "                    \"mention_cnt\": 0,\n",
        "                }\n",
        "\n",
        "    def load_users(self):\n",
        "        \"\"\"\n",
        "        Load users from local file.\n",
        "        \"\"\"\n",
        "        file_path = \"user_statistic.csv\"\n",
        "        cnt = 1\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                # print(len(row), row)\n",
        "                user_id, activity,\tdiversity,\tconformity  = row\n",
        "                # user_id, name, gender, age, status, pos, neg = row\n",
        "                self.users[cnt] = {\n",
        "                    \"activity\": activity,\n",
        "                    \"diversity\": diversity,\n",
        "                    \"conformity\": conformity\n",
        "                }\n",
        "                cnt += 1\n",
        "\n",
        "    def load_interactions_rating(self):\n",
        "      \"\"\"\n",
        "      Load user-item interactions (with rating) from local file.\n",
        "      Stores in self.interrating as a dict:\n",
        "      {user_id: [(item_id, rating), ...], ...}\n",
        "      \"\"\"\n",
        "      file_path = \"/content/drive/MyDrive/S4065511/data/RecAgent/Movielens-1M/agent4rec/mapped_ratings.csv\"\n",
        "      with open(file_path, \"r\", newline=\"\") as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader)  # Skip the header line\n",
        "        for row in reader:\n",
        "            user_id, item_id, rating = row\n",
        "            user_id = int(user_id)\n",
        "            item_id = int(item_id)\n",
        "            rating = int(rating)\n",
        "            if user_id not in self.interrating:\n",
        "                self.interrating[user_id] = []\n",
        "            self.interrating[user_id].append((item_id, rating))\n",
        "\n",
        "            if user_id not in self.user_ratings:\n",
        "                self.user_ratings[user_id] = []\n",
        "            self.user_ratings[user_id].append(rating)\n",
        "\n",
        "            # Store item rating\n",
        "            if item_id not in self.item_ratings:\n",
        "                self.item_ratings[item_id] = []\n",
        "            self.item_ratings[item_id].append(rating)\n",
        "\n",
        "      # Compute and store average historical rating for each user\n",
        "      self.user_avg_rating = {uid: sum(ratings)/len(ratings) for uid, ratings in self.user_ratings.items() if ratings}\n",
        "\n",
        "      # Compute and store average historical rating for each item\n",
        "      self.item_avg_rating = {iid: sum(ratings)/len(ratings) for iid, ratings in self.item_ratings.items() if ratings}\n",
        "\n",
        "\n",
        "    def get_full_items(self):\n",
        "        return list(self.items.keys())\n",
        "\n",
        "    def get_inter_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of interactions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"inter_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def add_inter_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        print(\"item ids:\", item_ids)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"inter_cnt\"] += 1\n",
        "\n",
        "    def add_mention_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"mention_cnt\"] += 1\n",
        "\n",
        "    def get_mention_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of mentions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"mention_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def get_item_names(self, item_ids):\n",
        "        return [\"<\" + self.items[item_id][\"name\"] + \">\" for item_id in item_ids]\n",
        "\n",
        "    def get_item_ids(self, item_names):\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] in item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_item_ids_exact(self, item_names):\n",
        "        \"\"\"\n",
        "        Get item ids from item names.\n",
        "        I coundn't find any difference with the get_item_ids(item_names) function\n",
        "        \"\"\"\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] == item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_full_users(self):\n",
        "        return list(self.users.keys())\n",
        "\n",
        "    def get_user_names(self, user_ids):\n",
        "        return [self.users[user_id][\"name\"] for user_id in user_ids]\n",
        "\n",
        "    def get_user_ids(self, user_names):\n",
        "        user_ids = []\n",
        "        for user in user_names:\n",
        "            for user_id, user_info in self.users.items():\n",
        "                if user_info[\"name\"] == user:\n",
        "                    user_ids.append(user_id)\n",
        "                    break\n",
        "        return user_ids\n",
        "\n",
        "    def get_user_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of users.\n",
        "        \"\"\"\n",
        "        return len(self.users.keys())\n",
        "\n",
        "    def get_item_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of items.\n",
        "        \"\"\"\n",
        "        return len(self.items.keys())\n",
        "\n",
        "    def search_items(self, item, k=50):\n",
        "        \"\"\"\n",
        "        Search similar items from faiss db.\n",
        "        Args:\n",
        "            item: str, item name\n",
        "            k: int, number of similar items to return\n",
        "        \"\"\"\n",
        "        docs = self.db.similarity_search(item, k)\n",
        "        item_names = [doc.page_content for doc in docs]\n",
        "        return item_names\n",
        "\n",
        "    def get_genres_by_id(self, item_ids):\n",
        "        \"\"\"\n",
        "        Get genre of items by item id.\n",
        "        \"\"\"\n",
        "        # return [self.items[item_id][\"genre\"] for item_id in item_ids]\n",
        "        return [\n",
        "            genre\n",
        "            for item_id in item_ids\n",
        "            for genre in self.items[item_id][\"genre\"].split('|')\n",
        "        ]\n",
        "\n",
        "    def hit_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Return 1 if any of the top-k predicted are relevant, else 0.\"\"\"\n",
        "        return int(bool(set(ground_truth) & set(predicted[:k])))\n",
        "\n",
        "    def ndcg_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Compute NDCG@k for a single user.\"\"\"\n",
        "        def dcg(rel):\n",
        "          return np.sum([(2**r - 1) / np.log2(i + 2) for i, r in enumerate(rel)])\n",
        "\n",
        "        rel = [1 if item in ground_truth else 0 for item in predicted[:k]]\n",
        "        ideal_rel = sorted([1]*min(len(ground_truth), k) + [0]*(k - min(len(ground_truth), k)), reverse=True)\n",
        "        dcg_score = dcg(rel)\n",
        "        idcg_score = dcg(ideal_rel)\n",
        "        return dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
        "\n",
        "    def mse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute MSE for ratings (on items in both sets).\"\"\"\n",
        "        if items is None:\n",
        "           items = set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        else:\n",
        "           items = set(items) & set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        if not items:\n",
        "           return np.nan\n",
        "        errors = [(ground_truth_ratings[i] - predicted_ratings[i]) ** 2 for i in items]\n",
        "        return np.mean(errors)\n",
        "\n",
        "    def rmse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute RMSE for ratings.\"\"\"\n",
        "        return np.sqrt(self.mse(ground_truth_ratings, predicted_ratings, items))\n",
        "\n",
        "    def safe_log(self, x):\n",
        "        \"\"\"Numerically safe log.\"\"\"\n",
        "        return math.log(max(x, 1e-15))\n",
        "\n",
        "    def ordered_probit_probs(self, pred_int, K, taus=None):\n",
        "        \"\"\"\n",
        "        Compute ordered probit class probabilities for a predicted integer rating.\n",
        "\n",
        "        pred_int : int\n",
        "            The predicted integer rating (e.g., 1..K).\n",
        "        K : int\n",
        "            Number of rating classes (e.g., 5 for 15 stars).\n",
        "        taus : list or array, optional\n",
        "            Thresholds separating the ordered categories.\n",
        "            If None, uses equally spaced thresholds [1.5, 2.5, ..., K-0.5].\n",
        "        \"\"\"\n",
        "\n",
        "        if taus is None:\n",
        "           taus = np.array([1.5 + i for i in range(K-1)])  # default thresholds\n",
        "\n",
        "        assert len(taus) == K-1\n",
        "\n",
        "        def Phi(z):\n",
        "            return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))  # Normal CDF\n",
        "\n",
        "        probs = []\n",
        "        for k in range(1, K+1):\n",
        "           if k == 1:\n",
        "              lower = -np.inf\n",
        "              upper = taus[0]\n",
        "           elif k == K:\n",
        "              lower = taus[-1]\n",
        "              upper = np.inf\n",
        "           else:\n",
        "              lower = taus[k-2]\n",
        "              upper = taus[k-1]\n",
        "           p_lower = 0.0 if lower == -np.inf else Phi((lower - pred_int))\n",
        "           p_upper = 1.0 if upper == np.inf else Phi((upper - pred_int))\n",
        "           probs.append(max(p_upper - p_lower, 1e-15))\n",
        "\n",
        "        probs = np.array(probs)\n",
        "        probs /= probs.sum()  # normalize\n",
        "        return probs\n",
        "\n",
        "\n",
        "class EvaluatorRS:\n",
        "\n",
        "    def __init__(self, evaluator_data):\n",
        "        self.data = evaluator_data\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.record = {}\n",
        "        self.round_record = {}\n",
        "        self.positive = {}\n",
        "        self.interaction_dict = {}\n",
        "        self.inter_df = None\n",
        "        self.inter_num = 0\n",
        "        for user in self.data.get_full_users():\n",
        "            self.record[user] = []\n",
        "            self.positive[user] = []\n",
        "            self.round_record[user] = []\n",
        "        self.user_data = {\n",
        "            \"user\": [],\n",
        "            \"N_expose\": [],\n",
        "            \"N_view\": [],\n",
        "            \"N_like\": [],\n",
        "            \"N_exit\": [],\n",
        "            \"S_sat\": []\n",
        "            }\n",
        "        self.rating_feeling = {\n",
        "            \"User\": [],\n",
        "            \"Rating\": [],\n",
        "            \"Feelings\": []\n",
        "        }\n",
        "\n",
        "        # Store user interactions\n",
        "        self.user_directory = defaultdict(list)\n",
        "\n",
        "    def add_interaction(self, user_id, page, recommended, rated):\n",
        "        self.user_directory[user_id].append({\n",
        "        \"page\": page,\n",
        "        \"recommended_id\": recommended,\n",
        "        \"rated_id\": rated\n",
        "        })\n",
        "\n",
        "    def ordered_probit_loglik(self, y_true, y_pred_int, K=5, taus=None):\n",
        "        \"\"\"\n",
        "        Compute log-likelihood for ordered probit model given integer predictions.\n",
        "\n",
        "        y_true : list or array\n",
        "           True ratings (1..K).\n",
        "        y_pred_int : list or array\n",
        "           Predicted integer ratings (1..K).\n",
        "        K : int\n",
        "           Number of rating categories (default 5).\n",
        "        taus : list or array, optional\n",
        "           Thresholds (default: equally spaced).\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(y_true) == len(y_pred_int), \"Mismatch in true vs predicted length\"\n",
        "        ll = 0.0\n",
        "        for t, p in zip(y_true, y_pred_int):\n",
        "           probs = self.data.ordered_probit_probs(p, K, taus)\n",
        "           ll += self.data.safe_log(probs[t-1])  # subtract 1 for 0-based index\n",
        "        avg_ll = ll / len(y_true)\n",
        "        return ll, avg_ll\n",
        "\n",
        "    def update_user_interactions(self, user_id, new_items):\n",
        "        \"\"\"\n",
        "        Updates the directory of user_id and interacted_items.\n",
        "        - interaction_dict: dict mapping user_id -> set of interacted item ids\n",
        "        - user_id: int or str\n",
        "        - new_items: iterable of item ids (list, set, etc)\n",
        "\n",
        "        After calling, interaction_dict[user_id] contains all unique interacted items.\n",
        "        \"\"\"\n",
        "        # Ensure the user's interaction set exists\n",
        "        if user_id not in self.interaction_dict:\n",
        "          self.interaction_dict[user_id] = set()\n",
        "\n",
        "        new_items = set(new_items) - self.interaction_dict[user_id]\n",
        "        self.interaction_dict[user_id].update(new_items)\n",
        "\n",
        "    def save_interaction(self):\n",
        "        \"\"\"\n",
        "        Save the interaction history to a csv file.\n",
        "        \"\"\"\n",
        "        inters = []\n",
        "        users = self.data.get_full_users()\n",
        "        for user in users:\n",
        "            for item in self.positive[user]:\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 1}\n",
        "                inters.append(new_row)\n",
        "\n",
        "            for item in self.record[user]:\n",
        "                if item in self.positive[user]:\n",
        "                    continue\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 0}\n",
        "                inters.append(new_row)\n",
        "\n",
        "        df = pd.DataFrame(inters)\n",
        "        df.to_csv(\n",
        "            self.config[\"interaction_path\"],\n",
        "            index=False,\n",
        "        )\n",
        "\n",
        "        self.inter_df = df\n",
        "\n",
        "    def add_user(self, user_id, N_expose, N_view, N_like, N_exit, S_sat):\n",
        "        self.user_data[\"user\"].append(user_id)\n",
        "        self.user_data[\"N_expose\"].append(N_expose)\n",
        "        self.user_data[\"N_view\"].append(N_view)\n",
        "        self.user_data[\"N_like\"].append(N_like)\n",
        "        self.user_data[\"N_exit\"].append(N_exit)\n",
        "        self.user_data[\"S_sat\"].append(S_sat)\n",
        "\n",
        "    def add_review(self, user_id, rating, feelings):\n",
        "        self.rating_feeling[\"User\"].append(user_id)\n",
        "        self.rating_feeling[\"Rating\"].append(rating)\n",
        "        self.rating_feeling[\"Feelings\"].append(feelings)\n",
        "\n",
        "    def satisfaction_metrics(self):\n",
        "        sm_df = pd.DataFrame(self.user_data)\n",
        "        if len(sm_df) == 0:\n",
        "           return None  # no data yet\n",
        "\n",
        "        metrics = {}\n",
        "        sm_df[\"view_ratio\"] = sm_df[\"N_view\"] / sm_df[\"N_expose\"]\n",
        "        sm_df[\"like_ratio\"] = sm_df[\"N_like\"] / sm_df[\"N_expose\"]\n",
        "\n",
        "        metrics[\"P_view\"] = sm_df[\"view_ratio\"].mean()\n",
        "        metrics[\"N_like\"] = sm_df[\"N_like\"].mean()\n",
        "        metrics[\"P_like\"] = sm_df[\"like_ratio\"].mean()\n",
        "        metrics[\"N_exit\"] = sm_df[\"N_exit\"].mean()\n",
        "        metrics[\"S_sat\"] = sm_df[\"S_sat\"].mean()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_entropy(\n",
        "        self,\n",
        "    ):\n",
        "        tot_entropy = 0\n",
        "        for user in self.record.keys():\n",
        "            inters = self.record[user]\n",
        "            genres = self.data.get_genres_by_id(inters)\n",
        "            entropy = calculate_entropy(genres)\n",
        "            tot_entropy += entropy\n",
        "\n",
        "        return tot_entropy / len(self.record.keys())\n",
        "\n",
        "    def calculate_user_metrics(\n",
        "        self, user_id, sim_recommended, all_items, threshold = 3):\n",
        "        \"\"\"\n",
        "        Evaluate precision, recall, (optionally real) accuracy, and F1 for a single user.\n",
        "\n",
        "        Returns:\n",
        "            dict: { 'precision': float, 'recall': float, 'accuracy': float, 'f1': float }\n",
        "        \"\"\"\n",
        "\n",
        "        if user_id not in self.data.interrating:\n",
        "           print(\"User not found in interrating\")\n",
        "           return {'precision': 0, 'recall': 0, 'accuracy': 0, 'f1': 0}\n",
        "\n",
        "\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= threshold and item in all_items)\n",
        "        sim_recommended = set(sim_recommended)\n",
        "        all_items = set(all_items)\n",
        "\n",
        "        TP = len(gt_relevant & sim_recommended)\n",
        "        FP = len(sim_recommended - gt_relevant)\n",
        "        FN = len(gt_relevant - sim_recommended)\n",
        "        TN = len(all_items - (gt_relevant | sim_recommended))\n",
        "\n",
        "        precision = TP / (TP + FP) if (TP + FP) else 0.0\n",
        "        recall = TP / (TP + FN) if (TP + FN) else 0.0\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0.0\n",
        "        accuracy = (TP + TN) / len(all_items) if all_items else 0\n",
        "\n",
        "        print(\"precision:\", precision, \"recall:\", recall, \"accuracy:\", accuracy, \"f1:\", f1)\n",
        "        return precision, recall, accuracy, f1\n",
        "\n",
        "    def precisionandrecallk(\n",
        "        self, user_id, recommended, k):\n",
        "        if user_id not in self.data.interrating:\n",
        "           return {'precision_at_k': 0, 'recall_at_k': 0}\n",
        "\n",
        "        sim_recommended = list(dict.fromkeys(recommended))\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= 3)\n",
        "        recommended_at_k = sim_recommended[:k]\n",
        "        hits = sum([1 for item in recommended_at_k if item in gt_relevant])\n",
        "        precision_at_k = hits / k\n",
        "        recall_at_k = hits / len(gt_relevant) if gt_relevant else 0\n",
        "        return precision_at_k, recall_at_k\n",
        "\n",
        "\n",
        "\n",
        "    def calculation_of_rating(self, user_id, item_id, book_rating):\n",
        "        # item_ids = self.data.get_item_ids([item_names])\n",
        "        if user_id in self.data.interrating:\n",
        "           # Check for item in user's ratings\n",
        "           for (itm, rating) in self.data.interrating[user_id]:\n",
        "               if itm == item_id:\n",
        "                  return (rating, book_rating)\n",
        "\n",
        "        # If not found\n",
        "        return (0, book_rating)\n",
        "\n",
        "\n",
        "    def calc_mse_rmse_rating_percentages(self, rating_pairs):\n",
        "\n",
        "        print(\"Incoming rating_pairs:\", rating_pairs[:20])  # show first 20 pairs\n",
        "        print(\"Total pairs:\", len(rating_pairs))\n",
        "\n",
        "        # Remove pairs with zero in ground truth or predicted rating\n",
        "        filtered_pairs = [(gt, pred) for gt, pred in rating_pairs\n",
        "                          if int(gt) != 0]\n",
        "\n",
        "        print(\"After filtering:\", filtered_pairs[:20])\n",
        "        print(\"Remaining pairs:\", len(filtered_pairs))\n",
        "\n",
        "        if not filtered_pairs:\n",
        "           # No valid data after filtering\n",
        "           return None, None, {}, {}, None, None, None\n",
        "\n",
        "        # Convert ratings to int\n",
        "        gt = [int(gt) for gt, pred in filtered_pairs]\n",
        "        pred = [int(pred) for gt, pred in filtered_pairs]\n",
        "        mse = np.mean([(g - p) ** 2 for g, p in zip(gt, pred)])\n",
        "        rmse = np.sqrt(mse)\n",
        "        loglike, ob_loglike = self.ordered_probit_loglik(gt, pred)\n",
        "        rho, p_value = spearmanr(gt, pred)\n",
        "\n",
        "        gt_count = Counter(gt)\n",
        "        pred_count = Counter(pred)\n",
        "        total = len(filtered_pairs)\n",
        "\n",
        "        gt_pct = {r: gt_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        pred_pct = {r: pred_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        return mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, rho\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZtlDMkk0zp4"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored, cprint\n",
        "import pandas as pd\n",
        "import os\n",
        "import os.path as op\n",
        "import json\n",
        "import asyncio\n",
        "\n",
        "import time\n",
        "import re\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nest_asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class Arena(abstract_arena):\n",
        "    def __init__(self, args):\n",
        "        super().__init__(args)\n",
        "\n",
        "\n",
        "        self.max_pages = args.max_pages\n",
        "        self.finished_num = 0\n",
        "        self.results_df = pd.DataFrame(columns=[\"User\", \"Predicted\", \"Ground Truth\"])\n",
        "        global global_k_tokens\n",
        "        global global_start_time\n",
        "        global global_steps\n",
        "        global global_last_tokens_record\n",
        "        global global_interval\n",
        "        global global_finished_users\n",
        "        global global_finished_pages\n",
        "        global global_error_cast\n",
        "        global lock\n",
        "        self.fulldata = evaluator_data()\n",
        "        self.recommenderevaluator = EvaluatorRS(self.fulldata)\n",
        "        self.pairs = []\n",
        "        self.user_history = {i: [] for i in range(0, self.n_avatars)}\n",
        "        self.user_interactions = {i: [] for i in range(0, self.n_avatars)}\n",
        "        self.user_item_list = {i: [] for i in range(0, self.n_avatars)}\n",
        "        self.av_hits = []\n",
        "        self.av_ndcg = []\n",
        "        self.hit = []\n",
        "        self.ndcg = []\n",
        "\n",
        "    def load_additional_info(self):\n",
        "\n",
        "        # self.user_profile_csv = pd.read_csv(f'{self.dataset}/raw_data/agg_top_25.csv')\n",
        "        self.user_profile_csv = pd.read_csv(f'{self.data_path}/{self.dataset}/agg_top_25.csv')\n",
        "\n",
        "        # return super().load_additional_info()\n",
        "        self.add_advert = self.args.add_advert\n",
        "        self.display_advert = self.args.display_advert\n",
        "        if(self.add_advert):\n",
        "            self.total_adverts, self.clicked_adverts = 0, 0\n",
        "            advert_pool = pd.read_pickle(f'{self.dataset}/simulation/advertisement_review.pkl')\n",
        "            advert_dict = {'all': {**advert_pool['pop_high_rating'], **advert_pool['pop_low_rating'], **advert_pool['unpop_high_rating'], **advert_pool['unpop_low_rating']},\n",
        "                        'pop_high':advert_pool['pop_high_rating'], 'pop_low':advert_pool['pop_low_rating'], 'unpop_high':advert_pool['unpop_high_rating'], 'unpop_low':advert_pool['unpop_low_rating']}\n",
        "            # print(self.args.advert_type)\n",
        "            self.advert = advert_dict[self.args.advert_type]\n",
        "            self.advert_word = \"The best movie you should not miss in your life! \"\n",
        "\n",
        "    def initialize_all_avatars(self):\n",
        "        \"\"\"\n",
        "        initialize avatars\n",
        "        \"\"\"\n",
        "        super().initialize_all_avatars()\n",
        "        # self.persona_df = pd.read_csv(f\"datasets/{self.dataset}/simulation/all_personas_like_information_house.csv\")\n",
        "        # self.persona_df = pd.read_csv(f\"{self.dataset}/simulation/all_personas_description_modify.csv\")\n",
        "        self.persona_df = pd.read_csv(f\"{self.data_path}/{self.dataset}/all_personas_description_modify.csv\")\n",
        "        # self.user_statistic = pd.read_csv(f'{self.dataset}/simulation/user_statistic.csv', index_col=0)\n",
        "        self.user_statistic = pd.read_csv(f'{self.data_path}/{self.dataset}/user_statistic.csv', index_col=0)\n",
        "        # @ avatars and evaluation indicators\n",
        "        self.avatars = {}\n",
        "        self.ratings = {}\n",
        "        self.new_train_dict = {}\n",
        "        self.exit_page = {}\n",
        "        self.perf_per_page = {}\n",
        "        self.watch = {}\n",
        "        self.n_likes = {}\n",
        "        self.remaining_users = list(range(self.n_avatars))\n",
        "\n",
        "        for avatar_id in self.simulated_avatars_id:\n",
        "            self.avatars[avatar_id] = Avatar(self.args, avatar_id, self.persona_df.loc[avatar_id], self.user_statistic.loc[avatar_id])\n",
        "            self.new_train_dict[avatar_id] = self.data.train_user_list[avatar_id]\n",
        "            self.ratings[avatar_id] = []\n",
        "            self.n_likes[avatar_id] = []\n",
        "            self.watch[avatar_id] = []\n",
        "            self.exit_page[avatar_id] = 0\n",
        "            self.perf_per_page[avatar_id] = []\n",
        "\n",
        "    def page_generator(self, avatar_id):\n",
        "        \"\"\"\n",
        "        generate one page items for one avatar\n",
        "        \"\"\"\n",
        "        i = 0\n",
        "        while (i+1)*self.items_per_page < self.data.n_items:\n",
        "            yield self.full_rankings[avatar_id][i*self.items_per_page:(i+1)*self.items_per_page]\n",
        "            i += 1\n",
        "\n",
        "    def validate_all_avatars(self):\n",
        "        global_start_time = time.time()\n",
        "        print(\"global start time\", global_start_time)\n",
        "        # self.precision_list = []\n",
        "        # self.recall_list = []\n",
        "        # self.accuracy_list = []\n",
        "        # self.f1_list = []\n",
        "        # self.rmse_list = []\n",
        "        # self.mae_list = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        accuracies = []\n",
        "        f1s = []\n",
        "        read = []\n",
        "\n",
        "        # initialize dictionaries to store values for each k\n",
        "        precision_scores = {1: [], 3: [], 5: [], 10: []}\n",
        "        recall_scores = {1: [], 3: [], 5: [], 10: []}\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        loop = asyncio.get_event_loop()\n",
        "        executor = ThreadPoolExecutor(max_workers=100)\n",
        "        tasks = []\n",
        "\n",
        "        t1 = time.time()\n",
        "        for avatar_id in self.simulated_avatars_id:\n",
        "            tasks.append(self.async_validate_one_avatar(avatar_id, loop, executor))\n",
        "        loop.run_until_complete(asyncio.wait(tasks))\n",
        "        t2 = time.time()\n",
        "        print(f\"Time cost: {t2-t1}s\")\n",
        "\n",
        "        for user_id in self.user_history:\n",
        "            # print(\"user: \", user)\n",
        "            # user_id = user + 1\n",
        "            # read_books = recsys.data.get_item_ids(user_history[user_id])\n",
        "            read_books = self.user_history[user_id]\n",
        "            # print(\"read books: \", read_books)\n",
        "            # print(\"read books length: \", len(read_books))\n",
        "            item_set = self.recommenderevaluator.interaction_dict.get(user_id, set())\n",
        "            all_item = list(item_set)\n",
        "            # print(\"all item: \", all_item)\n",
        "            # print(\"all item length: \", len(all_item))\n",
        "            precision, recall, accuracy, f1 = self.recommenderevaluator.calculate_user_metrics(user_id, read_books, all_item)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            accuracies.append(accuracy)\n",
        "            # read_list = recsys.data.get_item_ids(user_history[user_id])\n",
        "            read_list = self.user_history[user_id]\n",
        "            read.append(get_entropy(read_list, self.recommenderevaluator.data))\n",
        "            f1s.append(f1)\n",
        "            for k in [1, 3, 5, 10]:\n",
        "                precisonk, recallk = self.recommenderevaluator.precisionandrecallk(user_id, self.user_history[user_id], k)\n",
        "                print(f\"Precision@{k}: {precisonk}, Recall@{k}: {recallk}\")\n",
        "                precision_scores[k].append(precisonk)\n",
        "                recall_scores[k].append(recallk)\n",
        "\n",
        "        mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, spearman = self.recommenderevaluator.calc_mse_rmse_rating_percentages(self.pairs)\n",
        "\n",
        "\n",
        "        avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "        avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "        avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0\n",
        "        avg_f1 = sum(f1s) / len(f1s) if f1s else 0\n",
        "\n",
        "\n",
        "        round_summary = []\n",
        "        # print(\"User Directory: \", self.recommenderevaluator.user_directory)\n",
        "        for user, logs in self.recommenderevaluator.user_directory.items():\n",
        "            current_round = 1\n",
        "            prev_page = 0\n",
        "            round_pages = []\n",
        "            round_recommended = []\n",
        "            round_rated = []\n",
        "\n",
        "            for entry in logs:\n",
        "                page = entry[\"page\"]\n",
        "                # print(\"page\", page)\n",
        "\n",
        "                # Detect round reset (page goes back to 1)\n",
        "                if page <= prev_page:\n",
        "                    # Save previous round\n",
        "                    N_expose = len(round_recommended)\n",
        "                    N_view = len(round_rated)\n",
        "                    # NOTE: rated_id are item IDs, not ratings  adjust if ratings are available\n",
        "                    N_like = len([r for r in round_rated if r > 3])\n",
        "                    N_exit = len(round_pages)\n",
        "                    S_sat = 5\n",
        "\n",
        "                    self.recommenderevaluator.add_user(user, N_expose, N_view, N_like, N_exit, S_sat)\n",
        "\n",
        "                    # Start new round\n",
        "                    current_round += 1\n",
        "                    round_pages = []\n",
        "                    round_recommended = []\n",
        "                    round_rated = []\n",
        "                # Accumulate round data\n",
        "                round_pages.append(page)\n",
        "                round_recommended.extend(entry[\"recommended_id\"])\n",
        "                round_rated.extend(entry[\"rated_id\"])\n",
        "                prev_page = page\n",
        "            # Save the last round after loop\n",
        "            if round_pages:\n",
        "                N_expose = len(round_recommended)\n",
        "                N_view = len(round_rated)\n",
        "                N_like = len([r for r in round_rated if r > 3])  # adjust if ratings exist\n",
        "                N_exit = len(round_pages)\n",
        "                S_sat = 5\n",
        "\n",
        "\n",
        "                self.recommenderevaluator.add_user(user, N_expose, N_view, N_like, N_exit, S_sat)\n",
        "\n",
        "        metrics = self.recommenderevaluator.satisfaction_metrics()\n",
        "        print(\"Total Satisfaction Metrics (Pview, Nlike, Plike, Nexit, Ssat):\", metrics)\n",
        "        # calculate averages\n",
        "        for k in [1, 3, 5, 10]:\n",
        "            mavg_precision = np.mean(precision_scores[k])\n",
        "            mavg_recall = np.mean(recall_scores[k])\n",
        "            print(f\"Average Precision@{k}: {mavg_precision:.4f}, Average Recall@{k}: {mavg_recall:.4f}\")\n",
        "\n",
        "        # with open(self.storage_base_path + \"/validation_metrics.txt\", 'w') as f:\n",
        "        #     f.write(f\"Total simulation time: {round(time.time() - self.start_time, 2)}s\\n\")\n",
        "        #     f.write(f\"n_avatars: {self.n_avatars}\\n\")\n",
        "        #     f.write(f\"Average precision: {np.mean(self.precision_list)}\\n\")\n",
        "        #     f.write(f\"Average recall: {np.mean(self.recall_list)}\\n\")\n",
        "        #     f.write(f\"Average accuracy: {np.mean(self.accuracy_list)}\\n\")\n",
        "        #     f.write(f\"Average f1: {np.mean(self.f1_list)}\\n\")\n",
        "\n",
        "    async def async_validate_one_avatar(self, avatar_id, loop, executor):\n",
        "        \"\"\"\n",
        "        async\n",
        "        validate the effectiveness of the model for one avatar\n",
        "        avatar_id: the id of the simulated avatar\n",
        "        \"\"\"\n",
        "        avatar_ = self.avatars[avatar_id]\n",
        "        train_list, val_list, test_list = self.data.train_user_list[avatar_id], self.data.valid_user_list[avatar_id], self.data.test_user_list[avatar_id]\n",
        "\n",
        "        # Take the union for calculating precision.\n",
        "        all_items = list(range(self.data.n_items))\n",
        "        observed_items = list(set(train_list) | set(val_list) | set(test_list))\n",
        "        selection_candidates = list(set(val_list) | set(test_list))\n",
        "        unobserved_items = list(set(all_items) - set(observed_items))\n",
        "        # Pick 5 randomly from the test_list.\n",
        "        min_val = min(len(selection_candidates), 10//(self.val_ratio+1))\n",
        "\n",
        "\n",
        "        test_observed_items = np.random.choice(selection_candidates, int(min_val), replace=False)\n",
        "        print(\"x = \", len(test_observed_items))\n",
        "        test_unobserved_items = np.random.choice(unobserved_items, int(min_val*self.val_ratio), replace=False)\n",
        "        print(\"y = \", len(test_unobserved_items))\n",
        "\n",
        "        forced_items_ids = np.concatenate((test_observed_items, test_unobserved_items))\n",
        "        print(\"x + y = \", len(forced_items_ids))\n",
        "        # Randomly shuffle.\n",
        "        np.random.shuffle(forced_items_ids)\n",
        "\n",
        "        forced_items = [self.movie_detail.loc[idx] for idx in forced_items_ids]\n",
        "\n",
        "        truth_tmp = [self.movie_detail.loc[idx] for idx in test_observed_items]\n",
        "        truth_list = [\"<- Movie Title: \" + item.title + \" ->\"\n",
        "                            + \" <- History ratings:\" + str(round(item.rating, 2)) + \" ->\" + \"\\n\"\n",
        "                            for item in truth_tmp]\n",
        "        truth_str = ''.join(truth_list)\n",
        "        cprint(truth_str, color='white', attrs=['bold'])\n",
        "\n",
        "        recommended_items = [\"<- Movie Title: \" + item.title + \" ->\"\n",
        "                            + \" <- History ratings:\" + str(round(item.rating, 2)) + \" ->\" + \"\\n\"\n",
        "                            for item in forced_items]\n",
        "        recommended_items_str = ''.join(recommended_items)\n",
        "\n",
        "        response = await loop.run_in_executor(executor, avatar_.reaction_to_forced_items, recommended_items_str)\n",
        "        cprint(response, color='yellow', attrs=None)\n",
        "\n",
        "        # pattern = re.compile(r'BOOKT:\\s*(.*?)\\s* BOOKA:\\s*(.*?)\\s* BOOKP:\\s*(.*?)\\s* WATCH:\\s*(.*?)\\s* REASON:\\s*(.*?)\\s*')\n",
        "        pattern = re.compile(r'''MOVIE:\\s*(.*?)\\s*;\\s*WATCH:\\s*(.*?)\\s*;\\s*REASON:\\s*(.*?)(?:;\\s*|$)(?:RATING:\\s*(\\d+)\\s*;\\s*)?''', re.VERBOSE | re.DOTALL)\n",
        "        matches = re.findall(pattern, response)\n",
        "        # pattern = re.compile(r'BOOK:\\s*(.*?)\\s* READ:\\s*(.*?);\\s*REASON:\\s*(.*?)(?:\\n|$)\\s*RATING:\\s*(.*?')\n",
        "        # matches = re.findall(pattern, response)\n",
        "\n",
        "        # print(matches[:len(forced_items)])\n",
        "        # watched_movies = [(movie_title.strip(';')) for movie_title, watch, reason in matches if (watch.strip(';') == 'yes')]\n",
        "        like_movies = [(idx, book.strip(';'), rating) for idx, (book, read, reason, rating) in enumerate(matches[:len(forced_items)]) if read.strip().lower() == 'yes']\n",
        "        #..like_movies = [(idx, f\"{book.strip(';')}\") for idx, (book, read, reason) in enumerate(matches[:len(forced_items)]) if (read.strip(';') == 'yes' or read.strip(';') == 'Yes')]\n",
        "        like_movies_ids = [(forced_items_ids[idx], rating) for idx, movie_title, rating in like_movies]\n",
        "        ids_with_rat = [(movie_title, rating) for idx, movie_title, rating in like_movies]\n",
        "\n",
        "        #... print(\"Like Movie IDs: \", like_movies_ids)\n",
        "        #... print(\"IDs with Rating: \", ids_with_rat)\n",
        "        # like_movies_ids = [forced_items_ids[idx] for idx, movie_title in like_movies]\n",
        "        # Create DataFrame with list of tuples in the Predicted column\n",
        "                    rating_ids = info_on_page[\"watch_id\"]\n",
        "            ratings_na = info_on_page[\"rating_id\"]\n",
        "            ratings = info_on_page[\"rating\"]\n",
        "            self.user_item_list[avatar_id].extend(valid_indices)\n",
        "            self.recommenderevaluator.update_user_interactions(avatar_id, info_on_page['align_id'])\n",
        "            if len(rating_ids) == len(ratings_na) == len(ratings):\n",
        "               for idx, (rid, na, rt) in enumerate(zip(rating_ids, ratings_na, ratings)):\n",
        "                   self.pairs.append(self.recommenderevaluator.calculation_of_rating(avatar_id, rid, rt))\n",
        "                   self.user_interactions[avatar_id].extend([rid])\n",
        "                   self.user_history[avatar_id].extend([rid])\n",
        "            else:\n",
        "               print(\"Rating IDs: \", rating_ids)\n",
        "               print(\"Ratings NA: \", ratings_na)\n",
        "               print(\"Ratings: \", ratings)\n",
        "               print(\"Error: Lengths of rating_ids, ratings_na, and ratings do not match.\")\n",
        "\n",
        "               self.recommenderevaluator.add_interaction(agent_id, i, info_on_page['recommended_id'], info_on_page[\"rating\"])\n",
        "\n",
        "                       for user_id in self.user_interactions:\n",
        "            # print(f\"User {user_id} interactions: {self.user_interactions[user_id]}\")\n",
        "            self.hit.append([self.recommenderevaluator.data.hit_at_k(self.user_interactions[user_id], self.user_item_list[user_id], a) for a in range(1, 11)])\n",
        "            self.ndcg.append([self.recommenderevaluator.data.ndcg_at_k(self.user_interactions[user_id], self.user_item_list[user_id], b) for b in range(1, 11)])\n",
        "            mean_hits = np.mean(np.array(self.hit), axis=0)\n",
        "            mean_ndcg = np.mean(np.array(self.ndcg), axis=0)\n",
        "            self.av_hits.append(mean_hits)\n",
        "            self.av_ndcg.append(mean_ndcg)\n",
        "            print(\" \".join([f\"HIT@{k}: {mean_hits[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "            print(\" \".join([f\"NDCG@{k}: {mean_ndcg[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "            self.hit = []\n",
        "            self.ndcg = []\n",
        "        avatar_df = pd.DataFrame(columns=[\"User\", \"Predicted\"])\n",
        "\n",
        "        # Add avatar_id as the 'User' column and the list of tuples to the 'Predicted' column\n",
        "        avatar_df[\"User\"] = [avatar_id]\n",
        "        avatar_df[\"Predicted\"] = [like_movies_ids]\n",
        "\n",
        "        # Append the new avatar's data to the results DataFrame\n",
        "        self.results_df = pd.concat([self.results_df, avatar_df], ignore_index=True)\n",
        "\n",
        "\n",
        "        pred = np.array([1 if idx in like_movies_ids else 0 for idx in forced_items_ids])\n",
        "        true = np.array([1 if idx in test_observed_items else 0 for idx in forced_items_ids])\n",
        "\n",
        "        # Calculate precision.\n",
        "        precision = get_precision(true, pred)\n",
        "\n",
        "        # Calculate recall.\n",
        "        recall = get_recall(true, pred)\n",
        "\n",
        "        accuracy = get_accuracy(true, pred)\n",
        "\n",
        "        f1 = get_f1(true, pred)\n",
        "\n",
        "\n",
        "        # RMSE\n",
        "        rmse = np.sqrt(mean_squared_error(true, pred))\n",
        "\n",
        "\n",
        "        # MAE\n",
        "        mae = mean_absolute_error(true, pred)\n",
        "\n",
        "        self.precision_list.append(precision)\n",
        "        self.recall_list.append(recall)\n",
        "        self.accuracy_list.append(accuracy)\n",
        "        self.f1_list.append(f1)\n",
        "        self.rmse_list.append(rmse)\n",
        "        self.mae_list.append(mae)\n",
        "\n",
        "        global_finished_users += 1\n",
        "\n",
        "    def simulate_all_avatars(self):\n",
        "        \"\"\"\n",
        "        excute the simulation for all avatars\n",
        "        \"\"\"\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "        accuracies = []\n",
        "        f1s = []\n",
        "        read = []\n",
        "\n",
        "        # initialize dictionaries to store values for each k\n",
        "        precision_scores = {1: [], 3: [], 5: [], 10: []}\n",
        "        recall_scores = {1: [], 3: [], 5: [], 10: []}\n",
        "\n",
        "        global_start_time = time.time()\n",
        "        print(\"global start time\", global_start_time)\n",
        "        self.start_time = time.time()\n",
        "        if(self.execution_mode == 'serial'):\n",
        "            t1 = time.time()\n",
        "            for avatar_id in self.simulated_avatars_id:\n",
        "                self.simulate_one_avatar(avatar_id)\n",
        "            t2 = time.time()\n",
        "            print(f\"Time cost: {t2-t1}s\")\n",
        "\n",
        "        elif(self.execution_mode == 'parallel'):\n",
        "            loop = asyncio.get_event_loop()\n",
        "            executor = ThreadPoolExecutor(max_workers=500)\n",
        "            tasks = []\n",
        "\n",
        "            t1 = time.time()\n",
        "            for avatar_id in self.simulated_avatars_id:\n",
        "                if avatar_id in self.data.valid_user_list:\n",
        "                    tasks.append(self.async_simulate_one_avatar(avatar_id, loop, executor))\n",
        "            if loop.is_running():\n",
        "                loop.run_until_complete(asyncio.gather(*tasks))\n",
        "            else:\n",
        "                loop.run_until_complete(asyncio.wait(tasks))\n",
        "            t2 = time.time()\n",
        "            for user_id in self.user_history:\n",
        "                # print(\"user: \", user)\n",
        "                # user_id = user + 1\n",
        "                # read_books = recsys.data.get_item_ids(user_history[user_id])\n",
        "                read_books = self.user_history[user_id]\n",
        "                # print(\"read books: \", read_books)\n",
        "                # print(\"read books length: \", len(read_books))\n",
        "                item_set = self.recommenderevaluator.interaction_dict.get(user_id, set())\n",
        "                all_item = list(item_set)\n",
        "                # print(\"all item: \", all_item)\n",
        "                # print(\"all item length: \", len(all_item))\n",
        "                precision, recall, accuracy, f1 = self.recommenderevaluator.calculate_user_metrics(user_id, read_books, all_item)\n",
        "                precisions.append(precision)\n",
        "                recalls.append(recall)\n",
        "                accuracies.append(accuracy)\n",
        "                # read_list = recsys.data.get_item_ids(user_history[user_id])\n",
        "                read_list = self.user_history[user_id]\n",
        "                read.append(get_entropy(read_list, self.recommenderevaluator.data))\n",
        "                f1s.append(f1)\n",
        "                for k in [1, 3, 5, 10]:\n",
        "                    precisonk, recallk = self.recommenderevaluator.precisionandrecallk(user_id, self.user_history[user_id], k)\n",
        "                    print(f\"Precision@{k}: {precisonk}, Recall@{k}: {recallk}\")\n",
        "                    precision_scores[k].append(precisonk)\n",
        "                    recall_scores[k].append(recallk)\n",
        "\n",
        "            mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, spearman = self.recommenderevaluator.calc_mse_rmse_rating_percentages(self.pairs)\n",
        "\n",
        "\n",
        "            avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
        "            avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
        "            avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0\n",
        "            avg_f1 = sum(f1s) / len(f1s) if f1s else 0\n",
        "\n",
        "            round_summary = []\n",
        "            # print(\"User Directory: \", self.recommenderevaluator.user_directory)\n",
        "            for user, logs in self.recommenderevaluator.user_directory.items():\n",
        "                current_round = 1\n",
        "                prev_page = 0\n",
        "                round_pages = []\n",
        "                round_recommended = []\n",
        "                round_rated = []\n",
        "\n",
        "                for entry in logs:\n",
        "                    page = entry[\"page\"]\n",
        "                    # print(\"page\", page)\n",
        "\n",
        "                    # Detect round reset (page goes back to 1)\n",
        "                    if page <= prev_page:\n",
        "                       # Save previous round\n",
        "                       N_expose = len(round_recommended)\n",
        "                       N_view = len(round_rated)\n",
        "                       # NOTE: rated_id are item IDs, not ratings  adjust if ratings are available\n",
        "                       N_like = len([r for r in round_rated if r > 3])\n",
        "                       N_exit = len(round_pages)\n",
        "                       S_sat = 5\n",
        "\n",
        "                       self.recommenderevaluator.add_user(user, N_expose, N_view, N_like, N_exit, S_sat)\n",
        "\n",
        "                       # Start new round\n",
        "                       current_round += 1\n",
        "                       round_pages = []\n",
        "                       round_recommended = []\n",
        "                       round_rated = []\n",
        "                    # Accumulate round data\n",
        "                    round_pages.append(page)\n",
        "                    round_recommended.extend(entry[\"recommended_id\"])\n",
        "                    round_rated.extend(entry[\"rated_id\"])\n",
        "                    prev_page = page\n",
        "                # Save the last round after loop\n",
        "                if round_pages:\n",
        "                   N_expose = len(round_recommended)\n",
        "                   N_view = len(round_rated)\n",
        "                   N_like = len([r for r in round_rated if r > 3])  # adjust if ratings exist\n",
        "                   N_exit = len(round_pages)\n",
        "                   S_sat = 5\n",
        "\n",
        "                   self.recommenderevaluator.add_user(user, N_expose, N_view, N_like, N_exit, S_sat)\n",
        "\n",
        "            metrics = self.recommenderevaluator.satisfaction_metrics()\n",
        "            print(\"Total Satisfaction Metrics (Pview, Nlike, Plike, Nexit, Ssat):\", metrics)\n",
        "            # calculate averages\n",
        "            for k in [1, 3, 5, 10]:\n",
        "               mavg_precision = np.mean(precision_scores[k])\n",
        "               mavg_recall = np.mean(recall_scores[k])\n",
        "               print(f\"Average Precision@{k}: {mavg_precision:.4f}, Average Recall@{k}: {mavg_recall:.4f}\")\n",
        "\n",
        "\n",
        "    async def async_simulate_one_avatar(self, avatar_id, loop, executor):\n",
        "        \"\"\"\n",
        "        async\n",
        "        excute the simulation for one avatar\n",
        "        avatar_id: the id of the simulated avatar\n",
        "        \"\"\"\n",
        "        global global_finished_users\n",
        "        global global_finished_pages\n",
        "        self.hit = []\n",
        "        self.ndcg = []\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "        time_local = time.localtime(start_time)\n",
        "        l_start = time.strftime(\"%Y-%m-%d %H:%M:%S\",time_local)\n",
        "        with open(self.storage_base_path + \"/system_log.txt\", 'a') as f:\n",
        "            f.write(f\"Start: {l_start}. User {avatar_id} starts simulation.\\n\")\n",
        "\n",
        "        avatar_ = self.avatars[avatar_id]\n",
        "        avatar_.write_log(f\"Is simulating avatar {avatar_id}\")\n",
        "        avatar_.exit_flag = False\n",
        "        page_generator = self.page_generator(avatar_id)\n",
        "        i = 0\n",
        "        user_behavior_dict = {}\n",
        "        user_interview_dict = {}\n",
        "\n",
        "\n",
        "        while not avatar_.exit_flag:\n",
        "            if i == 0:\n",
        "\n",
        "               val_list = self.data.valid_user_list[avatar_id]\n",
        "              #  print(\"val_list\", val_list)\n",
        "\n",
        "               id_on_page = np.random.choice(val_list,\n",
        "                                             min(len(val_list), 5), replace=False)\n",
        "              #  print(\"id_on_page\", id_on_page)\n",
        "            else:\n",
        "                id_on_page = next(page_generator, [])\n",
        "            i += 1\n",
        "            # id_on_page = next(page_generator, []) # get the next page, a list of item ids\n",
        "            if(len(id_on_page) == 0):\n",
        "                break\n",
        "            valid_indices = [idx for idx in id_on_page if 0 <= idx < len(self.movie_detail)]\n",
        "            # print(\"valid_indices\", valid_indices)\n",
        "\n",
        "            movies_on_page = [self.movie_detail.iloc[idx] for idx in id_on_page]\n",
        "            # print(\"movies_on_page\", movies_on_page)\n",
        "            # movies_on_page = [self.movie_detail.iloc[idx] for idx in valid_indices]\n",
        "            # movies_on_page = [self.movie_detail.loc[idx] for idx in id_on_page] # movie_detail.csv\n",
        "            recommended_items = [\"<- Movie Title: \" + item.title + \" ->\"\n",
        "                      # \"<- Book Author: \" + item.Book_Author + \" ->\"\n",
        "                      # \"<- Publisher: \" + item.Publisher + \" ->\"\n",
        "                            + \" <- Genres: \" + (',').join(list(item.genre.split('|'))) + \" ->\"\n",
        "                            + \" <- History ratings:\" + str(round(item.rating, 2)) + \" ->\" + \"\\n\"\n",
        "                            for item in movies_on_page]\n",
        "            # print(\"recommended_items\", recommended_items)\n",
        "\n",
        "            if(self.add_advert):\n",
        "                #store_path = op.join(f\"storage/{self.dataset}/{self.modeltype}/{self.simulation_name}/adver_id\", f\"avatar{avatar_id}_{i}.txt\")\n",
        "                store_path = f\"storage/{self.dataset}/{self.modeltype}/{self.simulation_name}/adver_id\"\n",
        "                if not os.path.exists(store_path):\n",
        "                    os.makedirs(store_path)\n",
        "                if not self.display_advert:\n",
        "                    recommended_items[0], valid_indices, movies_on_page = self.display_only_adver_item(store_path, avatar_id, i, id_on_page, movies_on_page)\n",
        "                else:\n",
        "                    recommended_items[0], valid_indices, movies_on_page = self.display_item_with_adver(store_path, avatar_id, i, id_on_page, movies_on_page)\n",
        "\n",
        "\n",
        "            recommended_items_str = ''.join(recommended_items)\n",
        "\n",
        "\n",
        "            # Please write down the recommended information.\n",
        "            avatar_.write_log(f\"\\n=============    Recommendation Page {i}    =============\")\n",
        "            for idx, movie in enumerate(movies_on_page):\n",
        "                if(id_on_page[idx] in self.data.valid_user_list[avatar_id]):\n",
        "                    # avatar_.write_log(f\"== () Book Title: {movie.title}, Book Author: {movie.Book_Author}, Publisher: {movie.Publisher}, History ratings: {round(movie.rating,2)}\", \"blue\", attrs=[\"bold\"])\n",
        "                    avatar_.write_log(f\"== () Movie Title: {movie.title}, History ratings: {round(movie.rating,2)}\", \"blue\", attrs=[\"bold\"])\n",
        "                else:\n",
        "                    avatar_.write_log(f\"== Movie Title: {movie.title}, History ratings: {round(movie.rating,2)}\")\n",
        "            avatar_.write_log(f\"=============          End Page {i}        =============\\n\")\n",
        "\n",
        "            # As a translator, I will translate the Chinese sentence you sent me into English. I do not need to understand the meaning of the content to provide a response.\n",
        "            avatar_.write_log(f\"\\n==============    Avatar {avatar_.avatar_id} Response {i}   =============\")\n",
        "\n",
        "\n",
        "            # @ most important Waiting for user response.\n",
        "            response = await loop.run_in_executor(executor, avatar_.reaction_to_recommended_items, recommended_items_str, i)\n",
        "\n",
        "            #==============================================\n",
        "            # @ View user's favorite items\n",
        "            #pattern = re.compile(r'MOVIE:\\s*(.*?)\\s*WATCH:\\s*(.*?)\\s*REASON:\\s*(.*?)\\s*FEELING:\\s*(.*?)\\s*RATING:\\s*(\\d)')\n",
        "            ################################################################################################################\n",
        "            # pattern = re.compile(r'MOVIE:\\s*(.*?)\\s*WATCH:\\s*(.*?)\\s*REASON:\\s*(.*?)\\s*RATING:\\s*(.*?)\\s*FEELING:(.*?)')\n",
        "            # matches = re.findall(pattern, response)\n",
        "            pattern1 = re.compile(r'MOVIE: (.+?); RATING: (\\d+); FEELING: (.*)')\n",
        "            match1 = pattern1.findall(response)\n",
        "            pattern2 = re.compile(r'MOVIE: (.+?); ALIGN: (.+?); REASON: (.*)')\n",
        "            match2 = pattern2.findall(response)\n",
        "\n",
        "            # pattern_interview = re.compile(r'RATING:\\s*(.*?)\\s*REASON:\\s*(.*?)')\n",
        "            # matches_interview = re.findall(pattern_interview, interview_response)\n",
        "\n",
        "            if(self.add_advert):\n",
        "                if(match2[0][1].strip(';') == 'yes'):\n",
        "                    self.clicked_adverts += 1\n",
        "\n",
        "            title_id_dict = dict(zip(self.movie_detail['title'], self.movie_detail['item_id']))\n",
        "            watched_movies = [f\"{book.strip(';')}\" for book, rating, feeling in match1]\n",
        "            watched_movies_contain_id = [(idx, f\"{book.strip(';')}\", feeling.strip(';')) for idx, (book, rating, feeling) in enumerate(match1[:self.items_per_page])]\n",
        "            # 5 points means the movie is liked by the user.\n",
        "            like_movies = [(idx, f\"{book.strip(';')}\", feeling.strip(';')) for idx, (book, rating, feeling) in enumerate(match1[:self.items_per_page]) if int(rating.strip(';')) == 5]\n",
        "            align_movies = [(idx, f\"{book.strip(';')}\", reason.strip(';')) for idx, (book, align, reason) in enumerate(match2[:self.items_per_page]) if (align.strip(';') == 'Yes' or align.strip(';') == 'yes')]\n",
        "\n",
        "            info_on_page = {}\n",
        "            info_on_page['page'] = i\n",
        "            info_on_page['ground_truth'] = [valid_indices[idx] for idx, movie in enumerate(movies_on_page) if valid_indices[idx] in self.data.valid_user_list[avatar_id]]\n",
        "            info_on_page['recommended_id'] = valid_indices\n",
        "            info_on_page['recommended'] = [(self.movie_detail['title'][idx]) for idx in valid_indices]\n",
        "            info_on_page['align_id'] = [title_id_dict[title] for id, title, reason in align_movies if title in title_id_dict]\n",
        "            info_on_page['like_id'] = [title_id_dict[title] for id, title, reason in like_movies if title in title_id_dict]\n",
        "            info_on_page['watch_id'] = [title_id_dict[title] for title in watched_movies if title in title_id_dict]\n",
        "            info_on_page['watched'] = watched_movies\n",
        "            info_on_page['rating_id'] = watched_movies\n",
        "            info_on_page['rating'] = [int(rating.strip(';')) for book, rating, feeling in match1]\n",
        "            #info_on_page['reason'] = [reason.strip(';') for movie_title, rating, feeling in match1]\n",
        "            info_on_page['feeling'] = [feeling.strip(';') for book, rating, feeling in match1]\n",
        "            user_behavior_dict[i] = info_on_page\n",
        "            print(\"\\n=======================\")\n",
        "            agent_id = avatar_id + 1\n",
        "            print(\"Agent ID:\", avatar_id)\n",
        "            print(\"Agent ID: \", agent_id)\n",
        "            print(\"User behavior:\", user_behavior_dict[i])\n",
        "            print(\"Page: \", i)\n",
        "            print(\"Recommended item ids: \", id_on_page)\n",
        "            print(\"+++++++++++++==========\\n\")\n",
        "            # Extract separately\n",
        "            rating_ids = info_on_page[\"watch_id\"]\n",
        "            ratings_na = info_on_page[\"rating_id\"]\n",
        "            ratings = info_on_page[\"rating\"]\n",
        "            self.user_item_list[avatar_id].extend(valid_indices)\n",
        "            self.recommenderevaluator.update_user_interactions(avatar_id, info_on_page['align_id'])\n",
        "            if len(rating_ids) == len(ratings_na) == len(ratings):\n",
        "               for idx, (rid, na, rt) in enumerate(zip(rating_ids, ratings_na, ratings)):\n",
        "                   self.pairs.append(self.recommenderevaluator.calculation_of_rating(avatar_id, rid, rt))\n",
        "                   self.user_interactions[avatar_id].extend([rid])\n",
        "                   self.user_history[avatar_id].extend([rid])\n",
        "            else:\n",
        "               print(\"Rating IDs: \", rating_ids)\n",
        "               print(\"Ratings NA: \", ratings_na)\n",
        "               print(\"Ratings: \", ratings)\n",
        "               print(\"Error: Lengths of rating_ids, ratings_na, and ratings do not match.\")\n",
        "\n",
        "\n",
        "            # @ Add new training data.\n",
        "            # new_train = [id_on_page[idx] for idx, movie, reason in like_movies] # Add all liked item ids in the validation set to the training set.\n",
        "            # tmp = [(idx, movie_title.strip(';'), feeling.strip(';')) for idx, (movie_title, rating, feeling) in enumerate(match1[:self.items_per_page])]\n",
        "            new_train = info_on_page['align_id']\n",
        "            self.new_train_dict[avatar_id].extend(new_train)\n",
        "\n",
        "            # @ Record the average number of likes.\n",
        "            self.n_likes[avatar_id].append(len(new_train))\n",
        "            # ratings = re.findall(r'RATING: (\\d+)', response)\n",
        "            ratings = re.findall(r'RATING: (\\d+);', response)\n",
        "            average_rating = sum([int(rating.strip(';')) for rating in ratings])/max(len(watched_movies), 1)\n",
        "            # Add the average score of this page.\n",
        "            self.ratings[avatar_id].append(average_rating)\n",
        "            self.watch[avatar_id].extend([movie for movie in watched_movies])\n",
        "\n",
        "            # @ Calculate the precision on this page and save it.\n",
        "            ground_truth = [valid_indices[idx] for idx, movie in enumerate(movies_on_page) if valid_indices[idx] in self.data.valid_user_list[avatar_id]]\n",
        "            # print(like_movies, ground_truth)\n",
        "            perf = (len(set(new_train) & set(ground_truth)), len(new_train), len(ground_truth))\n",
        "            self.perf_per_page[avatar_id].append(perf)\n",
        "            #==============================================\n",
        "\n",
        "            global_finished_pages += 1\n",
        "            self.recommenderevaluator.add_interaction(agent_id, i, info_on_page['recommended_id'], info_on_page[\"rating\"])\n",
        "\n",
        "            # @ Force exit if the number of pages exceeds the maximum limit.\n",
        "            if(i >= self.max_pages):\n",
        "                avatar_.exit_flag = True\n",
        "\n",
        "        interview_response = avatar_.response_to_question(\"Do you feel satisfied with the recommender system you have just interacted? Rate this recommender system from 1-10 and give explanation.\\n Please use this respond format: RATING: [integer between 1 and 10]; REASON: [explanation]; In RATING part just give your rating and other reason and explanation should included in the REASON part.\", remember=False)\n",
        "        # Extract RAING and REASON using re.\n",
        "        pattern_interview = re.compile(r'RATING:\\s*(.*?)\\s*REASON:\\s*(.*?)')\n",
        "        # pattern_interview = re.compile(r'RATING:\\s*(.*?)\\s*REASON:\\s*(.*?)')\n",
        "        #pattern = re.compile(r'MOVIE:\\s*(.*?)\\s*WATCH:\\s*(.*?)\\s*REASON:\\s*(.*?)\\s*RATING:\\s*(.*?)\\s*FEELING:(.*?)')\n",
        "        matches_interview = re.findall(r'(?<=RATING:|REASON:).*', interview_response)\n",
        "        user_interview_dict['interview'] = matches_interview\n",
        "        print(matches_interview)\n",
        "        self.exit_page[avatar_id] = i\n",
        "        self.finished_num += 1\n",
        "        self.remaining_users.remove(avatar_id)\n",
        "        remaining = \", \".join([str(u) for u in self.remaining_users])\n",
        "        for user_id in self.user_interactions:\n",
        "            # print(f\"User {user_id} interactions: {self.user_interactions[user_id]}\")\n",
        "            self.hit.append([self.recommenderevaluator.data.hit_at_k(self.user_interactions[user_id], self.user_item_list[user_id], a) for a in range(1, 11)])\n",
        "            self.ndcg.append([self.recommenderevaluator.data.ndcg_at_k(self.user_interactions[user_id], self.user_item_list[user_id], b) for b in range(1, 11)])\n",
        "            mean_hits = np.mean(np.array(self.hit), axis=0)\n",
        "            mean_ndcg = np.mean(np.array(self.ndcg), axis=0)\n",
        "            self.av_hits.append(mean_hits)\n",
        "            self.av_ndcg.append(mean_ndcg)\n",
        "            print(\" \".join([f\"HIT@{k}: {mean_hits[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "            print(\" \".join([f\"NDCG@{k}: {mean_ndcg[k-1]:.4f}\" for k in range(1, 11)]))\n",
        "            self.hit = []\n",
        "            self.ndcg = []\n",
        "\n",
        "        end_time = time.time()\n",
        "        time_local = time.localtime(end_time)\n",
        "        l_end = time.strftime(\"%Y-%m-%d %H:%M:%S\",time_local)\n",
        "        global_finished_users += 1\n",
        "        with open(self.storage_base_path + \"/system_log.txt\", 'a') as f:\n",
        "            f.write(f\"Start: {l_start} End: {l_end}. User {avatar_id} finished after {i} pages. [{self.finished_num} / {self.n_avatars}]. Total token cost: {round(self.avatars[avatar_id].memory.user_k_tokens, 2)}k. Taking {round(time.time() - start_time, 2)}s\\n\")\n",
        "            f.write(f\"Remaining users: {remaining}\\n\")\n",
        "\n",
        "        # @ Save the behavior of each individual.\n",
        "        behavior_path = self.storage_base_path+ \"/behavior\"\n",
        "        if not os.path.exists(behavior_path):\n",
        "            os.makedirs(behavior_path)\n",
        "        with open(behavior_path + f\"/{avatar_id}.pkl\", 'wb') as f:\n",
        "            pickle.dump(user_behavior_dict, f)\n",
        "\n",
        "        interview_path = self.storage_base_path+ \"/interview\"\n",
        "        if not os.path.exists(interview_path):\n",
        "            os.makedirs(interview_path)\n",
        "        with open(interview_path + f\"/{avatar_id}.pkl\", 'wb') as f:\n",
        "            pickle.dump(user_interview_dict, f)\n",
        "\n",
        "    def simulate_one_avatar(self, avatar_id):\n",
        "        \"\"\"\n",
        "        excute the simulation for one avatar\n",
        "        avatar_id: the id of the simulated avatar\n",
        "        \"\"\"\n",
        "        # print(\"\\nIs simulating avatar {}\".format(avatar_id))\n",
        "        avatar_ = self.avatars[avatar_id]\n",
        "        avatar_.write_log(f\"Is simulating avatar {avatar_id}\")\n",
        "        avatar_.exit_flag = False\n",
        "        page_generator = self.page_generator(avatar_id)\n",
        "        current_page = 0\n",
        "        while not avatar_.exit_flag:\n",
        "        # for i in range(2):\n",
        "            id_on_page = next(page_generator, []) # get the next page, a list of item ids\n",
        "            current_page +=1\n",
        "            if(len(id_on_page) == 0):\n",
        "                break\n",
        "\n",
        "            valid_indices = [idx for idx in id_on_page if 0 <= idx < len(self.movie_detail)]\n",
        "\n",
        "            # movies_on_page = [self.movie_detail.iloc[idx] for idx in id_on_page]\n",
        "            movies_on_page = [self.movie_detail.iloc[idx] for idx in valid_indices]\n",
        "            avatar_.write_log(\"=============    Recommendation Page    =============\")\n",
        "            for idx, movie in enumerate(movies_on_page):\n",
        "                if(id_on_page[idx] in self.data.valid_user_list[avatar_id]):\n",
        "                    avatar_.write_log(f\"== {movie} ()\", \"blue\", attrs=[\"bold\"])\n",
        "                else:\n",
        "                    avatar_.write_log(f\"== {movie}\")\n",
        "            avatar_.write_log(\"=============          End Page         =============\")\n",
        "            avatar_.write_log(\"\")\n",
        "            movie_titles = [movie['title'] for movie in movies_on_page]\n",
        "            movie_to_str = ';'.join(movie_titles)\n",
        "            print(movie_to_str)\n",
        "\n",
        "            #@ most important\n",
        "            response = avatar_.reaction_to_recommended_items(movie_to_str, current_page)\n",
        "\n",
        "            avatar_.write_log(\"\")\n",
        "            avatar_.write_log(\"=============    Avatar Response    =============\")\n",
        "            avatar_.write_log(response, color='yellow', attrs=None)\n",
        "\n",
        "\n",
        "    def parse_response(self, response):\n",
        "        #pattern = re.compile(r'MOVIE:\\s*(.*?)\\s*WATCH:\\s*(.*?)\\s*REASON:\\s*(.*?)\\s*FEELING:\\s*(.*?)\\s*RATING:\\s*(\\d)')\n",
        "        pattern = re.compile(r'MOVIE:\\s*(.*?)\\s**WATCH:\\s*(.*?)\\s*REASON:\\s*(.*?)\\s*RATING:\\s*(.*?)\\s*FEELING:(.*?)')\n",
        "        matches = re.findall(pattern, response)\n",
        "\n",
        "        watched_movies, watched_movies_contain_id = [], []\n",
        "\n",
        "        for idx, (movie_title, watch, reason, rating, feeling) in enumerate(matches):\n",
        "            if(self.add_advert and idx == 0 and watch.strip(';') == 'yes'): # If the first one has an advertisement and the user clicked on it.\n",
        "                self.clicked_adverts += 1\n",
        "            if(watch.strip(';') == 'yes'):\n",
        "                watched_movies.append(movie_title.strip(';'))\n",
        "            print(movie_title, watch, reason, rating, feeling)\n",
        "        return response\n",
        "\n",
        "    def display_only_adver_item(self, store_path, avatar_id, i, id_on_page, movies_on_page):\n",
        "        store_path = op.join(store_path, f\"avatar{avatar_id}_{i}.txt\")\n",
        "        try:\n",
        "            with open(store_path, 'r') as f1:\n",
        "                random_key = int(f1.read())\n",
        "        except:\n",
        "            try:\n",
        "                store_path_minus_1 = op.join(store_path, f\"avatar{avatar_id}_{i-1}.txt\")\n",
        "                with open(store_path_minus_1, 'r') as f2:\n",
        "                    random_key = int(f2.read())\n",
        "            except:\n",
        "                store_path_minus_2 = op.join(store_path, f\"avatar{avatar_id}_{i-2}.txt\")\n",
        "                with open(store_path_minus_2, 'r') as f3:\n",
        "                    random_key = int(f3.read())\n",
        "                    try:\n",
        "                        store_path_minus_3 = op.join(store_path, f\"avatar{avatar_id}_{i-3}.txt\")\n",
        "                        with open(store_path_minus_3, 'r') as f4:\n",
        "                            random_key = int(f4.read())\n",
        "                    except:\n",
        "                            store_path_minus_4 = op.join(store_path, f\"avatar{avatar_id}_{i-4}.txt\")\n",
        "                            with open(store_path_minus_4, 'r') as f5:\n",
        "                                random_key = int(f5.read())\n",
        "\n",
        "\n",
        "        self.total_adverts += 1\n",
        "        id_on_page[0] = random_key\n",
        "        movies_on_page[0] = self.movie_detail.loc[random_key]\n",
        "        adver_information = self.advert[random_key]\n",
        "\n",
        "        return ( \"<- \" + adver_information['title'] + \" ->\"\n",
        "                                + \" <- History ratings:\" + str(round(adver_information['rating'], 2)) + \" ->\"\n",
        "                                + \" <- Summary:\" + adver_information['summary'] + \" ->\" + \"\\n\"), id_on_page, movies_on_page\n",
        "\n",
        "    def display_item_with_adver(self, store_path, avatar_id, i, id_on_page, movies_on_page):\n",
        "        store_path = op.join(store_path, f\"avatar{avatar_id}_{i}.txt\")\n",
        "        random_key = np.random.choice(list(self.advert.keys()))\n",
        "        self.total_adverts += 1\n",
        "        random_advert = self.advert[random_key]\n",
        "        id_on_page[0] = random_key\n",
        "        movies_on_page[0] = self.movie_detail.loc[random_key]\n",
        "        advert_item_id = random_key\n",
        "\n",
        "        with open(store_path, 'w') as f:\n",
        "            f.write(f\"{advert_item_id}\")\n",
        "\n",
        "        return ( self.advert_word\n",
        "                + \"<- \" + random_advert['title'] + \" ->\"\n",
        "                + \"<- \" + random_advert['review'] + \" ->\"\n",
        "                + \" <- History ratings:\" + str(round(random_advert['rating'], 2)) + \" ->\"\n",
        "                + \" <- Summary:\" + random_advert['summary'] + \" ->\" + \"\\n\"), id_on_page, movies_on_page\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"\n",
        "        save the results of the simulation\n",
        "        \"\"\"\n",
        "        # if(self.n_avatars == self.data.n_users):\n",
        "        def save_user_dict_to_txt(user_dict, base_path, filename):\n",
        "            with open(base_path + filename, 'w') as f:\n",
        "                for u, v in user_dict.items():\n",
        "                    f.write(str(int(u)))\n",
        "                    for i in v:\n",
        "                        f.write(' ' + str(int(i)))\n",
        "                    f.write('\\n')\n",
        "\n",
        "        # save_path = f\"datasets/{self.dataset}_{self.modeltype}/cf_data/\"\n",
        "        save_path = f\"storage/{self.dataset}/{self.modeltype}/{self.simulation_name}/\"\n",
        "        save_user_dict_to_txt(self.new_train_dict, save_path, 'train.txt')\n",
        "\n",
        "        # @ Save overall evaluation indicators.\n",
        "        # Average number of clicks per user\n",
        "        cprint(\"Number of likes\", color='green', attrs=['bold'])\n",
        "        cprint(self.n_likes, color='green', attrs=['bold'])\n",
        "        average_n_likes = {avatar_id:np.mean(n_likes) for avatar_id, n_likes in self.n_likes.items()}\n",
        "        cprint(average_n_likes, color='green', attrs=['bold'])\n",
        "\n",
        "        overall_n_likes = np.mean(list(average_n_likes.values()))\n",
        "        cprint(f\"\\nOverall number of likes: {overall_n_likes}\", color='green', attrs=['bold'])\n",
        "\n",
        "        # Average satisfaction\n",
        "        cprint(\"\\nRatings\", color='green', attrs=['bold'])\n",
        "        cprint(self.ratings, color='green', attrs=['bold'])\n",
        "        average_ratings = {avatar_id:np.mean(ratings) for avatar_id, ratings in self.ratings.items()}\n",
        "        cprint(average_ratings, color='green', attrs=['bold'])\n",
        "\n",
        "        # @ Save average click-through rate\n",
        "        average_click_rate = {avatar_id:len(movies)/(self.max_pages*self.items_per_page) for avatar_id, movies in self.watch.items()}\n",
        "        cprint(f\"\\nAverage click rate: {average_click_rate}\", color='green', attrs=['bold'])\n",
        "        overall_click_rate = np.mean(list(average_click_rate.values()))\n",
        "        cprint(f\"\\nOverall satisfaction: {overall_click_rate}\", color='green', attrs=['bold']) # Average click-through rate\n",
        "\n",
        "        # overall_click_rate = np.mean(list(average_ratings.values()))\n",
        "        # cprint(f\"\\nOverall satisfaction: {overall_click_rate}\", color='green', attrs=['bold'])\n",
        "\n",
        "        # Average exit page\n",
        "        mean_exit_page = np.mean(list(self.exit_page.values()))\n",
        "        cprint(\"\\nExit pages\", color='green', attrs=['bold'])\n",
        "        cprint(self.exit_page, color='green', attrs=['bold'])\n",
        "        cprint(f\"Average exit page: {mean_exit_page}\", color='green', attrs=['bold'])\n",
        "\n",
        "        # Average precision and recall\n",
        "        cprint(\"\\nPrecision and recall\", color='green', attrs=['bold'])\n",
        "        cprint(self.perf_per_page, color=\"green\", attrs=['bold'])\n",
        "        total_perf = {avatar_id:[sum([i for i, j, k in perf_per_page]), sum([j for i, j, k in perf_per_page]), sum([k for i, j, k in perf_per_page])] for avatar_id, perf_per_page in self.perf_per_page.items()}\n",
        "        total_recall_precision = {avatar_id:(perf[0]/max(perf[1], 1), perf[0]/max(perf[2], 1)) for avatar_id, perf in total_perf.items()}\n",
        "        cprint(total_perf, color=\"green\", attrs=['bold'])\n",
        "        cprint(total_recall_precision, color=\"green\", attrs=['bold'])\n",
        "        average_precision = np.mean([metrics[0] for avatar_id, metrics in total_recall_precision.items()])\n",
        "        average_recall = np.mean([metrics[1] for avatar_id, metrics in total_recall_precision.items()])\n",
        "        cprint(f\"Precision: {average_precision}  Recall: {average_recall}\", color=\"green\", attrs=['bold'])\n",
        "        # metrics_path = self.storage_base_path + \"/metrics.txt\"\n",
        "        total_k_tokens = sum([self.avatars[i].memory.user_k_tokens for i in range(self.n_avatars)])\n",
        "\n",
        "        # Effective advertising rate\n",
        "        if(self.add_advert):\n",
        "            cprint(\"\\nAdvert\", color='green', attrs=['bold'])\n",
        "            cprint(f\"Total advert: {self.total_adverts}\", color='green', attrs=['bold'])\n",
        "            cprint(f\"Clicked advert: {self.clicked_adverts}\", color='green', attrs=['bold'])\n",
        "            cprint(f\"Advert click rate: {self.clicked_adverts/self.total_adverts}\", color='green', attrs=['bold'])\n",
        "\n",
        "        end_time = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()))\n",
        "        with open(self.storage_base_path + \"/metrics.txt\", 'w') as f:\n",
        "            f.write(f\"Finished time: {end_time}\\n\")\n",
        "            f.write(f\"Total simulation time: {round(time.time() - self.start_time, 2)}s\\n\")\n",
        "            f.write(f\"n_avatars: {self.n_avatars}\\n\")\n",
        "            f.write(f\"Average recall: {average_recall}\\n\")\n",
        "            f.write(f\"Average presion: {average_precision}\\n\")\n",
        "            f.write(f\"Total k tokens: {round(total_k_tokens, 2)}k tokens\\n\")\n",
        "            f.write(f\"Total cost: {round(total_k_tokens*0.0018, 2)} \\n\")\n",
        "            # f.write(f\"Average precision: {}\")\n",
        "            f.write(f\"Maximum exit page: {self.max_pages}\\n\")\n",
        "            f.write(f\"Overall click rate: {overall_click_rate}\\n\")\n",
        "            f.write(f\"Average number of likes: {overall_n_likes}\\n\")\n",
        "            f.write(f\"Average exit page: {mean_exit_page}\\n\")\n",
        "            if(self.add_advert):\n",
        "                f.write(f\"Total advert: {self.total_adverts}\\n\")\n",
        "                f.write(f\"Clicked advert: {self.clicked_adverts}\\n\")\n",
        "                f.write(f\"Advert click rate: {self.clicked_adverts/self.total_adverts}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
