{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTezUYAmfzAC",
        "outputId": "53ca33cf-967b-4d11-d1a9-f7a1a13853a2"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import six\n",
        "\n",
        "# Some notes:\n",
        "#\n",
        "#   These represent properties of the documents. Presumably we can add more or\n",
        "#   remove documents from the candidate set. But these do not include features\n",
        "#   that depend on both the user and the document.\n",
        "#\n",
        "\n",
        "\n",
        "class CandidateSet(object):\n",
        "  \"\"\"Class to represent a collection of AbstractDocuments.\n",
        "\n",
        "     The candidate set is represented as a hashmap (dictionary), with documents\n",
        "     indexed by their document ID.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"Initializes a document candidate set with 0 documents.\"\"\"\n",
        "    self._documents = {}\n",
        "\n",
        "  def size(self):\n",
        "    \"\"\"Returns an integer, the number of documents in this candidate set.\"\"\"\n",
        "    return len(self._documents)\n",
        "\n",
        "  def get_all_documents(self):\n",
        "    \"\"\"Returns all documents.\"\"\"\n",
        "    return self.get_documents(self._documents.keys())\n",
        "\n",
        "  def get_documents(self, document_ids):\n",
        "    \"\"\"Gets the documents associated with the specified document IDs.\n",
        "\n",
        "    Args:\n",
        "      document_ids: an array representing indices into the candidate set.\n",
        "        Indices can be integers or string-encoded integers.\n",
        "\n",
        "    Returns:\n",
        "      (documents) an ordered list of AbstractDocuments associated with the\n",
        "        document ids.\n",
        "    \"\"\"\n",
        "    return [self._documents[int(k)] for k in document_ids]\n",
        "\n",
        "  def add_document(self, document):\n",
        "    \"\"\"Adds a document to the candidate set.\"\"\"\n",
        "    self._documents[document.doc_id()] = document\n",
        "\n",
        "  def remove_document(self, document):\n",
        "    \"\"\"Removes a document from the set (to simulate a changing corpus).\"\"\"\n",
        "    del self._documents[document.doc_id()]\n",
        "\n",
        "  def create_observation(self):\n",
        "    \"\"\"Returns a dictionary of observable features of documents.\"\"\"\n",
        "    return {\n",
        "        str(k): self._documents[k].create_observation()\n",
        "        for k in self._documents.keys()\n",
        "    }\n",
        "\n",
        "  def observation_space(self):\n",
        "    return spaces.Dict({\n",
        "        str(k): self._documents[k].observation_space()\n",
        "        for k in self._documents.keys()\n",
        "    })\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractDocumentSampler(object):\n",
        "  \"\"\"Abstract class to sample documents.\"\"\"\n",
        "\n",
        "  def __init__(self, doc_ctor, seed=0):\n",
        "    self._doc_ctor = doc_ctor\n",
        "    self._seed = seed\n",
        "    self.reset_sampler()\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    self._rng = np.random.RandomState(self._seed)\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def sample_document(self):\n",
        "    \"\"\"Samples and return an instantiation of AbstractDocument.\"\"\"\n",
        "\n",
        "  def get_doc_ctor(self):\n",
        "    \"\"\"Returns the constructor/class of the documents that will be sampled.\"\"\"\n",
        "    return self._doc_ctor\n",
        "\n",
        "  @property\n",
        "  def num_clusters(self):\n",
        "    \"\"\"Returns the number of document clusters. Returns 0 if not applicable.\"\"\"\n",
        "    return 0\n",
        "\n",
        "  def update_state(self, documents, responses):\n",
        "    \"\"\"Update document state (if needed) given user's (or users') responses.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractDocument(object):\n",
        "  \"\"\"Abstract class to represent a document and its properties.\"\"\"\n",
        "\n",
        "  # Number of features to represent the document.\n",
        "  NUM_FEATURES = None\n",
        "\n",
        "  def __init__(self, doc_id):\n",
        "    self._doc_id = doc_id  # Unique identifier for the document\n",
        "\n",
        "  def doc_id(self):\n",
        "    \"\"\"Returns the document ID.\"\"\"\n",
        "    return self._doc_id\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def create_observation(self):\n",
        "    \"\"\"Returns observable properties of this document as a float array.\"\"\"\n",
        "\n",
        "  @classmethod\n",
        "  @abc.abstractmethod\n",
        "  def observation_space(cls):\n",
        "    \"\"\"Gym space that defines how documents are represented.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSY62x-qfzAJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"Abstract classes that encode a user's state and dynamics.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import six\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractResponse(object):\n",
        "  \"\"\"Abstract class to model a user response.\"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  @abc.abstractmethod\n",
        "  def response_space():\n",
        "    \"\"\"ArraySpec that defines how a single response is represented.\"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def create_observation(self):\n",
        "    \"\"\"Creates a tensor observation of this response.\"\"\"\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractUserState(object):\n",
        "  \"\"\"Abstract class to represent a user's state.\"\"\"\n",
        "\n",
        "  # Number of features to represent the user's interests.\n",
        "  NUM_FEATURES = None\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def create_observation(self):\n",
        "    \"\"\"Generates obs of underlying state to simulate partial observability.\n",
        "\n",
        "    Returns:\n",
        "      obs: A float array of the observed user features.\n",
        "    \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  @abc.abstractmethod\n",
        "  def observation_space():\n",
        "    \"\"\"Gym.spaces object that defines how user states are represented.\"\"\"\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractUserSampler(object):\n",
        "  \"\"\"Abstract class to sample users.\"\"\"\n",
        "\n",
        "  def __init__(self, user_ctor, seed=0):\n",
        "    \"\"\"Creates a new user state sampler.\n",
        "\n",
        "    User states of the type user_ctor are sampled.\n",
        "\n",
        "    Args:\n",
        "      user_ctor: A class/constructor for the type of user states that will be\n",
        "        sampled.\n",
        "      seed: An integer for a random seed.\n",
        "    \"\"\"\n",
        "    self._user_ctor = user_ctor\n",
        "    self._seed = seed\n",
        "    self.reset_sampler()\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    self._rng = np.random.RandomState(self._seed)\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def sample_user(self):\n",
        "    \"\"\"Creates a new instantiation of this user's hidden state parameters.\"\"\"\n",
        "\n",
        "  def get_user_ctor(self):\n",
        "    \"\"\"Returns the constructor/class of the user states that will be sampled.\"\"\"\n",
        "    return self._user_ctor\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractUserModel(object):\n",
        "  \"\"\"Abstract class to represent an encoding of a user's dynamics.\"\"\"\n",
        "\n",
        "  def __init__(self, response_model_ctor, user_sampler, slate_size):\n",
        "    \"\"\"Initializes a new user model.\n",
        "\n",
        "    Args:\n",
        "      response_model_ctor: A class/constructor representing the type of\n",
        "        responses this model will generate.\n",
        "      user_sampler: An instance of AbstractUserSampler that can generate\n",
        "        initial user states from an inital state distribution.\n",
        "      slate_size: integer number of documents that can be served to the user at\n",
        "        any interaction.\n",
        "    \"\"\"\n",
        "    if not response_model_ctor:\n",
        "      raise TypeError('response_model_ctor is a required callable')\n",
        "\n",
        "    self._user_sampler = user_sampler\n",
        "    self._user_state = self._user_sampler.sample_user()\n",
        "    self._response_model_ctor = response_model_ctor\n",
        "    self._slate_size = slate_size\n",
        "\n",
        "  ## Transition model\n",
        "  @abc.abstractmethod\n",
        "  def update_state(self, slate_documents, responses):\n",
        "    \"\"\"Updates the user's state based on the slate and document selected.\n",
        "\n",
        "    Args:\n",
        "      slate_documents: A list of AbstractDocuments for items in the slate.\n",
        "      responses: A list of AbstractResponses for each item in the slate.\n",
        "    Updates: The user's hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Resets the user.\"\"\"\n",
        "    self._user_state = self._user_sampler.sample_user()\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    \"\"\"Resets the sampler.\"\"\"\n",
        "    self._user_sampler.reset_sampler()\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def is_terminal(self):\n",
        "    \"\"\"Returns a boolean indicating whether this session is over.\"\"\"\n",
        "\n",
        "  ## Choice model\n",
        "  @abc.abstractmethod\n",
        "  def simulate_response(self, documents):\n",
        "    \"\"\"Simulates the user's response to a slate of documents.\n",
        "\n",
        "    This could involve simulating models of attention, as well as random\n",
        "    sampling for selection from scored documents.\n",
        "\n",
        "    Args:\n",
        "      documents: a list of AbstractDocuments\n",
        "\n",
        "    Returns:\n",
        "      (response) a list of AbstractResponse objects for each slate item\n",
        "    \"\"\"\n",
        "\n",
        "  def response_space(self):\n",
        "    res_space = self._response_model_ctor.response_space()\n",
        "    return spaces.Tuple(tuple([\n",
        "        res_space,\n",
        "    ] * self._slate_size))\n",
        "\n",
        "  def get_response_model_ctor(self):\n",
        "    \"\"\"Returns a constructor for the type of response this model will create.\"\"\"\n",
        "    return self._response_model_ctor\n",
        "\n",
        "  def observation_space(self):\n",
        "    \"\"\"A Gym.spaces object that describes possible user observations.\"\"\"\n",
        "    return self._user_state.observation_space()\n",
        "\n",
        "  def create_observation(self):\n",
        "    \"\"\"Emits obesrvation about user's state.\"\"\"\n",
        "    return self._user_state.create_observation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkhZv78afzAL"
      },
      "outputs": [],
      "source": [
        "\"\"\"Abstract classes that encode a user's state and dynamics.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import numpy as np\n",
        "import six\n",
        "\n",
        "\n",
        "def softmax(vector):\n",
        "  \"\"\"Computes the softmax of a vector.\"\"\"\n",
        "  normalized_vector = np.array(vector) - np.max(\n",
        "      vector)  # For numerical stability\n",
        "  return np.exp(normalized_vector) / np.sum(np.exp(normalized_vector))\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractChoiceModel(object):\n",
        "  \"\"\"Abstract class to represent the user choice model.\n",
        "\n",
        "  Each user has a choice model.\n",
        "  \"\"\"\n",
        "  _scores = None\n",
        "  _score_no_click = None\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def score_documents(self, user_state, doc_obs):\n",
        "    \"\"\"Computes unnormalized scores of documents in the slate given user state.\n",
        "\n",
        "    Args:\n",
        "      user_state: An instance of AbstractUserState.\n",
        "      doc_obs: A numpy array that represents the observation of all documents in\n",
        "        the slate.\n",
        "    Attributes:\n",
        "      scores: A numpy array that stores the scores of all documents.\n",
        "      score_no_click: A float that represents the score for the action of\n",
        "        picking no document.\n",
        "    \"\"\"\n",
        "\n",
        "  @property\n",
        "  def scores(self):\n",
        "    return self._scores\n",
        "\n",
        "  @property\n",
        "  def score_no_click(self):\n",
        "    return self._score_no_click\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def choose_item(self):\n",
        "    \"\"\"Returns selected index of document in the slate.\n",
        "\n",
        "    Returns:\n",
        "      selected_index: a integer indicating which item was chosen, or None if\n",
        "        none were selected.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "class NormalizableChoiceModel(AbstractChoiceModel):\n",
        "  \"\"\"A normalizable choice model.\"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def _score_documents_helper(user_state, doc_obs):\n",
        "    scores = np.array([])\n",
        "    for doc in doc_obs:\n",
        "      scores = np.append(scores, user_state.score_document(doc))\n",
        "    return scores\n",
        "\n",
        "  def choose_item(self):\n",
        "    all_scores = np.append(self._scores, self._score_no_click)\n",
        "    all_probs = all_scores / np.sum(all_scores)\n",
        "    selected_index = np.random.choice(len(all_probs), p=all_probs)\n",
        "    if selected_index == len(all_probs) - 1:\n",
        "      selected_index = None\n",
        "    return selected_index\n",
        "\n",
        "\n",
        "class MultinomialLogitChoiceModel(NormalizableChoiceModel):\n",
        "  \"\"\"A multinomial logit choice model.\n",
        "\n",
        "   Samples item x in scores according to\n",
        "     p(x) = exp(x) / Sum_{y in scores} exp(y)\n",
        "\n",
        "   Args:\n",
        "     choice_features: a dict that stores the features used in choice model:\n",
        "       `no_click_mass`: a float indicating the mass given to a no click option.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, choice_features):\n",
        "    self._no_click_mass = choice_features.get('no_click_mass', -float('Inf'))\n",
        "\n",
        "  def score_documents(self, user_state, doc_obs):\n",
        "    logits = self._score_documents_helper(user_state, doc_obs)\n",
        "    logits = np.append(logits, self._no_click_mass)\n",
        "    # Use softmax scores instead of exponential scores to avoid overflow.\n",
        "    all_scores = softmax(logits)\n",
        "    self._scores = all_scores[:-1]\n",
        "    self._score_no_click = all_scores[-1]\n",
        "\n",
        "\n",
        "class MultinomialProportionalChoiceModel(NormalizableChoiceModel):\n",
        "  \"\"\"A multinomial proportional choice function.\n",
        "\n",
        "  Samples item x in scores according to\n",
        "    p(x) = x - min_normalizer / sum(x - min_normalizer)\n",
        "\n",
        "  Attributes:\n",
        "    min_normalizer: A float (<= 0) used to offset the scores to be positive.\n",
        "      Specifically, if the scores have negative elements, then they do not\n",
        "      form a valid probability distribution for sampling. Subtracting the\n",
        "      least expected element is one heuristic for normalization.\n",
        "    no_click_mass: An optional float indicating the mass given to a no click\n",
        "      option\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, choice_features):\n",
        "    self._min_normalizer = choice_features.get('min_normalizer')\n",
        "    self._no_click_mass = choice_features.get('no_click_mass', 0)\n",
        "\n",
        "  def score_documents(self, user_state, doc_obs):\n",
        "    scores = self._score_documents_helper(user_state, doc_obs)\n",
        "    all_scores = np.append(scores, self._no_click_mass)\n",
        "    all_scores = all_scores - self._min_normalizer\n",
        "    assert all_scores[\n",
        "        all_scores <\n",
        "        0.0].size == 0, 'Normalized scores have non-positive elements.'\n",
        "    self._scores = all_scores[:-1]\n",
        "    self._score_no_click = all_scores[-1]\n",
        "\n",
        "\n",
        "class CascadeChoiceModel(NormalizableChoiceModel):\n",
        "  \"\"\"The base class for cascade choice models.\n",
        "\n",
        "  Attributes:\n",
        "    attention_prob: The probability of examining a document i given document i -\n",
        "      1 not clicked.\n",
        "    score_scaling: A multiplicative factor to convert score of document i to the\n",
        "      click probability of examined document i.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if either attention_prob or base_attention_prob is invalid.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, choice_features):\n",
        "    self._attention_prob = choice_features.get('attention_prob', 1.0)\n",
        "    self._score_scaling = choice_features.get('score_scaling')\n",
        "    if self._attention_prob < 0.0 or self._attention_prob > 1.0:\n",
        "      raise ValueError('attention_prob must be in [0,1].')\n",
        "    if self._score_scaling < 0.0:\n",
        "      raise ValueError('score_scaling must be positive.')\n",
        "\n",
        "  def _positional_normalization(self, scores):\n",
        "    \"\"\"Computes the click probability of each document in _scores.\n",
        "\n",
        "    The probability to click item i conditioned on unclicked item i - 1 is:\n",
        "      attention_prob * score_scaling * score(i)\n",
        "    We also compute the probability of not clicking any items in _score_no_click\n",
        "    Because they are already probabilities, the normlaization in choose_item\n",
        "    is no-op but we utilize random choice there.\n",
        "\n",
        "    Args:\n",
        "      scores: normalizable scores.\n",
        "    \"\"\"\n",
        "    self._score_no_click = 1.0\n",
        "    for i in range(len(scores)):\n",
        "      s = self._score_scaling * scores[i]\n",
        "      assert s <= 1.0, ('score_scaling cannot convert score %f into a '\n",
        "                        'probability') % scores[i]\n",
        "      scores[i] = self._score_no_click * self._attention_prob * s\n",
        "      self._score_no_click *= (1.0 - self._attention_prob * s)\n",
        "    self._scores = scores\n",
        "\n",
        "\n",
        "class ExponentialCascadeChoiceModel(CascadeChoiceModel):\n",
        "  \"\"\"An exponential cascade choice model.\n",
        "\n",
        "  Clicks the item at position i according to\n",
        "    p(i) = attention_prob * score_scaling * exp(score(i))\n",
        "  by going through the slate in order, and stopping once an item has been\n",
        "  clicked.\n",
        "  \"\"\"\n",
        "\n",
        "  def score_documents(self, user_state, doc_obs):\n",
        "    scores = self._score_documents_helper(user_state, doc_obs)\n",
        "    scores = np.exp(scores)\n",
        "    self._positional_normalization(scores)\n",
        "\n",
        "\n",
        "class ProportionalCascadeChoiceModel(CascadeChoiceModel):\n",
        "  \"\"\"A proportional cascade choice model.\n",
        "\n",
        "  Clicks the item at position i according to\n",
        "    attention_prob * score_scaling * (score(i) - min_normalizer)\n",
        "  by going through the slate in order, and stopping once an item has been\n",
        "  clicked.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, choice_features):\n",
        "    self._min_normalizer = choice_features.get('min_normalizer')\n",
        "    super(ProportionalCascadeChoiceModel, self).__init__(choice_features)\n",
        "\n",
        "  def score_documents(self, user_state, doc_obs):\n",
        "    scores = self._score_documents_helper(user_state, doc_obs)\n",
        "    scores = scores - self._min_normalizer\n",
        "    assert not scores[\n",
        "        scores < 0.0], 'Normalized scores have non-positive elements.'\n",
        "    self._positional_normalization(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDJ4U3B9fzAN"
      },
      "outputs": [],
      "source": [
        "\"\"\"Class to represent the environment in the recommender system setting.\n",
        "\n",
        "   Thus, it models things such as (1) the user's state, for example his/her\n",
        "   interests and circumstances, (2) the documents available to suggest from and\n",
        "   their properties, (3) simulates the selection of an item in the slate (or a\n",
        "   no-op/quit), and (4) models the change in a user's state based on the slate\n",
        "   presented and the document selected.\n",
        "\n",
        "   The agent interacting with the environment is the recommender system.  The\n",
        "   agent receives the state, which is an observation of the user's state and\n",
        "   observations of the candidate documents. The agent then provides an action,\n",
        "   which is a slate (an array of indices into the candidate set).\n",
        "\n",
        "   The goal of the agent is to learn a recommendation policy: a policy that\n",
        "   serves the user a slate (action) based on user and document features (state)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import collections\n",
        "import itertools\n",
        "\n",
        "import six\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractEnvironment(object):\n",
        "  \"\"\"Abstract class representing the recommender system environment.\n",
        "\n",
        "  Attributes:\n",
        "    user_model: An list or single instantiation of AbstractUserModel\n",
        "      representing the user/users.\n",
        "    document_sampler: An instantiation of AbstractDocumentSampler.\n",
        "    num_candidates: An integer representing the size of the candidate_set.\n",
        "    slate_size: An integer representing the slate size.\n",
        "    candidate_set: An instantiation of CandidateSet.\n",
        "    num_clusters: An integer representing the number of document clusters.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               user_model,\n",
        "               document_sampler,\n",
        "               num_candidates,\n",
        "               slate_size,\n",
        "               resample_documents=True):\n",
        "    \"\"\"Initializes a new simulation environment.\n",
        "\n",
        "    Args:\n",
        "      user_model: An instantiation of AbstractUserModel or list of such\n",
        "        instantiations\n",
        "      document_sampler: An instantiation of AbstractDocumentSampler\n",
        "      num_candidates: An integer representing the size of the candidate_set\n",
        "      slate_size: An integer representing the slate size\n",
        "      resample_documents: A boolean indicating whether to resample the candidate\n",
        "        set every step\n",
        "    \"\"\"\n",
        "    self._user_model = user_model\n",
        "    self._document_sampler = document_sampler\n",
        "    self._slate_size = slate_size\n",
        "    self._num_candidates = num_candidates\n",
        "    self._resample_documents = resample_documents\n",
        "\n",
        "    # Create a candidate set.\n",
        "    self._do_resample_documents()\n",
        "    assert (slate_size <= num_candidates\n",
        "           ), 'Slate size %d cannot be larger than number of candidates %d' % (\n",
        "               slate_size, num_candidates)\n",
        "\n",
        "  def _do_resample_documents(self):\n",
        "    # TODO(sanmit): eventually model this creation with content creators.\n",
        "    self._candidate_set = CandidateSet()\n",
        "    for _ in range(self._num_candidates):\n",
        "      self._candidate_set.add_document(self._document_sampler.sample_document())\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def reset(self):\n",
        "    \"\"\"Resets the environment and return the first observation.\n",
        "\n",
        "    Returns:\n",
        "      user_obs: An array of floats representing observations of the user's\n",
        "        current state\n",
        "      doc_obs: An OrderedDict of document observations keyed by document ids\n",
        "    \"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def reset_sampler(self):\n",
        "    \"\"\"Resets the relevant samplers of documents and user/users.\"\"\"\n",
        "\n",
        "  @property\n",
        "  def num_candidates(self):\n",
        "    return self._num_candidates\n",
        "\n",
        "  @property\n",
        "  def slate_size(self):\n",
        "    return self._slate_size\n",
        "\n",
        "  @property\n",
        "  def candidate_set(self):\n",
        "    return self._candidate_set\n",
        "\n",
        "  @property\n",
        "  def user_model(self):\n",
        "    return self._user_model\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def step(self, slate):\n",
        "    \"\"\"Executes the action, returns next state observation and reward.\n",
        "\n",
        "    Args:\n",
        "      slate: An integer array of size slate_size (or list of such arrays), where\n",
        "      each element is an index into the set of current_documents presented.\n",
        "\n",
        "    Returns:\n",
        "      user_obs: A gym observation representing the user's next state\n",
        "      doc_obs: A list of observations of the documents\n",
        "      responses: A list of AbstractResponse objects for each item in the slate\n",
        "      done: A boolean indicating whether the episode has terminated\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "class SingleUserEnvironment(AbstractEnvironment):\n",
        "  \"\"\"Class to represent the environment with one user.\n",
        "\n",
        "  Attributes:\n",
        "    user_model: An instantiation of AbstractUserModel that represents a user.\n",
        "    document_sampler: An instantiation of AbstractDocumentSampler.\n",
        "    num_candidates: An integer representing the size of the candidate_set.\n",
        "    slate_size: An integer representing the slate size.\n",
        "    candidate_set: An instantiation of CandidateSet.\n",
        "    num_clusters: An integer representing the number of document clusters.\n",
        "  \"\"\"\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Resets the environment and return the first observation.\n",
        "\n",
        "    Returns:\n",
        "      user_obs: An array of floats representing observations of the user's\n",
        "        current state\n",
        "      doc_obs: An OrderedDict of document observations keyed by document ids\n",
        "    \"\"\"\n",
        "    self._user_model.reset()\n",
        "    user_obs = self._user_model.create_observation()\n",
        "    if self._resample_documents:\n",
        "      self._do_resample_documents()\n",
        "    self._current_documents = collections.OrderedDict(\n",
        "        self._candidate_set.create_observation())\n",
        "    return (user_obs, self._current_documents)\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    \"\"\"Resets the relevant samplers of documents and user/users.\"\"\"\n",
        "    self._document_sampler.reset_sampler()\n",
        "    self._user_model.reset_sampler()\n",
        "\n",
        "  def step(self, slate):\n",
        "    \"\"\"Executes the action, returns next state observation and reward.\n",
        "\n",
        "    Args:\n",
        "      slate: An integer array of size slate_size, where each element is an index\n",
        "        into the set of current_documents presented\n",
        "\n",
        "    Returns:\n",
        "      user_obs: A gym observation representing the user's next state\n",
        "      doc_obs: A list of observations of the documents\n",
        "      responses: A list of AbstractResponse objects for each item in the slate\n",
        "      done: A boolean indicating whether the episode has terminated\n",
        "    \"\"\"\n",
        "\n",
        "    assert (len(slate) <= self._slate_size\n",
        "           ), 'Received unexpectedly large slate size: expecting %s, got %s' % (\n",
        "               self._slate_size, len(slate))\n",
        "\n",
        "    # Get the documents associated with the slate\n",
        "    doc_ids = list(self._current_documents)  # pytype: disable=attribute-error\n",
        "\n",
        "    mapped_slate = [doc_ids[x] for x in slate]\n",
        "\n",
        "    documents = self._candidate_set.get_documents(mapped_slate)\n",
        "\n",
        "    # Simulate the user's response\n",
        "    responses = self._user_model.simulate_response(documents)\n",
        "\n",
        "    # Update the user's state.\n",
        "    self._user_model.update_state(documents, responses)\n",
        "\n",
        "    # Update the documents' state.\n",
        "    self._document_sampler.update_state(documents, responses)\n",
        "\n",
        "    # Obtain next user state observation.\n",
        "    user_obs = self._user_model.create_observation()\n",
        "\n",
        "    # Check if reaches a terminal state and return.\n",
        "    done = self._user_model.is_terminal()\n",
        "\n",
        "    # Optionally, recreate the candidate set to simulate candidate\n",
        "    # generators for the next query.\n",
        "    if self._resample_documents:\n",
        "      self._do_resample_documents()\n",
        "\n",
        "    # Create observation of candidate set.\n",
        "    self._current_documents = collections.OrderedDict(\n",
        "        self._candidate_set.create_observation())\n",
        "\n",
        "    return (user_obs, self._current_documents, responses, done)\n",
        "\n",
        "\n",
        "Environment = SingleUserEnvironment  # for backwards compatability\n",
        "\n",
        "\n",
        "class MultiUserEnvironment(AbstractEnvironment):\n",
        "  \"\"\"Class to represent environment with multiple users.\n",
        "\n",
        "  Attributes:\n",
        "    user_model: A list of AbstractUserModel instances that represent users.\n",
        "    num_users: An integer representing the number of users.\n",
        "    document_sampler: An instantiation of AbstractDocumentSampler.\n",
        "    num_candidates: An integer representing the size of the candidate_set.\n",
        "    slate_size: An integer representing the slate size.\n",
        "    candidate_set: An instantiation of CandidateSet.\n",
        "    num_clusters: An integer representing the number of document clusters.\n",
        "  \"\"\"\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Resets the environment and return the first observation.\n",
        "\n",
        "    Returns:\n",
        "      user_obs: An array of floats representing observations of the user's\n",
        "        current state\n",
        "      doc_obs: An OrderedDict of document observations keyed by document ids\n",
        "    \"\"\"\n",
        "    for user_model in self.user_model:\n",
        "      user_model.reset()\n",
        "    user_obs = [\n",
        "        user_model.create_observation() for user_model in self.user_model\n",
        "    ]\n",
        "    if self._resample_documents:\n",
        "      self._do_resample_documents()\n",
        "    self._current_documents = collections.OrderedDict(\n",
        "        self._candidate_set.create_observation())\n",
        "    return (user_obs, self._current_documents)\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    self._document_sampler.reset_sampler()\n",
        "    for user_model in self.user_model:\n",
        "      user_model.reset_sampler()\n",
        "\n",
        "  @property\n",
        "  def num_users(self):\n",
        "    return len(self.user_model)\n",
        "\n",
        "  def step(self, slates):\n",
        "    \"\"\"Executes the action, returns next state observation and reward.\n",
        "\n",
        "    Args:\n",
        "      slates: A list of slates, where each slate is an integer array of size\n",
        "        slate_size, where each element is an index into the set of\n",
        "        current_documents presented\n",
        "\n",
        "    Returns:\n",
        "      user_obs: A list of gym observation representing all users' next state\n",
        "      doc_obs: A list of observations of the documents\n",
        "      responses: A list of AbstractResponse objects for each item in the slate\n",
        "      done: A boolean indicating whether the episode has terminated\n",
        "    \"\"\"\n",
        "\n",
        "    assert (len(slates) == self.num_users\n",
        "           ), 'Received unexpected number of slates: expecting %s, got %s' % (\n",
        "               self._slate_size, len(slates))\n",
        "    for i, slate in enumerate(slates):\n",
        "      assert (len(slate) <= self._slate_size\n",
        "             ), 'Slate %s is too large : expecting size %s, got %s' % (\n",
        "                 i, self._slate_size, len(slate))\n",
        "\n",
        "    all_user_obs = []\n",
        "    all_documents = []  # Accumulate documents served to each user.\n",
        "    all_responses = []  # Accumulate each user's responses to served documents.\n",
        "    for user_model, slate in zip(self.user_model, slates):\n",
        "      # Get the documents associated with the slate\n",
        "      doc_ids = list(self._current_documents)  # pytype: disable=attribute-error\n",
        "      mapped_slate = [doc_ids[x] for x in slate]\n",
        "      documents = self._candidate_set.get_documents(mapped_slate)\n",
        "      if user_model.is_terminal():\n",
        "        responses = []\n",
        "      else:\n",
        "        # Simulate the user's response\n",
        "        responses = user_model.simulate_response(documents)\n",
        "\n",
        "        # Update the user's state.\n",
        "        user_model.update_state(documents, responses)\n",
        "\n",
        "      # Obtain next user state observation.\n",
        "      all_user_obs.append(user_model.create_observation())\n",
        "      all_documents.append(documents)\n",
        "      all_responses.append(responses)\n",
        "\n",
        "    def flatten(list_):\n",
        "      return list(itertools.chain(*list_))\n",
        "\n",
        "    # Update the documents' state.\n",
        "    self._document_sampler.update_state(\n",
        "        flatten(all_documents), flatten(all_responses))\n",
        "\n",
        "    # Check if reaches a terminal state and return.\n",
        "    done = all([user_model.is_terminal() for user_model in self.user_model])\n",
        "\n",
        "    # Optionally, recreate the candidate set to simulate candidate\n",
        "    # generators for the next query.\n",
        "    if self._resample_documents:\n",
        "      self._do_resample_documents()\n",
        "\n",
        "    # Create observation of candidate set.\n",
        "    self._current_documents = collections.OrderedDict(\n",
        "        self._candidate_set.create_observation())\n",
        "\n",
        "    return (all_user_obs, self._current_documents, all_responses, done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hNhjT9YfzAO"
      },
      "outputs": [],
      "source": [
        "\"\"\"A wrapper for using Gym environment.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _dummy_metrics_aggregator(responses, metrics, info):\n",
        "  del responses  # Unused.\n",
        "  del metrics  # Unused.\n",
        "  del info  # Unused.\n",
        "  return\n",
        "\n",
        "\n",
        "def _dummy_metrics_writer(metrics, add_summary_fn):\n",
        "  del metrics  # Unused.\n",
        "  del add_summary_fn  # Unused.\n",
        "  return\n",
        "\n",
        "\n",
        "class RecSimGymEnv(gym.Env):\n",
        "  \"\"\"Class to wrap recommender system environment to gym.Env.\n",
        "\n",
        "  Attributes:\n",
        "    game_over: A boolean indicating whether the current game has finished\n",
        "    action_space: A gym.spaces object that specifies the space for possible\n",
        "      actions.\n",
        "    observation_space: A gym.spaces object that specifies the space for possible\n",
        "      observations.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               raw_environment,\n",
        "               reward_aggregator,\n",
        "               metrics_aggregator=_dummy_metrics_aggregator,\n",
        "               metrics_writer=_dummy_metrics_writer):\n",
        "    \"\"\"Initializes a RecSim environment conforming to gym.Env.\n",
        "\n",
        "    Args:\n",
        "      raw_environment: A recsim recommender system environment.\n",
        "      reward_aggregator: A function mapping a list of responses to a number.\n",
        "      metrics_aggregator: A function aggregating metrics over all steps given\n",
        "        responses and response_names.\n",
        "      metrics_writer:  A function writing final metrics to TensorBoard.\n",
        "    \"\"\"\n",
        "    self._environment = raw_environment\n",
        "    self._reward_aggregator = reward_aggregator\n",
        "    self._metrics_aggregator = metrics_aggregator\n",
        "    self._metrics_writer = metrics_writer\n",
        "    self.reset_metrics()\n",
        "\n",
        "  @property\n",
        "  def environment(self):\n",
        "    \"\"\"Returns the recsim recommender system environment.\"\"\"\n",
        "    return self._environment\n",
        "\n",
        "  @property\n",
        "  def game_over(self):\n",
        "    return False\n",
        "\n",
        "  @property\n",
        "  def action_space(self):\n",
        "    \"\"\"Returns the action space of the environment.\n",
        "\n",
        "    Each action is a vector that specified document slate. Each element in the\n",
        "    vector corresponds to the index of the document in the candidate set.\n",
        "    \"\"\"\n",
        "    action_space = spaces.MultiDiscrete(\n",
        "        self._environment.num_candidates * np.ones(\n",
        "            (self._environment.slate_size,)\n",
        "        ))\n",
        "    if isinstance(self._environment, MultiUserEnvironment):\n",
        "      action_space = spaces.Tuple([action_space] * self._environment.num_users)\n",
        "    return action_space\n",
        "\n",
        "  @property\n",
        "  def observation_space(self):\n",
        "    \"\"\"Returns the observation space of the environment.\n",
        "\n",
        "    Each observation is a dictionary with three keys `user`, `doc` and\n",
        "    `response` that includes observation about user state, document and user\n",
        "    response, respectively.\n",
        "    \"\"\"\n",
        "    if isinstance(self._environment, MultiUserEnvironment):\n",
        "      user_obs_space = self._environment.user_model[0].observation_space()\n",
        "      resp_obs_space = self._environment.user_model[0].response_space()\n",
        "      user_obs_space = spaces.Tuple(\n",
        "          [user_obs_space] * self._environment.num_users)\n",
        "      resp_obs_space = spaces.Tuple(\n",
        "          [resp_obs_space] * self._environment.num_users)\n",
        "\n",
        "    if isinstance(self._environment, SingleUserEnvironment):\n",
        "      user_obs_space = self._environment.user_model.observation_space()\n",
        "      resp_obs_space = self._environment.user_model.response_space()\n",
        "\n",
        "    return spaces.Dict({\n",
        "        'user': user_obs_space,\n",
        "        'doc': self._environment.candidate_set.observation_space(),\n",
        "        'response': resp_obs_space,\n",
        "    })\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Runs one timestep of the environment's dynamics.\n",
        "\n",
        "    When end of episode is reached, you are responsible for calling `reset()`\n",
        "    to reset this environment's state. Accepts an action and returns a tuple\n",
        "    (observation, reward, done, info).\n",
        "\n",
        "    Args:\n",
        "      action (object): An action provided by the environment\n",
        "\n",
        "    Returns:\n",
        "      A four-tuple of (observation, reward, done, info) where:\n",
        "        observation (object): agent's observation that include\n",
        "          1. User's state features\n",
        "          2. Document's observation\n",
        "          3. Observation about user's slate responses.\n",
        "        reward (float) : The amount of reward returned after previous action\n",
        "        done (boolean): Whether the episode has ended, in which case further\n",
        "          step() calls will return undefined results\n",
        "        info (dict): Contains responses for the full slate for\n",
        "          debugging/learning.\n",
        "    \"\"\"\n",
        "    user_obs, doc_obs, responses, done = self._environment.step(action)\n",
        "    # print(\"RecSim responses: \", responses)\n",
        "    if isinstance(self._environment, MultiUserEnvironment):\n",
        "      all_responses = tuple(\n",
        "          tuple(\n",
        "              response.create_observation() for response in single_user_resps\n",
        "              ) for single_user_resps in responses\n",
        "          )\n",
        "    else:  # single user environment\n",
        "      if isinstance(responses, list):  # Check if responses is a list or iterable\n",
        "          all_responses = tuple(\n",
        "             response.create_observation() for response in responses)\n",
        "      else:\n",
        "        all_responses = (responses,)  # If it's not a list, make it a single-element tuple\n",
        "    obs = dict(\n",
        "        user=user_obs,\n",
        "        doc=doc_obs,\n",
        "        response=all_responses)\n",
        "\n",
        "    # extract rewards from responses\n",
        "    reward = self._reward_aggregator(responses)\n",
        "    info = self.extract_env_info()\n",
        "    return obs, reward, done, info\n",
        "\n",
        "  def reset(self):\n",
        "    user_obs, doc_obs = self._environment.reset()\n",
        "    return dict(user=user_obs, doc=doc_obs, response=None)\n",
        "\n",
        "  def reset_sampler(self):\n",
        "    self._environment.reset_sampler()\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def close(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def seed(self, seed=None):\n",
        "    np.random.seed(seed=seed)\n",
        "\n",
        "  def extract_env_info(self):\n",
        "    info = {'env': self._environment}\n",
        "    return info\n",
        "\n",
        "  def reset_metrics(self):\n",
        "    \"\"\"Resets every metric to zero.\n",
        "\n",
        "    We reset metrics for every iteration but not every episode. On the other\n",
        "    hand, reset() gets called for every episode.\n",
        "    \"\"\"\n",
        "    self._metrics = collections.defaultdict(float)\n",
        "\n",
        "  def update_metrics(self, responses, info=None):\n",
        "    \"\"\"Updates metrics with one step responses.\"\"\"\n",
        "    self._metrics = self._metrics_aggregator(\n",
        "        responses, self._metrics, info)\n",
        "\n",
        "  def write_metrics(self, add_summary_fn):\n",
        "    \"\"\"Writes metrics to TensorBoard by calling add_summary_fn.\"\"\"\n",
        "    self._metrics_writer(self._metrics, add_summary_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "986HpRv-fzAX",
        "outputId": "dd817c92-fd3e-460b-9afb-18898a660422"
      },
      "outputs": [],
      "source": [
        "r\"\"\"An executable class to run agents in the simulator.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from absl import flags\n",
        "from dopamine.discrete_domains import checkpointer\n",
        "import gin\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "\n",
        "\n",
        "flags.DEFINE_bool(\n",
        "    'debug_mode', False,\n",
        "    'If set to true, the agent will output in-episode statistics '\n",
        "    'to Tensorboard. Disabled by default as this results in '\n",
        "    'slower training.')\n",
        "flags.DEFINE_string('agent_name', None, 'Name of the agent.')\n",
        "flags.DEFINE_string('base_dir', None,\n",
        "                    'Base directory to host all required sub-directories.')\n",
        "flags.DEFINE_string(\n",
        "    'environment_name', 'interest_evolution',\n",
        "    'The environment with which to run the experiment. Supported choices are '\n",
        "    '{interest_evolution, interest_exploration}.')\n",
        "flags.DEFINE_string(\n",
        "    'episode_log_file', '',\n",
        "    'Filename under base_dir to output simulated episodes in SequenceExample.')\n",
        "flags.DEFINE_multi_string(\n",
        "    'gin_files', [], 'List of paths to gin configuration files (e.g.'\n",
        "    '\"third_party/py/dopamine/agents/dqn/dqn.gin\").')\n",
        "flags.DEFINE_multi_string(\n",
        "    'gin_bindings', [],\n",
        "    'Gin bindings to override the values set in the config files '\n",
        "    '(e.g. \"runner_lib.Runner.max_steps_per_episode=100')\n",
        "\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def load_gin_configs(gin_files, gin_bindings):\n",
        "  \"\"\"Loads gin configuration files.\n",
        "\n",
        "  Args:\n",
        "    gin_files: list, of paths to the gin configuration files for this\n",
        "      experiment.\n",
        "    gin_bindings: list, of gin parameter bindings to override the values in the\n",
        "      config files.\n",
        "  \"\"\"\n",
        "  gin.parse_config_files_and_bindings(\n",
        "      gin_files, bindings=gin_bindings, skip_unknown=False)\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "class Runner(object):\n",
        "  \"\"\"Object that handles running experiments.\n",
        "\n",
        "  Here we use the term 'experiment' to mean simulating interactions between the\n",
        "  agent and the environment and reporting some statistics pertaining to these\n",
        "  interactions.\n",
        "  \"\"\"\n",
        "\n",
        "  _output_dir = None\n",
        "  _checkpoint_dir = None\n",
        "  _agent = None\n",
        "  _checkpointer = None\n",
        "\n",
        "  def __init__(self,\n",
        "               base_dir,\n",
        "               create_agent_fn,\n",
        "               env,\n",
        "               episode_log_file='',\n",
        "               checkpoint_file_prefix='ckpt',\n",
        "               max_steps_per_episode=27000):\n",
        "    \"\"\"Initializes the Runner object in charge of running a full experiment.\n",
        "\n",
        "    Args:\n",
        "      base_dir: str, the base directory to host all required sub-directories.\n",
        "      create_agent_fn: A function that takes as args a Tensorflow session and an\n",
        "        environment, and returns an agent.\n",
        "      env: A Gym environment for running the experiments.\n",
        "      episode_log_file: Path to output simulated episodes in tf.SequenceExample.\n",
        "        Disable logging if episode_log_file is an empty string.\n",
        "      checkpoint_file_prefix: str, the prefix to use for checkpoint files.\n",
        "      max_steps_per_episode: int, maximum number of steps after which an episode\n",
        "        terminates.\n",
        "    \"\"\"\n",
        "    tf.logging.info('max_steps_per_episode = %s', max_steps_per_episode)\n",
        "\n",
        "    if base_dir is None:\n",
        "      raise ValueError('Missing base_dir.')\n",
        "\n",
        "    self._base_dir = base_dir\n",
        "    self._create_agent_fn = create_agent_fn\n",
        "    self._env = env\n",
        "    self._checkpoint_file_prefix = checkpoint_file_prefix\n",
        "    self._max_steps_per_episode = max_steps_per_episode\n",
        "    self._episode_log_file = episode_log_file\n",
        "    self._episode_writer = None\n",
        "\n",
        "  def _set_up(self, eval_mode):\n",
        "    \"\"\"Sets up the runner by creating and initializing the agent.\"\"\"\n",
        "    # Reset the tf default graph to avoid name collisions from previous runs\n",
        "    # before doing anything else.\n",
        "    tf.reset_default_graph()\n",
        "    self._summary_writer = tf.summary.FileWriter(self._output_dir)\n",
        "    if self._episode_log_file:\n",
        "      self._episode_writer = tf.io.TFRecordWriter(\n",
        "          os.path.join(self._output_dir, self._episode_log_file))\n",
        "    # Set up a session and initialize variables.\n",
        "    self._sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
        "    self._agent = self._create_agent_fn(\n",
        "        self._sess,\n",
        "        self._env,\n",
        "        summary_writer=self._summary_writer,\n",
        "        eval_mode=eval_mode)\n",
        "    # type check: env/agent must both be multi- or single-user\n",
        "    if self._agent.multi_user and not isinstance(\n",
        "        self._env.environment, MultiUserEnvironment):\n",
        "      raise ValueError('Multi-user agent requires multi-user environment.')\n",
        "    if not self._agent.multi_user and isinstance(\n",
        "        self._env.environment, MultiUserEnvironment):\n",
        "      raise ValueError('Single-user agent requires single-user environment.')\n",
        "    self._summary_writer.add_graph(graph=tf.get_default_graph())\n",
        "    self._sess.run(tf.global_variables_initializer())\n",
        "    self._sess.run(tf.local_variables_initializer())\n",
        "\n",
        "  def _initialize_checkpointer_and_maybe_resume(self, checkpoint_file_prefix):\n",
        "    \"\"\"Reloads the latest checkpoint if it exists.\n",
        "\n",
        "    This method will first create a `Checkpointer` object and then call\n",
        "    `checkpointer.get_latest_checkpoint_number` to determine if there is a valid\n",
        "    checkpoint in self._checkpoint_dir, and what the largest file number is.\n",
        "    If a valid checkpoint file is found, it will load the bundled data from this\n",
        "    file and will pass it to the agent for it to reload its data.\n",
        "    If the agent is able to successfully unbundle, this method will increase and\n",
        "    return the iteration number keyed by 'current_iteration' and the step number\n",
        "    keyed by 'total_steps' as the return values.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_file_prefix: str, the checkpoint file prefix.\n",
        "    Returns:\n",
        "      start_iteration: The iteration number to be continued after the latest\n",
        "        checkpoint.\n",
        "      start_step: The step number to be continued after the latest checkpoint.\n",
        "    \"\"\"\n",
        "    self._checkpointer = checkpointer.Checkpointer(self._checkpoint_dir,\n",
        "                                                   checkpoint_file_prefix)\n",
        "    start_iteration = 0\n",
        "    start_step = 0\n",
        "    # Check if checkpoint exists.\n",
        "    # Note that the existence of checkpoint 0 means that we have finished\n",
        "    # iteration 0 (so we will start from iteration 1).\n",
        "    latest_checkpoint_version = checkpointer.get_latest_checkpoint_number(\n",
        "        self._checkpoint_dir)\n",
        "    if latest_checkpoint_version >= 0:\n",
        "      assert not self._episode_writer, 'Can only log episodes from scratch.'\n",
        "      experiment_data = self._checkpointer.load_checkpoint(\n",
        "          latest_checkpoint_version)\n",
        "      start_iteration = experiment_data['current_iteration'] + 1\n",
        "      del experiment_data['current_iteration']\n",
        "      start_step = experiment_data['total_steps'] + 1\n",
        "      del experiment_data['total_steps']\n",
        "      if self._agent.unbundle(self._checkpoint_dir, latest_checkpoint_version,\n",
        "                              experiment_data):\n",
        "        tf.logging.info(\n",
        "            'Reloaded checkpoint and will start from '\n",
        "            'iteration %d', start_iteration)\n",
        "    return start_iteration, start_step\n",
        "\n",
        "  def _log_one_step(self, user_obs, doc_obs, slate, responses, reward,\n",
        "                    is_terminal, sequence_example):\n",
        "    \"\"\"Adds one step of agent-environment interaction into SequenceExample.\n",
        "\n",
        "    Args:\n",
        "      user_obs: An array of floats representing user state observations\n",
        "      doc_obs: A list of observations of the documents\n",
        "      slate: An array of indices to doc_obs\n",
        "      responses: A list of observations of responses for items in the slate\n",
        "      reward: A float for the reward returned after this step\n",
        "      is_terminal: A boolean for whether a terminal state has been reached\n",
        "      sequence_example: A SequenceExample proto for logging current episode\n",
        "    \"\"\"\n",
        "\n",
        "    def _add_float_feature(feature, values):\n",
        "      feature.feature.add(float_list=tf.train.FloatList(value=values))\n",
        "\n",
        "    def _add_int64_feature(feature, values):\n",
        "      feature.feature.add(int64_list=tf.train.Int64List(value=values))\n",
        "\n",
        "    if self._episode_writer is None:\n",
        "      return\n",
        "    fl = sequence_example.feature_lists.feature_list\n",
        "\n",
        "    if isinstance(self._env.environment, MultiUserEnvironment):\n",
        "      for i, (single_user,\n",
        "              single_slate,\n",
        "              single_user_responses,\n",
        "              single_reward) in enumerate(zip(user_obs,\n",
        "                                              slate,\n",
        "                                              responses,\n",
        "                                              reward)):\n",
        "        user_space = list(self._env.observation_space.spaces['user'].spaces)[i]\n",
        "        _add_float_feature(fl['user_%d' % i], spaces.flatten(\n",
        "            user_space, single_user))\n",
        "        _add_int64_feature(fl['slate_%d' % i], single_slate)\n",
        "        _add_float_feature(fl['reward_%d' % i], [single_reward])\n",
        "        for j, response in enumerate(single_user_responses):\n",
        "          resp_space = self._env.observation_space.spaces['response'][i][0]\n",
        "          for k in response:\n",
        "            _add_float_feature(fl['response_%d_%d_%s' % (i, j, k)],\n",
        "                               spaces.flatten(resp_space, response))\n",
        "    else:  # single-user environment\n",
        "      _add_float_feature(\n",
        "          fl['user'],\n",
        "          spaces.flatten(self._env.observation_space.spaces['user'], user_obs))\n",
        "      _add_int64_feature(fl['slate'], slate)\n",
        "      for i, response in enumerate(responses):\n",
        "        resp_space = self._env.observation_space.spaces['response'][0]\n",
        "        for k in response:\n",
        "          _add_float_feature(fl['response_%d_%s' % (i, k)],\n",
        "                             spaces.flatten(resp_space, response))\n",
        "      _add_float_feature(fl['reward'], [reward])\n",
        "\n",
        "    for i, doc in enumerate(list(doc_obs.values())):\n",
        "      doc_space = list(\n",
        "          self._env.observation_space.spaces['doc'].spaces.values())[i]\n",
        "      _add_float_feature(fl['doc_%d' % i], spaces.flatten(doc_space, doc))\n",
        "\n",
        "    _add_int64_feature(fl['is_terminal'], [is_terminal])\n",
        "\n",
        "  def _run_one_episode(self):\n",
        "    \"\"\"Executes a full trajectory of the agent interacting with the environment.\n",
        "\n",
        "    Returns:\n",
        "      The number of steps taken and the total reward.\n",
        "    \"\"\"\n",
        "    step_number = 0\n",
        "    total_reward = 0.\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    sequence_example = tf.train.SequenceExample()\n",
        "    observation = self._env.reset()\n",
        "    action = self._agent.begin_episode(observation)\n",
        "\n",
        "    # Keep interacting until we reach a terminal state.\n",
        "    while True:\n",
        "      last_observation = observation\n",
        "      observation, reward, done, info = self._env.step(action)\n",
        "      self._log_one_step(last_observation['user'], last_observation['doc'],\n",
        "                         action, observation['response'], reward, done,\n",
        "                         sequence_example)\n",
        "      # Update environment-specific metrics with responses to the slate.\n",
        "      self._env.update_metrics(observation['response'], info)\n",
        "\n",
        "      total_reward += reward\n",
        "      step_number += 1\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "      elif step_number == self._max_steps_per_episode:\n",
        "        # Stop the run loop once we reach the true end of episode.\n",
        "        break\n",
        "      else:\n",
        "        action = self._agent.step(reward, observation)\n",
        "\n",
        "    self._agent.end_episode(reward, observation)\n",
        "    if self._episode_writer is not None:\n",
        "      self._episode_writer.write(sequence_example.SerializeToString())\n",
        "\n",
        "    time_diff = time.time() - start_time\n",
        "    self._update_episode_metrics(\n",
        "        episode_length=step_number,\n",
        "        episode_time=time_diff,\n",
        "        episode_reward=total_reward)\n",
        "\n",
        "    return step_number, total_reward\n",
        "\n",
        "  def _initialize_metrics(self):\n",
        "    \"\"\"Initializes the metrics.\"\"\"\n",
        "    self._stats = {\n",
        "        'episode_length': [],\n",
        "        'episode_time': [],\n",
        "        'episode_reward': [],\n",
        "    }\n",
        "    # Initialize environment-specific metrics.\n",
        "    self._env.reset_metrics()\n",
        "\n",
        "  def _update_episode_metrics(self, episode_length, episode_time,\n",
        "                              episode_reward):\n",
        "    \"\"\"Updates the episode metrics with one episode.\"\"\"\n",
        "\n",
        "    self._stats['episode_length'].append(episode_length)\n",
        "    self._stats['episode_time'].append(episode_time)\n",
        "    self._stats['episode_reward'].append(episode_reward)\n",
        "\n",
        "  def _write_metrics(self, step, suffix):\n",
        "    \"\"\"Writes the metrics to Tensorboard summaries.\"\"\"\n",
        "\n",
        "    def add_summary(tag, value):\n",
        "      summary = tf.Summary(\n",
        "          value=[tf.Summary.Value(tag=tag + '/' + suffix, simple_value=value)])\n",
        "      self._summary_writer.add_summary(summary, step)\n",
        "\n",
        "    num_steps = np.sum(self._stats['episode_length'])\n",
        "    time_per_step = np.sum(self._stats['episode_time']) / num_steps\n",
        "\n",
        "    add_summary('TimePerStep', time_per_step)\n",
        "    add_summary('AverageEpisodeLength', np.mean(self._stats['episode_length']))\n",
        "    add_summary('AverageEpisodeRewards', np.mean(self._stats['episode_reward']))\n",
        "    add_summary('StdEpisodeRewards', np.std(self._stats['episode_reward']))\n",
        "\n",
        "    # Environment-specific Tensorboard summaries.\n",
        "    self._env.write_metrics(add_summary)\n",
        "\n",
        "    self._summary_writer.flush()\n",
        "\n",
        "  def _checkpoint_experiment(self, iteration, total_steps):\n",
        "    \"\"\"Checkpoints experiment data.\n",
        "\n",
        "    Args:\n",
        "      iteration: int, iteration number for checkpointing.\n",
        "      total_steps: int, total number of steps for all iterations so far.\n",
        "    \"\"\"\n",
        "    experiment_data = self._agent.bundle_and_checkpoint(self._checkpoint_dir,\n",
        "                                                        iteration)\n",
        "    if experiment_data:\n",
        "      experiment_data['current_iteration'] = iteration\n",
        "      experiment_data['total_steps'] = total_steps\n",
        "      self._checkpointer.save_checkpoint(iteration, experiment_data)\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "class TrainRunner(Runner):\n",
        "  \"\"\"Object that handles running the training.\n",
        "\n",
        "  See main.py for a simple example to train an agent.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, max_training_steps=250000, num_iterations=100,\n",
        "               checkpoint_frequency=1, **kwargs):\n",
        "    tf.logging.info(\n",
        "        'max_training_steps = %s, number_iterations = %s,'\n",
        "        'checkpoint frequency = %s iterations.', max_training_steps,\n",
        "        num_iterations, checkpoint_frequency)\n",
        "\n",
        "    super(TrainRunner, self).__init__(**kwargs)\n",
        "    self._max_training_steps = max_training_steps\n",
        "    self._num_iterations = num_iterations\n",
        "    self._checkpoint_frequency = checkpoint_frequency\n",
        "\n",
        "    self._output_dir = os.path.join(self._base_dir, 'train')\n",
        "    self._checkpoint_dir = os.path.join(self._output_dir, 'checkpoints')\n",
        "\n",
        "    self._set_up(eval_mode=False)\n",
        "\n",
        "  def run_experiment(self):\n",
        "    \"\"\"Runs a full experiment, spread over multiple iterations.\"\"\"\n",
        "    tf.logging.info('Beginning training...')\n",
        "    start_iter, total_steps = self._initialize_checkpointer_and_maybe_resume(\n",
        "        self._checkpoint_file_prefix)\n",
        "    if self._num_iterations <= start_iter:\n",
        "      tf.logging.warning('num_iterations (%d) < start_iteration(%d)',\n",
        "                         self._num_iterations, start_iter)\n",
        "      return\n",
        "\n",
        "    for iteration in range(start_iter, self._num_iterations):\n",
        "      tf.logging.info('Starting iteration %d', iteration)\n",
        "      total_steps = self._run_train_phase(total_steps)\n",
        "      if iteration % self._checkpoint_frequency == 0:\n",
        "        self._checkpoint_experiment(iteration, total_steps)\n",
        "\n",
        "  def _run_train_phase(self, total_steps):\n",
        "    \"\"\"Runs training phase and updates total_steps.\"\"\"\n",
        "\n",
        "    self._initialize_metrics()\n",
        "\n",
        "    num_steps = 0\n",
        "\n",
        "    while num_steps < self._max_training_steps:\n",
        "      episode_length, _ = self._run_one_episode()\n",
        "      num_steps += episode_length\n",
        "\n",
        "    total_steps += num_steps\n",
        "    self._write_metrics(total_steps, suffix='train')\n",
        "    return total_steps\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "class EvalRunner(Runner):\n",
        "  \"\"\"Object that handles running the evaluation.\n",
        "\n",
        "  See main.py for a simple example to evaluate an agent.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               max_eval_episodes=125000,\n",
        "               test_mode=False,\n",
        "               min_interval_secs=30,\n",
        "               train_base_dir=None,\n",
        "               **kwargs):\n",
        "    tf.logging.info('max_eval_episodes = %s', max_eval_episodes)\n",
        "    super(EvalRunner, self).__init__(**kwargs)\n",
        "    self._max_eval_episodes = max_eval_episodes\n",
        "    self._test_mode = test_mode\n",
        "    self._min_interval_secs = min_interval_secs\n",
        "\n",
        "    self._output_dir = os.path.join(self._base_dir,\n",
        "                                    'eval_%s' % max_eval_episodes)\n",
        "    tf.io.gfile.makedirs(self._output_dir)\n",
        "    if train_base_dir is None:\n",
        "      train_base_dir = self._base_dir\n",
        "    self._checkpoint_dir = os.path.join(train_base_dir, 'train', 'checkpoints')\n",
        "\n",
        "    self._set_up(eval_mode=True)\n",
        "\n",
        "  def run_experiment(self):\n",
        "    \"\"\"Runs a full experiment, spread over multiple iterations.\"\"\"\n",
        "    tf.logging.info('Beginning evaluation...')\n",
        "    # Use the checkpointer class.\n",
        "    self._checkpointer = checkpointer.Checkpointer(\n",
        "        self._checkpoint_dir, self._checkpoint_file_prefix)\n",
        "    checkpoint_version = -1\n",
        "    # Check new checkpoints in a loop.\n",
        "    while True:\n",
        "      # Check if checkpoint exists.\n",
        "      # Note that the existence of checkpoint 0 means that we have finished\n",
        "      # iteration 0 (so we will start from iteration 1).\n",
        "      latest_checkpoint_version = checkpointer.get_latest_checkpoint_number(\n",
        "          self._checkpoint_dir)\n",
        "      # checkpoints_iterator already makes sure a new checkpoint exists.\n",
        "      if latest_checkpoint_version <= checkpoint_version:\n",
        "        time.sleep(self._min_interval_secs)\n",
        "        continue\n",
        "      checkpoint_version = latest_checkpoint_version\n",
        "      experiment_data = self._checkpointer.load_checkpoint(\n",
        "          latest_checkpoint_version)\n",
        "      assert self._agent.unbundle(self._checkpoint_dir,\n",
        "                                  latest_checkpoint_version, experiment_data)\n",
        "\n",
        "      self._run_eval_phase(experiment_data['total_steps'])\n",
        "      if self._test_mode:\n",
        "        break\n",
        "\n",
        "  def _run_eval_phase(self, total_steps):\n",
        "    \"\"\"Runs evaluation phase given model has been trained for total_steps.\"\"\"\n",
        "\n",
        "    self._env.reset_sampler()\n",
        "    self._initialize_metrics()\n",
        "\n",
        "    num_episodes = 0\n",
        "    episode_rewards = []\n",
        "\n",
        "    while num_episodes < self._max_eval_episodes:\n",
        "      _, episode_reward = self._run_one_episode()\n",
        "      episode_rewards.append(episode_reward)\n",
        "      num_episodes += 1\n",
        "\n",
        "    self._write_metrics(total_steps, suffix='eval')\n",
        "\n",
        "    output_file = os.path.join(self._output_dir, 'returns_%s' % total_steps)\n",
        "    tf.logging.info('eval_file: %s', output_file)\n",
        "    with tf.io.gfile.GFile(output_file, 'w+') as f:\n",
        "      f.write(str(episode_rewards))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqJMc5ovfzAZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"Utility functions for RecSim environment.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "def aggregate_video_cluster_metrics(responses, metrics, info=None):\n",
        "  \"\"\"Aggregates the video cluster metrics with one step responses.\n",
        "\n",
        "  Args:\n",
        "    responses: a dictionary of names, observed responses.\n",
        "    metrics: A dictionary mapping from metric_name to its value in float.\n",
        "    info: Additional info for computing metrics (ignored here)\n",
        "\n",
        "  Returns:\n",
        "    A dictionary storing metrics after aggregation.\n",
        "  \"\"\"\n",
        "  del info  # Unused.\n",
        "  is_clicked = False\n",
        "  metrics['impression'] += 1\n",
        "\n",
        "  for response in responses:\n",
        "    if not response['click']:\n",
        "      continue\n",
        "    is_clicked = True\n",
        "    metrics['click'] += 1\n",
        "    metrics['quality'] += response['quality']\n",
        "    cluster_id = response['cluster_id']\n",
        "    metrics['cluster_watch_count_cluster_%d' % cluster_id] += 1\n",
        "\n",
        "  if not is_clicked:\n",
        "    metrics['cluster_watch_count_no_click'] += 1\n",
        "  return metrics\n",
        "\n",
        "\n",
        "def write_video_cluster_metrics(metrics, add_summary_fn):\n",
        "  \"\"\"Writes average video cluster metrics using add_summary_fn.\"\"\"\n",
        "  add_summary_fn('CTR', metrics['click'] / metrics['impression'])\n",
        "  if metrics['click'] > 0:\n",
        "    add_summary_fn('AverageQuality', metrics['quality'] / metrics['click'])\n",
        "  for k in metrics:\n",
        "    prefix = 'cluster_watch_count_cluster_'\n",
        "    if k.startswith(prefix):\n",
        "      add_summary_fn('cluster_watch_count_frac/cluster_%s' % k[len(prefix):],\n",
        "                     metrics[k] / metrics['impression'])\n",
        "  add_summary_fn(\n",
        "      'cluster_watch_count_frac/no_click',\n",
        "      metrics['cluster_watch_count_no_click'] / metrics['impression'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI7V77etfzAa"
      },
      "outputs": [],
      "source": [
        "env_config = {'slate_size': 2,\n",
        "              'seed': 0,\n",
        "              'num_candidates': 15,\n",
        "              'resample_documents': True}\n",
        "ie_environment = create_environment(env_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfloZMe1fzAb"
      },
      "outputs": [],
      "source": [
        "initial_observation = ie_environment.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TamWtwAfzAb",
        "outputId": "01c09838-d4d6-4402-ec4d-5014e275367e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Observable Features\n",
            "[]\n",
            "User Response\n",
            "None\n",
            "Document Observable Features\n",
            "ID: 15 features: {'quality': array(1.22720163), 'cluster_id': 1}\n",
            "ID: 16 features: {'quality': array(1.29258489), 'cluster_id': 1}\n",
            "ID: 17 features: {'quality': array(1.23977078), 'cluster_id': 1}\n",
            "ID: 18 features: {'quality': array(1.46045555), 'cluster_id': 1}\n",
            "ID: 19 features: {'quality': array(2.10233425), 'cluster_id': 0}\n",
            "ID: 20 features: {'quality': array(1.09572905), 'cluster_id': 1}\n",
            "ID: 21 features: {'quality': array(2.37256963), 'cluster_id': 0}\n",
            "ID: 22 features: {'quality': array(1.34928002), 'cluster_id': 1}\n",
            "ID: 23 features: {'quality': array(1.00670188), 'cluster_id': 1}\n",
            "ID: 24 features: {'quality': array(1.20448562), 'cluster_id': 1}\n",
            "ID: 25 features: {'quality': array(2.18351159), 'cluster_id': 0}\n",
            "ID: 26 features: {'quality': array(1.19411585), 'cluster_id': 1}\n",
            "ID: 27 features: {'quality': array(1.03514646), 'cluster_id': 1}\n",
            "ID: 28 features: {'quality': array(2.29592623), 'cluster_id': 0}\n",
            "ID: 29 features: {'quality': array(2.05936556), 'cluster_id': 0}\n"
          ]
        }
      ],
      "source": [
        "print('User Observable Features')\n",
        "print(initial_observation['user'])\n",
        "print('User Response')\n",
        "print(initial_observation['response'])\n",
        "print('Document Observable Features')\n",
        "for doc_id, doc_features in initial_observation['doc'].items():\n",
        "  print('ID:', doc_id, 'features:', doc_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_ADYoKBfzAb",
        "outputId": "dd4e9991-7e98-410c-e27b-7e1b3250e104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document observation space\n",
            "15 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "16 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "17 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "18 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "19 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "20 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "21 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "22 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "23 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "24 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "25 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "26 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "27 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "28 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "29 : Dict('cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32))\n",
            "Response observation space\n",
            "Tuple(Dict('click': Discrete(2), 'cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32)), Dict('click': Discrete(2), 'cluster_id': Discrete(2), 'quality': Box(0.0, inf, (), float32)))\n",
            "User observation space\n",
            "Box([], [], (0,), float32)\n"
          ]
        }
      ],
      "source": [
        "print('Document observation space')\n",
        "for key, space in ie_environment.observation_space['doc'].spaces.items():\n",
        "  print(key, ':', space)\n",
        "print('Response observation space')\n",
        "print(ie_environment.observation_space['response'])\n",
        "print('User observation space')\n",
        "print(ie_environment.observation_space['user'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rocvgyv_fzAc",
        "outputId": "ea096cc8-0406-4e08-dcf4-6a7cd51a404d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('15', {'quality': array(1.22720163), 'cluster_id': 1})\n",
            "('16', {'quality': array(1.29258489), 'cluster_id': 1})\n"
          ]
        }
      ],
      "source": [
        "slate = [0, 1]\n",
        "for slate_doc in slate:\n",
        "  print(list(initial_observation['doc'].items())[slate_doc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi8W1wYAfzAc",
        "outputId": "8d19d6e9-66c0-4a8a-ee66-6d3cf57bef07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiDiscrete([15 15])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ie_environment.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fOCXPR2fzAd"
      },
      "outputs": [],
      "source": [
        "observation, reward, done, _ = ie_environment.step(slate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfJ-p1mPfzAd"
      },
      "outputs": [],
      "source": [
        "\"\"\"Abstract interface for recommender system agents.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "from absl import logging\n",
        "import six\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractRecommenderAgent(object):\n",
        "  \"\"\"Abstract class to model a recommender system agent.\"\"\"\n",
        "  _multi_user = False\n",
        "\n",
        "  def __init__(self, action_space):\n",
        "    \"\"\"Initializes AbstractRecommenderAgent.\n",
        "\n",
        "    Args:\n",
        "      action_space: A gym.spaces object that specifies the format of actions.\n",
        "    \"\"\"\n",
        "    self._slate_size = action_space.nvec.shape[0]\n",
        "\n",
        "  @property\n",
        "  def multi_user(self):\n",
        "    \"\"\"Returns boolean indicating whether this agent serves multiple users.\"\"\"\n",
        "    return self._multi_user\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def step(self, reward, observation):\n",
        "    \"\"\"Records the most recent transition and returns the agent's next action.\n",
        "\n",
        "    We store the observation of the last time step since we want to store it\n",
        "    with the reward.\n",
        "\n",
        "    Args:\n",
        "      reward: The reward received from the agent's most recent action as a\n",
        "        float.\n",
        "      observation: A dictionary that includes the most recent observations.\n",
        "\n",
        "    Returns:\n",
        "      slate: An integer array of size _slate_size, where each element is an\n",
        "        index into the list of doc_obs\n",
        "    \"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def bundle_and_checkpoint(self, checkpoint_dir, iteration_number):\n",
        "    \"\"\"Returns a self-contained bundle of the agent's state.\n",
        "\n",
        "    This is used for checkpointing. It will return a dictionary containing all\n",
        "    non-TensorFlow objects (to be saved into a file by the caller), and it saves\n",
        "    all TensorFlow objects into a checkpoint file.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string for the directory where objects will be saved.\n",
        "      iteration_number: An integer of iteration number to use for naming the\n",
        "        checkpoint file.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary containing additional Python objects to be checkpointed by\n",
        "        the experiment. Each key is a string for the object name and the value\n",
        "        is actual object. If the checkpoint directory does not exist, returns\n",
        "        empty dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def unbundle(self, checkpoint_dir, iteration_number, bundle_dict):\n",
        "    \"\"\"Restores the agent from a checkpoint.\n",
        "\n",
        "    Restores the agent's Python objects to those specified in bundle_dict,\n",
        "    and restores the TensorFlow objects to those specified in the\n",
        "    checkpoint_dir. If the checkpoint_dir does not exist, will not reset the\n",
        "    agent's state.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string that represents the path to the checkpoint saved\n",
        "        by tf.Save.\n",
        "      iteration_number: An integer that represents the checkpoint version and is\n",
        "        used when restoring replay buffer.\n",
        "      bundle_dict: A dict containing additional Python objects owned by the\n",
        "        agent. Each key is an object name and the value is the actual object.\n",
        "\n",
        "    Returns:\n",
        "      bool, True if unbundling was successful.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "class AbstractEpisodicRecommenderAgent(AbstractRecommenderAgent):\n",
        "  \"\"\"Abstract class for recommender systems that solves episodic tasks.\"\"\"\n",
        "\n",
        "  def __init__(self, action_space, summary_writer=None):\n",
        "    \"\"\"Initializes AbstractEpisodicRecommenderAgent.\n",
        "\n",
        "    Args:\n",
        "      action_space: A gym.spaces object that specifies the format of actions.\n",
        "      summary_writer: A Tensorflow summary writer to pass to the agent\n",
        "        for in-agent training statistics in Tensorboard.\n",
        "    \"\"\"\n",
        "    super(AbstractEpisodicRecommenderAgent, self).__init__(action_space)\n",
        "    self._episode_num = 0\n",
        "    self._summary_writer = summary_writer\n",
        "\n",
        "  def begin_episode(self, observation=None):\n",
        "    \"\"\"Returns the agent's first action for this episode.\n",
        "\n",
        "    Args:\n",
        "      observation: numpy array, the environment's initial observation.\n",
        "\n",
        "    Returns:\n",
        "      slate: An integer array of size _slate_size, where each element is an\n",
        "        index into the list of doc_obs\n",
        "    \"\"\"\n",
        "    self._episode_num += 1\n",
        "    return self.step(0, observation)\n",
        "\n",
        "  def end_episode(self, reward, observation=None):\n",
        "    \"\"\"Signals the end of the episode to the agent.\n",
        "\n",
        "    Args:\n",
        "      reward: An float that is the last reward from the environment.\n",
        "      observation: numpy array that represents the last observation of the\n",
        "        episode.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  def bundle_and_checkpoint(self, checkpoint_dir, iteration_number):\n",
        "    \"\"\"Returns a self-contained bundle of the agent's state.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string that represents the path to the checkpoint and is\n",
        "        used when we save TensorFlow objects by tf.Save.\n",
        "      iteration_number: An integer that represents the checkpoint version and is\n",
        "        used when restoring replay buffer.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary containing additional Python objects to be checkpointed by\n",
        "        the experiment. Each key is a string for the object name and the value\n",
        "        is actual object. If the checkpoint directory does not exist, returns\n",
        "        empty dictionary.\n",
        "    \"\"\"\n",
        "    del checkpoint_dir  # Unused.\n",
        "    del iteration_number  # Unused.\n",
        "    bundle_dict = {}\n",
        "    bundle_dict['episode_num'] = self._episode_num\n",
        "    return bundle_dict\n",
        "\n",
        "  def unbundle(self, checkpoint_dir, iteration_number, bundle_dict):\n",
        "    \"\"\"Restores the agent from a checkpoint.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string that represents the path to the checkpoint and is\n",
        "        used when we save TensorFlow objects by tf.Save.\n",
        "      iteration_number: An integer that represents the checkpoint version and is\n",
        "        used when restoring replay buffer.\n",
        "      bundle_dict: A dict containing additional Python objects owned by the\n",
        "        agent. Each key is an object name and the value is the actual object.\n",
        "\n",
        "    Returns:\n",
        "      bool, True if unbundling was successful.\n",
        "    \"\"\"\n",
        "    del checkpoint_dir  # Unused.\n",
        "    del iteration_number  # Unused.\n",
        "    if 'episode_num' not in bundle_dict:\n",
        "      logging.warning(\n",
        "          'Could not unbundle from checkpoint files with exception.')\n",
        "      return False\n",
        "    self._episode_num = bundle_dict['episode_num']\n",
        "    return True\n",
        "\n",
        "\n",
        "@six.add_metaclass(abc.ABCMeta)\n",
        "class AbstractMultiUserEpisodicRecommenderAgent(\n",
        "    AbstractEpisodicRecommenderAgent):\n",
        "  \"\"\"Abstract class to model a recommender agent handling multiple users.\"\"\"\n",
        "  _multi_user = True\n",
        "\n",
        "  def __init__(self, action_space):\n",
        "    \"\"\"Initializes AbstractMultiUserEpisodicRecommenderAgent.\n",
        "\n",
        "    Args:\n",
        "      action_space: A gym.spaces object that specifies the format of actions.\n",
        "    \"\"\"\n",
        "    self._num_users = len(action_space)\n",
        "    if not self._num_users > 0:\n",
        "      raise ValueError('Multi-user agent must have at least 1 user.')\n",
        "    super(AbstractMultiUserEpisodicRecommenderAgent, self).__init__(\n",
        "        action_space[0]\n",
        "    )\n",
        "\n",
        "\n",
        "class AbstractHierarchicalAgentLayer(AbstractRecommenderAgent):\n",
        "  \"\"\"Parent class for stackable agent layers.\"\"\"\n",
        "\n",
        "  def __init__(self, action_space, *base_agent_ctors):\n",
        "    super(AbstractHierarchicalAgentLayer, self).__init__(action_space)\n",
        "    self._base_agent_ctors = base_agent_ctors\n",
        "    self._base_agents = None\n",
        "\n",
        "  def _preprocess_reward_observation(self, reward, observation):\n",
        "    r\"\"\"Modifies the reward and observation before passing to base agent.\n",
        "\n",
        "    This function is used to modify the observation and reward before\n",
        "    propagating it downward to the base agent. For example, it can\n",
        "    inject additional features like sufficient statistics by inserting fields\n",
        "    to observation[\\'user\\'], or, to implement regularization schemes by\n",
        "    subtracting penalties from the reward.\n",
        "\n",
        "    Args:\n",
        "      reward: float number.\n",
        "      observation: gym space in recsim format.\n",
        "\n",
        "    Returns:\n",
        "      reward: float number.\n",
        "      observation: gym space in recsim format.\n",
        "    \"\"\"\n",
        "    return reward, observation\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def _postprocess_actions(self, action_list):\n",
        "    r\"\"\"Aggregates (possibly abstract) base agent actions into a valid slate.\"\"\"\n",
        "\n",
        "  def begin_episode(self, observation=None):\n",
        "    if observation is not None:\n",
        "      _, observation = self._preprocess_reward_observation(0, observation)\n",
        "    action_list = [\n",
        "        base_agent.begin_episode(observation=observation)\n",
        "        for base_agent in self._base_agents\n",
        "    ]\n",
        "    return self._postprocess_actions(action_list)\n",
        "\n",
        "  def end_episode(self, reward, observation):\n",
        "    reward, observation = self._preprocess_reward_observation(\n",
        "        reward, observation)\n",
        "    action_list = [\n",
        "        base_agent.end_episode(reward, observation=observation)\n",
        "        for base_agent in self._base_agents\n",
        "    ]\n",
        "    return self._postprocess_actions(action_list)\n",
        "\n",
        "  def bundle_and_checkpoint(self, checkpoint_dir, iteration_number):\n",
        "    \"\"\"Returns a self-contained bundle of the agent's state.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string for the directory where objects will be saved.\n",
        "      iteration_number: An integer of iteration number to use for naming the\n",
        "        checkpoint file.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary containing additional Python objects to be checkpointed by\n",
        "        the experiment. Each key is a string for the object name and the value\n",
        "        is actual object. If the checkpoint directory does not exist, returns\n",
        "        empty dictionary.\n",
        "    \"\"\"\n",
        "    bundle_dict = {}\n",
        "    for i, base_agent in enumerate(self._base_agents):\n",
        "      base_bundle_dict = base_agent.bundle_and_checkpoint(\n",
        "          checkpoint_dir, iteration_number)\n",
        "      bundle_dict['base_agent_bundle_{}'.format(i)] = base_bundle_dict\n",
        "    return bundle_dict\n",
        "\n",
        "  def unbundle(self, checkpoint_dir, iteration_number, bundle_dict):\n",
        "    \"\"\"Restores the agent from a checkpoint.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_dir: A string that represents the path to the checkpoint saved\n",
        "        by tf.Save.\n",
        "      iteration_number: An integer that represents the checkpoint version and is\n",
        "        used when restoring replay buffer.\n",
        "      bundle_dict: A dict containing additional Python objects owned by the\n",
        "        agent. Each key is an object name and the value is the actual object.\n",
        "\n",
        "    Returns:\n",
        "      bool, True if unbundling was successful.\n",
        "    \"\"\"\n",
        "    success = True\n",
        "    for i, base_agent in enumerate(self._base_agents):\n",
        "      if 'base_agent_bundle_{}'.format(i) not in bundle_dict:\n",
        "        logging.warning('Base agent bundle not found in bundle.')\n",
        "        return False\n",
        "      success &= base_agent.unbundle(\n",
        "          checkpoint_dir, iteration_number,\n",
        "          bundle_dict['base_agent_bundle_{}'.format(i)])\n",
        "    return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jRFe8agfzAe"
      },
      "outputs": [],
      "source": [
        "\"\"\"Helper classes to record user response history on recommendations.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "\n",
        "class SufficientStatisticsLayer(AbstractHierarchicalAgentLayer):\n",
        "  \"\"\"A module to log user responses on different clusters.\n",
        "\n",
        "  This module assumes each document belongs to single cluster and we know the\n",
        "  number of possible clusters. Every time we increase impression count for a\n",
        "  cluster if the agent recommends a document from that cluster. We also increase\n",
        "  click count for a cluster if user responds a click.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, base_agent_ctor, observation_space, action_space,\n",
        "               sufficient_statistics_space, **kwargs):\n",
        "    \"\"\"Initializes a UserClusterHistory object.\n",
        "\n",
        "    Args:\n",
        "      base_agent_ctor: a constructor for the base agent.\n",
        "      observation_space: a gym.spaces object specifying the format of\n",
        "        observations.\n",
        "      action_space: A gym.spaces object that specifies the format of actions.\n",
        "      sufficient_statistics_space: a gym.spaces object specifying the format of\n",
        "        the created sufficient statistics.\n",
        "      **kwargs: arguments to pass to the downstream agent at construction time.\n",
        "    \"\"\"\n",
        "    super(SufficientStatisticsLayer, self).__init__(action_space,\n",
        "                                                    base_agent_ctor)\n",
        "    self._sufficient_statistcs_space = sufficient_statistics_space\n",
        "    self._sufficient_statistics = None\n",
        "    augmented_observation_space = {\n",
        "        'user':\n",
        "            spaces.Dict({\n",
        "                'raw_observation': observation_space.spaces['user'],\n",
        "                'sufficient_statistics': sufficient_statistics_space\n",
        "            }),\n",
        "        'response':\n",
        "            observation_space.spaces['response'],\n",
        "        'doc':\n",
        "            observation_space.spaces['doc']\n",
        "    }\n",
        "    self._observation_space = observation_space\n",
        "    self._base_observation_space = spaces.Dict(augmented_observation_space)\n",
        "    kwargs['observation_space'] = self._base_observation_space\n",
        "    kwargs['action_space'] = action_space\n",
        "    self._base_agents = [\n",
        "        self._base_agent_ctors[0](**kwargs),\n",
        "    ]\n",
        "    self._reset()\n",
        "\n",
        "  @property\n",
        "  def observation_space(self):\n",
        "    return self._observation_space\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def _update(self, observation):\n",
        "    \"\"\"Updates self._sufficient_statistics given a new observation.\n",
        "\n",
        "    If self._sufficient_statistics is None, this function must also initialize\n",
        "    it.\n",
        "\n",
        "    Args:\n",
        "     observation: an observation conforming to self._observation_space.\n",
        "    \"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def _create_observation(self):\n",
        "    \"\"\"Formats self._sufficient_statistics into an observation.\"\"\"\n",
        "\n",
        "  def _preprocess_reward_observation(self, reward, observation):\n",
        "    self._update(observation)\n",
        "    augmented_observation = {key: value for key, value in observation.items()}\n",
        "    augmented_observation['user'] = {\n",
        "        'raw_observation': augmented_observation['user'],\n",
        "        'sufficient_statistics': self._create_observation()\n",
        "    }\n",
        "    return reward, augmented_observation\n",
        "\n",
        "  def _postprocess_actions(self, action_list):\n",
        "    # Does not modify the action of the base agent.\n",
        "    return action_list[0]\n",
        "\n",
        "  def step(self, reward, observation):\n",
        "    reward, augmented_observation = self._preprocess_reward_observation(\n",
        "        reward, observation)\n",
        "    action_list = [\n",
        "        base_agent.step(reward, augmented_observation)\n",
        "        for base_agent in self._base_agents\n",
        "    ]\n",
        "    return self._postprocess_actions(action_list)\n",
        "\n",
        "  def end_episode(self, reward, observation):\n",
        "    super(SufficientStatisticsLayer, self).end_episode(reward, observation)\n",
        "    self._reset()\n",
        "\n",
        "  def _reset(self):\n",
        "    \"\"\"Resets the memory for a new user.\"\"\"\n",
        "    self._sufficient_statistics = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrEaTa-ffzAf"
      },
      "outputs": [],
      "source": [
        "\"\"\"Helper class to collect cluster click and impression counts.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class ClusterClickStatsLayer(SufficientStatisticsLayer):\n",
        "  \"\"\"Track impressions and clicks on a per-cluster basis and pass down to agent.\n",
        "\n",
        "  This module assumes each document belongs to single cluster and we know the\n",
        "  number of possible clusters. Every time we increase impression count for a\n",
        "  cluster if the agent recommends a document from that cluster. We also increase\n",
        "  click count for a cluster if user responds a click.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, base_agent_ctor, observation_space, action_space,\n",
        "               **kwargs):\n",
        "    \"\"\"Initializes a ClusterClickStatsLayer object.\n",
        "\n",
        "    Args:\n",
        "      base_agent_ctor: a constructor for the base agent.\n",
        "      observation_space: a gym.spaces object specifying the format of\n",
        "        observations.\n",
        "      action_space: A gym.spaces object that specifies the format of actions.\n",
        "      **kwargs: arguments to pass to the downstream agent at construction time.\n",
        "    \"\"\"\n",
        "    single_response_space = observation_space.spaces['response'].spaces[0]\n",
        "    if 'cluster_id' not in single_response_space.spaces:\n",
        "      raise ValueError('observation_space.spaces[\\'response\\']'\n",
        "                       ' must contain \\'cluster_id\\' key.')\n",
        "    cluster_id_space = single_response_space.spaces['cluster_id']\n",
        "    if isinstance(cluster_id_space, spaces.Box):\n",
        "      if len(cluster_id_space.high) > 1:\n",
        "        raise ValueError('cluster_id response field must be 0 dimensional.')\n",
        "      num_clusters = cluster_id_space.high\n",
        "    elif isinstance(cluster_id_space, spaces.Discrete):\n",
        "      num_clusters = cluster_id_space.n\n",
        "    else:\n",
        "      raise ValueError('cluster_id response field must be either gym.spaces.Box'\n",
        "                       ' or gym spaces.Discrete')\n",
        "    self._num_clusters = num_clusters\n",
        "    if 'click' not in single_response_space.spaces:\n",
        "      raise ValueError(\n",
        "          'observation_space.spaces[\\'response\\'] must contain \\'click\\' key.')\n",
        "    suf_stat_space = spaces.Dict({\n",
        "        'impression_count':\n",
        "            spaces.Box(\n",
        "                shape=(num_clusters,), dtype=np.float32, low=0.0, high=np.inf),\n",
        "        'click_count':\n",
        "            spaces.Box(\n",
        "                shape=(num_clusters,), dtype=np.float32, low=0.0, high=np.inf)\n",
        "    })\n",
        "    super(ClusterClickStatsLayer,\n",
        "          self).__init__(base_agent_ctor, observation_space, action_space,\n",
        "                         suf_stat_space, **kwargs)\n",
        "\n",
        "  def _create_observation(self):\n",
        "    return {\n",
        "        'impression_count':\n",
        "            np.array(self._sufficient_statistics['impression_count']),\n",
        "        'click_count':\n",
        "            np.array(self._sufficient_statistics['click_count']),\n",
        "    }\n",
        "\n",
        "  def _update(self, observation):\n",
        "    \"\"\"Updates user impression/click count given user response on each item.\"\"\"\n",
        "    if self._sufficient_statistics is None:\n",
        "      self._sufficient_statistics = {\n",
        "          'impression_count': [\n",
        "              0,\n",
        "          ] * self._num_clusters,\n",
        "          'click_count': [\n",
        "              0,\n",
        "          ] * self._num_clusters\n",
        "      }\n",
        "    if observation['response'] is not None:\n",
        "      for response in observation['response']:\n",
        "        cluster_id = int(response['cluster_id'])\n",
        "        self._sufficient_statistics['impression_count'][cluster_id] += 1\n",
        "        if response['click']:\n",
        "          self._sufficient_statistics['click_count'][cluster_id] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E74dZkYHfzA0"
      },
      "outputs": [],
      "source": [
        "\"\"\"Classes for Bandit Algorithms.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MABAlgorithm(object):\n",
        "  \"\"\"Base class for Multi-armed bandit (MAB) algorithms.\n",
        "\n",
        "  We implement multi-armed bandit algorithms with confidence width tuning\n",
        "  proposed in Hsu et al. https://arxiv.org/abs/1904.02664.\n",
        "\n",
        "  Attributes:\n",
        "    pulls: A numpy array which counts number of pulls of each arm\n",
        "    reward: A numpy array which sums up reward of each arm\n",
        "    optimism_scaling: A float specifying the confidence level. Default value\n",
        "      (1.0) corresponds to the exploration strategy presented in the literature.\n",
        "      A smaller number means less exploration and more exploitation.\n",
        "    _rng: An instance of random.RandomState for random number generation\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_arms, params, seed=0):\n",
        "    \"\"\"Initializes MABAlgorithm.\n",
        "\n",
        "    Args:\n",
        "      num_arms: Number of arms. Must be greater than one.\n",
        "      params: A dictionary which includes additional parameters like\n",
        "        optimism_scaling. Default is an empty dictionary.\n",
        "      seed: Random seed for this object. Default is zero.\n",
        "    \"\"\"\n",
        "    if num_arms < 2:\n",
        "      raise ValueError('num_arms must be greater than one.')\n",
        "    self.pulls = np.zeros(num_arms)\n",
        "    self.reward = np.zeros(num_arms)\n",
        "    self._rng = np.random.RandomState(seed)\n",
        "\n",
        "    self.optimism_scaling = 1.0\n",
        "    for attr, val in params.items():\n",
        "      setattr(self, attr, val)\n",
        "\n",
        "  def set_state(self, pulls, reward):\n",
        "    if len(pulls) != len(self.pulls) or len(reward) != len(self.reward):\n",
        "      raise ValueError('Cannot set state with a different number of arms.')\n",
        "    self.pulls[:] = pulls\n",
        "    self.reward[:] = reward\n",
        "\n",
        "  def update(self, arm, reward):\n",
        "    if reward < 0 or reward > 1:\n",
        "      raise ValueError('reward must be in [0, 1].')\n",
        "    self.pulls[arm] += 1\n",
        "    self.reward[arm] += reward\n",
        "\n",
        "\n",
        "class UCB1(MABAlgorithm):\n",
        "  \"\"\"UCB1 algorithm.\n",
        "\n",
        "  See \"Finite-time Analysis of the Multiarmed Bandit Problem\" by Auer,\n",
        "  Cesa-Bianchi, and Fischer.\n",
        "  \"\"\"\n",
        "\n",
        "  def get_score(self, t):\n",
        "    \"\"\"Computes upper confidence bounds of reward / pulls at round t.\"\"\"\n",
        "    # Pull any arm that we haven't pulled.\n",
        "    if not all(self.pulls):\n",
        "      return np.where(self.pulls > 0, 0, np.Inf)\n",
        "    ct = self.optimism_scaling * np.sqrt(2 * np.log(t))\n",
        "    return self.reward / self.pulls + ct * np.sqrt(1 / self.pulls)\n",
        "\n",
        "  def get_arm(self, t):\n",
        "    return np.argmax(self.get_score(t))\n",
        "\n",
        "  @staticmethod\n",
        "  def print():\n",
        "    return 'UCB1'\n",
        "\n",
        "\n",
        "class KLUCB(MABAlgorithm):\n",
        "  \"\"\"Kullback-Leibler Upper Confidence Bounds (KL-UCB) algorithm.\n",
        "\n",
        "  See \"The KL-UCB algorithm for bounded stochastic bandits and beyond\" by\n",
        "  Garivier and Cappe.\n",
        "  \"\"\"\n",
        "\n",
        "  def get_score(self, t):\n",
        "    \"\"\"Computes upper confidence bounds of reward / pulls at round t.\"\"\"\n",
        "    # Pull any arm that we haven't pulled.\n",
        "    if not all(self.pulls):\n",
        "      return np.where(self.pulls > 0, 0, np.Inf)\n",
        "    c = self.optimism_scaling**2 * (np.log(t) +\n",
        "                                    3 * np.log(np.log(t))) / self.pulls\n",
        "    p = self.reward / self.pulls\n",
        "\n",
        "    # KL-divergence d(p, q) is strictly increasing over [p, 1].\n",
        "    # Use binary search to find q such that d(p, q) <= c.\n",
        "    qmin = p\n",
        "    qmax = np.ones(p.size)\n",
        "    for _ in range(16):  # Error bounded by 2^-16.\n",
        "      q = (qmax + qmin) / 2\n",
        "      ndx = (np.where(p > 0, p * np.log(p / q), 0) +\n",
        "             np.where(p < 1, (1 - p) * np.log((1 - p) / (1 - q)), 0)) < c\n",
        "      qmin[ndx] = q[ndx]\n",
        "      qmax[~ndx] = q[~ndx]\n",
        "\n",
        "    return q\n",
        "\n",
        "  def get_arm(self, t):\n",
        "    return np.argmax(self.get_score(t))\n",
        "\n",
        "  @staticmethod\n",
        "  def print():\n",
        "    return 'KL-UCB'\n",
        "\n",
        "\n",
        "class ThompsonSampling(MABAlgorithm):\n",
        "  \"\"\"Thompson Sampling algorithm for the Bernoulli bandit.\n",
        "\n",
        "  See \"Further Optimal Regret Bounds for Thompson Sampling\" by Agrawal and\n",
        "    Goyal.\n",
        "  \"\"\"\n",
        "\n",
        "  def update(self, arm, reward):\n",
        "    if reward > 0 and reward < 1:\n",
        "      reward = float(self._rng.rand() < reward)\n",
        "    MABAlgorithm.update(self, arm, reward)\n",
        "\n",
        "  def get_score(self, t):\n",
        "    \"\"\"Samples scores from the posterior distribution.\"\"\"\n",
        "    del t\n",
        "    # Generate a beta distribution based on the expectation of reward.\n",
        "    alpha = 1 + self.reward / self.optimism_scaling**2\n",
        "    beta = 1 + (self.pulls - self.reward) / self.optimism_scaling**2\n",
        "    return self._rng.beta(alpha, beta)\n",
        "\n",
        "  def get_arm(self, t):\n",
        "    return np.argmax(self.get_score(t))\n",
        "\n",
        "  @staticmethod\n",
        "  def print():\n",
        "    return 'ThompsonSampling'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RFVKuXOfzA4",
        "outputId": "52aed1cc-9cc1-4207-ce8d-2db5ed4fa268"
      },
      "outputs": [],
      "source": [
        "tmp_base_dir = 'recsim/recsim/'\n",
        "runner = TrainRunner(\n",
        "    base_dir=tmp_base_dir,\n",
        "    create_agent_fn=create_agent,\n",
        "    env=create_environment(env_config),\n",
        "    episode_log_file=\"\",\n",
        "    max_training_steps=50,\n",
        "    num_iterations=10)\n",
        "runner.run_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fczh2MMjfzA5",
        "outputId": "5b4bfda2-ac0c-4c8c-cfdc-91634842a007"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the MovieLens-1M dataset\n",
        "ratings_df = pd.read_csv('amazon_book_interaction_rating.csv')\n",
        "movies_df = pd.read_csv('amazon_book_item.csv')\n",
        "users_df = pd.read_csv('user_profiles.csv')\n",
        "user = users_df[['id', 'name', 'gender', 'age']]\n",
        "user = user.rename(columns={'id': 'user_id'})\n",
        "movies_df = movies_df.rename(columns={'id': 'item_id'})\n",
        "\n",
        "\n",
        "# Compute average rating per movie\n",
        "avg_ratings = ratings_df.groupby('item_id')['rating'].mean().to_dict()\n",
        "\n",
        "# Merge datasets\n",
        "data = ratings_df.merge(movies_df, on=\"item_id\").merge(user_reduced, on=\"user_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qdJUVCcGGp",
        "outputId": "8f0dca63-276b-4e0b-97a4-bf63d96299d4"
      },
      "outputs": [],
      "source": [
        "# Extract unique single-word genres\n",
        "unique_genres = {\n",
        "    word.strip().lower()\n",
        "    for genres in movies_df['genre'].dropna()\n",
        "    for genre in genres\n",
        "    for word in genre.replace('-', ' ').split()   # split by space and hyphen\n",
        "    if word.strip() != ''\n",
        "}\n",
        "\n",
        "# Map each genre (word) to an index\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(sorted(unique_genres))}\n",
        "num_genres = len(unique_genres)\n",
        "\n",
        "# print(num_genres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiFvpk4tfzA6",
        "outputId": "f0a2ba0e-af51-45ba-d511-e5ed153a0ed4"
      },
      "outputs": [],
      "source": [
        "# Merge the two datasets based on the 'lister_music_id' column\n",
        "user_character = pd.merge(ratings_df, movies_df, on='item_id', how='left')\n",
        "\n",
        "# Filter the dataset for ratings 4 and 5\n",
        "filtered_df = user_character[user_character[\"rating\"].isin([4, 5])]\n",
        "\n",
        "# Group by user_id and collect all genres into a single list\n",
        "user_genres = (\n",
        "    filtered_df.groupby(\"user_id\")[\"genre\"]\n",
        "    .apply(lambda x: [g for sublist in x for g in sublist])  # flatten lists\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Deduplicate and sort genres per user\n",
        "user_genres[\"genre\"] = user_genres[\"genre\"].apply(\n",
        "    lambda x: \"|\".join(sorted(set(x)))\n",
        ")\n",
        "\n",
        "# print(user_genres.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0b7UF0W09iO"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from typing import Any, Dict, Optional, List, Tuple\n",
        "from yacs.config import CfgNode\n",
        "import os\n",
        "import math\n",
        "\n",
        "\n",
        "# logger\n",
        "def set_logger(log_file, name=\"default\"):\n",
        "    \"\"\"\n",
        "    Set logger.\n",
        "    Args:\n",
        "        log_file (str): log file path\n",
        "        name (str): logger name\n",
        "    \"\"\"\n",
        "\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "        \"%(asctime)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "    print(formatter.format(logging.LogRecord(\n",
        "    name='root',\n",
        "    level=logging.INFO,\n",
        "    pathname=None,\n",
        "    lineno=None,\n",
        "    msg='Test message',\n",
        "    args=None,\n",
        "    exc_info=None,\n",
        "    )))\n",
        "    output_folder = \"output\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Create the 'log' folder if it doesn't exist\n",
        "    log_folder = os.path.join(output_folder, \"log\")\n",
        "    if not os.path.exists(log_folder):\n",
        "        os.makedirs(log_folder)\n",
        "\n",
        "    # Create the 'message' folder if it doesn't exist\n",
        "    message_folder = os.path.join(output_folder, \"message\")\n",
        "    if not os.path.exists(message_folder):\n",
        "        os.makedirs(message_folder)\n",
        "    log_file = os.path.join(log_folder, log_file)\n",
        "    handler = logging.FileHandler(log_file, mode=\"w\")\n",
        "    handler.setLevel(logging.INFO)\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.handlers = []\n",
        "    logger.addHandler(handler)\n",
        "    # print(logger)\n",
        "    return logger\n",
        "\n",
        "def load_cfg(cfg_file: str, new_allowed: bool = True) -> CfgNode:\n",
        "    \"\"\"\n",
        "    Load config from file.\n",
        "    Args:\n",
        "        cfg_file (str): config file path\n",
        "        new_allowed (bool): whether to allow new keys in config\n",
        "    \"\"\"\n",
        "    with open(cfg_file, \"r\") as fi:\n",
        "        cfg = CfgNode.load_cfg(fi)\n",
        "    cfg.set_new_allowed(new_allowed)\n",
        "    return cfg\n",
        "\n",
        "def add_variable_to_config(cfg: CfgNode, name: str, value: Any) -> CfgNode:\n",
        "    \"\"\"\n",
        "    Add variable to config.\n",
        "    Args:\n",
        "        cfg (CfgNode): config\n",
        "        name (str): variable name\n",
        "        value (Any): variable value\n",
        "    \"\"\"\n",
        "    cfg.defrost()\n",
        "    cfg[name] = value\n",
        "    cfg.freeze()\n",
        "    return cfg\n",
        "\n",
        "def ensure_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Make sure the directory exists, if it does not exist, create it\n",
        "    Args:\n",
        "        dir_path (str): The directory path.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "def calculate_entropy(movie_types):\n",
        "    type_freq = {}\n",
        "    for movie_type in movie_types:\n",
        "        if movie_type in type_freq:\n",
        "            type_freq[movie_type] += 1\n",
        "        else:\n",
        "            type_freq[movie_type] = 1\n",
        "\n",
        "    total_movies = len(movie_types)\n",
        "\n",
        "    entropy = 0\n",
        "    for key in type_freq:\n",
        "        prob = type_freq[key] / total_movies\n",
        "        entropy -= prob * math.log2(prob)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def get_entropy(inters, data):\n",
        "    genres = data.get_genres_by_id(inters)\n",
        "    entropy = calculate_entropy(genres)\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45F6QMZmzGlg"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class Data:\n",
        "    \"\"\"\n",
        "    Data class for loading data from local files.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.items = {}\n",
        "        self.users = {}\n",
        "        self.db = None\n",
        "        self.tot_relationship_num = 0\n",
        "        self.netwerk_density = 0.0\n",
        "        self.role_id = -1\n",
        "        self.interrating = {}\n",
        "        self.user_ratings = {}\n",
        "        self.item_ratings = {}\n",
        "        self.load_items(config[\"item_path\"])\n",
        "        self.load_users(config[\"user_path\"])\n",
        "        self.load_interactions_rating(config[\"rating_path\"])\n",
        "\n",
        "    def load_items(self, file_path):\n",
        "        \"\"\"\n",
        "        Load items from local file.\n",
        "        \"\"\"\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                item_id, title, genre, description = row\n",
        "                self.items[int(item_id)] = {\n",
        "                    \"name\": title.strip(),\n",
        "                    \"genre\": genre,\n",
        "                    \"description\": description.strip(),\n",
        "                    \"inter_cnt\": 0,\n",
        "                    \"mention_cnt\": 0,\n",
        "                }\n",
        "\n",
        "    def load_users(self, file_path):\n",
        "        \"\"\"\n",
        "        Load users from local file.\n",
        "        \"\"\"\n",
        "        cnt = 1\n",
        "        with open(file_path, \"r\", newline=\"\") as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip the header line\n",
        "            for row in reader:\n",
        "                # print(len(row), row)\n",
        "                user_id, name, gender, age, traits, status, interest, feature = row\n",
        "                self.users[cnt] = {\n",
        "                    \"name\": name,\n",
        "                    \"gender\": gender,\n",
        "                    \"age\": int(age),\n",
        "                    \"traits\": traits,\n",
        "                    \"status\": status,\n",
        "                    \"interest\": interest,\n",
        "                    \"feature\": feature,\n",
        "                }\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "\n",
        "\n",
        "    def load_interactions_rating(self, file_path):\n",
        "      \"\"\"\n",
        "      Load user-item interactions (with rating) from local file.\n",
        "      Stores in self.interrating as a dict:\n",
        "      {user_id: [(item_id, rating), ...], ...}\n",
        "      \"\"\"\n",
        "      with open(file_path, \"r\", newline=\"\") as file:\n",
        "        reader = csv.reader(file)\n",
        "        header = next(reader)  # Skip the header line\n",
        "        for row in reader:\n",
        "            user_id, item_id, rating = row\n",
        "            user_id = int(user_id)\n",
        "            item_id = int(item_id)\n",
        "            rating = int(rating)\n",
        "            if user_id not in self.interrating:\n",
        "                self.interrating[user_id] = []\n",
        "            self.interrating[user_id].append((item_id, rating))\n",
        "\n",
        "            if user_id not in self.user_ratings:\n",
        "                self.user_ratings[user_id] = []\n",
        "            self.user_ratings[user_id].append(rating)\n",
        "\n",
        "            # Store item rating\n",
        "            if item_id not in self.item_ratings:\n",
        "                self.item_ratings[item_id] = []\n",
        "            self.item_ratings[item_id].append(rating)\n",
        "\n",
        "      # Compute and store average historical rating for each user\n",
        "      self.user_avg_rating = {uid: sum(ratings)/len(ratings) for uid, ratings in self.user_ratings.items() if ratings}\n",
        "\n",
        "      # Compute and store average historical rating for each item\n",
        "      self.item_avg_rating = {iid: sum(ratings)/len(ratings) for iid, ratings in self.item_ratings.items() if ratings}\n",
        "\n",
        "\n",
        "    def get_full_items(self):\n",
        "        return list(self.items.keys())\n",
        "\n",
        "    def get_inter_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of interactions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"inter_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def add_inter_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        # print(\"item ids:\", item_ids)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"inter_cnt\"] += 1\n",
        "\n",
        "    def add_mention_cnt(self, item_names):\n",
        "        item_ids = self.get_item_ids(item_names)\n",
        "        for item_id in item_ids:\n",
        "            self.items[item_id][\"mention_cnt\"] += 1\n",
        "\n",
        "    def get_mention_popular_items(self):\n",
        "        \"\"\"\n",
        "        Get the most popular items based on the number of mentions.\n",
        "        \"\"\"\n",
        "        ids = sorted(\n",
        "            self.items.keys(), key=lambda x: self.items[x][\"mention_cnt\"], reverse=True\n",
        "        )[:3]\n",
        "        return self.get_item_names(ids)\n",
        "\n",
        "    def get_item_names(self, item_ids):\n",
        "        return [\"<\" + self.items[item_id][\"name\"] + \">\" for item_id in item_ids]\n",
        "\n",
        "    def get_item_ids(self, item_names):\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] in item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_item_ids_exact(self, item_names):\n",
        "        \"\"\"\n",
        "        Get item ids from item names.\n",
        "        I coundn't find any difference with the get_item_ids(item_names) function\n",
        "        \"\"\"\n",
        "        item_ids = []\n",
        "        for item in item_names:\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] == item:\n",
        "                    item_ids.append(item_id)\n",
        "                    break\n",
        "        return item_ids\n",
        "\n",
        "    def get_full_users(self):\n",
        "        return list(self.users.keys())\n",
        "\n",
        "    def get_user_profile(self, user_id):\n",
        "        \"\"\"\n",
        "        Return the user profile as a formatted string for the given user_id.\n",
        "        \"\"\"\n",
        "        user = self.users.get(user_id)\n",
        "        if not user:\n",
        "           return f\"User ID {user_id} not found.\"\n",
        "\n",
        "        profile = (\n",
        "        f\"User ID: {user_id};; Name: {user['name']}\\n\"\n",
        "        f\"Gender: {user['gender']};; Age: {user['age']};; Status: {user['status']}\\n\"\n",
        "        f\"Traits: {user['traits']};; Interest: {user['interest']};; Feature: {user['feature']}\\n\")\n",
        "        # f\"Positive Behavior: {user['positive_behavior']};; Negative Behavior: {user['negative_behavior']}\")\n",
        "        return profile\n",
        "\n",
        "    def get_user_names(self, user_ids):\n",
        "        return [self.users[user_id][\"name\"] for user_id in user_ids]\n",
        "\n",
        "    def get_user_ids(self, user_names):\n",
        "        user_ids = []\n",
        "        for user in user_names:\n",
        "            for user_id, user_info in self.users.items():\n",
        "                if user_info[\"name\"] == user:\n",
        "                    user_ids.append(user_id)\n",
        "                    break\n",
        "        return user_ids\n",
        "\n",
        "    def get_user_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of users.\n",
        "        \"\"\"\n",
        "        return len(self.users.keys())\n",
        "\n",
        "    def get_item_num(self):\n",
        "        \"\"\"\n",
        "        Return the number of items.\n",
        "        \"\"\"\n",
        "        return len(self.items.keys())\n",
        "\n",
        "    def search_items(self, item, k=50):\n",
        "        \"\"\"\n",
        "        Search similar items from faiss db.\n",
        "        Args:\n",
        "            item: str, item name\n",
        "            k: int, number of similar items to return\n",
        "        \"\"\"\n",
        "        docs = self.db.similarity_search(item, k)\n",
        "        item_names = [doc.page_content for doc in docs]\n",
        "        return item_names\n",
        "\n",
        "\n",
        "    def get_item_description_by_id(self, item_ids):\n",
        "        \"\"\"\n",
        "        Get description of items by item id.\n",
        "        \"\"\"\n",
        "        return [self.items[item_id][\"description\"] for item_id in item_ids]\n",
        "\n",
        "    def get_item_description_by_name(self, item_names):\n",
        "        \"\"\"\n",
        "        Get description of items by item name.\n",
        "        \"\"\"\n",
        "        item_descriptions = []\n",
        "        for item in item_names:\n",
        "            found = False\n",
        "            for item_id, item_info in self.items.items():\n",
        "                if item_info[\"name\"] == item.strip(\" <>\"):\n",
        "                    item_descriptions.append(item_info[\"description\"])\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                item_descriptions.append(\"\")\n",
        "        return item_descriptions\n",
        "\n",
        "    def get_genres_by_id(self, item_ids):\n",
        "        \"\"\"\n",
        "        Get genre of items by item id.\n",
        "        \"\"\"\n",
        "        # return [self.items[item_id][\"genre\"] for item_id in item_ids]\n",
        "        return [\n",
        "            genre\n",
        "            for item_id in item_ids\n",
        "            for genre in self.items[item_id][\"genre\"].split('|')\n",
        "        ]\n",
        "\n",
        "    def hit_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Return 1 if any of the top-k predicted are relevant, else 0.\"\"\"\n",
        "        return int(bool(set(ground_truth) & set(predicted[:k])))\n",
        "\n",
        "    def ndcg_at_k(self, ground_truth, predicted, k):\n",
        "        \"\"\"Compute NDCG@k for a single user.\"\"\"\n",
        "        def dcg(rel):\n",
        "          return np.sum([(2**r - 1) / np.log2(i + 2) for i, r in enumerate(rel)])\n",
        "\n",
        "        rel = [1 if item in ground_truth else 0 for item in predicted[:k]]\n",
        "        ideal_rel = sorted([1]*min(len(ground_truth), k) + [0]*(k - min(len(ground_truth), k)), reverse=True)\n",
        "        dcg_score = dcg(rel)\n",
        "        idcg_score = dcg(ideal_rel)\n",
        "        return dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
        "\n",
        "    def mse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute MSE for ratings (on items in both sets).\"\"\"\n",
        "        if items is None:\n",
        "           items = set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        else:\n",
        "           items = set(items) & set(ground_truth_ratings.keys()) & set(predicted_ratings.keys())\n",
        "        if not items:\n",
        "           return np.nan\n",
        "        errors = [(ground_truth_ratings[i] - predicted_ratings[i]) ** 2 for i in items]\n",
        "        return np.mean(errors)\n",
        "\n",
        "    def rmse(self, ground_truth_ratings, predicted_ratings, items=None):\n",
        "        \"\"\"Compute RMSE for ratings.\"\"\"\n",
        "        return np.sqrt(self.mse(ground_truth_ratings, predicted_ratings, items))\n",
        "\n",
        "    def safe_log(self, x):\n",
        "        \"\"\"Numerically safe log.\"\"\"\n",
        "        return math.log(max(x, 1e-15))\n",
        "\n",
        "    def ordered_probit_probs(self, pred_int, K, taus=None):\n",
        "        \"\"\"\n",
        "        Compute ordered probit class probabilities for a predicted integer rating.\n",
        "\n",
        "        pred_int : int\n",
        "            The predicted integer rating (e.g., 1..K).\n",
        "        K : int\n",
        "            Number of rating classes (e.g., 5 for 15 stars).\n",
        "        taus : list or array, optional\n",
        "            Thresholds separating the ordered categories.\n",
        "            If None, uses equally spaced thresholds [1.5, 2.5, ..., K-0.5].\n",
        "        \"\"\"\n",
        "\n",
        "        if taus is None:\n",
        "           taus = np.array([1.5 + i for i in range(K-1)])  # default thresholds\n",
        "\n",
        "        assert len(taus) == K-1\n",
        "\n",
        "        def Phi(z):\n",
        "            return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))  # Normal CDF\n",
        "\n",
        "        probs = []\n",
        "        for k in range(1, K+1):\n",
        "           if k == 1:\n",
        "              lower = -np.inf\n",
        "              upper = taus[0]\n",
        "           elif k == K:\n",
        "              lower = taus[-1]\n",
        "              upper = np.inf\n",
        "           else:\n",
        "              lower = taus[k-2]\n",
        "              upper = taus[k-1]\n",
        "           p_lower = 0.0 if lower == -np.inf else Phi((lower - pred_int))\n",
        "           p_upper = 1.0 if upper == np.inf else Phi((upper - pred_int))\n",
        "           probs.append(max(p_upper - p_lower, 1e-15))\n",
        "\n",
        "        probs = np.array(probs)\n",
        "        probs /= probs.sum()  # normalize\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X92tbRkIzdBa"
      },
      "outputs": [],
      "source": [
        "class BaseModel(object):\n",
        "    \"\"\"Base class for all models.\"\"\"\n",
        "\n",
        "    def __init__(self, config, n_users, n_items):\n",
        "        self.config = config\n",
        "        self.items = None\n",
        "\n",
        "    def get_full_sort_items(self, user_id, *args, **kwargs):\n",
        "        \"\"\"Get a list of sorted items for a given user.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _sort_full_items(self, user_id, *args, **kwargs):\n",
        "        \"\"\"Sort a list of items for a given user.\"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyhE0Cc6zg7R",
        "outputId": "e6384369-deb8-4409-db09-7f2f6473bed7"
      },
      "outputs": [],
      "source": [
        "from typing import Union, List, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MF(BaseModel, nn.Module):\n",
        "    def __init__(self, config, n_users, n_items):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "        self.config = config\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        torch.manual_seed(config['seed'])\n",
        "        # define layers and loss\n",
        "        self.user_embedding = nn.Embedding(self.n_users+1, self.embedding_size)\n",
        "        self.item_embedding = nn.Embedding(self.n_items+1, self.embedding_size)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        \"\"\"Predicts the rating of a user for an item.\"\"\"\n",
        "        user_embed = self.user_embedding(user)\n",
        "        item_embed = self.item_embedding(item)\n",
        "\n",
        "        # Dot product between user and item embeddings to predict rating\n",
        "        predicted_rating = (user_embed * item_embed).sum(1)\n",
        "\n",
        "        return predicted_rating\n",
        "\n",
        "    def get_full_sort_items(self, user, items):\n",
        "        \"\"\"Get a list of sorted items for a given user.\"\"\"\n",
        "        predicted_ratings = self.forward(user, items)\n",
        "        sorted_items = self._sort_full_items(user, predicted_ratings, items)\n",
        "        return sorted_items.tolist()\n",
        "\n",
        "    def _sort_full_items(self, user, predicted_ratings, items):\n",
        "        \"\"\"Sort items based on their predicted ratings.\"\"\"\n",
        "        # Sort items based on ratings in descending order and return item indices\n",
        "        _, sorted_indices = torch.sort(predicted_ratings, descending=True)\n",
        "        return items[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMY5uoHwz985"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Tuple, Iterable, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LightGCN(BaseModel, nn.Module):\n",
        "    \"\"\"\n",
        "    LightGCN for recommendation.\n",
        "    Reference: He et al., \"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation\"\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        n_users: int,\n",
        "        n_items: int,\n",
        "        interactions: Iterable[Tuple[int, int]],\n",
        "        n_layers: int = 3,\n",
        "        embedding_dim: int = 64,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        interactions: iterable of (user_id, item_id) pairs (duplicates okay, handled as multi-edges of weight 1)\n",
        "        \"\"\"\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        torch.manual_seed(config.get(\"seed\", 2023))\n",
        "\n",
        "        # Embeddings\n",
        "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "\n",
        "        # Build normalized adjacency once\n",
        "        self.Graph = self._build_normalized_adj(interactions).to(self.device)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    # ---------- Graph utilities ----------\n",
        "    def _build_normalized_adj(self, interactions: Iterable[Tuple[int, int]]) -> torch.sparse.FloatTensor:\n",
        "        \"\"\"\n",
        "        Build the symmetrically normalized adjacency matrix:\n",
        "            A_hat = D^{-1/2} * A * D^{-1/2}\n",
        "        for the bipartite user-item graph where nodes = users + items\n",
        "        Size: (n_nodes, n_nodes) with n_nodes = n_users + n_items\n",
        "        \"\"\"\n",
        "        n_nodes = self.n_users + self.n_items\n",
        "\n",
        "        # Collect COO edges (user <-> item, undirected)\n",
        "        rows = []\n",
        "        cols = []\n",
        "        vals = []\n",
        "\n",
        "        for u, i, *rest in interactions:\n",
        "            # Allow (u,i) or (u,i,rating)  rating ignored here (implicit 1)\n",
        "            if u < 0 or u >= self.n_users or i < 0 or i >= self.n_items:\n",
        "                continue\n",
        "            i_offset = self.n_users + i  # item node index in unified graph\n",
        "            # u -> i\n",
        "            rows.append(u); cols.append(i_offset); vals.append(1.0)\n",
        "            # i -> u\n",
        "            rows.append(i_offset); cols.append(u); vals.append(1.0)\n",
        "\n",
        "        if len(rows) == 0:\n",
        "            # Empty graph fallback (identity to avoid NaNs)\n",
        "            indices = torch.arange(n_nodes, dtype=torch.long)\n",
        "            indices = torch.stack([indices, indices], dim=0)\n",
        "            values = torch.ones(n_nodes, dtype=torch.float32)\n",
        "            return torch.sparse_coo_tensor(indices, values, (n_nodes, n_nodes)).coalesce()\n",
        "\n",
        "        indices = torch.tensor([rows, cols], dtype=torch.long)\n",
        "        values = torch.tensor(vals, dtype=torch.float32)\n",
        "        A = torch.sparse_coo_tensor(indices, values, (n_nodes, n_nodes)).coalesce()\n",
        "\n",
        "        # Degree vector d = sum of rows\n",
        "        deg = torch.sparse.sum(A, dim=1).to_dense()  # (n_nodes,)\n",
        "        # Avoid divide-by-zero\n",
        "        deg = torch.clamp(deg, min=1e-12)\n",
        "        d_inv_sqrt = torch.pow(deg, -0.5)\n",
        "\n",
        "        # Normalize values: for each edge (i,j), val *= d^-1/2[i] * d^-1/2[j]\n",
        "        row, col = A.indices()\n",
        "        norm_vals = A.values() * d_inv_sqrt[row] * d_inv_sqrt[col]\n",
        "\n",
        "        A_hat = torch.sparse_coo_tensor(A.indices(), norm_vals, A.size()).coalesce()\n",
        "        return A_hat\n",
        "\n",
        "    # ---------- Embedding propagation ----------\n",
        "    def propagate(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Perform K-layer LightGCN propagation and return final user & item embeddings.\n",
        "        E^(0) = concat([U, I])  -> shape (n_users + n_items, d)\n",
        "        E_final = 1/(K+1) * sum_{k=0..K} E^(k)\n",
        "        \"\"\"\n",
        "        E_u0 = self.user_embedding.weight\n",
        "        E_i0 = self.item_embedding.weight\n",
        "        E0 = torch.cat([E_u0, E_i0], dim=0)  # (n_users + n_items, d)\n",
        "\n",
        "        all_layers = [E0]\n",
        "        x = E0\n",
        "        for _ in range(self.n_layers):\n",
        "            x = torch.sparse.mm(self.Graph, x)  # LightGCN propagation (no weights, no nonlinearity)\n",
        "            all_layers.append(x)\n",
        "\n",
        "        E = torch.stack(all_layers, dim=0).mean(dim=0)  # layer-wise average\n",
        "        Eu, Ei = torch.split(E, [self.n_users, self.n_items], dim=0)\n",
        "        return Eu, Ei\n",
        "\n",
        "    # ---------- Scoring ----------\n",
        "    def forward(self, users: torch.Tensor, items: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predict scores for (users, items). Supports:\n",
        "          - users: (B,), items: (B,)  -> elementwise scores\n",
        "          - users: (B,), items: (N,)  -> broadcast users for all N items (returns (B,N))\n",
        "        \"\"\"\n",
        "        users = users.to(self.device)\n",
        "        items = items.to(self.device)\n",
        "\n",
        "        Eu, Ei = self.propagate()\n",
        "\n",
        "        if users.dim() == 1 and items.dim() == 1 and users.shape[0] == items.shape[0]:\n",
        "            u_emb = Eu[users]                   # (B, d)\n",
        "            i_emb = Ei[items]                   # (B, d)\n",
        "            return (u_emb * i_emb).sum(dim=1)   # (B,)\n",
        "\n",
        "        # Broadcast to (B, N)\n",
        "        u_emb = Eu[users]                       # (B, d)\n",
        "        i_emb = Ei[items]                       # (N, d)\n",
        "        scores = u_emb @ i_emb.t()              # (B, N)\n",
        "        return scores\n",
        "\n",
        "    def predict(self, user_ids: List[int], item_ids: Optional[List[int]] = None) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Convenience method to get scores as numpy.\n",
        "        - If item_ids is None: scores for all items for each user -> shape (B, n_items)\n",
        "        - Else: scores for user_ids x item_ids -> (B, len(item_ids))\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            u = torch.tensor(user_ids, dtype=torch.long, device=self.device)\n",
        "            if item_ids is None:\n",
        "                items = torch.arange(self.n_items, dtype=torch.long, device=self.device)\n",
        "                scores = self.forward(u, items)        # (B, n_items)\n",
        "            else:\n",
        "                items = torch.tensor(item_ids, dtype=torch.long, device=self.device)\n",
        "                scores = self.forward(u, items)        # (B, len(item_ids))\n",
        "        return scores.detach().cpu().numpy()\n",
        "\n",
        "    # ---------- Ranking API (BaseModel) ----------\n",
        "    def get_full_sort_items(self, user_id: int, seen_items: Optional[Iterable[int]] = None, top_k: Optional[int] = None) -> List[int]:\n",
        "        \"\"\"\n",
        "        Rank all items for a given user (descending by predicted score).\n",
        "        Optionally drop previously seen items.\n",
        "        \"\"\"\n",
        "        scores = self.predict([user_id], None).ravel()  # (n_items,)\n",
        "        if seen_items is not None:\n",
        "            # push seen items to bottom\n",
        "            seen_items = [i for i in seen_items if 0 <= i < self.n_items]\n",
        "            scores[np.array(seen_items, dtype=np.int64)] = -np.inf\n",
        "\n",
        "        order = np.argsort(-scores)  # descending\n",
        "        if top_k is not None:\n",
        "            order = order[:top_k]\n",
        "        return order.tolist()\n",
        "\n",
        "    def _sort_full_items(self, user_id: int, predicted_ratings: torch.Tensor, items: torch.Tensor):\n",
        "        # Not used here; keeping for BaseModel compatibility\n",
        "        _, idx = torch.sort(predicted_ratings, descending=True)\n",
        "        return items[idx]\n",
        "\n",
        "\n",
        "class BPRLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Pairwise Bayesian Personalized Ranking loss with L2 regularization on embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, reg: float = 1e-4):\n",
        "        super().__init__()\n",
        "        self.reg = reg\n",
        "\n",
        "    def forward(self, u_emb, pos_emb, neg_emb):\n",
        "        pos_scores = (u_emb * pos_emb).sum(dim=1)\n",
        "        neg_scores = (u_emb * neg_emb).sum(dim=1)\n",
        "        loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
        "        reg = (u_emb.norm(2).pow(2) + pos_emb.norm(2).pow(2) + neg_emb.norm(2).pow(2)) / u_emb.shape[0]\n",
        "        return loss + self.reg * reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XSUDaZZz_Iu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Optional, Tuple, Iterable, List, Dict\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class InteractionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that yields dense user vectors (torch.float32).\n",
        "    Accepts a scipy.sparse CSR matrix or a numpy array of shape (n_users, n_items).\n",
        "    \"\"\"\n",
        "    def __init__(self, user_item_matrix):\n",
        "        # Accept CSR matrix or numpy array\n",
        "        if hasattr(user_item_matrix, \"toarray\") and hasattr(user_item_matrix, \"tocsr\"):\n",
        "            self.mat = user_item_matrix.tocsr()\n",
        "            self.is_sparse = True\n",
        "            self.n_users, self.n_items = self.mat.shape\n",
        "        else:\n",
        "            self.mat = np.asarray(user_item_matrix, dtype=np.float32)\n",
        "            self.is_sparse = False\n",
        "            self.n_users, self.n_items = self.mat.shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_sparse:\n",
        "            row = self.mat.getrow(idx).toarray().astype(np.float32).squeeze(0)\n",
        "            return torch.from_numpy(row)\n",
        "        else:\n",
        "            return torch.from_numpy(self.mat[idx].astype(np.float32))\n",
        "\n",
        "\n",
        "class MultiVAE(BaseModel, nn.Module):\n",
        "    \"\"\"\n",
        "    MultiVAE model (variational autoencoder for collaborative filtering).\n",
        "    - encoder: two-layer MLP -> mu, logvar\n",
        "    - decoder: linear mapping from latent z to item logits\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: dict,\n",
        "        n_users: int,\n",
        "        n_items: int,\n",
        "        hidden_dim: int = 600,\n",
        "        latent_dim: int = 200,\n",
        "        dropout=0.5,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "\n",
        "        # model dims\n",
        "        self.hidden_dim = config.get(\"vae_hidden_dim\", hidden_dim)\n",
        "        self.latent_dim = config.get(\"vae_latent_dim\", latent_dim)\n",
        "        self.dropout = config.get(\"vae_dropout\", dropout)\n",
        "\n",
        "        # encoder\n",
        "        self.encoder_fc1 = nn.Linear(n_items, self.hidden_dim)\n",
        "        self.encoder_fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.mu_layer = nn.Linear(self.hidden_dim, self.latent_dim)\n",
        "        self.logvar_layer = nn.Linear(self.hidden_dim, self.latent_dim)\n",
        "\n",
        "        # decoder (linear + bias to produce logits over items)\n",
        "        self.decoder = nn.Linear(self.latent_dim, n_items, bias=True)\n",
        "\n",
        "        self.act = nn.Tanh()\n",
        "        self.drop = nn.Dropout(self.dropout)\n",
        "\n",
        "        # initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    # ---------- VAE ops ----------\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        x: (B, n_items) input user vectors\n",
        "        returns mu, logvar (each (B, latent_dim))\n",
        "        \"\"\"\n",
        "        h = self.drop(self.act(self.encoder_fc1(x)))\n",
        "        h = self.drop(self.act(self.encoder_fc2(h)))\n",
        "        mu = self.mu_layer(h)\n",
        "        logvar = self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns logits for items: (B, n_items)\n",
        "        \"\"\"\n",
        "        logits = self.decoder(z)\n",
        "        return logits\n",
        "\n",
        "    def forward(self, x: torch.Tensor, sample: bool = True) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        One forward pass:\n",
        "        - encodes x -> mu, logvar\n",
        "        - draws z (reparameterization)\n",
        "        - decodes logits\n",
        "        Returns: logits, mu, logvar\n",
        "        \"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        if self.training and sample:\n",
        "            z = self.reparameterize(mu, logvar)\n",
        "        else:\n",
        "            z = mu  # use mean for deterministic inference\n",
        "        logits = self.decode(z)\n",
        "        return logits, mu, logvar\n",
        "\n",
        "    # ---------- Loss / ELBO ----------\n",
        "    def loss_function(\n",
        "        self,\n",
        "        logits: torch.Tensor,\n",
        "        input_batch: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "        anneal: float = 1.0,\n",
        "    ) -> Tuple[torch.Tensor, float, float]:\n",
        "        \"\"\"\n",
        "        Multinomial likelihood version used in MultiVAE:\n",
        "        recon_loss = - sum_j x_j * log_softmax(logits)_j\n",
        "\n",
        "        KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n",
        "        total_loss = recon_loss + anneal * KL\n",
        "        Returns (loss, recon_loss_scalar, kl_scalar)\n",
        "        \"\"\"\n",
        "        # reconstruction: log softmax and weighted by counts\n",
        "        log_softmax = F.log_softmax(logits, dim=1)  # (B, n_items)\n",
        "        # input_batch may be counts (0/1 or counts). multiply and sum per sample\n",
        "        recon = -torch.sum(log_softmax * input_batch, dim=1)  # (B,)\n",
        "        recon_loss = torch.mean(recon)\n",
        "\n",
        "        # KL\n",
        "        kl = -0.5 * torch.sum(1.0 + logvar - mu.pow(2) - logvar.exp(), dim=1)  # (B,)\n",
        "        kl_loss = torch.mean(kl)\n",
        "\n",
        "        loss = recon_loss + anneal * kl_loss\n",
        "        return loss, recon_loss.item(), kl_loss.item()\n",
        "\n",
        "\n",
        "    # ---------- Embeddings helper (for ranking similar to LightGCN propagate) ----------\n",
        "    def get_user_latent(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Return deterministic latent mu for x (no sampling).\n",
        "        x: (B, n_items)\n",
        "        returns mu: (B, latent_dim)\n",
        "        \"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        return mu\n",
        "\n",
        "    # ---------- Prediction / Ranking (BaseModel methods) ----------\n",
        "    def predict(self, user_vectors: torch.Tensor) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Predict item scores for a batch of user vectors.\n",
        "        user_vectors: torch.Tensor (B, n_items) on cpu or device\n",
        "        returns: numpy array (B, n_items) of logits (higher = more recommended)\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            user_vectors = user_vectors.to(self.device)\n",
        "            logits, mu, logvar = self.forward(user_vectors, sample=False)\n",
        "            # Return logits (no softmax) so they can be sorted. move to cpu\n",
        "            return logits.detach().cpu().numpy()\n",
        "\n",
        "    def get_full_sort_items(self, user_id: int, user_item_matrix, seen_items: Optional[Iterable[int]] = None, top_k: Optional[int] = None) -> List[int]:\n",
        "        \"\"\"\n",
        "        Rank all items for a given user.\n",
        "        - user_item_matrix: the full user-item matrix (csr or numpy) to extract the user's vector\n",
        "        - seen_items: optional iterable to mask (push to bottom)\n",
        "        \"\"\"\n",
        "        # build user vector\n",
        "        if hasattr(user_item_matrix, \"getrow\"):\n",
        "            vec = user_item_matrix.getrow(user_id).toarray().astype(np.float32)\n",
        "            user_vec = torch.from_numpy(vec).to(self.device)\n",
        "        else:\n",
        "            user_vec = torch.from_numpy(np.asarray(user_item_matrix[user_id], dtype=np.float32)).to(self.device)\n",
        "\n",
        "        scores = self.predict(user_vec.unsqueeze(0)).ravel()  # (n_items,)\n",
        "\n",
        "        if seen_items is not None:\n",
        "            seen = [i for i in seen_items if 0 <= i < self.n_items]\n",
        "            scores[np.array(seen, dtype=np.int64)] = -np.inf\n",
        "\n",
        "        order = np.argsort(-scores)\n",
        "        if top_k is not None:\n",
        "            order = order[:top_k]\n",
        "        return order.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HcBS4Gi0Dtj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class FMModel(BaseModel, nn.Module):\n",
        "    def __init__(self, config, n_users, n_items, n_factors=16):\n",
        "        BaseModel.__init__(self, config, n_users, n_items)\n",
        "        nn.Module.__init__(self)\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "\n",
        "        # Linear terms\n",
        "        self.user_bias = nn.Embedding(n_users, 1)\n",
        "        self.item_bias = nn.Embedding(n_items, 1)\n",
        "\n",
        "        # Factorization embeddings\n",
        "        self.user_embedding = nn.Embedding(n_users, n_factors)\n",
        "        self.item_embedding = nn.Embedding(n_items, n_factors)\n",
        "\n",
        "        # Global bias\n",
        "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        # Init\n",
        "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
        "        nn.init.zeros_(self.user_bias.weight)\n",
        "        nn.init.zeros_(self.item_bias.weight)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        user_vec = self.user_embedding(user_ids)\n",
        "        item_vec = self.item_embedding(item_ids)\n",
        "\n",
        "        linear_terms = self.user_bias(user_ids) + self.item_bias(item_ids)\n",
        "        interaction = torch.sum(user_vec * item_vec, dim=1, keepdim=True)\n",
        "\n",
        "        score = self.global_bias + linear_terms + interaction\n",
        "        return score.view(-1)\n",
        "\n",
        "    def get_full_sort_items(self, user_id):\n",
        "        device = next(self.parameters()).device\n",
        "        user_id_tensor = torch.tensor([user_id], device=device)\n",
        "        item_ids = torch.arange(self.n_items, device=device)\n",
        "        user_id_expand = user_id_tensor.expand(self.n_items)\n",
        "        scores = self.forward(user_id_expand, item_ids)\n",
        "        return torch.argsort(scores, descending=True).tolist()\n",
        "\n",
        "    def _sort_full_items(self, user_id):\n",
        "        return self.get_full_sort_items(user_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC0qtKCO0JfC"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Iterable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "\n",
        "# ------------------------------\n",
        "# Utility: set all seeds\n",
        "# ------------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def sasrec_pointwise_step(model, batch, device, logit_clip=20.0):\n",
        "    users, seqs, pos_items, neg_items, mask = batch\n",
        "    seqs, pos_items, neg_items = seqs.to(device), pos_items.to(device), neg_items.to(device)\n",
        "    mask = mask.to(device).bool()\n",
        "\n",
        "    seq_out = model(seqs)\n",
        "    item_emb = model.item_embedding.weight\n",
        "\n",
        "    pos_logits = torch.sum(seq_out * item_emb[pos_items], dim=-1).clamp(-logit_clip, logit_clip)\n",
        "    neg_logits = torch.sum(seq_out * item_emb[neg_items], dim=-1).clamp(-logit_clip, logit_clip)\n",
        "\n",
        "    valid_mask = (pos_items > 0) & mask\n",
        "    if valid_mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
        "\n",
        "    loss_pos = F.binary_cross_entropy_with_logits(pos_logits[valid_mask], torch.ones_like(pos_logits[valid_mask]))\n",
        "    loss_neg = F.binary_cross_entropy_with_logits(neg_logits[valid_mask], torch.zeros_like(neg_logits[valid_mask]))\n",
        "\n",
        "    loss = loss_pos + loss_neg\n",
        "\n",
        "    # L2 reg, skip padding embedding\n",
        "    if model.l2_emb > 0:\n",
        "        loss += model.l2_emb * (item_emb[1:].norm(p=2) ** 2) / 2\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Dataset & Collate\n",
        "class SASRecDataset(Dataset):\n",
        "    \"\"\"Builds sequences for SASRec training.\n",
        "\n",
        "    Args:\n",
        "        user2items: dict mapping user_id -> list of interacted item ids (in time order)\n",
        "        n_items: total number of items (max ID)\n",
        "        max_seq_len: truncate/pad sequences to this length\n",
        "        min_seq_len: smallest effective length (>=2 to have a next item)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 user2items: Dict[int, List[int]],\n",
        "                 n_items: int,\n",
        "                 max_seq_len: int = 50,\n",
        "                 min_seq_len: int = 2):\n",
        "        self.user2items = user2items\n",
        "        self.users = [u for u, seq in user2items.items() if len(seq) >= min_seq_len]\n",
        "        self.n_items = n_items\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        user = self.users[idx]\n",
        "        full = self.user2items[user]\n",
        "        # Truncate to latest max_seq_len\n",
        "        seq = full[-self.max_seq_len:]\n",
        "        return user, seq\n",
        "\n",
        "\n",
        "def _pad_sequence(seq: list, max_len: int) -> list:\n",
        "    \"\"\"Left-pad sequence with 0 to max_len.\"\"\"\n",
        "    seq = seq[-max_len:]\n",
        "    return [0] * (max_len - len(seq)) + seq\n",
        "\n",
        "def _build_pos_items(seq: list) -> list:\n",
        "    \"\"\"Next-item targets, last position padded with 0.\"\"\"\n",
        "    return seq[1:] + [0]\n",
        "\n",
        "\n",
        "def _sample_negatives(seq: list, n_items: int) -> list:\n",
        "    \"\"\"Sample negatives for each position, avoiding seq items.\"\"\"\n",
        "    user_set = set(seq)\n",
        "    negatives = []\n",
        "    for _ in range(len(seq)):\n",
        "        neg = random.randint(1, n_items - 1)  # avoid 0\n",
        "        while neg in user_set:\n",
        "            neg = random.randint(1, n_items - 1)\n",
        "        negatives.append(neg)\n",
        "    return negatives\n",
        "\n",
        "\n",
        "def sasrec_collate(batch, n_items: int, max_seq_len: int):\n",
        "    users, seqs = zip(*batch)\n",
        "    seqs = [_pad_sequence(s, max_seq_len) for s in seqs]\n",
        "\n",
        "    pos_items = [_build_pos_items(s) for s in seqs]\n",
        "    neg_items = [_sample_negatives(s, n_items) for s in seqs]\n",
        "    mask = [[1 if x != 0 else 0 for x in s] for s in seqs]\n",
        "\n",
        "    return (\n",
        "        torch.tensor(users, dtype=torch.long),\n",
        "        torch.tensor(seqs, dtype=torch.long),\n",
        "        torch.tensor(pos_items, dtype=torch.long),\n",
        "        torch.tensor(neg_items, dtype=torch.long),\n",
        "        torch.tensor(mask, dtype=torch.float),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_user2items(train_data):\n",
        "    user2items = defaultdict(list)\n",
        "    for u, i, r in sorted(train_data, key=lambda x: (x[0], x[2])):\n",
        "        user2items[u].append(i)\n",
        "    return user2items\n",
        "\n",
        "\n",
        "class SASRec(nn.Module, BaseModel):\n",
        "    def __init__(self, config, n_users: int, n_items: int):\n",
        "        nn.Module.__init__(self)  # initialize nn.Module\n",
        "        BaseModel.__init__(self, config, n_users, n_items)  # keep BaseModel logic\n",
        "\n",
        "        self.n_items = n_items\n",
        "        self.hidden_units = int(config.get(\"hidden_units\", 128))\n",
        "        self.max_seq_len = int(config.get(\"max_seq_len\", 50))\n",
        "        self.num_heads = int(config.get(\"num_heads\", 2))\n",
        "        self.num_blocks = int(config.get(\"num_blocks\", 2))\n",
        "        self.dropout_rate = float(config.get(\"dropout_rate\", 0.2))\n",
        "        self.l2_emb = float(config.get(\"l2_emb\", 0.0))\n",
        "\n",
        "        # Embeddings\n",
        "        self.item_embedding = nn.Embedding(n_items + 1, self.hidden_units, padding_idx=0)\n",
        "        self.position_embedding = nn.Embedding(self.max_seq_len, self.hidden_units)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=self.hidden_units,\n",
        "                nhead=self.num_heads,\n",
        "                dim_feedforward=self.hidden_units * 4,\n",
        "                dropout=self.dropout_rate,\n",
        "                activation=\"gelu\",\n",
        "                batch_first=True,\n",
        "            ) for _ in range(self.num_blocks)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(self.dropout_rate)\n",
        "        self.layer_norm = nn.LayerNorm(self.hidden_units)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.02)\n",
        "        nn.init.normal_(self.position_embedding.weight, std=0.02)\n",
        "\n",
        "    def _causal_mask(self, L: int, device=None):\n",
        "        # True means masked in PyTorch\n",
        "        mask = torch.triu(torch.ones(L, L, device=device), diagonal=1).bool()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, item_seq: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encode sequence safely, with padding & causal masks.\n",
        "        Args:\n",
        "            item_seq: (B, L) padded with 0 on left\n",
        "        Returns:\n",
        "            seq_out: (B, L, H)\n",
        "        \"\"\"\n",
        "        B, L = item_seq.shape\n",
        "        device = item_seq.device\n",
        "        pos_ids = torch.arange(L, device=device).unsqueeze(0).expand(B, L)\n",
        "\n",
        "        # Embeddings\n",
        "        x = self.item_embedding(item_seq) + self.position_embedding(pos_ids)\n",
        "        x = self.layer_norm(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        key_padding_mask = (item_seq == 0)  # True = pad\n",
        "        attn_mask = self._causal_mask(L, device=device)  # True = masked\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(\n",
        "            x,\n",
        "            src_mask=attn_mask,\n",
        "            src_key_padding_mask=key_padding_mask\n",
        "            )\n",
        "            # Safety: replace NaN/inf\n",
        "            if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "               x = torch.nan_to_num(x, nan=0.0, posinf=1e4, neginf=-1e4)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_full_sort_items(self, user_id, user_seq: torch.Tensor):\n",
        "        \"\"\"Return sorted item IDs by score for a single user.\n",
        "        Args:\n",
        "            user_seq: (1, L)\n",
        "        Returns:\n",
        "            torch.Tensor of sorted item ids (desc)\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        seq_out = self.forward(user_seq)[:, -1, :]  # (1, H)\n",
        "        all_item_emb = self.item_embedding.weight  # (n_items+1, H)\n",
        "        scores = torch.matmul(seq_out, all_item_emb.t()).squeeze(0)  # (n_items+1,)\n",
        "        # Avoid recommending padding id 0\n",
        "        scores[0] = -1e9\n",
        "        return torch.argsort(scores, descending=True)\n",
        "\n",
        "    def _sort_full_items(self, user_id, *args, **kwargs):\n",
        "        raise NotImplementedError(\"Use get_full_sort_items(user_id, user_seq)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmWOM2XrztQ5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import spearmanr\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class Recommender:\n",
        "    \"\"\"\n",
        "    Recommender System class\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, logger, data):\n",
        "        self.data = data\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.page_size = config[\"page_size\"]\n",
        "        self.items_per_page = config[\"items_per_page\"]\n",
        "        self.random_k = config[\"rec_random_k\"]\n",
        "        self.train_data = []\n",
        "        self.n_layers = 3\n",
        "        self.embedding_dim = 4\n",
        "        if config[\"rec_model\"] == \"MF\":\n",
        "           self.model = MF(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"LightGCN\":\n",
        "           self.model = LightGCN(config, self.data.get_user_num(), self.data.get_item_num(), self.train_data, n_layers=self.n_layers, embedding_dim=self.embedding_dim)\n",
        "        elif config[\"rec_model\"] == \"SASRec\":\n",
        "           self.model = SASRec(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"MultiVAE\":\n",
        "           self.model = MultiVAE(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        elif config[\"rec_model\"] == \"FM\":\n",
        "           self.model = FMModel(config, self.data.get_user_num(), self.data.get_item_num())\n",
        "        else:\n",
        "           raise ValueError(f\"Unknown model: {config['rec_model']}\")\n",
        "\n",
        "        self.criterion = nn.MSELoss()\n",
        "        if config[\"rec_model\"] != \"FM\":\n",
        "           self.optimizer = optim.Adam(self.model.parameters(), lr=config[\"lr\"], weight_decay=1e-5)\n",
        "\n",
        "        self.epoch_num = config[\"epoch_num\"]\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.record = {}\n",
        "        self.round_record = {}\n",
        "        self.positive = {}\n",
        "        self.interaction_dict = {}\n",
        "        self.inter_df = None\n",
        "        self.inter_num = 0\n",
        "        for user in self.data.get_full_users():\n",
        "            self.record[user] = []\n",
        "            self.positive[user] = []\n",
        "            self.round_record[user] = []\n",
        "        self.user_data = {\n",
        "            \"user\": [],\n",
        "            \"N_expose\": [],\n",
        "            \"N_view\": [],\n",
        "            \"N_like\": [],\n",
        "            \"N_exit\": [],\n",
        "            \"S_sat\": []\n",
        "            }\n",
        "        self.rating_feeling = {\n",
        "            \"User\": [],\n",
        "            \"Rating\": [],\n",
        "            \"Feelings\": []\n",
        "        }\n",
        "\n",
        "    def sample_bpr_triples(self,\n",
        "                           user_pos_items: List[List[int]],\n",
        "                           n_items: int,\n",
        "                           batch_size: int,\n",
        "                           device: torch.device,\n",
        "                           ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        user_pos_items: list of lists; for each user u, a list of items they've interacted with (positive)\n",
        "        returns (users, pos_items, neg_items) tensors of length batch_size\n",
        "        \"\"\"\n",
        "        users = []\n",
        "        pos = []\n",
        "        neg = []\n",
        "        for _ in range(batch_size):\n",
        "           # sample a user with at least one positive\n",
        "           while True:\n",
        "               u = np.random.randint(0, len(user_pos_items))\n",
        "               if len(user_pos_items[u]) > 0:\n",
        "                  break\n",
        "\n",
        "           i = np.random.choice(user_pos_items[u])\n",
        "           # sample a negative item\n",
        "\n",
        "           while True:\n",
        "               j = np.random.randint(0, n_items)\n",
        "               if j not in user_pos_items[u]:\n",
        "                  break\n",
        "\n",
        "           users.append(u)\n",
        "           pos.append(i)\n",
        "           neg.append(j)\n",
        "\n",
        "        return (\n",
        "        torch.tensor(users, dtype=torch.long, device=self.device),\n",
        "        torch.tensor(pos, dtype=torch.long, device=self.device),\n",
        "        torch.tensor(neg, dtype=torch.long, device=self.device),\n",
        "        )\n",
        "\n",
        "    def train_lightgcn_bpr(self,\n",
        "        reg: float = 1e-4,\n",
        "        log: bool = True):\n",
        "        \"\"\"\n",
        "        Train LightGCN with BPR loss.\n",
        "        - train_interactions/val_interactions can be (u,i) or (u,i,rating>0) tuples.\n",
        "        - If ckpt_path is provided, saves the best (by simple val recall proxy) state dict.\n",
        "        \"\"\"\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config[\"lr\"])\n",
        "        self.criterion = BPRLoss(reg=reg)\n",
        "\n",
        "        # Build user -> positives list\n",
        "        user_pos = [[] for _ in range(self.model.n_users)]\n",
        "        for u, i, *rest in self.train_data:\n",
        "            if 0 <= u < self.model.n_users and 0 <= i < self.model.n_items:\n",
        "               user_pos[u].append(i)\n",
        "\n",
        "        # Basic validation proxy: count of positives ranked in top-10 (cheap & optional)\n",
        "        def quick_val_topk_hits(k: int = 10) -> float:\n",
        "            if self.val_data is None:\n",
        "               return -1.0\n",
        "            # build val positives per user\n",
        "            val_pos = [[] for _ in range(self.model.n_users)]\n",
        "            for u, i, *rest in self.val_data:\n",
        "               if 0 <= u < self.model.n_users and 0 <= i < self.model.n_items:\n",
        "                   val_pos[u].append(i)\n",
        "\n",
        "            hits = 0\n",
        "            total = 0\n",
        "\n",
        "            for u in range(self.model.n_users):\n",
        "               if not val_pos[u]:\n",
        "                  continue\n",
        "               recs = self.model.get_full_sort_items(u, seen_items=set(user_pos[u]), top_k=k)\n",
        "               s = set(val_pos[u])\n",
        "               hits += len([r for r in recs if r in s])\n",
        "               total += min(k, len(s))\n",
        "            return hits / total if total > 0 else -1.0\n",
        "\n",
        "        best_metric = -math.inf\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_lightGCN_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "            self.model.train()\n",
        "\n",
        "            # One epoch of mini-batch BPR\n",
        "            n_steps = max(1, sum(len(v) for v in user_pos) // max(1, config['batch_size']))\n",
        "            losses = []\n",
        "            for _ in range(n_steps):\n",
        "                users, pos_items, neg_items = self.sample_bpr_triples(user_pos, self.model.n_items, config['batch_size'], self.device)\n",
        "                Eu, Ei = self.model.propagate()\n",
        "                u_emb = Eu[users]\n",
        "                p_emb = Ei[pos_items]\n",
        "                n_emb = Ei[neg_items]\n",
        "                loss = self.criterion(u_emb, p_emb, n_emb)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "            # quick validation metric\n",
        "            metric = quick_val_topk_hits(k=10)\n",
        "            if log:\n",
        "               print(f\"[Epoch {epoch:3d}] BPR Loss: {np.mean(losses):.4f} | Val@10: {metric:.4f}\")\n",
        "\n",
        "            # Save checkpoint if validation improves\n",
        "            if metric > best_metric:\n",
        "               best_metric = metric\n",
        "               torch.save({\n",
        "                   \"epoch\": self.epoch_num + 1,\n",
        "                   \"model_state_dict\": self.model.state_dict(),\n",
        "                   \"n_users\": self.data.get_user_num(),\n",
        "                   \"n_items\": self.data.get_item_num(),\n",
        "                   \"n_layers\": self.n_layers,\n",
        "                   \"embedding_dim\": self.embedding_dim,\n",
        "                   \"metric\": metric,\n",
        "                   }, ckpt_file)\n",
        "               self.logger.info(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        # Load best (optional)\n",
        "        if ckpt_file is not None and best_metric > -math.inf:\n",
        "           # At the end, reload the best weights for inference\n",
        "           checkpoint = torch.load(ckpt_file)\n",
        "           self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def bce_sampled_loss(self, seq_out: torch.Tensor,\n",
        "        pos_items: torch.Tensor,\n",
        "        neg_items: torch.Tensor,\n",
        "        item_embedding: nn.Embedding,\n",
        "        mask: torch.Tensor,\n",
        "        l2_emb: float = 0.0) -> torch.Tensor:\n",
        "        \"\"\"Binary cross-entropy on sampled positives/negatives per position.\n",
        "        Args:\n",
        "            seq_out: (B, L, H)\n",
        "            pos_items: (B, L) next-item ids (0 where no target)\n",
        "            neg_items: (B, L) sampled negatives (0 where no target)\n",
        "            item_embedding: embedding module (to fetch item vectors)\n",
        "            mask: (B, L) boolean, True where a target exists (i.e., pos_items > 0)\n",
        "            l2_emb: weight decay on item embeddings (regularizes pos/neg lookups)\n",
        "        \"\"\"\n",
        "        B, L, H = seq_out.shape\n",
        "\n",
        "        pos_vecs = item_embedding(pos_items)  # (B, L, H)\n",
        "        neg_vecs = item_embedding(neg_items)  # (B, L, H)\n",
        "\n",
        "        pos_logits = (seq_out * pos_vecs).sum(-1)  # (B, L)\n",
        "        neg_logits = (seq_out * neg_vecs).sum(-1)  # (B, L)\n",
        "\n",
        "        # Targets: pos -> 1, neg -> 0\n",
        "        pos_loss = F.binary_cross_entropy_with_logits(pos_logits[mask], torch.ones_like(pos_logits[mask]))\n",
        "        neg_loss = F.binary_cross_entropy_with_logits(neg_logits[mask], torch.zeros_like(neg_logits[mask]))\n",
        "        loss = pos_loss + neg_loss\n",
        "\n",
        "        if l2_emb > 0:\n",
        "           reg = (pos_vecs[mask].pow(2).sum() + neg_vecs[mask].pow(2).sum()) / mask.sum().clamp_min(1)\n",
        "           loss = loss + l2_emb * reg\n",
        "        return loss\n",
        "\n",
        "    def train_sasrec(self, grad_clip=1.0, logit_clip=20.0):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Build user->items dict and dataset\n",
        "        user2items = build_user2items(self.train_data)\n",
        "        n_items_global = int(self.data.get_item_num())\n",
        "        max_seq_len = self.model.max_seq_len\n",
        "\n",
        "        train_dataset = SASRecDataset(user2items, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=True,\n",
        "            collate_fn=lambda batch: sasrec_collate(batch, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "            )\n",
        "\n",
        "        # Validation loader\n",
        "        val_user2items = build_user2items(self.val_data)\n",
        "        val_dataset = SASRecDataset(val_user2items, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.config['batch_size'],\n",
        "            shuffle=False,\n",
        "            collate_fn=lambda batch: sasrec_collate(batch, n_items=n_items_global, max_seq_len=max_seq_len)\n",
        "            )\n",
        "\n",
        "        # Checkpoint setup\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_SASRec_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "        best_metric = -float(\"inf\")\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "           self.model.train()\n",
        "           running = 0.0\n",
        "           n_steps = 0\n",
        "\n",
        "           for users, seqs, pos, neg, umask in train_loader:\n",
        "              users, seqs, pos, neg, umask = (\n",
        "                users.to(self.device),\n",
        "                seqs.to(self.device),\n",
        "                pos.to(self.device),\n",
        "                neg.to(self.device),\n",
        "                umask.to(self.device).bool(),  # ensure bool type\n",
        "                )\n",
        "\n",
        "              # Compute mask dynamically\n",
        "              mask = pos > 0\n",
        "              mask = mask.bool()\n",
        "              if mask.sum() == 0:\n",
        "                 continue  # skip batch with no valid positions\n",
        "\n",
        "              # Compute stable loss\n",
        "              loss = sasrec_pointwise_step(self.model, (users, seqs, pos, neg, mask), device=self.device, logit_clip=logit_clip)\n",
        "\n",
        "              self.optimizer.zero_grad(set_to_none=True)\n",
        "              loss.backward()\n",
        "              if grad_clip is not None:\n",
        "                 nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "              self.optimizer.step()\n",
        "\n",
        "              running += loss.item()\n",
        "              n_steps += 1\n",
        "\n",
        "           avg_loss = running / max(1, n_steps)\n",
        "           print(f\"Epoch {epoch}/{self.epoch_num} - train loss: {avg_loss:.4f}\")\n",
        "\n",
        "           # Validation\n",
        "           if val_loader is not None:\n",
        "              self.model.eval()\n",
        "              val_loss = 0.0\n",
        "              n_val_steps = 0\n",
        "              with torch.no_grad():\n",
        "                  for users, seqs, pos, neg, umask in val_loader:\n",
        "                     users, seqs, pos, neg, umask = (\n",
        "                         users.to(self.device),\n",
        "                         seqs.to(self.device),\n",
        "                         pos.to(self.device),\n",
        "                         neg.to(self.device),\n",
        "                         umask.to(self.device).bool(),)\n",
        "\n",
        "                     mask = pos > 0\n",
        "                     if mask.sum() == 0:\n",
        "                        # print(\"Skipped empty batch\")\n",
        "                        continue\n",
        "\n",
        "                     loss = sasrec_pointwise_step(self.model, (users, seqs, pos, neg, mask), device=self.device, logit_clip=logit_clip)\n",
        "                    #  print(\"Batch loss:\", loss.item())\n",
        "                     val_loss += loss.item()\n",
        "                     n_val_steps += 1\n",
        "              val_loss /= max(1, n_val_steps)\n",
        "              metric = -val_loss\n",
        "              print(f\"Epoch {epoch}, Val Loss: {val_loss:.4f}\")\n",
        "           else:\n",
        "              metric = -avg_loss\n",
        "\n",
        "           # Save best model\n",
        "           if metric > best_metric:\n",
        "              best_metric = metric\n",
        "              torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"metric\": metric,\n",
        "              }, ckpt_file)\n",
        "              print(f\"Best model updated at epoch {epoch}, saved to {ckpt_file}\")\n",
        "\n",
        "        # Load best model after training\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "\n",
        "    def train_fm(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.config['lr'])\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        best_metric = -math.inf\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_FM_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        #  Wrap datasets into DataLoaders\n",
        "        train_loader = DataLoader(self.train_data, batch_size=self.config['batch_size'], shuffle=True)\n",
        "        val_loader = None\n",
        "        if self.val_data is not None:\n",
        "           val_loader = DataLoader(self.val_data, batch_size=self.config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "        for epoch in range(self.epoch_num):\n",
        "           self.model.train()\n",
        "           total_loss = 0\n",
        "\n",
        "           for user, item, rating in train_loader:  # must be DataLoader\n",
        "              user, item, rating = user.to(self.device), item.to(self.device), rating.float().to(self.device)\n",
        "\n",
        "              self.optimizer.zero_grad()\n",
        "              preds = self.model(user, item)\n",
        "              loss = self.criterion(preds, rating)\n",
        "              loss.backward()\n",
        "              self.optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "           avg_loss = total_loss / len(train_loader)\n",
        "           print(f\"Epoch {epoch+1}/{self.epoch_num}, Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "           metric = None\n",
        "           if val_loader is not None:\n",
        "              self.model.eval()\n",
        "              with torch.no_grad():\n",
        "                  val_loss = 0\n",
        "                  for user, item, rating in val_loader:\n",
        "                      user, item, rating = user.to(self.device), item.to(self.device), rating.to(self.device)\n",
        "                      preds = self.model(user, item)\n",
        "                      val_loss += self.criterion(preds, rating).item()\n",
        "                  val_loss /= len(val_loader)\n",
        "\n",
        "              metric = -val_loss\n",
        "              print(f\"Epoch {epoch+1}, Val Loss: {val_loss:.4f}\")\n",
        "           else:\n",
        "              metric = -avg_loss  # fallback if no validation set\n",
        "\n",
        "           # save best model\n",
        "           if metric > best_metric:\n",
        "              best_metric = metric\n",
        "              torch.save({\n",
        "                \"epoch\": epoch+1,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"n_users\": self.model.n_users,\n",
        "                \"n_items\": self.model.n_items,\n",
        "                \"n_factors\": self.model.n_factors,\n",
        "                \"metric\": metric,\n",
        "                }, ckpt_file)\n",
        "              print(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "\n",
        "    def train_multivae(self,\n",
        "        weight_decay: float = 0.0,\n",
        "        anneal_cap: float = 0.2,\n",
        "        total_anneal_steps: int = 200000,\n",
        "        patience: int = 100,\n",
        "        verbose: bool = True,):\n",
        "        \"\"\"\n",
        "        Train MultiVAE on user-item matrix (CSR or dense numpy).\n",
        "        - anneal_cap: maximum beta for KL weighting\n",
        "        - total_anneal_steps: number of optimization steps over which to ramp beta from 0->anneal_cap\n",
        "        \"\"\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        dataset = InteractionDataset(self.train_matrix)\n",
        "        loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True, drop_last=False)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config['lr'], weight_decay=weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        update_count = 0\n",
        "        best_val_loss = float(\"inf\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MultiVAE_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        wait = 0\n",
        "\n",
        "        # AMP scaler (for mixed precision training)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "        # validation dataset (create once, not per epoch)\n",
        "        val_loader, val_dataset = None, None\n",
        "        if self.val_matrix is not None:\n",
        "           val_dataset = InteractionDataset(self.val_matrix)\n",
        "           val_loader = DataLoader(val_dataset, batch_size=self.config['batch_size'], shuffle=False)\n",
        "\n",
        "        for epoch in range(1, self.epoch_num + 1):\n",
        "            self.model.train()\n",
        "            epoch_loss, epoch_recon, epoch_kl, n_batches = 0.0, 0.0, 0.0, 0\n",
        "\n",
        "            for batch in loader:\n",
        "                batch = batch.to(self.device).float()\n",
        "                assert batch.shape[1] == self.model.n_items, \"Batch dimension mismatch!\"\n",
        "\n",
        "                # anneal factor\n",
        "                if total_anneal_steps > 0:\n",
        "                   anneal = min(anneal_cap, update_count / total_anneal_steps)\n",
        "                else:\n",
        "                   anneal = anneal_cap\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                    logits, mu, logvar = self.model(batch, sample=True)\n",
        "                    # clamp logvar inside model (optional, numerical stability)\n",
        "                    logvar = torch.clamp(logvar, min=-10, max=10)\n",
        "                    loss, recon_l, kl_l = self.model.loss_function(logits, batch, mu, logvar, anneal)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                epoch_recon += recon_l\n",
        "                epoch_kl += kl_l\n",
        "                update_count += 1\n",
        "                n_batches += 1\n",
        "\n",
        "            scheduler.step()\n",
        "            avg_train_elbo = epoch_loss / n_batches\n",
        "\n",
        "            if verbose:\n",
        "               print(f\"[Epoch {epoch}] Train ELBO: {avg_train_elbo:.4f} | \"\n",
        "                  f\"Recon: {epoch_recon / n_batches:.4f} | KL: {epoch_kl / n_batches:.4f} | \"\n",
        "                  f\"Anneal: {anneal:.4f}\")\n",
        "\n",
        "            # ---------- Validation ----------\n",
        "            if val_loader is not None:\n",
        "               self.model.eval()\n",
        "               val_losses = []\n",
        "               with torch.no_grad():\n",
        "                   for vb in val_loader:\n",
        "                      vb = vb.to(self.device).float()\n",
        "                      logits, mu, logvar = self.model(vb, sample=False)\n",
        "                      logvar = torch.clamp(logvar, min=-10, max=10)\n",
        "                      vloss, vrec, vkl = self.model.loss_function(logits, vb, mu, logvar, anneal)\n",
        "                      val_losses.append(vloss.item() * len(vb))\n",
        "\n",
        "               val_loss = float(np.sum(val_losses) / len(val_dataset))\n",
        "\n",
        "               if verbose:\n",
        "                 print(f\"  -> Val ELBO: {val_loss:.4f}\")\n",
        "\n",
        "               # save best with early stopping\n",
        "               if val_loss < best_val_loss:\n",
        "                  best_val_loss = val_loss\n",
        "                  wait = 0\n",
        "                  torch.save({\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state_dict\": self.model.state_dict(),\n",
        "                    \"optimizer\": self.optimizer.state_dict(),\n",
        "                    \"n_users\": self.data.get_user_num(),\n",
        "                    \"n_items\": self.data.get_item_num(),\n",
        "                    \"hidden_dim\": self.config[\"vae_hidden_dim\"],\n",
        "                    \"latent_dim\": self.config[\"vae_latent_dim\"],\n",
        "                    \"config\": self.config,\n",
        "                    }, ckpt_file)\n",
        "                  self.logger.info(f\"Best model updated at epoch {epoch}, saved to {ckpt_file}\")\n",
        "               else:\n",
        "                  wait += 1\n",
        "                  if wait >= patience:\n",
        "                     print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "                     break\n",
        "\n",
        "        # reload best model\n",
        "        checkpoint = torch.load(ckpt_file, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "\n",
        "    def swap_items(self, lst, page_size, random_k):\n",
        "        total_pages = len(lst) // page_size\n",
        "        lst = lst[: total_pages * page_size]\n",
        "        for page in range(1, total_pages // 2 + 1):\n",
        "            start_idx = (page - 1) * page_size\n",
        "            end_idx = start_idx + page_size - 1\n",
        "            symmetric_start_idx = (total_pages - page) * page_size\n",
        "            symmetric_end_idx = symmetric_start_idx + page_size\n",
        "\n",
        "            for k in range(1, random_k + 1):\n",
        "                lst[end_idx - k], lst[symmetric_end_idx - k] = (\n",
        "                    lst[symmetric_end_idx - k],\n",
        "                    lst[end_idx - k],\n",
        "                )\n",
        "\n",
        "        return lst\n",
        "\n",
        "    def add_random_items(self, user, item_ids):\n",
        "        item_ids = self.swap_items(item_ids, self.page_size, self.random_k)\n",
        "        return item_ids\n",
        "\n",
        "    def ordered_probit_loglik(self, y_true, y_pred_int, K=5, taus=None):\n",
        "        \"\"\"\n",
        "        Compute log-likelihood for ordered probit model given integer predictions.\n",
        "\n",
        "        y_true : list or array\n",
        "           True ratings (1..K).\n",
        "        y_pred_int : list or array\n",
        "           Predicted integer ratings (1..K).\n",
        "        K : int\n",
        "           Number of rating categories (default 5).\n",
        "        taus : list or array, optional\n",
        "           Thresholds (default: equally spaced).\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(y_true) == len(y_pred_int), \"Mismatch in true vs predicted length\"\n",
        "        ll = 0.0\n",
        "        for t, p in zip(y_true, y_pred_int):\n",
        "           probs = self.data.ordered_probit_probs(p, K, taus)\n",
        "           ll += self.data.safe_log(probs[t-1])  # subtract 1 for 0-based index\n",
        "        avg_ll = ll / len(y_true)\n",
        "        return ll, avg_ll\n",
        "\n",
        "    def update_user_interactions(self, user_id, new_items):\n",
        "        \"\"\"\n",
        "        Updates the directory of user_id and interacted_items.\n",
        "        - interaction_dict: dict mapping user_id -> set of interacted item ids\n",
        "        - user_id: int or str\n",
        "        - new_items: iterable of item ids (list, set, etc)\n",
        "\n",
        "        After calling, interaction_dict[user_id] contains all unique interacted items.\n",
        "        \"\"\"\n",
        "        # Ensure the user's interaction set exists\n",
        "        if user_id not in self.interaction_dict:\n",
        "          self.interaction_dict[user_id] = set()\n",
        "\n",
        "        new_items = set(new_items) - self.interaction_dict[user_id]\n",
        "        self.interaction_dict[user_id].update(new_items)\n",
        "\n",
        "    def get_full_manual_items(self, user_id, gt_ratio, rd_ratio, total_items, read = None, heard = None):\n",
        "        \"\"\"\n",
        "        Get a list of manual items for a given user.\n",
        "        \"\"\"\n",
        "        gtruth_items = self.data.interrating[user_id]\n",
        "        gt_items = [item for item, rating in gtruth_items]\n",
        "        rd_items = self.data.get_full_items()\n",
        "\n",
        "        # Remove any gt_items from rd_items to avoid duplicates\n",
        "        rd_items = list(set(rd_items) - set(gt_items))\n",
        "\n",
        "        # 1. Determine counts\n",
        "        total_ratio = gt_ratio + rd_ratio\n",
        "        gt_count = round(total_items * gt_ratio / total_ratio)\n",
        "        rd_count = total_items - gt_count\n",
        "\n",
        "        # Make sure we don't try to sample more than available\n",
        "        gt_count = min(gt_count, len(gt_items))\n",
        "        rd_count = min(rd_count, len(rd_items))\n",
        "\n",
        "        # 2. Randomly sample\n",
        "        chosen_gt = random.sample(gt_items, gt_count) if gt_count > 0 else []\n",
        "        chosen_rd = random.sample(rd_items, rd_count) if rd_count > 0 else []\n",
        "\n",
        "        # 3. Combine and shuffle if desired\n",
        "        final_items = chosen_gt + chosen_rd\n",
        "\n",
        "        # items discriptions\n",
        "        sorted_item_names = self.data.get_item_names(final_items)\n",
        "        description = self.data.get_item_description_by_id(final_items)\n",
        "        eb_item = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([final_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return final_items, eb_item, chosen_gt\n",
        "\n",
        "    def get_full_sort_items(self, user, random=False):\n",
        "        \"\"\"\n",
        "        Get a list of sorted items for a given user.\n",
        "        \"\"\"\n",
        "        items = self.data.get_full_items()\n",
        "        user_tensor = torch.tensor(user)\n",
        "        items_tensor = torch.tensor(items)\n",
        "        sorted_items = self.model.get_full_sort_items(user_tensor, items_tensor)\n",
        "        if self.random_k > 0 and random == True:\n",
        "            sorted_items = self.add_random_items(user, sorted_items)\n",
        "        sorted_items = [item for item in sorted_items if item not in self.record[user]]\n",
        "        sorted_item_names = self.data.get_item_names(sorted_items)\n",
        "        description = self.data.get_item_description_by_id(sorted_items)\n",
        "        items = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([sorted_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return sorted_items, items\n",
        "\n",
        "    def get_item(self, idx):\n",
        "        item_name = self.data.get_item_names([idx])[0]\n",
        "        description = self.data.get_item_description_by_id([idx])[0]\n",
        "        item = item_name + \";;\" + description\n",
        "        return item\n",
        "\n",
        "    def get_search_items(self, item_name):\n",
        "        return self.data.search_items(item_name)\n",
        "\n",
        "    def get_inter_num(self):\n",
        "        return self.inter_num\n",
        "\n",
        "    def update_history_by_name(self, user_id, item_names):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        item_names = [item_name.strip(\" <>'\\\"\") for item_name in item_names]\n",
        "        item_ids = self.data.get_item_ids(item_names)\n",
        "        self.record[user_id].extend(item_ids)\n",
        "\n",
        "    def update_history_by_id(self, user_id, item_ids):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        self.record[user_id].extend(item_ids)\n",
        "\n",
        "    def update_positive(self, user_id, item_names):\n",
        "        \"\"\"\n",
        "        Update the positive history of a given user.\n",
        "        \"\"\"\n",
        "        item_ids = self.data.get_item_ids(item_names)\n",
        "        if len(item_ids) == 0:\n",
        "            return\n",
        "        self.positive[user_id].extend(item_ids)\n",
        "        self.inter_num += len(item_ids)\n",
        "\n",
        "    def update_positive_by_id(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Update the history of a given user.\n",
        "        \"\"\"\n",
        "        self.positive[user_id].append(item_id)\n",
        "\n",
        "    def save_interaction(self):\n",
        "        \"\"\"\n",
        "        Save the interaction history to a csv file.\n",
        "        \"\"\"\n",
        "        inters = []\n",
        "        users = self.data.get_full_users()\n",
        "        for user in users:\n",
        "            for item in self.positive[user]:\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 1}\n",
        "                inters.append(new_row)\n",
        "\n",
        "            for item in self.record[user]:\n",
        "                if item in self.positive[user]:\n",
        "                    continue\n",
        "                new_row = {\"user_id\": user, \"item_id\": item, \"rating\": 0}\n",
        "                inters.append(new_row)\n",
        "\n",
        "        df = pd.DataFrame(inters)\n",
        "        df.to_csv(\n",
        "            self.config[\"interaction_path\"],\n",
        "            index=False,\n",
        "        )\n",
        "\n",
        "        self.inter_df = df\n",
        "\n",
        "    def add_train_data(self, user, item, label):\n",
        "        self.train_data.append((user, item, label))\n",
        "\n",
        "    def clear_train_data(self):\n",
        "        self.train_data = []\n",
        "\n",
        "    def add_user(self, user_id, N_expose, N_view, N_like, N_exit, S_sat):\n",
        "        self.user_data[\"user\"].append(user_id)\n",
        "        self.user_data[\"N_expose\"].append(N_expose)\n",
        "        self.user_data[\"N_view\"].append(N_view)\n",
        "        self.user_data[\"N_like\"].append(N_like)\n",
        "        self.user_data[\"N_exit\"].append(N_exit)\n",
        "        self.user_data[\"S_sat\"].append(S_sat)\n",
        "\n",
        "    def add_review(self, user_id, rating, feelings):\n",
        "        self.rating_feeling[\"User\"].append(user_id)\n",
        "        self.rating_feeling[\"Rating\"].append(rating)\n",
        "        self.rating_feeling[\"Feelings\"].append(feelings)\n",
        "\n",
        "    def satisfaction_metrics(self):\n",
        "        sm_df = pd.DataFrame(self.user_data)\n",
        "        if len(sm_df) == 0:\n",
        "           return None  # no data yet\n",
        "\n",
        "        metrics = {}\n",
        "        sm_df[\"view_ratio\"] = sm_df[\"N_view\"] / sm_df[\"N_expose\"]\n",
        "        sm_df[\"like_ratio\"] = sm_df[\"N_like\"] / sm_df[\"N_expose\"]\n",
        "\n",
        "        metrics[\"P_view\"] = sm_df[\"view_ratio\"].mean()\n",
        "        metrics[\"N_like\"] = sm_df[\"N_like\"].mean()\n",
        "        metrics[\"P_like\"] = sm_df[\"like_ratio\"].mean()\n",
        "        metrics[\"N_exit\"] = sm_df[\"N_exit\"].mean()\n",
        "        metrics[\"S_sat\"] = sm_df[\"S_sat\"].mean()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_entropy(\n",
        "        self,\n",
        "    ):\n",
        "        tot_entropy = 0\n",
        "        for user in self.record.keys():\n",
        "            inters = self.record[user]\n",
        "            genres = self.data.get_genres_by_id(inters)\n",
        "            entropy = calculate_entropy(genres)\n",
        "            tot_entropy += entropy\n",
        "\n",
        "        return tot_entropy / len(self.record.keys())\n",
        "\n",
        "    def check_train_data(self):\n",
        "        \"\"\"\n",
        "        Print or inspect the training data.\n",
        "        \"\"\"\n",
        "        print(\"Training Data:\")\n",
        "        for user, item, label in self.train_data:\n",
        "            print(f\"User: {user}, Item: {item}, Label: {label}\")\n",
        "\n",
        "    def create_train_data(self):\n",
        "        \"\"\"\n",
        "        Create a training dataset with random samples.\n",
        "\n",
        "        Args:\n",
        "            num_samples (int): Number of samples to generate.\n",
        "        \"\"\"\n",
        "        self.clear_train_data()  # Clear existing training data\n",
        "        all_data = self.data.interrating  # You need to implement this or use available interaction data\n",
        "\n",
        "        # Convert dict to list of (user, item, label)\n",
        "        # triplets = []\n",
        "        for user, interactions in all_data.items():\n",
        "            for item, rating in interactions:\n",
        "                self.add_train_data(user, item, float(rating))\n",
        "                # triplets.append((user, item, float(rating)))  # keep exact rating\n",
        "\n",
        "        # Split 80% train, 20% temp (to further split into val/test)\n",
        "        self.train_data, self.temp_data = train_test_split(self.train_data, test_size=0.2, random_state=2025)\n",
        "\n",
        "        # Split temp into 10% val and 10% test (from the total dataset)\n",
        "        self.val_data, self.test_data = train_test_split(self.temp_data, test_size=0.5, random_state=2025)\n",
        "\n",
        "        train_users = max([u for u, i, r in self.train_data]) + 1\n",
        "        train_items = max([i for u, i, r in self.train_data]) + 1\n",
        "\n",
        "        val_users = max([u for u, i, r in self.val_data]) + 1\n",
        "        val_items = max([i for u, i, r in self.val_data]) + 1\n",
        "\n",
        "        test_users = max([u for u, i, r in self.test_data]) + 1\n",
        "        test_items = max([i for u, i, r in self.test_data]) + 1\n",
        "\n",
        "        n_items_global = int(self.data.get_item_num())\n",
        "\n",
        "        # Initialize user-item matrix\n",
        "        self.train_matrix = np.zeros((train_users, n_items_global), dtype=np.float32)\n",
        "        self.val_matrix = np.zeros((val_users, n_items_global), dtype=np.float32)\n",
        "        self.test_matrix = np.zeros((test_users, n_items_global), dtype=np.float32)\n",
        "\n",
        "        # Fill interactions safely\n",
        "        for u, i, r in self.train_data:\n",
        "           if i >= n_items_global: continue  # skip bad indices\n",
        "           self.train_matrix[u, i] = r\n",
        "\n",
        "        for u, i, r in self.val_data:\n",
        "           if i >= n_items_global: continue\n",
        "           self.val_matrix[u, i] = r\n",
        "\n",
        "        for u, i, r in self.test_data:\n",
        "           if i >= n_items_global: continue\n",
        "           self.test_matrix[u, i] = r\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_user_metrics(\n",
        "        self, user_id, sim_recommended, all_items, threshold = 3):\n",
        "        \"\"\"\n",
        "        Evaluate precision, recall, (optionally real) accuracy, and F1 for a single user.\n",
        "\n",
        "        Returns:\n",
        "            dict: { 'precision': float, 'recall': float, 'accuracy': float, 'f1': float }\n",
        "        \"\"\"\n",
        "\n",
        "        if user_id not in self.data.interrating:\n",
        "           return {'precision': 0, 'recall': 0, 'accuracy': 0, 'f1': 0}\n",
        "\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= threshold and item in all_items)\n",
        "        sim_recommended = set(sim_recommended)\n",
        "        all_items = set(all_items)\n",
        "\n",
        "        TP = len(gt_relevant & sim_recommended)\n",
        "        FP = len(sim_recommended - gt_relevant)\n",
        "        FN = len(gt_relevant - sim_recommended)\n",
        "        TN = len(all_items - (gt_relevant | sim_recommended))\n",
        "\n",
        "        precision = TP / (TP + FP) if (TP + FP) else 0.0\n",
        "        recall = TP / (TP + FN) if (TP + FN) else 0.0\n",
        "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0.0\n",
        "        accuracy = (TP + TN) / len(all_items) if all_items else 0\n",
        "\n",
        "        print(\"precision:\", precision, \"recall:\", recall, \"accuracy:\", accuracy, \"f1:\", f1)\n",
        "        return precision, recall, accuracy, f1\n",
        "\n",
        "    def precisionandrecallk(\n",
        "        self, user_id, recommended, k):\n",
        "        if user_id not in self.data.interrating:\n",
        "           return {'precision_at_k': 0, 'recall_at_k': 0}\n",
        "\n",
        "        sim_recommended = list(dict.fromkeys(recommended))\n",
        "        ground_truth_pairs = self.data.interrating[user_id]\n",
        "        gt_relevant = set(item for item, rating in ground_truth_pairs if rating >= 3)\n",
        "        recommended_at_k = sim_recommended[:k]\n",
        "        hits = sum([1 for item in recommended_at_k if item in gt_relevant])\n",
        "        precision_at_k = hits / k\n",
        "        recall_at_k = hits / len(gt_relevant) if gt_relevant else 0\n",
        "        return precision_at_k, recall_at_k\n",
        "\n",
        "\n",
        "    def calculation_of_rating(self, user_id, item_names, book_rating):\n",
        "        item_ids = self.data.get_item_ids([item_names])\n",
        "        if user_id in self.data.interrating:\n",
        "           # Check for item in user's ratings\n",
        "           for (itm, rating) in self.data.interrating[user_id]:\n",
        "               if itm == item_ids[0]:\n",
        "                  return (rating, book_rating)\n",
        "\n",
        "        # If not found\n",
        "        return (0, book_rating)\n",
        "\n",
        "\n",
        "    def calc_mse_rmse_rating_percentages(self, rating_pairs):\n",
        "\n",
        "        print(\"Incoming rating_pairs:\", rating_pairs[:20])  # show first 20 pairs\n",
        "        print(\"Total pairs:\", len(rating_pairs))\n",
        "\n",
        "        # Remove pairs with zero in ground truth or predicted rating\n",
        "        filtered_pairs = [(gt, pred) for gt, pred in rating_pairs\n",
        "                          if int(gt) != 0]\n",
        "\n",
        "        print(\"After filtering:\", filtered_pairs[:20])\n",
        "        print(\"Remaining pairs:\", len(filtered_pairs))\n",
        "\n",
        "        if not filtered_pairs:\n",
        "           # No valid data after filtering\n",
        "           return None, None, {}, {}, None, None, None\n",
        "\n",
        "        # Convert ratings to int\n",
        "        gt = [int(gt) for gt, pred in filtered_pairs]\n",
        "        pred = [int(pred) for gt, pred in filtered_pairs]\n",
        "        mse = np.mean([(g - p) ** 2 for g, p in zip(gt, pred)])\n",
        "        rmse = np.sqrt(mse)\n",
        "        loglike, ob_loglike = self.ordered_probit_loglik(gt, pred)\n",
        "        rho, p_value = spearmanr(gt, pred)\n",
        "\n",
        "        gt_count = Counter(gt)\n",
        "        pred_count = Counter(pred)\n",
        "        total = len(filtered_pairs)\n",
        "\n",
        "        gt_pct = {r: gt_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        pred_pct = {r: pred_count.get(r, 0) / total * 100 for r in range(1, 6)}\n",
        "        return mse, rmse, gt_pct, pred_pct, loglike, ob_loglike, rho\n",
        "\n",
        "\n",
        "    def test_recommendations(self, user_id):\n",
        "        # Get the full list of items\n",
        "        all_items = self.data.get_full_items()\n",
        "\n",
        "        # Convert the user ID to tensor\n",
        "        user_tensor = torch.tensor(user_id)\n",
        "\n",
        "        # Convert all items to tensor\n",
        "        items_tensor = torch.tensor(all_items)\n",
        "\n",
        "        # Get sorted items based on the model's prediction\n",
        "        sorted_items = self.model.get_full_sort_items(user_tensor, items_tensor)\n",
        "\n",
        "        # Filter out items that are already in the user's history\n",
        "        recommended_items = [item for item in sorted_items if item not in self.record[user_id]]\n",
        "\n",
        "        # Return the recommended items\n",
        "        return recommended_items\n",
        "\n",
        "    def evaluate(self, dataset):\n",
        "        self.model.eval()\n",
        "        users = torch.tensor([x[0] for x in dataset])\n",
        "        items = torch.tensor([x[1] for x in dataset])\n",
        "        labels = torch.tensor([x[2] for x in dataset]).float()\n",
        "\n",
        "        with torch.no_grad():\n",
        "             outputs = self.model(users, items)\n",
        "             loss = self.criterion(outputs, labels)\n",
        "        return loss.item()\n",
        "\n",
        "    def load_checkpoint(self, path=\"best_model.pth\", resume_training=False):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        if resume_training:\n",
        "           # Load optimizer state to resume training exactly where it left off\n",
        "           self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "           start_epoch = checkpoint[\"epoch\"]\n",
        "           self.logger.info(f\"Resuming training from epoch {start_epoch}\")\n",
        "           return start_epoch\n",
        "        else:\n",
        "           self.model.eval()  # set to eval mode for inference\n",
        "\n",
        "    def train_mf(self):\n",
        "        if len(self.train_data) == 0:\n",
        "            print(\"No training data!\")\n",
        "            return\n",
        "\n",
        "        users = [x[0] for x in self.train_data]\n",
        "        items = [x[1] for x in self.train_data]\n",
        "        labels = [x[2] for x in self.train_data]\n",
        "\n",
        "\n",
        "        dataset = torch.utils.data.TensorDataset(\n",
        "        torch.tensor(users), torch.tensor(items), torch.tensor(labels))\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=self.config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        best_val_loss = float(\"inf\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MF_model.pth\")\n",
        "        os.makedirs(self.config['checkpoint_path'], exist_ok=True)\n",
        "\n",
        "        for epoch in range(self.epoch_num):\n",
        "            epoch_loss = 0.0\n",
        "\n",
        "            for user, item, label in train_loader:\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(user, item)\n",
        "                loss = self.criterion(outputs, label.float())\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            val_loss = self.evaluate(self.val_data)  # Evaluate on validation set\n",
        "\n",
        "            self.logger.info(\n",
        "            f\"Epoch {epoch+1}/{self.epoch_num}, Train Loss: {epoch_loss/len(train_loader):.4f}, \"\n",
        "            f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "            # Save checkpoint if validation improves\n",
        "            if val_loss < best_val_loss:\n",
        "               best_val_loss = val_loss\n",
        "               torch.save({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": self.model.state_dict(),\n",
        "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
        "                \"val_loss\": val_loss,\n",
        "                }, ckpt_file)\n",
        "               self.logger.info(f\"Best model updated at epoch {epoch+1}, saved to {ckpt_file}\")\n",
        "\n",
        "        # At the end, reload the best weights for inference\n",
        "        checkpoint = torch.load(ckpt_file)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    def load_best_model(self):\n",
        "        if self.config['rec_model'] == 'MF':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MF_model.pth\")\n",
        "        elif self.config['rec_model'] == 'MultiVAE':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_MultiVAE_model.pth\")\n",
        "        elif self.config['rec_model'] == 'LightGCN':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_lightGCN_model.pth\")\n",
        "        elif self.config['rec_model'] == 'FM':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_FM_model.pth\")\n",
        "        elif self.config['rec_model'] == 'SASRec':\n",
        "           ckpt_file = os.path.join(self.config['checkpoint_path'], \"best_SASRec_model.pth\")\n",
        "        else:\n",
        "           raise ValueError(f\"Unknown model type: {self.config['rec_model']}\")\n",
        "\n",
        "        # Build full checkpoint file path\n",
        "        checkpoint = torch.load(ckpt_file)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.model.eval()\n",
        "        self.logger.info(f\"Loaded best model from {ckpt_file}\")\n",
        "\n",
        "    def get_rec_discription(self, final_items):\n",
        "        # items discriptions\n",
        "        sorted_item_names = self.data.get_item_names(final_items)\n",
        "        description = self.data.get_item_description_by_id(final_items)\n",
        "        eb_item = [\n",
        "            sorted_item_names[i]\n",
        "            + \";;\"\n",
        "            + description[i]\n",
        "            + \";; Genre: \"\n",
        "            + self.data.get_genres_by_id([final_items[i]])[0]\n",
        "            for i in range(len(sorted_item_names))\n",
        "        ]\n",
        "        return eb_item\n",
        "\n",
        "    def get_full_rankings(self, use_test=False, batch_size=512):\n",
        "        \"\"\"\n",
        "        Compute full rankings for all users in self.data.\n",
        "        - training items are pushed to the end\n",
        "        - optionally, ground-truth test items can be put on top\n",
        "        \"\"\"\n",
        "        if self.config['rec_model'] == 'MF':\n",
        "           n_users = self.data.get_user_num()\n",
        "           n_items = self.data.get_item_num()\n",
        "\n",
        "           item_embed = self.model.item_embedding.weight[:n_items, :]\n",
        "\n",
        "           self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "           for user in range(n_users):\n",
        "              user_tensor = torch.tensor([user])\n",
        "              user_embed = self.model.user_embedding(user_tensor)\n",
        "\n",
        "              scores = torch.matmul(user_embed, item_embed.T).squeeze(0).detach().numpy()\n",
        "\n",
        "              # Only consider valid item indices\n",
        "              train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "              scores[train_items] = -np.inf\n",
        "\n",
        "              self.full_rankings[user] = np.argsort(-scores)\n",
        "\n",
        "              # # Optionally move ground-truth test items on top\n",
        "              if use_test:\n",
        "                 test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                 for idx, item in enumerate(test_items):\n",
        "                    if item in self.full_rankings[user]:\n",
        "                       current_pos = np.where(self.full_rankings[user] == item)[0][0]\n",
        "                       self.full_rankings[user][idx], self.full_rankings[user][current_pos] = (\n",
        "                         self.full_rankings[user][current_pos],\n",
        "                         self.full_rankings[user][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'LightGCN':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            # === 1. Get all user/item embeddings from LightGCN ===\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                all_user_emb, all_item_emb = self.model.propagate()\n",
        "                # shapes: (n_users, embed_dim), (n_items, embed_dim)\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            for user in range(n_users):\n",
        "               # Get user embedding\n",
        "               user_embed = all_user_emb[user].unsqueeze(0)   # (1, embed_dim)\n",
        "\n",
        "               # Compute scores for all items (dot product)\n",
        "               scores = torch.matmul(user_embed, all_item_emb.T).squeeze(0).cpu().numpy()\n",
        "\n",
        "               # Push training items to -inf\n",
        "               train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "               scores[train_items] = -np.inf\n",
        "\n",
        "               # Sort descending\n",
        "               self.full_rankings[user] = np.argsort(-scores)\n",
        "\n",
        "               # # Optionally move ground-truth test items on top\n",
        "               if use_test:\n",
        "                  test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                  for idx, item in enumerate(test_items):\n",
        "                     if item in self.full_rankings[user]:\n",
        "                        current_pos = np.where(self.full_rankings[user] == item)[0][0]\n",
        "                        self.full_rankings[user][idx], self.full_rankings[user][current_pos] = (\n",
        "                           self.full_rankings[user][current_pos],\n",
        "                           self.full_rankings[user][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'MultiVAE':\n",
        "            # n_users = self.data.get_user_num()\n",
        "            # n_items = self.data.get_item_num()\n",
        "            if use_test:\n",
        "               matrix = self.test_matrix\n",
        "            else:\n",
        "               matrix = self.train_matrix\n",
        "\n",
        "            n_users, n_items = matrix.shape\n",
        "\n",
        "            self.model.eval()\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for start in range(0, n_users, batch_size):\n",
        "                   end = min(start + batch_size, n_users)\n",
        "\n",
        "                   # === 1. Build user input batch (interaction vectors) ===\n",
        "                   batch_users = []\n",
        "                   for u in range(start, end):\n",
        "                      row = self.train_matrix[u]  # should return (n_items,) vector\n",
        "                      batch_users.append(row)\n",
        "                   batch_users = torch.tensor(batch_users, dtype=torch.float32).to(self.model.device)\n",
        "\n",
        "                   # === 2. Forward pass through MultiVAE ===\n",
        "                   logits, mu, logvar = self.model(batch_users)   # shape: (batch_size, n_items)\n",
        "                   scores = logits.cpu().numpy()\n",
        "\n",
        "                   # === 3. Postprocess each user in batch ===\n",
        "                   for i, u in enumerate(range(start, end)):\n",
        "                      user_scores = scores[i]\n",
        "\n",
        "                      train_items = [x[1] for x in self.train_data if x[0] == u and x[1] < n_items]\n",
        "                      user_scores[train_items] = -np.inf\n",
        "\n",
        "                      # Sort items by descending score\n",
        "                      self.full_rankings[u] = np.argsort(-user_scores)\n",
        "\n",
        "                      # Optionally move ground-truth test items on top\n",
        "                      if use_test:\n",
        "                         test_items = [x[1] for x in self.test_data if x[0] == u and x[1] < n_items]\n",
        "                         for idx, item in enumerate(test_items):\n",
        "                            if item in self.full_rankings[u]:\n",
        "                               current_pos = np.where(self.full_rankings[u] == item)[0][0]\n",
        "                               self.full_rankings[u][idx], self.full_rankings[u][current_pos] = (\n",
        "                                   self.full_rankings[u][current_pos],\n",
        "                                   self.full_rankings[u][idx])\n",
        "\n",
        "        elif self.config['rec_model'] == 'FM':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "\n",
        "            self.model.eval()\n",
        "            device = next(self.model.parameters()).device\n",
        "\n",
        "            for user in range(n_users):\n",
        "               # Generate all item IDs\n",
        "               item_ids = torch.arange(n_items, device=device)\n",
        "               user_ids = torch.full((n_items,), user, dtype=torch.long, device=device)\n",
        "\n",
        "               # Compute scores using FM forward\n",
        "               with torch.no_grad():\n",
        "                  scores = self.model(user_ids, item_ids).cpu().numpy()\n",
        "\n",
        "               # Push training items to the end\n",
        "               train_items = [x[1] for x in self.train_data if x[0] == user and x[1] < n_items]\n",
        "               scores[train_items] = -np.inf\n",
        "\n",
        "               # Sort items by descending score\n",
        "               ranking = np.argsort(-scores)\n",
        "\n",
        "               # Optionally move ground-truth test items to the top\n",
        "               if use_test:\n",
        "                  test_items = [x[1] for x in self.test_data if x[0] == user and x[1] < n_items]\n",
        "                  for idx, item in enumerate(test_items):\n",
        "                     if item in ranking:\n",
        "                        current_pos = np.where(ranking == item)[0][0]\n",
        "                        ranking[idx], ranking[current_pos] = ranking[current_pos], ranking[idx]\n",
        "\n",
        "               self.full_rankings[user] = ranking\n",
        "\n",
        "        elif self.config['rec_model'] == 'SASRec':\n",
        "            n_users = self.data.get_user_num()\n",
        "            n_items = self.data.get_item_num()\n",
        "\n",
        "            self.full_rankings = np.zeros((n_users, n_items), dtype=int)\n",
        "            self.model.eval()\n",
        "            device = next(self.model.parameters()).device\n",
        "\n",
        "            with torch.no_grad():\n",
        "               for start in range(0, n_users, batch_size):\n",
        "                  end = min(start + batch_size, n_users)\n",
        "                  batch_users = list(range(start, end))\n",
        "\n",
        "                  # Build input sequences for batch\n",
        "                  batch_seqs = []\n",
        "                  for u in batch_users:\n",
        "                     # Get user interaction sequence from train_data\n",
        "                     user_items = [x[1] for x in self.train_data if x[0] == u]\n",
        "                     padded_seq = _pad_sequence(user_items, self.model.max_seq_len)\n",
        "                     batch_seqs.append(padded_seq)\n",
        "\n",
        "                  batch_seqs = torch.tensor(batch_seqs, dtype=torch.long, device=device)\n",
        "\n",
        "                  # Forward pass: get sequence embeddings\n",
        "                  seq_out = self.model(batch_seqs)  # (B, L, H)\n",
        "                  seq_out_last = seq_out[:, -1, :]  # use last position (B, H)\n",
        "\n",
        "                  # All item embeddings\n",
        "                  all_item_emb = self.model.item_embedding.weight[:n_items, :]  # (n_items, H)\n",
        "\n",
        "                  # Compute scores\n",
        "                  scores = torch.matmul(seq_out_last, all_item_emb.T)  # (B, n_items)\n",
        "                  scores = scores.cpu().numpy()\n",
        "\n",
        "                  # Mask training items\n",
        "                  for i, u in enumerate(batch_users):\n",
        "                     train_items = [x[1] for x in self.train_data if x[0] == u and x[1] < n_items]\n",
        "                     scores[i, train_items] = -np.inf  # push train items to the end\n",
        "\n",
        "                     ranking = np.argsort(-scores[i])  # full ranking by score (highest first)\n",
        "                     if use_test:\n",
        "                        test_items = [x[1] for x in self.test_data if x[0] == u and x[1] < n_items]\n",
        "                        # Keep only test items that appear in ranking\n",
        "                        test_items_in_ranking = [item for item in ranking if item in test_items]\n",
        "                        # Take at most 5 test items\n",
        "                        top_test_items = test_items_in_ranking[:5]\n",
        "                        # Remaining items (exclude the ones we forced to the top)\n",
        "                        other_items = [item for item in ranking if item not in top_test_items]\n",
        "\n",
        "                        # New ranking: top test items first, then the rest in score order\n",
        "                        ranking = np.array(top_test_items + other_items)\n",
        "                     # Store final ranking\n",
        "                     self.full_rankings[u] = ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ0LO4G1fzA6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class MovieLensDocument(AbstractDocument):\n",
        "  def __init__(self, doc_id, genre_vector, avg_rating):\n",
        "    \"\"\"Initializes a MovieLens document with genre information and average rating.\"\"\"\n",
        "    self.genre_vector = genre_vector  # A vector encoding the movie's genres\n",
        "    self.avg_rating = avg_rating  # Average rating of the movie\n",
        "    super(MovieLensDocument, self).__init__(doc_id)\n",
        "\n",
        "  def create_observation(self):\n",
        "    \"\"\"Returns observable properties of this document as a float array.\"\"\"\n",
        "    return np.concatenate([self.genre_vector, [self.avg_rating]])\n",
        "\n",
        "  @staticmethod\n",
        "  def observation_space():\n",
        "    \"\"\"Defines the observation space for MovieLens documents.\"\"\"\n",
        "    return spaces.Box(shape=(num_genres + 1,), dtype=np.float32, low=0.0, high=5.0)\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Movie {} with genres {} and avg rating {:.2f}.\".format(self._doc_id, self.genre_vector, self.avg_rating)\n",
        "\n",
        "\n",
        "class MovieLensDocumentSampler(AbstractDocumentSampler):\n",
        "    def __init__(self, recsys, total_user, page_size=5, users=None, doc_ctor=MovieLensDocument, **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the sampler for MovieLens documents.\n",
        "        Args:\n",
        "            recsys: recommendation system object with full_rankings[user_id]\n",
        "            total_user: number of users to sample from\n",
        "            page_size: number of recommendations per page\n",
        "            users: list of user IDs to iterate over (default = first N users)\n",
        "        \"\"\"\n",
        "        super(MovieLensDocumentSampler, self).__init__(doc_ctor, **kwargs)\n",
        "        self.recsys = recsys\n",
        "        self.page_size = page_size\n",
        "        self._doc_count = {}   # track per-user doc count\n",
        "        self._page_index = {}  # track per-user page index\n",
        "\n",
        "        if users is None:\n",
        "            self.users = ratings_df['user_id'].unique()[:total_user]\n",
        "        else:\n",
        "            self.users = users\n",
        "\n",
        "        # initialize tracking per user\n",
        "        for uid in self.users:\n",
        "            self._doc_count[uid] = 0\n",
        "            self._page_index[uid] = 0\n",
        "\n",
        "    def sample_document(self, user_id):\n",
        "        \"\"\"Return one document for the given user_id.\"\"\"\n",
        "        if user_id not in self.users:\n",
        "            raise ValueError(f\"User {user_id} not found in sampler users.\")\n",
        "\n",
        "        self._doc_count[user_id] += 1\n",
        "\n",
        "        # Get this user's recommendation list\n",
        "        recommended_items = self.recsys.full_rankings[user_id]\n",
        "        recommended_items_list = recommended_items.tolist() if not isinstance(recommended_items, list) else recommended_items\n",
        "\n",
        "        # Compute start & end indices for current page\n",
        "        start_idx = self._page_index[user_id] * self.page_size\n",
        "        end_idx = start_idx + self.page_size\n",
        "\n",
        "        # Pick item within this page\n",
        "        item_idx = start_idx + (self._doc_count[user_id] - 1) % self.page_size\n",
        "        if item_idx >= len(recommended_items_list):\n",
        "            # No more recommendations left  reset this user\n",
        "            self._doc_count[user_id] = 0\n",
        "            self._page_index[user_id] = 0\n",
        "            return None\n",
        "\n",
        "        item_id = recommended_items_list[item_idx]\n",
        "        # print(\"user id: \", user_id, \"item id: \", item_id)\n",
        "\n",
        "        # Get movie info\n",
        "        movie = movies_df[movies_df['item_id'] == item_id].iloc[0]\n",
        "\n",
        "        # Encode genres\n",
        "        genre_vector = np.zeros(num_genres)\n",
        "        for genre in movie['processed_genre'].split('|'):\n",
        "            if genre in genre_to_index:\n",
        "                genre_vector[genre_to_index[genre]] = 1\n",
        "\n",
        "        # Avg rating\n",
        "        avg_rating = avg_ratings.get(movie['item_id'], 0.0)\n",
        "\n",
        "        doc_features = {\n",
        "            'doc_id': movie['item_id'],\n",
        "            'genre_vector': genre_vector,\n",
        "            'avg_rating': avg_rating\n",
        "        }\n",
        "\n",
        "        # When we finish a page (doc_count == page_size), move to next page\n",
        "        if self._doc_count[user_id] % self.page_size == 0:\n",
        "            self._page_index[user_id] += 1\n",
        "\n",
        "        return self._doc_ctor(**doc_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap4StI0xfzA7"
      },
      "outputs": [],
      "source": [
        "class MovieLensUserState(AbstractUserState):\n",
        "    \"\"\"Represents a user's preference state based on MovieLens data.\"\"\"\n",
        "\n",
        "    def __init__(self, genre_preferences, rating_sensitivity, observation_noise_stddev=0.1):\n",
        "        \"\"\"\n",
        "        Initializes a user with genre preferences and rating sensitivity.\n",
        "\n",
        "        Args:\n",
        "            genre_preferences: A vector representing the user's preference for each genre.\n",
        "            rating_sensitivity: A value that influences how sensitive the user is to rating differences.\n",
        "            observation_noise_stddev: Standard deviation of observation noise.\n",
        "        \"\"\"\n",
        "        self.genre_preferences = np.array(genre_preferences)\n",
        "        self.rating_sensitivity = rating_sensitivity\n",
        "        self._observation_noise = observation_noise_stddev\n",
        "        self.satisfaction = 0.5  # Initial satisfaction level\n",
        "        self.time_budget = 10  # Simulation steps user is active\n",
        "\n",
        "    def create_observation(self):\n",
        "        \"\"\"Returns a noisy observation of user preferences.\"\"\"\n",
        "        noise = np.random.normal(0, self._observation_noise, len(self.genre_preferences))\n",
        "        noisy_preferences = self.genre_preferences + noise\n",
        "        return np.clip(noisy_preferences, 0, 1)  # Ensure values stay within [0,1]\n",
        "\n",
        "    @staticmethod\n",
        "    def observation_space():\n",
        "        \"\"\"Defines the observation space for user preferences.\"\"\"\n",
        "        return spaces.Box(shape=(num_genres,), dtype=np.float32, low=0.0, high=1.0)\n",
        "\n",
        "    def score_document(self, doc_obs):\n",
        "        \"\"\"Computes a compatibility score between the user and the movie.\n",
        "\n",
        "        Args:\n",
        "            doc_obs: A movie's genre vector.\n",
        "\n",
        "        Returns:\n",
        "            A score indicating user interest in the movie.\n",
        "        \"\"\"\n",
        "        genre_match = np.dot(self.genre_preferences, doc_obs[:-1])  # Ignore avg rating in doc_obs\n",
        "        return genre_match * self.rating_sensitivity\n",
        "\n",
        "\n",
        "class MovieLensUserSampler(AbstractUserSampler):\n",
        "    \"\"\"Samples users with different genre preferences based on the data.\"\"\"\n",
        "\n",
        "    def __init__(self, user_id, user_ctor=MovieLensUserState, user_genres=None, genre_to_index=None, seed=42):\n",
        "        super().__init__(user_ctor, seed=seed)\n",
        "        self.user_genres = user_genres\n",
        "        self.genre_to_index = genre_to_index\n",
        "        self.user_id = user_id  # Store user_id internally\n",
        "\n",
        "    def sample_user(self):\n",
        "        if self.user_id is None:\n",
        "            raise ValueError(\"User ID has not been set. Use set_user_id() before sampling.\")\n",
        "\n",
        "        user_row = self.user_genres[self.user_genres['user_id'] == self.user_id]\n",
        "        if user_row.empty:\n",
        "            raise ValueError(f\"User with user_id {self.user_id} not found in the dataset.\")\n",
        "\n",
        "        user_row = user_row.iloc[0]\n",
        "        genre_str = user_row['processed_genre']\n",
        "        genres = genre_str.split('|')\n",
        "        genre_indices = [self.genre_to_index.get(genre, -1) for genre in genres if genre in self.genre_to_index]\n",
        "        genre_preferences = np.zeros(len(self.genre_to_index))\n",
        "        genre_preferences[genre_indices] = 1\n",
        "        genre_preferences /= genre_preferences.sum()\n",
        "\n",
        "        rating_sensitivity = np.random.uniform(0.5, 2.0)\n",
        "        return self._user_ctor(genre_preferences, rating_sensitivity)\n",
        "\n",
        "\n",
        "class MovieLensResponse(AbstractResponse):\n",
        "    \"\"\"Models user responses based on their preferences.\"\"\"\n",
        "\n",
        "    def __init__(self, clicked=False, engagement=0.0, rating=0.0):\n",
        "        self.clicked = clicked\n",
        "        self.engagement = engagement\n",
        "        self.rating = rating\n",
        "\n",
        "    def create_observation(self):\n",
        "        \"\"\"Creates a response observation.\"\"\"\n",
        "        return {'click': int(self.clicked), 'engagement': self.engagement, 'rating': self.rating}\n",
        "\n",
        "    @classmethod\n",
        "    def response_space(cls):\n",
        "        \"\"\"Defines response space (click, engagement, rating).\"\"\"\n",
        "        return spaces.Dict({\n",
        "            'click': spaces.Discrete(2),\n",
        "            'engagement': spaces.Box(low=0.0, high=100.0, shape=(), dtype=np.float32),\n",
        "            'rating': spaces.Box(low=0.0, high=5.0, shape=(), dtype=np.float32)\n",
        "        })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNh0nh84fzA8"
      },
      "outputs": [],
      "source": [
        "class CustomChoiceModel(NormalizableChoiceModel):\n",
        "    \"\"\"Custom choice model to represent user behavior in a movie recommendation system.\"\"\"\n",
        "\n",
        "    def __init__(self, choice_features=None):\n",
        "        if choice_features is None:\n",
        "            choice_features = {}\n",
        "\n",
        "        self._min_score = choice_features.get('min_score', 0.0)\n",
        "        self._no_click_mass = choice_features.get('no_click_mass', -2.0)\n",
        "        self._scores = None\n",
        "        self._score_no_click = None\n",
        "\n",
        "    def score_documents(self, user_state, doc_obs_list):\n",
        "        \"\"\"Computes scores for a list of documents based on user preferences.\"\"\"\n",
        "        scores = np.array([\n",
        "            np.dot(user_state.genre_preferences, doc_obs[:-1]) + 0.3 * user_state.rating_sensitivity\n",
        "            for doc_obs in doc_obs_list\n",
        "        ])\n",
        "\n",
        "        scores = np.append(scores, self._no_click_mass)  # Add a score for no-click option\n",
        "        all_scores = self._softmax(scores)\n",
        "        self._scores = all_scores[:-1]\n",
        "        self._score_no_click = all_scores[-1]\n",
        "\n",
        "    def choose_item(self, user_state, doc_obs_list, similarity_threshold=0.1):\n",
        "\n",
        "        \"\"\"\n",
        "        Selects multiple documents based on genre similarity.\n",
        "\n",
        "        Args:\n",
        "        user_state: The user's current state, containing `genre_preferences`.\n",
        "        doc_obs_list: List of document observations, each containing `genre_vector`.\n",
        "        similarity_threshold (float, optional): Minimum similarity required to select an item.\n",
        "\n",
        "        Returns:\n",
        "        List of selected item indices (or empty list if none are selected).\n",
        "        \"\"\"\n",
        "\n",
        "        # Compute genre similarity scores\n",
        "        similarity_scores = np.array([\n",
        "            np.dot(user_state.genre_preferences, doc_obs[:-1])  # Assuming last element isn't genre-related\n",
        "            for doc_obs in doc_obs_list])\n",
        "\n",
        "        # Normalize scores to get probabilities\n",
        "        similarity_probs = similarity_scores - np.min(similarity_scores)  # Ensure non-negative\n",
        "\n",
        "\n",
        "        if np.sum(similarity_probs) > 0:\n",
        "            similarity_probs /= np.sum(similarity_probs)\n",
        "        else:\n",
        "            return []  # No valid selections\n",
        "\n",
        "        # Select items that meet the similarity threshold\n",
        "        selected_indices = [i for i, score in enumerate(similarity_probs) if score >= similarity_threshold]\n",
        "\n",
        "        return selected_indices  # Returns indices of selected movies\n",
        "\n",
        "    def _softmax(self, vector):\n",
        "        \"\"\"Numerically stable softmax function.\"\"\"\n",
        "        vector = np.array(vector)\n",
        "        exp_vector = np.exp(vector - np.max(vector))  # Subtract max to prevent overflow\n",
        "        return exp_vector / np.sum(exp_vector)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntm0NwlyfzA8"
      },
      "outputs": [],
      "source": [
        "class MovieLensUserModel(AbstractUserModel):\n",
        "    \"\"\"MovieLens-1M User Model, integrating preferences and choice models.\"\"\"\n",
        "\n",
        "    def __init__(self, user_id, slate_size, seed=0):\n",
        "        super(MovieLensUserModel, self).__init__(\n",
        "            MovieLensResponse,\n",
        "            MovieLensUserSampler(user_id= user_id, user_genres=user_genres, genre_to_index=genre_to_index, seed=int(seed)),\n",
        "            slate_size\n",
        "        )\n",
        "        np.random.seed(seed)\n",
        "        self.user_id = user_id\n",
        "        self.users_df = users_df\n",
        "        self.user_genres = user_genres\n",
        "        self.slate_size = slate_size\n",
        "        self.choice_model = CustomChoiceModel({'min_score': 0.0, 'no_click_mass': -2.0})\n",
        "        self._initialize_user_state()\n",
        "\n",
        "    def _initialize_user_state(self):\n",
        "        \"\"\"Initializes a random user from the dataset with preferences.\"\"\"\n",
        "        # self.user_data = self.data[self.data[\"user_id\"] == self.user_id]\n",
        "        # genre_preferences = np.random.rand(num_genres)  # Random preference for each genre\n",
        "\n",
        "        self.user_data = self.user_genres[self.user_genres[\"user_id\"] == self.user_id]\n",
        "        if self.user_data.empty:\n",
        "           raise ValueError(f\"User {self.user_id} not found in user_genres\")\n",
        "\n",
        "        # Extract genre preferences\n",
        "        user_row = self.user_data.iloc[0]\n",
        "        genre_str = user_row[\"processed_genre\"]\n",
        "        genres = genre_str.split('|')\n",
        "        genre_indices = [genre_to_index[g] for g in genres if g in genre_to_index]\n",
        "\n",
        "        genre_preferences = np.zeros(len(genre_to_index))\n",
        "        if genre_indices:\n",
        "           genre_preferences[genre_indices] = 1\n",
        "           genre_preferences /= genre_preferences.sum()\n",
        "        else:\n",
        "           # fallback to random vector if no valid genres found\n",
        "           genre_preferences = np.random.rand(num_genres)\n",
        "           genre_preferences /= genre_preferences.sum()\n",
        "\n",
        "        self._user_state = MovieLensUserState(\n",
        "            genre_preferences, rating_sensitivity=np.random.uniform(0.5, 2.0)\n",
        "        )\n",
        "        self._user_state.satisfaction = 0.5  # Initial satisfaction level\n",
        "        self._user_state.time_budget = 20  # Simulation steps user is active\n",
        "\n",
        "    def simulate_response(self, slate_movies):\n",
        "        \"\"\"Simulates user responses to a set of recommended movies.\"\"\"\n",
        "        responses = [MovieLensResponse(clicked=False, engagement=0.0, rating=0.0) for _ in slate_movies]\n",
        "\n",
        "        # Convert slate movies to document observations\n",
        "        movie_observations = [movie.create_observation() for movie in slate_movies]\n",
        "\n",
        "        # Score documents and select one\n",
        "        self.choice_model.score_documents(self._user_state, movie_observations)\n",
        "        selected_indices = self.choice_model.choose_item(self._user_state, movie_observations)\n",
        "\n",
        "        for selected_index in selected_indices:\n",
        "            self._generate_response(slate_movies[selected_index], responses[selected_index])\n",
        "\n",
        "        return responses\n",
        "\n",
        "\n",
        "    def _generate_response(self, movie, response):\n",
        "        \"\"\"Generates user engagement response for a selected movie.\"\"\"\n",
        "        response.clicked = True\n",
        "        engagement_loc = np.dot(movie.genre_vector, self._user_state.genre_preferences)\n",
        "        log_engagement = np.random.normal(loc=engagement_loc, scale=0.5)\n",
        "        response.engagement = np.exp(log_engagement)\n",
        "        # response.rating = (movie.avg_rating)*2 + np.random.normal(0, 0.5)  # Small noise in rating\n",
        "        # Adjust the rating generation using user preferences and sensitivity\n",
        "        base_rating = movie.avg_rating  # The movie's average rating\n",
        "\n",
        "        # Apply genre preference and rating sensitivity to modify the base rating\n",
        "        genre_influence = np.dot(movie.genre_vector, self._user_state.genre_preferences)\n",
        "        sensitivity_factor = self._user_state.rating_sensitivity\n",
        "\n",
        "        # Use a weighted sum to determine the final rating with some noise\n",
        "        rating = base_rating + genre_influence * sensitivity_factor + np.random.normal(0, 0.5)\n",
        "\n",
        "        # Ensure the rating is within a reasonable range (0 to 5 for example)\n",
        "        response.rating = np.clip(rating, 0, 5)\n",
        "\n",
        "    def update_state(self, slate_movies, responses):\n",
        "        \"\"\"Updates user state based on interaction with the recommended slate.\"\"\"\n",
        "        for movie, response in zip(slate_movies, responses):\n",
        "            if response.clicked:\n",
        "                innovation = np.random.normal(scale=0.1)\n",
        "                self._user_state.satisfaction *= 0.9  # Memory decay for satisfaction\n",
        "                self._user_state.satisfaction += innovation\n",
        "                self._user_state.time_budget -= 1  # Reduce remaining time\n",
        "\n",
        "    def is_terminal(self):\n",
        "        \"\"\"Checks if the user has exhausted their time budget.\"\"\"\n",
        "        return self._user_state.time_budget <= 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UGIxL5XYTgF"
      },
      "outputs": [],
      "source": [
        "class MovieLensMultiUserEnvironment(MultiUserEnvironment):\n",
        "    \"\"\"Multi-user environment for MovieLens user models, each with its own candidate set.\"\"\"\n",
        "\n",
        "    def __init__(self, user_models, document_sampler, num_candidates, slate_size, resample_documents=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            user_models (list): List of MovieLensUserModel instances.\n",
        "            document_sampler: AbstractDocumentSampler for movies.\n",
        "            num_candidates (int): Number of candidate docs per user.\n",
        "            slate_size (int): Slate size for recommendations.\n",
        "            resample_documents (bool): If True, resample docs each step.\n",
        "        \"\"\"\n",
        "        self._user_models = user_models\n",
        "        self._document_sampler = document_sampler\n",
        "        self._num_candidates = num_candidates\n",
        "        self._slate_size = slate_size\n",
        "        self._resample_documents = resample_documents\n",
        "\n",
        "        # Each user gets their own candidate set\n",
        "        self._candidate_sets = {user_model.user_id: CandidateSet() for user_model in user_models}\n",
        "        self._current_documents = {}\n",
        "\n",
        "    @property\n",
        "    def user_model(self):\n",
        "        return self._user_models\n",
        "\n",
        "    @property\n",
        "    def num_users(self):\n",
        "        return len(self._user_models)\n",
        "\n",
        "    def _do_resample_documents(self):\n",
        "        \"\"\"Resample candidate sets for all users.\"\"\"\n",
        "        for user_model in self._user_models:\n",
        "            candidate_set = CandidateSet()\n",
        "            docs = [\n",
        "                self._document_sampler.sample_document(user_id=user_model.user_id)\n",
        "                for _ in range(self._num_candidates)\n",
        "            ]\n",
        "            for d in docs:\n",
        "                if d is not None:\n",
        "                    candidate_set.add_document(d)\n",
        "            self._candidate_sets[user_model.user_id] = candidate_set\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset all users and their candidate sets, return initial obs.\"\"\"\n",
        "        for user_model in self._user_models:\n",
        "            user_model.reset()\n",
        "\n",
        "        # Build candidate sets\n",
        "        self._do_resample_documents()\n",
        "\n",
        "        user_obs = [user_model.create_observation() for user_model in self._user_models]\n",
        "\n",
        "        # Create document observations per user\n",
        "        self._current_documents = {\n",
        "            user_model.user_id: collections.OrderedDict(\n",
        "                self._candidate_sets[user_model.user_id].create_observation()\n",
        "            )\n",
        "            for user_model in self._user_models\n",
        "        }\n",
        "\n",
        "        return user_obs, self._current_documents\n",
        "\n",
        "    def step(self, slates):\n",
        "        \"\"\"Run one simulation step for all users.\n",
        "\n",
        "        Args:\n",
        "             slates (list of list): Each element is a slate (list of indices) for that user.\n",
        "        \"\"\"\n",
        "        assert len(slates) == self.num_users, (\n",
        "            f\"Expected {self.num_users} slates, got {len(slates)}\"\n",
        "            )\n",
        "\n",
        "        user_obs_list = []\n",
        "        current_documents_list = []\n",
        "        responses_list = []\n",
        "\n",
        "        for user_model, slate in zip(self._user_models, slates):\n",
        "            if isinstance(slate, (int, np.integer)):\n",
        "               slate = [slate]   # wrap single int into a list\n",
        "\n",
        "            doc_ids = list(self._current_documents[user_model.user_id].keys())\n",
        "            mapped_slate = [doc_ids[x] for x in slate]\n",
        "            documents = self._candidate_sets[user_model.user_id].get_documents(mapped_slate)\n",
        "            if user_model.is_terminal():\n",
        "               responses = [MovieLensResponse(clicked=False, engagement=0.0, rating=0.0) for _ in documents]\n",
        "            else:\n",
        "               responses = user_model.simulate_response(documents)\n",
        "               user_model.update_state(documents, responses)\n",
        "\n",
        "            user_obs_list.append(user_model.create_observation())\n",
        "            current_documents_list.append(documents)\n",
        "            responses_list.append(responses)\n",
        "\n",
        "        # Update sampler with all docs & responses (flattened)\n",
        "        def flatten(lst):\n",
        "            return list(itertools.chain(*lst))\n",
        "\n",
        "        self._document_sampler.update_state(\n",
        "            flatten(current_documents_list),\n",
        "            flatten(responses_list)\n",
        "        )\n",
        "\n",
        "        done = all(user_model.is_terminal() for user_model in self._user_models)\n",
        "\n",
        "        if self._resample_documents:\n",
        "           self._do_resample_documents()\n",
        "\n",
        "        # Refresh current docs per user\n",
        "        self._current_documents = {\n",
        "        user_model.user_id: collections.OrderedDict(\n",
        "            self._candidate_sets[user_model.user_id].create_observation()\n",
        "            )\n",
        "        for user_model in self._user_models\n",
        "        }\n",
        "        return user_obs_list, current_documents_list, responses_list, done\n",
        "\n",
        "        # return user_obs_list, self._current_documents, responses_list, done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw8hfTRyfzA-"
      },
      "outputs": [],
      "source": [
        "# Assuming RecSimGymEnv, MovieLensSingleUserEnvironment, and other relevant classes are already imported\n",
        "\n",
        "def total_clicks_reward(responses_list):\n",
        "    \"\"\"Compute total clicks across all users and all movies in the slate.\"\"\"\n",
        "    reward = 0\n",
        "    for user_responses in responses_list:          # iterate per-user\n",
        "        for r in user_responses:                  # iterate per-movie\n",
        "            reward += r.clicked\n",
        "    return reward\n",
        "\n",
        "def aggregate_video_cluster_metrics(responses, metrics, info=None):\n",
        "    \"\"\"Aggregates the video cluster metrics with one step responses.\"\"\"\n",
        "    del info  # Unused.\n",
        "    is_clicked = False\n",
        "    metrics['impression'] += 1\n",
        "\n",
        "    for response in responses:\n",
        "        if not response['click']:\n",
        "            continue\n",
        "        is_clicked = True\n",
        "        metrics['click'] += 1\n",
        "        metrics['quality'] += response['quality']\n",
        "        cluster_id = response['cluster_id']\n",
        "        metrics['cluster_watch_count_cluster_%d' % cluster_id] += 1\n",
        "\n",
        "    if not is_clicked:\n",
        "        metrics['cluster_watch_count_no_click'] += 1\n",
        "    return metrics\n",
        "\n",
        "def write_video_cluster_metrics(metrics, add_summary_fn):\n",
        "    \"\"\"Writes average video cluster metrics using add_summary_fn.\"\"\"\n",
        "    add_summary_fn('CTR', metrics['click'] / metrics['impression'])\n",
        "    if metrics['click'] > 0:\n",
        "        add_summary_fn('AverageQuality', metrics['quality'] / metrics['click'])\n",
        "    for k in metrics:\n",
        "        prefix = 'cluster_watch_count_cluster_'\n",
        "        if k.startswith(prefix):\n",
        "            add_summary_fn('cluster_watch_count_frac/cluster_%s' % k[len(prefix):],\n",
        "                           metrics[k] / metrics['impression'])\n",
        "    add_summary_fn(\n",
        "        'cluster_watch_count_frac/no_click',\n",
        "        metrics['cluster_watch_count_no_click'] / metrics['impression'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GlfnXOGfzA-"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class EpsilonGreedyRecommenderAgent(AbstractEpisodicRecommenderAgent):\n",
        "    \"\"\"A simple -greedy recommender agent for MovieLens recommendations.\"\"\"\n",
        "\n",
        "    def __init__(self, action_space, slate_size, epsilon=0.1, summary_writer=None):\n",
        "        \"\"\"\n",
        "        Initializes the recommender agent.\n",
        "\n",
        "        Args:\n",
        "            action_space: The available action space.\n",
        "            slate_size: Number of movies to recommend in each step.\n",
        "            epsilon: Probability of exploration.\n",
        "            summary_writer: For logging metrics (if applicable).\n",
        "        \"\"\"\n",
        "        super().__init__(action_space, summary_writer)\n",
        "        self.epsilon = epsilon\n",
        "        self.slate_size = slate_size\n",
        "        self.q_values = defaultdict(float)  # Stores Q-values for movies\n",
        "        self.action_counts = defaultdict(int)  # Tracks number of times each movie is recommended\n",
        "        self.last_action = None  # Stores last recommended slate\n",
        "        self.last_docs = None          # new: list of doc_ids corresponding to last_action\n",
        "\n",
        "        # New: track sequential selection\n",
        "        self._next_start_idx = 0\n",
        "\n",
        "\n",
        "    def step(self, reward, observation):\n",
        "        # Update Q-values first (if reward is provided)\n",
        "        if reward is not None and self.last_action is not None and self.last_docs is not None:\n",
        "            self._update_q_values(reward, self.last_action, self.last_docs)\n",
        "\n",
        "        doc_ids = list(observation[\"doc\"].keys())\n",
        "        num_candidates = len(doc_ids)\n",
        "\n",
        "        # Sequential selection of slate\n",
        "        start_idx = self._next_start_idx\n",
        "        end_idx = start_idx + self.slate_size\n",
        "        slate_indices = list(range(start_idx, min(end_idx, num_candidates)))\n",
        "\n",
        "        # Wrap around if exceeding number of candidates\n",
        "        if end_idx > num_candidates:\n",
        "            overflow = end_idx - num_candidates\n",
        "            slate_indices += list(range(0, overflow))\n",
        "\n",
        "        # Update _next_start_idx for next step\n",
        "        self._next_start_idx = (self._next_start_idx + self.slate_size) % num_candidates\n",
        "\n",
        "        # Store last action and mapping\n",
        "        self.last_action = slate_indices\n",
        "        self.last_docs = doc_ids\n",
        "\n",
        "        return slate_indices\n",
        "\n",
        "    def _update_q_values(self, reward_dict, action, last_docs):\n",
        "        \"\"\"\n",
        "        reward_dict: dict mapping doc_id -> reward\n",
        "        action: list of indices (slate)\n",
        "        last_docs: list mapping indices -> doc_id\n",
        "        \"\"\"\n",
        "        for idx in action:\n",
        "            doc_id = last_docs[idx]\n",
        "            r = reward_dict.get(doc_id, 0.0)\n",
        "            self.action_counts[doc_id] += 1\n",
        "            self.q_values[doc_id] += (r - self.q_values[doc_id]) / self.action_counts[doc_id]\n",
        "\n",
        "\n",
        "    def _select_best_slate(self, doc_obs_list):\n",
        "        \"\"\"\n",
        "        Selects movies with the highest estimated Q-values.\n",
        "\n",
        "        Args:\n",
        "            doc_obs_list: List of available document observations (movies).\n",
        "\n",
        "        Returns:\n",
        "            A list of selected movie indices.\n",
        "        \"\"\"\n",
        "        movie_ids = list(range(len(doc_obs_list)))\n",
        "\n",
        "        if len(self.q_values) < self.slate_size:\n",
        "            # If we haven't explored enough, pick randomly\n",
        "            return np.random.choice(movie_ids, self.slate_size, replace=False).tolist()\n",
        "\n",
        "        # Sort movie IDs by Q-value in descending order and pick the top ones\n",
        "        sorted_movies = sorted(movie_ids, key=lambda movie: self.q_values[movie], reverse=True)\n",
        "        return sorted_movies[:self.slate_size]\n",
        "\n",
        "    def bundle_and_checkpoint(self, checkpoint_dir, iteration_number):\n",
        "        \"\"\"\n",
        "        Saves the agent's internal state for checkpointing.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_dir: Directory to store checkpoint data.\n",
        "            iteration_number: Current training iteration.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing saved Q-values and action counts.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"q_values\": dict(self.q_values),\n",
        "            \"action_counts\": dict(self.action_counts)\n",
        "        }\n",
        "\n",
        "    def unbundle(self, checkpoint_dir, iteration_number, bundle_dict):\n",
        "        \"\"\"\n",
        "        Restores the agent's state from a checkpoint.\n",
        "\n",
        "        Args:\n",
        "            checkpoint_dir: Directory containing checkpoint data.\n",
        "            iteration_number: The iteration at which the checkpoint was saved.\n",
        "            bundle_dict: Dictionary containing saved state.\n",
        "\n",
        "        Returns:\n",
        "            Boolean indicating whether restoration was successful.\n",
        "        \"\"\"\n",
        "        if \"q_values\" in bundle_dict:\n",
        "            self.q_values = defaultdict(float, bundle_dict[\"q_values\"])\n",
        "        if \"action_counts\" in bundle_dict:\n",
        "            self.action_counts = defaultdict(int, bundle_dict[\"action_counts\"])\n",
        "        return True\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
